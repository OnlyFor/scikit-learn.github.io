Search.setIndex({"alltitles": {"(Generalized) linear models": [[220, "generalized-linear-models"]], "1-way partial dependence with different models": [[193, "way-partial-dependence-with-different-models"]], "20 newsgroups dataset": [[104, "newsgroups-dataset"]], "2D interaction plots": [[193, "d-interaction-plots"]], "3D representation": [[193, "d-representation"]], "A constant prediction baseline": [[220, "a-constant-prediction-baseline"]], "A demo of K-Means clustering on the handwritten digits data": [[93, "a-demo-of-k-means-clustering-on-the-handwritten-digits-data"]], "A demo of structured Ward hierarchical clustering on an image of coins": [[82, "a-demo-of-structured-ward-hierarchical-clustering-on-an-image-of-coins"]], "A demo of the Spectral Biclustering algorithm": [[58, "a-demo-of-the-spectral-biclustering-algorithm"]], "A demo of the Spectral Co-Clustering algorithm": [[59, "a-demo-of-the-spectral-co-clustering-algorithm"]], "A demo of the mean-shift clustering algorithm": [[98, "a-demo-of-the-mean-shift-clustering-algorithm"]], "A more flexible plotting API": [[331, "a-more-flexible-plotting-api"]], "A note on shuffling": [[420, "a-note-on-shuffling"]], "A qualitative look at the predictions": [[52, "a-qualitative-look-at-the-predictions"]], "A simple algorithmic trick: warm restarts": [[392, "a-simple-algorithmic-trick-warm-restarts"]], "A simple example shipped with scikit-learn: iris dataset": [[1031, null]], "A tutorial on statistical-learning for scientific data processing": [[1028, "a-tutorial-on-statistical-learning-for-scientific-data-processing"]], "A typical workflow for triaging issues": [[385, "a-typical-workflow-for-triaging-issues"]], "AIC and BIC criteria": [[996, "aic-and-bic-criteria"]], "API Interface": [[407, "api-interface"]], "API Reference": [[2, "api-reference"]], "API changes": [[1048, "api-changes"]], "API changes summary": [[1041, "api-changes-summary"], [1041, "id4"], [1041, "id7"], [1041, "id10"], [1042, "api-changes-summary"], [1043, "api-changes-summary"], [1044, "api-changes-summary"], [1045, "api-changes-summary"], [1046, "api-changes-summary"], [1047, "api-changes-summary"], [1047, "id6"], [1048, "api-changes-summary"]], "API compatibility checkers": [[41, "module-sklearn.utils.estimator_checks"]], "APIs of scikit-learn objects": [[388, "apis-of-scikit-learn-objects"]], "ARDRegression": [[652, "ardregression"]], "ARFF parser": [[380, "arff-parser"]], "AWeber": [[1024, "id9"]], "Ability of Gaussian process regression (GPR) to estimate data noise-level": [[182, "ability-of-gaussian-process-regression-gpr-to-estimate-data-noise-level"]], "Ablation study": [[257, "ablation-study"]], "About the project": [[398, "about-the-project"]], "About us": [[0, "about-us"]], "Access pipeline steps": [[417, "access-pipeline-steps"]], "Access to nested parameters": [[417, "access-to-nested-parameters"]], "Accuracy of the Model": [[194, "accuracy-of-the-model"]], "Accuracy score": [[1000, "accuracy-score"]], "Accuracy vs alpha for training and testing sets": [[364, "accuracy-vs-alpha-for-training-and-testing-sets"]], "AdaBoost": [[423, "adaboost"]], "AdaBoostClassifier": [[561, "adaboostclassifier"]], "AdaBoostRegressor": [[562, "adaboostregressor"]], "Add support for monotonic constraints in tree-based models": [[335, "add-support-for-monotonic-constraints-in-tree-based-models"]], "Adding connectivity constraints": [[416, "adding-connectivity-constraints"]], "Additive Chi Squared Kernel": [[992, "additive-chi-squared-kernel"]], "AdditiveChi2Sampler": [[646, "additivechi2sampler"]], "Addressing the problem with a business metric": [[272, "addressing-the-problem-with-a-business-metric"]], "Adjustment for chance in clustering performance evaluation": [[72, "adjustment-for-chance-in-clustering-performance-evaluation"]], "Advanced Plotting With Partial Dependence": [[258, "advanced-plotting-with-partial-dependence"]], "Advantages:": [[416, null], [416, null], [416, null], [416, null], [416, null], [416, null], [416, null], [416, null]], "Affinity Propagation": [[416, "affinity-propagation"]], "AffinityPropagation": [[448, "affinitypropagation"]], "Agglomerative clustering with and without structure": [[74, "agglomerative-clustering-with-and-without-structure"]], "Agglomerative clustering with different metrics": [[75, "agglomerative-clustering-with-different-metrics"]], "AgglomerativeClustering": [[449, "agglomerativeclustering"]], "Aggressive elimination of candidates": [[989, "aggressive-elimination-of-candidates"]], "Algorithms": [[1004, "algorithms"]], "Alpine Linux": [[404, "alpine-linux"]], "Alternative compilers": [[384, "alternative-compilers"]], "Alternatives to brute force parameter search": [[989, "alternatives-to-brute-force-parameter-search"]], "Ames Housing dataset": [[257, "ames-housing-dataset"]], "Amount of resource and number of candidates at each iteration": [[989, "amount-of-resource-and-number-of-candidates-at-each-iteration"]], "An example custom estimator implementing a simple classifier": [[137, "an-example-custom-estimator-implementing-a-simple-classifier"]], "An example of K-Means++ initialization": [[94, "an-example-of-k-means-initialization"]], "An example of reshaping data would be the digits dataset": [[1031, null]], "An introduction to machine learning with scikit-learn": [[1025, "an-introduction-to-machine-learning-with-scikit-learn"]], "Anaconda and Enthought Deployment Manager for all supported platforms": [[404, "anaconda-and-enthought-deployment-manager-for-all-supported-platforms"]], "Analysis": [[139, "analysis"]], "Analysis of a bag-of-words document classifier": [[360, "analysis-of-a-bag-of-words-document-classifier"]], "Analysis of the error metrics": [[152, "analysis-of-the-error-metrics"]], "Analysis of the plots": [[193, "analysis-of-the-plots"]], "Analysis of the results": [[64, "analysis-of-the-results"]], "Analyzing results with the cv_results_ attribute": [[989, "analyzing-results-with-the-cv-results-attribute"]], "Analyzing the Bike Sharing Demand dataset": [[52, "analyzing-the-bike-sharing-demand-dataset"]], "Application example: vector quantization": [[1033, null]], "Applications and examples": [[424, "applications-and-examples"]], "Approximate nearest neighbors in TSNE": [[299, "approximate-nearest-neighbors-in-tsne"]], "Arch Linux": [[404, "arch-linux"]], "Architectural / general goals": [[1020, "architectural-general-goals"]], "Array API support (experimental)": [[412, "array-api-support-experimental"]], "Artwork": [[0, "artwork"]], "Attributes": [[400, "attributes"]], "Authors": [[1041, "authors"], [1041, "id20"]], "Automatic Relevance Determination (ARD)": [[204, "automatic-relevance-determination-ard"]], "Automatic Relevance Determination - ARD": [[996, "automatic-relevance-determination-ard"]], "Automatic parameter searches": [[399, "automatic-parameter-searches"]], "Auxiliary functions that operate on arrays": [[41, "module-sklearn.utils.arrayfuncs"]], "Available Plotting Utilities": [[1038, "available-plotting-utilities"]], "Available documentation for scikit-learn": [[1037, "available-documentation-for-scikit-learn"]], "BIRCH": [[416, "birch"]], "BNP Paribas Cardif": [[1024, "id29"]], "Bagging meta-estimator": [[423, "bagging-meta-estimator"]], "BaggingClassifier": [[563, "baggingclassifier"]], "BaggingRegressor": [[564, "baggingregressor"]], "Bags of words": [[1034, "bags-of-words"]], "Balance model complexity and cross-validated score": [[277, "balance-model-complexity-and-cross-validated-score"]], "Balanced accuracy score": [[1000, "balanced-accuracy-score"]], "Ball Tree": [[1003, "ball-tree"]], "BallTree": [[852, "balltree"]], "BaseEstimator": [[430, "baseestimator"]], "BaseEstimator and mixins:": [[388, null]], "Basic kernels": [[426, "basic-kernels"]], "Basic shrinkage": [[418, "basic-shrinkage"]], "Bayesian Regression": [[996, "bayesian-regression"]], "Bayesian Ridge Regression": [[996, "bayesian-ridge-regression"]], "Bayesian regressions with polynomial feature expansion": [[199, "bayesian-regressions-with-polynomial-feature-expansion"]], "Bayesian regressors": [[25, "bayesian-regressors"]], "BayesianGaussianMixture": [[805, "bayesiangaussianmixture"]], "BayesianRidge": [[653, "bayesianridge"]], "Before a release": [[390, "before-a-release"]], "Benchmark and plot helper functions": [[49, "benchmark-and-plot-helper-functions"]], "Benchmark bulk/atomic prediction speed for various regressors": [[49, "benchmark-bulk-atomic-prediction-speed-for-various-regressors"]], "Benchmark influence": [[46, "benchmark-influence"]], "Benchmark n_features influence on prediction speed": [[49, "benchmark-n-features-influence-on-prediction-speed"]], "Benchmark throughput": [[49, "benchmark-throughput"]], "Benchmarking classifiers": [[360, "benchmarking-classifiers"]], "Bernoulli Naive Bayes": [[1002, "bernoulli-naive-bayes"]], "Bernoulli Restricted Boltzmann machines": [[1005, "bernoulli-restricted-boltzmann-machines"]], "BernoulliNB": [[847, "bernoullinb"]], "BernoulliRBM": [[868, "bernoullirbm"]], "Bestofmedia Group": [[1024, "id13"]], "BiclusterMixin": [[431, "biclustermixin"]], "Biclustering": [[56, "biclustering"], [189, "biclustering"], [382, "biclustering"], [413, "biclustering"]], "Biclustering documents with the Spectral Co-clustering algorithm": [[57, "biclustering-documents-with-the-spectral-co-clustering-algorithm"]], "Biclustering evaluation": [[413, "biclustering-evaluation"]], "Biclustering metrics": [[27, "biclustering-metrics"]], "Bike sharing dataset preprocessing": [[193, "bike-sharing-dataset-preprocessing"]], "Binarizer": [[875, "binarizer"]], "Binary Case": [[996, "binary-case"]], "Binary case": [[1000, "binary-case"]], "Binary classification": [[1000, "binary-classification"]], "Birch": [[450, "birch"]], "Birchbox": [[1024, "id12"]], "Bisecting K-Means": [[416, "bisecting-k-means"]], "Bisecting K-Means and Regular K-Means Performance Comparison": [[78, "bisecting-k-means-and-regular-k-means-performance-comparison"]], "BisectingKMeans": [[451, "bisectingkmeans"]], "BisectingKMeans: divide and cluster": [[332, "bisectingkmeans-divide-and-cluster"]], "Blind source separation using FastICA": [[126, "blind-source-separation-using-fastica"]], "Boil down your script to something as small as possible": [[391, "boil-down-your-script-to-something-as-small-as-possible"]], "Bonus: how much can you trust the selection of alpha?": [[165, "bonus-how-much-can-you-trust-the-selection-of-alpha"]], "Booking.com": [[1024, "id8"]], "Breast cancer wisconsin (diagnostic) dataset": [[383, "breast-cancer-wisconsin-diagnostic-dataset"]], "Brier score loss": [[1000, "brier-score-loss"]], "Brute Force": [[1003, "brute-force"]], "Bug Tracker": [[1023, "bug-tracker"]], "Bug fixes": [[1044, "bug-fixes"], [1044, "id1"], [1044, "id3"], [1045, "bug-fixes"], [1045, "id3"], [1046, "bug-fixes"], [1046, "id3"], [1047, "bug-fixes"], [1047, "id5"], [1048, "bug-fixes"], [1048, "id4"]], "Bug triaging and issue curation": [[385, "bug-triaging-and-issue-curation"]], "Build a pipeline": [[417, "build-a-pipeline"]], "Build dependencies": [[384, "build-dependencies"]], "Build the dataset": [[181, "build-the-dataset"]], "Building a pipeline": [[1034, "building-a-pipeline"]], "Building a specific version from a tag": [[384, "building-a-specific-version-from-a-tag"]], "Building and testing for the ARM64 platform on a x86_64 machine": [[394, "building-and-testing-for-the-arm64-platform-on-a-x86-64-machine"]], "Building from source": [[384, "building-from-source"]], "Building the documentation": [[386, "building-the-documentation"]], "Bulk versus Atomic mode": [[373, "bulk-versus-atomic-mode"]], "Bunch": [[927, "bunch"]], "CCA": [[490, "cca"]], "CCA (PLS mode B with symmetric deflation)": [[117, "cca-pls-mode-b-with-symmetric-deflation"]], "CV splitters": [[369, "cv-splitters"], [369, "id3"]], "Caching nearest neighbors": [[301, "caching-nearest-neighbors"]], "Caching transformers within a Pipeline": [[106, "caching-transformers-within-a-pipeline"]], "Caching transformers: avoid repeated computation": [[417, "caching-transformers-avoid-repeated-computation"]], "CalibratedClassifierCV": [[445, "calibratedclassifiercv"]], "Calibrating a classifier": [[414, "calibrating-a-classifier"]], "Calibration": [[60, "calibration"], [189, "calibration"]], "Calibration curves": [[62, "calibration-curves"], [64, "calibration-curves"], [414, "calibration-curves"]], "Calibration of the confidence interval": [[152, "calibration-of-the-confidence-interval"]], "CalibrationDisplay": [[446, "calibrationdisplay"]], "California Housing dataset": [[381, "california-housing-dataset"]], "Calinski-Harabasz Index": [[416, "calinski-harabasz-index"]], "Canonical (symmetric) PLS": [[117, "canonical-symmetric-pls"]], "Canonical Correlation Analysis": [[419, "canonical-correlation-analysis"]], "Cardiotocography dataset": [[257, "cardiotocography-dataset"]], "Categorical Feature Support in Gradient Boosting": [[149, "categorical-feature-support-in-gradient-boosting"]], "Categorical Features Support": [[423, "categorical-features-support"]], "Categorical Naive Bayes": [[1002, "categorical-naive-bayes"]], "CategoricalNB": [[848, "categoricalnb"]], "Centering kernel matrices": [[1010, "centering-kernel-matrices"]], "Chain of binary classifiers": [[298, "chain-of-binary-classifiers"]], "Change the default value of a parameter": [[386, "change-the-default-value-of-a-parameter"]], "Change.org": [[1024, "id14"]], "Changed displays": [[1057, "changed-displays"]], "Changed models": [[1048, "changed-models"], [1049, "changed-models"], [1049, "id9"], [1049, "id22"], [1050, "changed-models"], [1050, "id6"], [1051, "changed-models"], [1052, "changed-models"], [1052, "id3"], [1053, "changed-models"], [1054, "changed-models"], [1055, "changed-models"], [1055, "id6"], [1056, "changed-models"], [1056, "id7"], [1057, "changed-models"], [1057, "id4"], [1058, "changed-models"], [1059, "changed-models"]], "Changelog": [[1041, "changelog"], [1041, "id1"], [1041, "id3"], [1041, "id6"], [1041, "id9"], [1041, "id12"], [1041, "id14"], [1041, "id16"], [1041, "id18"], [1041, "id19"], [1042, "changelog"], [1042, "id2"], [1043, "changelog"], [1044, "changelog"], [1045, "changelog"], [1045, "id2"], [1046, "changelog"], [1046, "id2"], [1047, "changelog"], [1047, "id1"], [1047, "id3"], [1048, "changelog"], [1048, "id2"], [1049, "changelog"], [1049, "id1"], [1049, "id5"], [1049, "id10"], [1049, "id23"], [1050, "changelog"], [1050, "id1"], [1050, "id2"], [1050, "id7"], [1051, "changelog"], [1051, "id1"], [1051, "id4"], [1052, "changelog"], [1052, "id1"], [1052, "id4"], [1053, "changelog"], [1053, "id1"], [1053, "id4"], [1054, "changelog"], [1054, "id6"], [1055, "changelog"], [1055, "id1"], [1055, "id7"], [1056, "changelog"], [1056, "id1"], [1056, "id9"], [1057, "changelog"], [1057, "id1"], [1057, "id6"], [1058, "changelog"], [1058, "id2"], [1059, "changelog"], [1059, "id1"], [1060, "changelog"]], "Changes impacting all modules": [[1056, "changes-impacting-all-modules"], [1056, "id8"], [1057, "changes-impacting-all-modules"], [1057, "id5"], [1058, "changes-impacting-all-modules"]], "Changes impacting many modules": [[1058, "changes-impacting-many-modules"], [1059, "changes-impacting-many-modules"]], "Changes to estimator checks": [[1049, "changes-to-estimator-checks"], [1050, "changes-to-estimator-checks"], [1051, "changes-to-estimator-checks"]], "Checking out pull requests as remote-tracking branches": [[394, "checking-out-pull-requests-as-remote-tracking-branches"]], "Checking scikit-learn compatibility of an estimator": [[328, "checking-scikit-learn-compatibility-of-an-estimator"]], "Checking the variability of the coefficients": [[192, "checking-the-variability-of-the-coefficients"]], "Chi-squared kernel": [[998, "chi-squared-kernel"]], "Choice of solver for Kernel PCA": [[421, "choice-of-solver-for-kernel-pca"]], "Choose parameters": [[46, "choose-parameters"]], "Choosing a resource": [[989, "choosing-a-resource"]], "Choosing min_resources and the number of candidates": [[989, "choosing-min-resources-and-the-number-of-candidates"]], "Choosing the parameters of the model": [[1025, null]], "Choosing the right estimator": [[1027, "choosing-the-right-estimator"]], "Citing scikit-learn": [[0, "citing-scikit-learn"]], "Class APIs and Estimator Types": [[400, "class-apis-and-estimator-types"]], "Class Likelihood Ratios to measure classification performance": [[281, "class-likelihood-ratios-to-measure-classification-performance"]], "Class likelihood ratios": [[1000, "class-likelihood-ratios"]], "ClassNamePrefixFeaturesOutMixin": [[432, "classnameprefixfeaturesoutmixin"]], "Classical linear regressors": [[25, "classical-linear-regressors"]], "Classification": [[65, "classification"], [68, "classification"], [184, "classification"], [189, "classification"], [996, "classification"], [1003, "id4"], [1004, "classification"], [1014, "classification"], [1015, "classification"], [1016, "classification"], [1032, "classification"]], "Classification and ROC analysis": [[288, "classification-and-roc-analysis"]], "Classification criteria": [[1016, "classification-criteria"]], "Classification metrics": [[27, "classification-metrics"], [1000, "classification-metrics"]], "Classification of text documents using sparse features": [[360, "classification-of-text-documents-using-sparse-features"]], "Classification pipeline": [[104, "classification-pipeline"]], "Classification report": [[1000, "classification-report"]], "Classifier comparison": [[67, "classifier-comparison"]], "ClassifierChain": [[843, "classifierchain"], [1001, "classifierchain"]], "ClassifierMixin": [[433, "classifiermixin"]], "Classifying irises:": [[1032, null]], "Clear definition of the public API": [[1051, "clear-definition-of-the-public-api"]], "Cloning": [[388, "cloning"]], "Closing issues: a tough call": [[385, null]], "Cluster centers - MiniBatchKMeans": [[125, "cluster-centers-minibatchkmeans"]], "ClusterMixin": [[434, "clustermixin"]], "Clustering": [[71, "clustering"], [189, "clustering"], [416, "clustering"]], "Clustering evaluation summary": [[361, "clustering-evaluation-summary"]], "Clustering for dictionary learning": [[421, null]], "Clustering metrics": [[27, "module-sklearn.metrics.cluster"], [1000, "clustering-metrics"]], "Clustering performance evaluation": [[416, "clustering-performance-evaluation"]], "Clustering sparse data with k-means": [[361, "clustering-sparse-data-with-k-means"]], "Clustering text documents using k-means": [[361, "clustering-text-documents-using-k-means"]], "Clustering using affinity propagation": [[51, "clustering-using-affinity-propagation"]], "Clustering: grouping observations together": [[1033, "clustering-grouping-observations-together"]], "Code Contributors": [[1045, "code-contributors"], [1046, "code-contributors"], [1047, "code-contributors"], [1047, "id7"]], "Code Review Guidelines": [[386, "code-review-guidelines"]], "Code and Documentation Contributors": [[1048, "code-and-documentation-contributors"], [1048, "id10"], [1049, "code-and-documentation-contributors"], [1049, "id8"], [1049, "id21"], [1049, "id41"]], "Coding guidelines": [[388, "coding-guidelines"]], "Cohen\u2019s kappa": [[1000, "cohen-s-kappa"]], "Color Quantization using K-Means": [[83, "color-quantization-using-k-means"]], "Column Transformer with Heterogeneous Data Sources": [[104, "column-transformer-with-heterogeneous-data-sources"]], "Column Transformer with Mixed Types": [[105, "column-transformer-with-mixed-types"]], "ColumnTransformer": [[472, "columntransformer"]], "ColumnTransformer for heterogeneous data": [[417, "columntransformer-for-heterogeneous-data"]], "ColumnTransformer is subscriptable": [[336, "columntransformer-is-subscriptable"]], "Combine predictors using stacking": [[160, "combine-predictors-using-stacking"]], "Combining the display objects into a single plot": [[248, "combining-the-display-objects-into-a-single-plot"]], "Common Vectorizer usage": [[424, "common-vectorizer-usage"]], "Common cases: predefined values": [[1000, "common-cases-predefined-values"]], "Common estimator checks": [[412, "common-estimator-checks"]], "Common pitfalls and recommended practices": [[369, "common-pitfalls-and-recommended-practices"]], "Common pitfalls and subtleties": [[369, "common-pitfalls-and-subtleties"]], "Common pitfalls in the interpretation of coefficients of linear models": [[192, "common-pitfalls-in-the-interpretation-of-coefficients-of-linear-models"]], "Communication Team": [[0, "communication-team"]], "Compact text representation": [[249, "compact-text-representation"]], "Compare BIRCH and MiniBatchKMeans": [[77, "compare-birch-and-minibatchkmeans"]], "Compare Stochastic learning strategies for MLPClassifier": [[315, "compare-stochastic-learning-strategies-for-mlpclassifier"]], "Compare cross decomposition methods": [[117, "compare-cross-decomposition-methods"]], "Compare different approaches to setting the regularization parameter": [[111, "compare-different-approaches-to-setting-the-regularization-parameter"]], "Compare probabilities": [[63, "compare-probabilities"]], "Compare the effect of different scalers on data with outliers": [[319, "compare-the-effect-of-different-scalers-on-data-with-outliers"]], "Compare times of SVR and Kernel Ridge Regression": [[253, "compare-times-of-svr-and-kernel-ridge-regression"]], "Compare with SVMs": [[170, "compare-with-svms"]], "Comparing Linear Bayesian Regressors": [[199, "comparing-linear-bayesian-regressors"]], "Comparing Nearest Neighbors with and without Neighborhood Components Analysis": [[307, "comparing-nearest-neighbors-with-and-without-neighborhood-components-analysis"]], "Comparing QuantileRegressor and LinearRegression": [[222, "comparing-quantileregressor-and-linearregression"]], "Comparing Random Forests and Histogram Gradient Boosting models": [[145, "comparing-random-forests-and-histogram-gradient-boosting-models"]], "Comparing Target Encoder with Other Encoders": [[325, "comparing-target-encoder-with-other-encoders"]], "Comparing anomaly detection algorithms for outlier detection on toy datasets": [[247, "comparing-anomaly-detection-algorithms-for-outlier-detection-on-toy-datasets"]], "Comparing different clustering algorithms on toy datasets": [[79, "comparing-different-clustering-algorithms-on-toy-datasets"]], "Comparing different hierarchical linkage methods on toy datasets": [[97, "comparing-different-hierarchical-linkage-methods-on-toy-datasets"]], "Comparing random forests and the multi-output meta estimator": [[159, "comparing-random-forests-and-the-multi-output-meta-estimator"]], "Comparing randomized search and grid search for hyperparameter estimation": [[286, "comparing-randomized-search-and-grid-search-for-hyperparameter-estimation"]], "Comparing the results": [[197, "comparing-the-results"]], "Comparing the two Lasso implementations on Dense data": [[206, "comparing-the-two-lasso-implementations-on-dense-data"]], "Comparing the two Lasso implementations on Sparse data": [[206, "comparing-the-two-lasso-implementations-on-sparse-data"]], "Comparing two models: Bayesian approach": [[278, "comparing-two-models-bayesian-approach"]], "Comparing two models: frequentist approach": [[278, "comparing-two-models-frequentist-approach"]], "Comparing various online solvers": [[227, "comparing-various-online-solvers"]], "Comparison between grid search and successive halving": [[289, "comparison-between-grid-search-and-successive-halving"]], "Comparison of Calibration of Classifiers": [[64, "comparison-of-calibration-of-classifiers"]], "Comparison of F-test and mutual information": [[169, "comparison-of-f-test-and-mutual-information"]], "Comparison of LDA and PCA 2D projection of Iris dataset": [[133, "comparison-of-lda-and-pca-2d-projection-of-iris-dataset"]], "Comparison of LDA and QDA": [[70, "comparison-of-lda-and-qda"]], "Comparison of Manifold Learning methods": [[240, "comparison-of-manifold-learning-methods"]], "Comparison of kernel ridge and Gaussian process regression": [[176, "comparison-of-kernel-ridge-and-gaussian-process-regression"]], "Comparison of kernel ridge regression and SVR": [[253, "comparison-of-kernel-ridge-regression-and-svr"]], "Comparison of results": [[113, "comparison-of-results"]], "Comparison of the K-Means and MiniBatchKMeans clustering algorithms": [[99, "comparison-of-the-k-means-and-minibatchkmeans-clustering-algorithms"]], "Comparison with special purpose text vectorizers": [[362, "comparison-with-special-purpose-text-vectorizers"]], "Comparison with the regularization parameter of SVM": [[996, "comparison-with-the-regularization-parameter-of-svm"]], "Complement Naive Bayes": [[1002, "complement-naive-bayes"]], "ComplementNB": [[849, "complementnb"]], "Complexity": [[1003, "complexity"], [1004, "complexity"], [1014, "complexity"], [1015, "complexity"], [1016, "complexity"]], "Complexity analysis": [[280, "complexity-analysis"]], "Components and loadings": [[1033, null]], "Composite estimators and parameter spaces": [[989, "composite-estimators-and-parameter-spaces"]], "CompoundKernel": [[620, "compoundkernel"]], "Compression via vector quantization": [[88, "compression-via-vector-quantization"]], "Compressive sensing: tomography reconstruction with L1 prior (Lasso)": [[53, "compressive-sensing-tomography-reconstruction-with-l1-prior-lasso"]], "Computation methods": [[1007, "computation-methods"]], "Computation times": [[1021, "computation-times"]], "Computational Performance": [[373, "computational-performance"]], "Compute Affinity Propagation": [[73, "compute-affinity-propagation"]], "Compute DBSCAN": [[84, "compute-dbscan"]], "Compute clustering": [[82, "compute-clustering"], [102, "compute-clustering"], [102, "id1"]], "Compute clustering with KMeans": [[99, "compute-clustering-with-kmeans"]], "Compute clustering with MeanShift": [[98, "compute-clustering-with-meanshift"]], "Compute clustering with MiniBatchKMeans": [[99, "compute-clustering-with-minibatchkmeans"]], "Compute paths": [[225, "compute-paths"]], "Compute regularization path": [[213, "compute-regularization-path"]], "Compute score and computation times": [[145, "compute-score-and-computation-times"]], "Compute the likelihood on test data": [[111, "compute-the-likelihood-on-test-data"]], "Compute train and test errors": [[291, "compute-train-and-test-errors"]], "Computing Centrality scores": [[55, "computing-centrality-scores"]], "Computing Principal Singular Vector using Randomized SVD": [[55, "computing-principal-singular-vector-using-randomized-svd"]], "Computing cross-validated metrics": [[420, "computing-cross-validated-metrics"]], "Computing the Adjacency matrix": [[55, "computing-the-adjacency-matrix"]], "Computing with scikit-learn": [[372, "computing-with-scikit-learn"]], "Concatenating multiple feature extraction methods": [[108, "concatenating-multiple-feature-extraction-methods"]], "Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture": [[263, "concentration-prior-type-analysis-of-variation-bayesian-gaussian-mixture"]], "Concluding remarks": [[43, "concluding-remarks"], [244, "concluding-remarks"]], "Conclusion": [[46, "conclusion"], [52, "conclusion"], [209, "conclusion"], [296, "conclusion"], [302, "conclusion"], [326, "conclusion"], [353, "conclusion"]], "Conclusions": [[204, "conclusions"]], "Configuration switches": [[374, "configuration-switches"]], "Configuring Scikit-learn for reduced validation overhead": [[373, "configuring-scikit-learn-for-reduced-validation-overhead"]], "Confusion matrix": [[271, "confusion-matrix"], [1000, "confusion-matrix"]], "ConfusionMatrixDisplay": [[705, "confusionmatrixdisplay"]], "Connectivity graph of an image": [[424, "connectivity-graph-of-an-image"]], "Connectivity-constrained clustering": [[1033, "connectivity-constrained-clustering"]], "Consideration regarding model refitting and cross-validation": [[272, "consideration-regarding-model-refitting-and-cross-validation"]], "ConstantKernel": [[621, "constantkernel"]], "Construct the kernel-based regression models": [[253, "construct-the-kernel-based-regression-models"]], "Consuming Estimator": [[254, "consuming-estimator"]], "Consuming and routing Meta-Estimator": [[254, "consuming-and-routing-meta-estimator"]], "Contingency Matrix": [[416, "contingency-matrix"]], "Continuous Integration (CI)": [[386, "continuous-integration-ci"]], "Contributing": [[386, "contributing"], [398, "contributing"]], "Contributing code": [[386, "contributing-code"]], "Contributor Experience Team": [[0, "contributor-experience-team"]], "Contributors": [[401, "contributors"]], "Controlling randomness": [[369, "controlling-randomness"]], "Controlling the tree size": [[423, "controlling-the-tree-size"]], "Conventions": [[1025, "conventions"]], "Convergence of the AdaBoostClassifier": [[139, "convergence-of-the-adaboostclassifier"]], "ConvergenceWarning": [[579, "convergencewarning"]], "Core Contributors": [[401, "core-contributors"]], "Cosine similarity": [[998, "cosine-similarity"]], "Cost-sensitive learning when gains and costs are not constant": [[272, "cost-sensitive-learning-when-gains-and-costs-are-not-constant"]], "Cost-sensitive learning with constant gains and costs": [[272, "cost-sensitive-learning-with-constant-gains-and-costs"]], "CountVectorizer": [[596, "countvectorizer"]], "Covariance estimation": [[110, "covariance-estimation"], [189, "covariance-estimation"], [418, "covariance-estimation"]], "Coverage error": [[1000, "coverage-error"]], "Crafting a minimal reproducer for scikit-learn": [[391, "crafting-a-minimal-reproducer-for-scikit-learn"]], "Create ConfusionMatrixDisplay": [[248, "create-confusionmatrixdisplay"]], "Create PrecisionRecallDisplay": [[248, "create-precisionrecalldisplay"]], "Create RocCurveDisplay": [[248, "create-roccurvedisplay"]], "Create Synthetic Dataset": [[326, "create-synthetic-dataset"]], "Create multi-label data, fit, and predict": [[285, "create-multi-label-data-fit-and-predict"]], "Create the data": [[132, "create-the-data"]], "Create the pipeline": [[352, "create-the-pipeline"]], "Creating a dataset": [[353, "creating-a-dataset"]], "Creating a non-noisy data set": [[224, "creating-a-non-noisy-data-set"]], "Creating the dataset": [[139, "creating-the-dataset"]], "Creating transformers": [[104, "creating-transformers"]], "Cross decomposition": [[116, "cross-decomposition"], [189, "cross-decomposition"], [419, "cross-decomposition"]], "Cross validation and model selection": [[420, "cross-validation-and-model-selection"]], "Cross validation iterators": [[420, "cross-validation-iterators"]], "Cross validation of time series data": [[420, "cross-validation-of-time-series-data"]], "Cross-validated estimators": [[1029, "cross-validated-estimators"]], "Cross-validation generators": [[1029, "cross-validation-generators"]], "Cross-validation iterators for grouped data": [[420, "cross-validation-iterators-for-grouped-data"]], "Cross-validation iterators for i.i.d. data": [[420, "cross-validation-iterators-for-i-i-d-data"]], "Cross-validation iterators with stratification based on class labels": [[420, "cross-validation-iterators-with-stratification-based-on-class-labels"]], "Cross-validation of likelihood ratios": [[281, "cross-validation-of-likelihood-ratios"]], "Cross-validation on diabetes Dataset Exercise": [[165, "cross-validation-on-diabetes-dataset-exercise"]], "Cross-validation: evaluating estimator performance": [[420, "cross-validation-evaluating-estimator-performance"]], "Curve Fitting with Bayesian Ridge Regression": [[200, "curve-fitting-with-bayesian-ridge-regression"]], "Custom Kernels": [[1015, "custom-kernels"]], "Custom imputation strategies for the SimpleImputer": [[336, "custom-imputation-strategies-for-the-simpleimputer"]], "Custom refit strategy of a grid search with cross-validation": [[276, "custom-refit-strategy-of-a-grid-search-with-cross-validation"]], "Custom transformers": [[1010, "custom-transformers"]], "Customizing the vectorizer classes": [[424, "customizing-the-vectorizer-classes"]], "Cython Best Practices, Conventions and Knowledge": [[387, "cython-best-practices-conventions-and-knowledge"]], "DBSCAN": [[416, "dbscan"], [452, "dbscan"]], "DO NOT report your data unless it is extremely necessary": [[391, "do-not-report-your-data-unless-it-is-extremely-necessary"]], "Data": [[63, "data"]], "Data Considerations": [[381, null]], "Data Loading and Feature Engineering": [[194, "data-loading-and-feature-engineering"]], "Data Preparation": [[150, "data-preparation"]], "Data Publica": [[1024, "id21"]], "Data and sample properties": [[400, "data-and-sample-properties"]], "Data exploration on the Bike Sharing Demand dataset": [[43, "data-exploration-on-the-bike-sharing-demand-dataset"]], "Data generation": [[70, "data-generation"], [84, "data-generation"], [92, "data-generation"], [156, "data-generation"], [173, "data-generation"], [182, "data-generation"], [268, "data-generation"], [338, "data-generation"], [356, "data-generation"]], "Data generation and model fitting": [[146, "data-generation-and-model-fitting"]], "Data leakage": [[369, "data-leakage"]], "Data leakage during pre-processing": [[369, "data-leakage-during-pre-processing"]], "Data loading": [[279, "data-loading"]], "Data preprocessing": [[153, "data-preprocessing"]], "DataConversionWarning": [[580, "dataconversionwarning"]], "DataDimensionalityWarning": [[581, "datadimensionalitywarning"]], "DataFrame Support": [[1058, "dataframe-support"]], "DataRobot": [[1024, "id18"]], "Dataiku": [[1024, "id25"]], "Dataset": [[62, "dataset"], [64, "dataset"], [209, "dataset"], [284, "dataset"]], "Dataset Versions": [[380, "dataset-versions"]], "Dataset and Gaussian process generation": [[185, "dataset-and-gaussian-process-generation"]], "Dataset and model": [[285, "dataset-and-model"]], "Dataset based latent variables model": [[117, "dataset-based-latent-variables-model"]], "Dataset examples": [[119, "dataset-examples"], [189, "dataset-examples"]], "Dataset generation": [[183, "dataset-generation"], [222, "dataset-generation"]], "Dataset loading utilities": [[379, "dataset-loading-utilities"], [391, "dataset-loading-utilities"]], "Dataset preparation": [[125, "dataset-preparation"], [240, "dataset-preparation"]], "Dataset preprocessing and model training": [[257, "dataset-preprocessing-and-model-training"]], "Dataset transformations": [[378, "dataset-transformations"]], "Datasets": [[1031, "datasets"]], "Datasets in svmlight / libsvm format": [[380, "datasets-in-svmlight-libsvm-format"]], "Davies-Bouldin Index": [[416, "davies-bouldin-index"]], "Dealing with multiclass target in classifiers": [[41, "module-sklearn.utils.multiclass"]], "Debian/Ubuntu": [[404, "debian-ubuntu"]], "Debugging memory errors in Cython with valgrind": [[394, "debugging-memory-errors-in-cython-with-valgrind"]], "Decision Making Process": [[401, "decision-making-process"]], "Decision Surfaces of RBF Kernel SVM and Linear SVM": [[252, "decision-surfaces-of-rbf-kernel-svm-and-linear-svm"]], "Decision Tree Regression": [[366, "decision-tree-regression"]], "Decision Tree Regression with AdaBoost": [[140, "decision-tree-regression-with-adaboost"]], "Decision Trees": [[189, "decision-trees"], [363, "decision-trees"], [1016, "decision-trees"]], "Decision boundary": [[302, "decision-boundary"]], "Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset": [[343, "decision-boundary-of-semi-supervised-classifiers-versus-svm-on-the-iris-dataset"]], "Decision path": [[368, "decision-path"]], "DecisionBoundaryDisplay": [[639, "decisionboundarydisplay"]], "DecisionTreeClassifier": [[920, "decisiontreeclassifier"]], "DecisionTreeRegressor": [[921, "decisiontreeregressor"]], "Decoding text files": [[424, "decoding-text-files"]], "Decomposing signals in components (matrix factorization problems)": [[421, "decomposing-signals-in-components-matrix-factorization-problems"]], "Decomposition": [[124, "decomposition"], [125, "decomposition"], [189, "decomposition"]], "Decomposition: Dictionary learning": [[125, "decomposition-dictionary-learning"]], "Decompositions: from a signal to components and loadings": [[1033, "decompositions-from-a-signal-to-components-and-loadings"]], "Define a function to visualize cross-validation behavior": [[273, "define-a-function-to-visualize-cross-validation-behavior"]], "Define algorithms for the manifold learning": [[240, "define-algorithms-for-the-manifold-learning"]], "Define our evaluation benchmark": [[93, "define-our-evaluation-benchmark"]], "Define our grid-search strategy": [[276, "define-our-grid-search-strategy"]], "Define preprocessing functions": [[362, "define-preprocessing-functions"]], "Define structure of the data": [[82, "define-structure-of-the-data"]], "Define the classifiers": [[275, "define-the-classifiers"]], "Defining the list of metrics to evaluate": [[72, "defining-the-list-of-metrics-to-evaluate"]], "Defining your scoring strategy from metric functions": [[1000, "defining-your-scoring-strategy-from-metric-functions"]], "Demo of DBSCAN clustering algorithm": [[84, "demo-of-dbscan-clustering-algorithm"]], "Demo of HDBSCAN clustering algorithm": [[90, "demo-of-hdbscan-clustering-algorithm"]], "Demo of OPTICS clustering algorithm": [[100, "demo-of-optics-clustering-algorithm"]], "Demo of affinity propagation clustering algorithm": [[73, "demo-of-affinity-propagation-clustering-algorithm"]], "Demonstrating the different strategies of KBinsDiscretizer": [[322, "demonstrating-the-different-strategies-of-kbinsdiscretizer"]], "Demonstration of k-means assumptions": [[92, "demonstration-of-k-means-assumptions"]], "Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV": [[282, "demonstration-of-multi-metric-evaluation-on-cross-val-score-and-gridsearchcv"]], "Density Estimation": [[422, "density-estimation"]], "Density Estimation for a Gaussian mixture": [[267, "density-estimation-for-a-gaussian-mixture"]], "Density Estimation: Histograms": [[422, "density-estimation-histograms"]], "Density estimation, novelty detection": [[1015, "density-estimation-novelty-detection"]], "DensityMixin": [[435, "densitymixin"]], "Dependencies": [[384, "dependencies"]], "Deprecation": [[386, "deprecation"]], "Deprecation / Default Value Change": [[254, "deprecation-default-value-change"]], "Deprecations: using FutureWarning from now on": [[1051, "deprecations-using-futurewarning-from-now-on"]], "Description of the simulated data": [[191, "description-of-the-simulated-data"]], "Design the proper kernel": [[181, "design-the-proper-kernel"]], "DetCurveDisplay": [[706, "detcurvedisplay"]], "Detection error tradeoff (DET)": [[1000, "detection-error-tradeoff-det"]], "Detection error tradeoff (DET) curve": [[275, "detection-error-tradeoff-det-curve"]], "Developer API for HTML representation": [[388, "developer-api-for-html-representation"]], "Developer API for check_is_fitted": [[388, "developer-api-for-check-is-fitted"]], "Developer API for set_output": [[388, "developer-api-for-set-output"]], "Developers\u2019 Tips and Tricks": [[394, "developers-tips-and-tricks"]], "Developer\u2019s Guide": [[389, "developer-s-guide"]], "Developing Estimators": [[136, "developing-estimators"], [189, "developing-estimators"]], "Developing scikit-learn estimators": [[388, "developing-scikit-learn-estimators"]], "Developing with the Plotting API": [[393, "developing-with-the-plotting-api"]], "Diabetes dataset": [[383, "diabetes-dataset"], [1032, null]], "DictVectorizer": [[362, "dictvectorizer"], [589, "dictvectorizer"]], "Dictionary Learning": [[421, "dictionary-learning"]], "Dictionary learning": [[125, "dictionary-learning"]], "Dictionary learning - positive code": [[125, "dictionary-learning-positive-code"]], "Dictionary learning - positive dictionary": [[125, "dictionary-learning-positive-dictionary"]], "Dictionary learning - positive dictionary & code": [[125, "dictionary-learning-positive-dictionary-code"]], "DictionaryLearning": [[539, "dictionarylearning"]], "Differences between solvers": [[996, "differences-between-solvers"]], "Different algorithms for the same problem": [[1032, null]], "Different label assignment strategies": [[416, "different-label-assignment-strategies"]], "Different linkage type: Ward, complete, average, and single linkage": [[416, "different-linkage-type-ward-complete-average-and-single-linkage"]], "Different objects": [[388, "different-objects"]], "Different scenario and useful concepts": [[996, "different-scenario-and-useful-concepts"]], "Different scoring and fitting weights": [[407, "different-scoring-and-fitting-weights"]], "Digits Classification Exercise": [[166, "digits-classification-exercise"]], "Digits dataset": [[68, "digits-dataset"]], "Dimensionality Reduction with Neighborhood Components Analysis": [[308, "dimensionality-reduction-with-neighborhood-components-analysis"]], "Dimensionality reduction": [[1003, "dimensionality-reduction"]], "Dimensionality reduction using Linear Discriminant Analysis": [[994, "dimensionality-reduction-using-linear-discriminant-analysis"]], "Discovering scikit-learn objects": [[41, "module-sklearn.utils.discovery"]], "Discretization": [[1010, "discretization"]], "Dispatching": [[396, "dispatching"]], "Display Objects": [[1038, "display-objects"]], "Display code coverage in pull requests": [[394, "display-code-coverage-in-pull-requests"]], "Display results": [[225, "display-results"]], "Display the distorted image": [[128, "display-the-distorted-image"]], "Displaying Pipelines": [[259, "displaying-pipelines"]], "Displaying a Complex Pipeline Chaining a Column Transformer": [[259, "displaying-a-complex-pipeline-chaining-a-column-transformer"]], "Displaying a Grid Search over a Pipeline with a Classifier": [[259, "displaying-a-grid-search-over-a-pipeline-with-a-classifier"]], "Displaying a Pipeline Chaining Multiple Preprocessing Steps & Classifier": [[259, "displaying-a-pipeline-chaining-multiple-preprocessing-steps-classifier"]], "Displaying a Pipeline and Dimensionality Reduction and Classifier": [[259, "displaying-a-pipeline-and-dimensionality-reduction-and-classifier"]], "Displaying a Pipeline with a Preprocessing Step and Classifier": [[259, "displaying-a-pipeline-with-a-preprocessing-step-and-classifier"]], "Displaying estimators and complex pipelines": [[249, "displaying-estimators-and-complex-pipelines"]], "Distance metrics": [[27, "distance-metrics"]], "DistanceMetric": [[707, "distancemetric"]], "Do you plan to implement transform for target y in a pipeline?": [[398, "do-you-plan-to-implement-transform-for-target-y-in-a-pipeline"]], "Do you support PyPy?": [[398, "do-you-support-pypy"]], "Documentation": [[386, "documentation"], [1041, "documentation"]], "Documentation Resources": [[1023, "documentation-resources"]], "Documentation Team": [[0, "documentation-team"]], "Documentation improvements": [[1044, "documentation-improvements"], [1045, "documentation-improvements"]], "Domain specific packages": [[1019, "domain-specific-packages"]], "Donating to the project": [[0, "donating-to-the-project"]], "Dot-Product kernel": [[426, "dot-product-kernel"]], "Dot-product kernel": [[185, "dot-product-kernel"]], "DotProduct": [[622, "dotproduct"]], "Download data, if not already on disk": [[55, "download-data-if-not-already-on-disk"]], "Download the data and make missing values sets": [[188, "download-the-data-and-make-missing-values-sets"]], "Download the dataset": [[160, "download-the-dataset"]], "Downloading datasets from the openml.org repository": [[380, "downloading-datasets-from-the-openml-org-repository"]], "Drawbacks:": [[416, null], [416, null], [416, null], [416, null], [416, null], [416, null], [416, null], [416, null]], "Dropping official support for PyPy": [[1060, "dropping-official-support-for-pypy"]], "Dummy estimators": [[1000, "dummy-estimators"]], "DummyClassifier": [[559, "dummyclassifier"]], "DummyRegressor": [[560, "dummyregressor"]], "D\u00b2 score": [[1000, "d2-score"]], "D\u00b2 score for classification": [[1000, "d2-score-for-classification"]], "Earlier versions": [[1041, "earlier-versions"]], "Early stopping in Gradient Boosting": [[150, "early-stopping-in-gradient-boosting"]], "Early stopping of Stochastic Gradient Descent": [[228, "early-stopping-of-stochastic-gradient-descent"]], "Effect of number of trees and early stopping": [[155, "effect-of-number-of-trees-and-early-stopping"]], "Effect of rescaling on a PCA dimensional reduction": [[324, "effect-of-rescaling-on-a-pca-dimensional-reduction"]], "Effect of rescaling on a k-neighbors models": [[324, "effect-of-rescaling-on-a-k-neighbors-models"]], "Effect of rescaling on model\u2019s performance": [[324, "effect-of-rescaling-on-model-s-performance"]], "Effect of transforming the targets in regression model": [[109, "effect-of-transforming-the-targets-in-regression-model"]], "Effect of varying threshold for self-training": [[341, "effect-of-varying-threshold-for-self-training"]], "EfficiencyWarning": [[582, "efficiencywarning"]], "Efficient Linear Algebra & Array Operations": [[395, "efficient-linear-algebra-array-operations"]], "Efficient Random Sampling": [[395, "efficient-random-sampling"]], "Efficient Routines for Sparse Matrices": [[395, "efficient-routines-for-sparse-matrices"]], "Eigenfaces - PCA using randomized SVD": [[125, "eigenfaces-pca-using-randomized-svd"]], "Elastic-Net": [[996, "elastic-net"]], "ElasticNet": [[204, "elasticnet"], [654, "elasticnet"]], "ElasticNetCV": [[655, "elasticnetcv"]], "EllipticEnvelope": [[477, "ellipticenvelope"]], "Embedding in 2D space": [[51, "embedding-in-2d-space"]], "Embedding techniques comparison": [[241, "embedding-techniques-comparison"]], "Emeritus Communication Team": [[0, "emeritus-communication-team"]], "Emeritus Contributor Experience Team": [[0, "emeritus-contributor-experience-team"]], "Emeritus Core Developers": [[0, "emeritus-core-developers"]], "Empirical covariance": [[418, "empirical-covariance"]], "Empirical evaluation of the impact of k-means initialization": [[96, "empirical-evaluation-of-the-impact-of-k-means-initialization"]], "Empirical validation": [[251, "empirical-validation"]], "EmpiricalCovariance": [[478, "empiricalcovariance"]], "Encoding categorical features": [[1010, "encoding-categorical-features"]], "Encoding strategy": [[88, "encoding-strategy"]], "Enforcing keyword-only arguments": [[1052, "enforcing-keyword-only-arguments"], [1054, "enforcing-keyword-only-arguments"]], "Enhancement proposals (SLEPs)": [[401, "enhancement-proposals-sleps"]], "Enhancements": [[1044, "enhancements"], [1045, "enhancements"], [1046, "enhancements"], [1047, "enhancements"], [1047, "id4"], [1048, "enhancements"], [1048, "id3"]], "Enriched estimator displays": [[335, "enriched-estimator-displays"]], "Ensemble methods": [[138, "ensemble-methods"], [189, "ensemble-methods"]], "Ensembles: Gradient boosting, random forests, bagging, voting, stacking": [[423, "ensembles-gradient-boosting-random-forests-bagging-voting-stacking"]], "Environment variables": [[374, "environment-variables"]], "Error Calculation": [[150, "error-calculation"]], "Error caused by file path length limit on Windows": [[404, "error-caused-by-file-path-length-limit-on-windows"]], "Errors and weights of the Weak Learners": [[139, "errors-and-weights-of-the-weak-learners"]], "Establishing a baseline model": [[197, "establishing-a-baseline-model"]], "Establishing parity between clusters": [[99, "establishing-parity-between-clusters"]], "Establishing the kernel approximation model": [[197, "establishing-the-kernel-approximation-model"]], "Establishing the kernelized SVM model": [[197, "establishing-the-kernelized-svm-model"]], "Estimate the covariance": [[115, "estimate-the-covariance"]], "Estimate the score": [[188, "estimate-the-score"]], "Estimated Attributes": [[388, "estimated-attributes"]], "Estimation algorithms": [[994, "estimation-algorithms"]], "Estimator Tags": [[388, "estimator-tags"]], "Estimator types": [[388, "estimator-types"]], "Estimators": [[369, "estimators"], [369, "id2"], [388, "estimators"], [412, "estimators"]], "Estimators objects": [[1031, "estimators-objects"]], "Estimators that handle NaN values": [[990, "estimators-that-handle-nan-values"]], "Evaluation": [[114, "evaluation"], [317, "evaluation"]], "Evaluation metrics": [[272, "evaluation-metrics"]], "Evaluation of outlier detection estimators": [[257, "evaluation-of-outlier-detection-estimators"]], "Evaluation of the calibration of predictions": [[220, "evaluation-of-the-calibration-of-predictions"]], "Evaluation of the performance on the test set": [[1034, "evaluation-of-the-performance-on-the-test-set"]], "Evaluation of the ranking power": [[220, "evaluation-of-the-ranking-power"]], "Evernote": [[1024, "id6"]], "Exact Kernel PCA": [[421, "exact-kernel-pca"]], "Exact PCA and probabilistic interpretation": [[421, "exact-pca-and-probabilistic-interpretation"]], "Example usage": [[412, "example-usage"]], "Example with noise-free target": [[183, "example-with-noise-free-target"]], "Example with noisy targets": [[183, "example-with-noisy-targets"]], "Examples": [[189, "examples"], [375, "examples"], [415, "examples"], [1041, "examples"]], "Examples based on real world datasets": [[42, "examples-based-on-real-world-datasets"], [189, "examples-based-on-real-world-datasets"]], "Exercise": [[1029, null], [1029, null], [1032, null], [1032, null]], "Exercise 1: Language identification": [[1034, "exercise-1-language-identification"]], "Exercise 2: Sentiment Analysis on movie reviews": [[1034, "exercise-2-sentiment-analysis-on-movie-reviews"]], "Exercise 3: CLI text classification utility": [[1034, "exercise-3-cli-text-classification-utility"]], "Exercises": [[1034, "exercises"]], "Exhausting the available resources": [[989, "exhausting-the-available-resources"]], "Exhaustive Grid Search": [[989, "exhaustive-grid-search"]], "Exp-Sine-Squared kernel": [[185, "exp-sine-squared-kernel"], [426, "exp-sine-squared-kernel"]], "ExpSineSquared": [[623, "expsinesquared"]], "Experimental / Under Development": [[1057, "experimental-under-development"]], "Experimental Array API support in LinearDiscriminantAnalysis": [[333, "experimental-array-api-support-in-lineardiscriminantanalysis"]], "Experimental features": [[390, "experimental-features"]], "Explained variance score": [[1000, "explained-variance-score"]], "Explicit feature map approximation for RBF kernels": [[252, "explicit-feature-map-approximation-for-rbf-kernels"]], "Exponentiation": [[624, "exponentiation"]], "Exporting": [[40, "exporting"]], "External Resources, Videos and Talks": [[1018, "external-resources-videos-and-talks"]], "External Tutorials": [[1018, "external-tutorials"]], "External dependencies": [[1041, "external-dependencies"]], "ExtraTreeClassifier": [[922, "extratreeclassifier"]], "ExtraTreeRegressor": [[923, "extratreeregressor"]], "ExtraTreesClassifier": [[565, "extratreesclassifier"]], "ExtraTreesRegressor": [[566, "extratreesregressor"]], "Extract noisy patches and reconstruct them using the dictionary": [[128, "extract-noisy-patches-and-reconstruct-them-using-the-dictionary"]], "Extract reference patches": [[128, "extract-reference-patches"]], "Extracting features": [[375, "extracting-features"]], "Extracting features from text files": [[1034, "extracting-features-from-text-files"]], "Extremely Randomized Trees": [[423, "extremely-randomized-trees"]], "Face completion with a multi-output estimators": [[256, "face-completion-with-a-multi-output-estimators"]], "Face recognition with eigenfaces": [[1030, "face-recognition-with-eigenfaces"]], "Faces dataset decompositions": [[125, "faces-dataset-decompositions"]], "Faces recognition example using eigenfaces and SVMs": [[45, "faces-recognition-example-using-eigenfaces-and-svms"]], "Factor Analysis": [[421, "factor-analysis"]], "Factor Analysis (with rotation) to visualize patterns": [[135, "factor-analysis-with-rotation-to-visualize-patterns"]], "Factor Analysis components - FA": [[125, "factor-analysis-components-fa"]], "FactorAnalysis": [[540, "factoranalysis"]], "Failure of Machine Learning to infer causal effects": [[191, "failure-of-machine-learning-to-infer-causal-effects"]], "FastICA": [[541, "fastica"]], "FastICA on 2D point clouds": [[127, "fastica-on-2d-point-clouds"]], "Faster parser in fetch_openml": [[333, "faster-parser-in-fetch-openml"]], "Feature Extraction Latency": [[373, "feature-extraction-latency"]], "Feature Extraction using TfidfVectorizer": [[361, "feature-extraction-using-tfidfvectorizer"]], "Feature Names Support": [[331, "feature-names-support"]], "Feature Selection": [[168, "feature-selection"], [189, "feature-selection"]], "Feature agglomeration": [[86, "feature-agglomeration"], [1017, "feature-agglomeration"], [1033, "feature-agglomeration"]], "Feature agglomeration vs. univariate selection": [[89, "feature-agglomeration-vs-univariate-selection"]], "Feature binarization": [[1010, "feature-binarization"]], "Feature discretization": [[321, "feature-discretization"]], "Feature extraction": [[424, "feature-extraction"]], "Feature hashing": [[424, "feature-hashing"]], "Feature importance based on feature permutation": [[146, "feature-importance-based-on-feature-permutation"]], "Feature importance based on mean decrease in impurity": [[146, "feature-importance-based-on-mean-decrease-in-impurity"]], "Feature importance based on mean decrease in impurity (MDI)": [[147, "feature-importance-based-on-mean-decrease-in-impurity-mdi"]], "Feature importance evaluation": [[423, "feature-importance-evaluation"]], "Feature importance from coefficients": [[174, "feature-importance-from-coefficients"]], "Feature importances with a forest of trees": [[146, "feature-importances-with-a-forest-of-trees"]], "Feature normalization": [[197, "feature-normalization"]], "Feature scaling": [[1017, null]], "Feature selection": [[425, "feature-selection"]], "Feature selection as part of a pipeline": [[425, "feature-selection-as-part-of-a-pipeline"]], "Feature selection using SelectFromModel": [[425, "feature-selection-using-selectfrommodel"]], "Feature selection with sparse data": [[425, null]], "Feature transformations with ensembles of trees": [[144, "feature-transformations-with-ensembles-of-trees"]], "FeatureAgglomeration": [[416, null], [453, "featureagglomeration"]], "FeatureHasher": [[362, "featurehasher"], [590, "featurehasher"]], "FeatureHasher and DictVectorizer Comparison": [[362, "featurehasher-and-dictvectorizer-comparison"]], "FeatureUnion": [[871, "featureunion"]], "FeatureUnion: composite feature spaces": [[417, "featureunion-composite-feature-spaces"]], "Features in Histogram Gradient Boosting Trees": [[155, "features-in-histogram-gradient-boosting-trees"]], "Fedora": [[404, "fedora"]], "Final conclusion": [[176, "final-conclusion"]], "Final remarks": [[92, "final-remarks"]], "Finding the Nearest Neighbors": [[1003, "finding-the-nearest-neighbors"]], "First example": [[48, "first-example"]], "First experiment: fixed ground truth labels and growing number of clusters": [[72, "first-experiment-fixed-ground-truth-labels-and-growing-number-of-clusters"]], "Fit ICA and PCA models": [[126, "fit-ica-and-pca-models"]], "Fit by cubic polynomial": [[200, "fit-by-cubic-polynomial"]], "Fit models": [[214, "fit-models"], [298, "fit-models"]], "Fit models and plot results": [[92, "fit-models-and-plot-results"]], "Fit regression model": [[153, "fit-regression-model"], [311, "fit-regression-model"], [355, "fit-regression-model"]], "Fit the model for outlier detection (default)": [[306, "fit-the-model-for-outlier-detection-default"]], "Fit the models": [[132, "fit-the-models"]], "Fit the regressors": [[199, "fit-the-regressors"], [199, "id2"]], "FitFailedWarning": [[583, "fitfailedwarning"]], "Fitting": [[388, "fitting"]], "Fitting SpectralBiclustering": [[58, "fitting-spectralbiclustering"]], "Fitting a QuantileRegressor": [[222, "fitting-a-quantileregressor"]], "Fitting additional trees": [[423, "fitting-additional-trees"]], "Fitting additional weak-learners": [[423, "fitting-additional-weak-learners"]], "Fitting an Elastic Net with a precomputed Gram Matrix and Weighted Samples": [[201, "fitting-an-elastic-net-with-a-precomputed-gram-matrix-and-weighted-samples"]], "Fitting an elliptic envelope": [[1006, "fitting-an-elliptic-envelope"]], "Fitting and calibration": [[63, "fitting-and-calibration"]], "Fitting and predicting: estimator basics": [[399, "fitting-and-predicting-estimator-basics"]], "Fitting non-linear quantile and least squares regressors": [[152, "fitting-non-linear-quantile-and-least-squares-regressors"]], "Fixed models": [[1054, "fixed-models"]], "FixedThresholdClassifier": [[807, "fixedthresholdclassifier"]], "FixedThresholdClassifier: Setting the decision threshold of a binary classifier": [[336, "fixedthresholdclassifier-setting-the-decision-threshold-of-a-binary-classifier"]], "Fixes": [[1041, "fixes"]], "Flexibility of IterativeImputer": [[990, "flexibility-of-iterativeimputer"]], "Folding and unfolding outdated diffs on pull requests": [[394, "folding-and-unfolding-outdated-diffs-on-pull-requests"]], "Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)": [[181, "forecasting-of-co2-level-on-mona-loa-dataset-using-gaussian-process-regression-gpr"]], "Forest covertypes": [[381, "forest-covertypes"]], "Forest covertypes dataset": [[257, "forest-covertypes-dataset"]], "Fowlkes-Mallows scores": [[416, "fowlkes-mallows-scores"]], "FreeBSD": [[384, "freebsd"]], "Frequency model \u2013 Poisson distribution": [[238, "frequency-model-poisson-distribution"]], "Frequently Asked Questions": [[398, "frequently-asked-questions"]], "From binary to multiclass and multilabel": [[1000, "from-binary-to-multiclass-and-multilabel"]], "From images": [[17, "module-sklearn.feature_extraction.image"]], "From occurrences to frequencies": [[1034, "from-occurrences-to-frequencies"]], "From text": [[17, "module-sklearn.feature_extraction.text"]], "Fruitful discussions": [[385, null]], "FunctionTransformer": [[876, "functiontransformer"]], "Funding": [[0, "funding"]], "GMM Initialization Methods": [[266, "gmm-initialization-methods"]], "GMM covariances": [[265, "gmm-covariances"]], "GPC examples": [[426, "gpc-examples"]], "Gallery examples": [[430, "gallery-examples"], [433, "gallery-examples"], [436, "gallery-examples"], [439, "gallery-examples"], [440, "gallery-examples"], [445, "gallery-examples"], [446, "gallery-examples"], [448, "gallery-examples"], [449, "gallery-examples"], [450, "gallery-examples"], [451, "gallery-examples"], [452, "gallery-examples"], [453, "gallery-examples"], [454, "gallery-examples"], [455, "gallery-examples"], [456, "gallery-examples"], [457, "gallery-examples"], [458, "gallery-examples"], [459, "gallery-examples"], [460, "gallery-examples"], [461, "gallery-examples"], [462, "gallery-examples"], [463, "gallery-examples"], [466, "gallery-examples"], [468, "gallery-examples"], [470, "gallery-examples"], [472, "gallery-examples"], [473, "gallery-examples"], [474, "gallery-examples"], [475, "gallery-examples"], [476, "gallery-examples"], [477, "gallery-examples"], [478, "gallery-examples"], [480, "gallery-examples"], [481, "gallery-examples"], [482, "gallery-examples"], [483, "gallery-examples"], [484, "gallery-examples"], [485, "gallery-examples"], [487, "gallery-examples"], [490, "gallery-examples"], [491, "gallery-examples"], [492, "gallery-examples"], [496, "gallery-examples"], [497, "gallery-examples"], [498, "gallery-examples"], [499, "gallery-examples"], [500, "gallery-examples"], [502, "gallery-examples"], [503, "gallery-examples"], [504, "gallery-examples"], [506, "gallery-examples"], [507, "gallery-examples"], [508, "gallery-examples"], [509, "gallery-examples"], [510, "gallery-examples"], [512, "gallery-examples"], [514, "gallery-examples"], [518, "gallery-examples"], [519, "gallery-examples"], [520, "gallery-examples"], [521, "gallery-examples"], [522, "gallery-examples"], [523, "gallery-examples"], [527, "gallery-examples"], [528, "gallery-examples"], [529, "gallery-examples"], [530, "gallery-examples"], [531, "gallery-examples"], [532, "gallery-examples"], [533, "gallery-examples"], [534, "gallery-examples"], [535, "gallery-examples"], [538, "gallery-examples"], [540, "gallery-examples"], [541, "gallery-examples"], [542, "gallery-examples"], [543, "gallery-examples"], [544, "gallery-examples"], [545, "gallery-examples"], [546, "gallery-examples"], [547, "gallery-examples"], [548, "gallery-examples"], [549, "gallery-examples"], [550, "gallery-examples"], [551, "gallery-examples"], [552, "gallery-examples"], [557, "gallery-examples"], [558, "gallery-examples"], [559, "gallery-examples"], [560, "gallery-examples"], [561, "gallery-examples"], [562, "gallery-examples"], [564, "gallery-examples"], [565, "gallery-examples"], [566, "gallery-examples"], [567, "gallery-examples"], [568, "gallery-examples"], [569, "gallery-examples"], [570, "gallery-examples"], [571, "gallery-examples"], [572, "gallery-examples"], [573, "gallery-examples"], [574, "gallery-examples"], [575, "gallery-examples"], [576, "gallery-examples"], [577, "gallery-examples"], [578, "gallery-examples"], [589, "gallery-examples"], [590, "gallery-examples"], [592, "gallery-examples"], [595, "gallery-examples"], [596, "gallery-examples"], [597, "gallery-examples"], [598, "gallery-examples"], [599, "gallery-examples"], [601, "gallery-examples"], [602, "gallery-examples"], [605, "gallery-examples"], [607, "gallery-examples"], [608, "gallery-examples"], [610, "gallery-examples"], [612, "gallery-examples"], [613, "gallery-examples"], [614, "gallery-examples"], [615, "gallery-examples"], [616, "gallery-examples"], [618, "gallery-examples"], [619, "gallery-examples"], [621, "gallery-examples"], [622, "gallery-examples"], [623, "gallery-examples"], [625, "gallery-examples"], [626, "gallery-examples"], [627, "gallery-examples"], [630, "gallery-examples"], [631, "gallery-examples"], [633, "gallery-examples"], [635, "gallery-examples"], [636, "gallery-examples"], [638, "gallery-examples"], [639, "gallery-examples"], [640, "gallery-examples"], [641, "gallery-examples"], [642, "gallery-examples"], [643, "gallery-examples"], [647, "gallery-examples"], [648, "gallery-examples"], [649, "gallery-examples"], [651, "gallery-examples"], [652, "gallery-examples"], [653, "gallery-examples"], [654, "gallery-examples"], [655, "gallery-examples"], [656, "gallery-examples"], [657, "gallery-examples"], [660, "gallery-examples"], [661, "gallery-examples"], [663, "gallery-examples"], [664, "gallery-examples"], [665, "gallery-examples"], [666, "gallery-examples"], [667, "gallery-examples"], [670, "gallery-examples"], [672, "gallery-examples"], [673, "gallery-examples"], [674, "gallery-examples"], [676, "gallery-examples"], [677, "gallery-examples"], [678, "gallery-examples"], [679, "gallery-examples"], [680, "gallery-examples"], [681, "gallery-examples"], [682, "gallery-examples"], [684, "gallery-examples"], [685, "gallery-examples"], [686, "gallery-examples"], [687, "gallery-examples"], [688, "gallery-examples"], [689, "gallery-examples"], [690, "gallery-examples"], [692, "gallery-examples"], [696, "gallery-examples"], [697, "gallery-examples"], [698, "gallery-examples"], [699, "gallery-examples"], [700, "gallery-examples"], [701, "gallery-examples"], [705, "gallery-examples"], [706, "gallery-examples"], [708, "gallery-examples"], [709, "gallery-examples"], [710, "gallery-examples"], [711, "gallery-examples"], [712, "gallery-examples"], [713, "gallery-examples"], [714, "gallery-examples"], [715, "gallery-examples"], [717, "gallery-examples"], [720, "gallery-examples"], [721, "gallery-examples"], [725, "gallery-examples"], [726, "gallery-examples"], [727, "gallery-examples"], [735, "gallery-examples"], [737, "gallery-examples"], [740, "gallery-examples"], [742, "gallery-examples"], [743, "gallery-examples"], [745, "gallery-examples"], [746, "gallery-examples"], [749, "gallery-examples"], [750, "gallery-examples"], [753, "gallery-examples"], [754, "gallery-examples"], [756, "gallery-examples"], [757, "gallery-examples"], [758, "gallery-examples"], [760, "gallery-examples"], [761, "gallery-examples"], [763, "gallery-examples"], [765, "gallery-examples"], [769, "gallery-examples"], [786, "gallery-examples"], [787, "gallery-examples"], [790, "gallery-examples"], [792, "gallery-examples"], [793, "gallery-examples"], [794, "gallery-examples"], [795, "gallery-examples"], [796, "gallery-examples"], [797, "gallery-examples"], [798, "gallery-examples"], [800, "gallery-examples"], [801, "gallery-examples"], [803, "gallery-examples"], [805, "gallery-examples"], [806, "gallery-examples"], [807, "gallery-examples"], [808, "gallery-examples"], [809, "gallery-examples"], [810, "gallery-examples"], [811, "gallery-examples"], [812, "gallery-examples"], [813, "gallery-examples"], [814, "gallery-examples"], [822, "gallery-examples"], [823, "gallery-examples"], [824, "gallery-examples"], [825, "gallery-examples"], [826, "gallery-examples"], [827, "gallery-examples"], [828, "gallery-examples"], [829, "gallery-examples"], [830, "gallery-examples"], [831, "gallery-examples"], [833, "gallery-examples"], [834, "gallery-examples"], [835, "gallery-examples"], [836, "gallery-examples"], [837, "gallery-examples"], [838, "gallery-examples"], [839, "gallery-examples"], [840, "gallery-examples"], [841, "gallery-examples"], [842, "gallery-examples"], [843, "gallery-examples"], [845, "gallery-examples"], [847, "gallery-examples"], [849, "gallery-examples"], [850, "gallery-examples"], [851, "gallery-examples"], [854, "gallery-examples"], [855, "gallery-examples"], [856, "gallery-examples"], [857, "gallery-examples"], [858, "gallery-examples"], [859, "gallery-examples"], [860, "gallery-examples"], [861, "gallery-examples"], [865, "gallery-examples"], [868, "gallery-examples"], [869, "gallery-examples"], [870, "gallery-examples"], [871, "gallery-examples"], [872, "gallery-examples"], [873, "gallery-examples"], [876, "gallery-examples"], [877, "gallery-examples"], [879, "gallery-examples"], [881, "gallery-examples"], [882, "gallery-examples"], [884, "gallery-examples"], [885, "gallery-examples"], [886, "gallery-examples"], [887, "gallery-examples"], [888, "gallery-examples"], [889, "gallery-examples"], [890, "gallery-examples"], [891, "gallery-examples"], [892, "gallery-examples"], [893, "gallery-examples"], [896, "gallery-examples"], [898, "gallery-examples"], [901, "gallery-examples"], [905, "gallery-examples"], [906, "gallery-examples"], [908, "gallery-examples"], [909, "gallery-examples"], [910, "gallery-examples"], [912, "gallery-examples"], [915, "gallery-examples"], [916, "gallery-examples"], [917, "gallery-examples"], [918, "gallery-examples"], [919, "gallery-examples"], [920, "gallery-examples"], [921, "gallery-examples"], [926, "gallery-examples"], [927, "gallery-examples"], [935, "gallery-examples"], [944, "gallery-examples"], [946, "gallery-examples"], [953, "gallery-examples"], [957, "gallery-examples"], [958, "gallery-examples"], [959, "gallery-examples"], [960, "gallery-examples"], [961, "gallery-examples"], [974, "gallery-examples"], [984, "gallery-examples"]], "Gamma loss for gradient boosting": [[334, "gamma-loss-for-gradient-boosting"]], "GammaRegressor": [[656, "gammaregressor"]], "Gaussian Mixture": [[999, "gaussian-mixture"]], "Gaussian Mixture Model Ellipsoids": [[264, "gaussian-mixture-model-ellipsoids"]], "Gaussian Mixture Model Selection": [[268, "gaussian-mixture-model-selection"]], "Gaussian Mixture Model Sine Curve": [[269, "gaussian-mixture-model-sine-curve"]], "Gaussian Mixture Models": [[189, "gaussian-mixture-models"], [262, "gaussian-mixture-models"]], "Gaussian Naive Bayes": [[62, "gaussian-naive-bayes"], [1002, "gaussian-naive-bayes"]], "Gaussian Naive-Bayes": [[61, "gaussian-naive-bayes"]], "Gaussian Process Classification (GPC)": [[426, "gaussian-process-classification-gpc"]], "Gaussian Process Regression (GPR)": [[426, "gaussian-process-regression-gpr"]], "Gaussian Process for Machine Learning": [[175, "gaussian-process-for-machine-learning"], [189, "gaussian-process-for-machine-learning"]], "Gaussian Processes": [[426, "gaussian-processes"]], "Gaussian Processes regression: basic introductory example": [[183, "gaussian-processes-regression-basic-introductory-example"]], "Gaussian mixture models": [[999, "gaussian-mixture-models"]], "Gaussian process classification (GPC) on iris dataset": [[178, "gaussian-process-classification-gpc-on-iris-dataset"], [426, "gaussian-process-classification-gpc-on-iris-dataset"]], "Gaussian process regression": [[176, "gaussian-process-regression"]], "Gaussian processes on discrete data structures": [[184, "gaussian-processes-on-discrete-data-structures"]], "Gaussian random projection": [[1012, "gaussian-random-projection"]], "GaussianMixture": [[806, "gaussianmixture"]], "GaussianNB": [[850, "gaussiannb"]], "GaussianProcessClassifier": [[618, "gaussianprocessclassifier"]], "GaussianProcessRegressor": [[619, "gaussianprocessregressor"]], "GaussianRandomProjection": [[904, "gaussianrandomprojection"]], "General Concepts": [[400, "general-concepts"]], "General recommendations": [[369, "general-recommendations"]], "Generalized Linear Models": [[189, "generalized-linear-models"], [198, "generalized-linear-models"], [996, "generalized-linear-models"]], "Generalized Linear Models, and Poisson loss for gradient boosting": [[329, "generalized-linear-models-and-poisson-loss-for-gradient-boosting"]], "Generalized linear models (GLM) for regression": [[25, "generalized-linear-models-glm-for-regression"]], "Generate data": [[82, "generate-data"], [102, "generate-data"], [113, "generate-data"], [214, "generate-data"], [317, "generate-data"]], "Generate data with outliers": [[306, "generate-data-with-outliers"]], "Generate distorted image": [[128, "generate-distorted-image"]], "Generate sample data": [[58, "generate-sample-data"], [73, "generate-sample-data"], [90, "generate-sample-data"], [98, "generate-sample-data"], [111, "generate-sample-data"], [126, "generate-sample-data"], [127, "generate-sample-data"], [170, "generate-sample-data"], [253, "generate-sample-data"], [291, "generate-sample-data"], [311, "generate-sample-data"], [355, "generate-sample-data"]], "Generate sinusoidal data with noise": [[200, "generate-sinusoidal-data-with-noise"]], "Generate synthetic data": [[275, "generate-synthetic-data"]], "Generate synthetic dataset": [[61, "generate-synthetic-dataset"], [199, "generate-synthetic-dataset"], [199, "id1"], [204, "generate-synthetic-dataset"]], "Generate the data": [[99, "generate-the-data"], [101, "generate-the-data"], [115, "generate-the-data"]], "Generated datasets": [[382, "generated-datasets"]], "Generated documentation on GitHub Actions": [[386, "generated-documentation-on-github-actions"]], "Generating Polars-engineered lagged features": [[52, "generating-polars-engineered-lagged-features"]], "Generating a dataset": [[176, "generating-a-dataset"]], "Generating polynomial features": [[1010, "generating-polynomial-features"]], "Generators for classification and clustering": [[382, "generators-for-classification-and-clustering"]], "Generators for decomposition": [[382, "generators-for-decomposition"]], "Generators for manifold learning": [[382, "generators-for-manifold-learning"]], "Generators for regression": [[382, "generators-for-regression"]], "Generic dictionary learning": [[421, "generic-dictionary-learning"]], "GenericUnivariateSelect": [[600, "genericunivariateselect"]], "Getting Started": [[399, "getting-started"]], "Getting reproducible results across multiple executions": [[369, "getting-reproducible-results-across-multiple-executions"]], "Gitter": [[1023, "gitter"]], "Glossary of Common Terms and API Elements": [[400, "glossary-of-common-terms-and-api-elements"]], "Good practices": [[391, "good-practices"]], "Governance": [[0, "governance"]], "Governance Model Changes": [[401, "governance-model-changes"]], "Gradient Boosting": [[43, "gradient-boosting"]], "Gradient Boosting Out-of-Bag estimates": [[151, "gradient-boosting-out-of-bag-estimates"]], "Gradient Boosting Regression Trees for Poisson regression": [[220, "gradient-boosting-regression-trees-for-poisson-regression"]], "Gradient Boosting regression": [[153, "gradient-boosting-regression"]], "Gradient Boosting regularization": [[154, "gradient-boosting-regularization"]], "Gradient boosting": [[193, "gradient-boosting"]], "Gradient boosting estimator with dropped categorical features": [[149, "gradient-boosting-estimator-with-dropped-categorical-features"]], "Gradient boosting estimator with native categorical support": [[149, "gradient-boosting-estimator-with-native-categorical-support"]], "Gradient boosting estimator with one-hot encoding": [[149, "gradient-boosting-estimator-with-one-hot-encoding"]], "Gradient boosting estimator with ordinal encoding": [[149, "gradient-boosting-estimator-with-ordinal-encoding"]], "Gradient-boosted trees": [[423, "gradient-boosted-trees"]], "GradientBoostingClassifier": [[567, "gradientboostingclassifier"]], "GradientBoostingClassifier and GradientBoostingRegressor": [[423, "gradientboostingclassifier-and-gradientboostingregressor"]], "GradientBoostingClassifier vs HistGradientBoostingClassifier": [[423, null]], "GradientBoostingRegressor": [[568, "gradientboostingregressor"]], "Graph Routines": [[395, "graph-routines"]], "Graphical model and parametrization": [[1005, "graphical-model-and-parametrization"]], "GraphicalLasso": [[479, "graphicallasso"]], "GraphicalLassoCV": [[480, "graphicallassocv"]], "Grid-search": [[1029, "grid-search"]], "Grid-search and cross-validated estimators": [[1029, "grid-search-and-cross-validated-estimators"]], "GridSearchCV": [[808, "gridsearchcv"]], "Group Shuffle Split": [[420, "group-shuffle-split"]], "Group k-fold": [[420, "group-k-fold"]], "GroupKFold": [[809, "groupkfold"]], "GroupShuffleSplit": [[810, "groupshufflesplit"]], "Grouping infrequent categories in OneHotEncoder": [[332, "grouping-infrequent-categories-in-onehotencoder"]], "Grouping infrequent categories in OrdinalEncoder": [[334, "grouping-infrequent-categories-in-ordinalencoder"]], "HDBSCAN": [[416, "hdbscan"], [454, "hdbscan"]], "HDBSCAN: hierarchical density-based clustering": [[334, "hdbscan-hierarchical-density-based-clustering"]], "HalvingGridSearchCV": [[811, "halvinggridsearchcv"]], "HalvingRandomSearchCV": [[812, "halvingrandomsearchcv"]], "Hamming loss": [[1000, "hamming-loss"]], "Handling Multicollinear Features": [[195, "handling-multicollinear-features"]], "Hash Functions": [[395, "hash-functions"]], "Hashing feature transformation using Totally Random Trees": [[158, "hashing-feature-transformation-using-totally-random-trees"]], "HashingVectorizer": [[361, "hashingvectorizer"], [597, "hashingvectorizer"]], "Helper Functions": [[395, "helper-functions"]], "Helper function": [[185, "helper-function"]], "Helper function to plot embedding": [[241, "helper-function-to-plot-embedding"]], "Hessian Eigenmapping": [[997, "hessian-eigenmapping"]], "Hierarchical Clustering": [[416, "id11"]], "Hierarchical agglomerative clustering: Ward": [[1033, "hierarchical-agglomerative-clustering-ward"]], "Hierarchical clustering": [[416, "hierarchical-clustering"]], "Hierarchical clustering: structured vs unstructured ward": [[102, "hierarchical-clustering-structured-vs-unstructured-ward"]], "Higher-level parallelism with joblib": [[374, "higher-level-parallelism-with-joblib"]], "Highlights": [[1041, "highlights"], [1044, "highlights"], [1045, "highlights"], [1048, "highlights"], [1049, "highlights"]], "Hinge loss": [[1000, "hinge-loss"]], "HistGradientBoosting Natively Supports Categorical DTypes in DataFrames": [[335, "histgradientboosting-natively-supports-categorical-dtypes-in-dataframes"]], "HistGradientBoostingClassifier": [[569, "histgradientboostingclassifier"]], "HistGradientBoostingRegressor": [[570, "histgradientboostingregressor"]], "Histogram-Based Gradient Boosting": [[423, "histogram-based-gradient-boosting"]], "Histogram-based Gradient Boosting Models are now stable": [[331, "histogram-based-gradient-boosting-models-are-now-stable"]], "History": [[0, "history"]], "Homogeneity, completeness and V-measure": [[416, "homogeneity-completeness-and-v-measure"]], "How can I contribute to scikit-learn?": [[398, "how-can-i-contribute-to-scikit-learn"]], "How can I create a bunch object?": [[398, "how-can-i-create-a-bunch-object"]], "How can I load my own datasets into a format usable by scikit-learn?": [[398, "how-can-i-load-my-own-datasets-into-a-format-usable-by-scikit-learn"]], "How can I obtain permission to use the images in scikit-learn for my work?": [[398, "how-can-i-obtain-permission-to-use-the-images-in-scikit-learn-for-my-work"]], "How do I deal with string data (or trees, graphs\u2026)?": [[398, "how-do-i-deal-with-string-data-or-trees-graphs"]], "How do I set a random_state for an entire execution?": [[398, "how-do-i-set-a-random-state-for-an-entire-execution"]], "How do you pronounce the project name?": [[398, "how-do-you-pronounce-the-project-name"]], "How should I save, export or deploy estimators for production?": [[398, "how-should-i-save-export-or-deploy-estimators-for-production"]], "How to avoid data leakage": [[369, "how-to-avoid-data-leakage"]], "How to contribute": [[386, "how-to-contribute"]], "How to make a good bug report": [[386, "how-to-make-a-good-bug-report"]], "How to optimize for speed": [[392, "how-to-optimize-for-speed"]], "HowAboutWe": [[1024, "id16"]], "Huber Regression": [[996, "huber-regression"]], "HuberRegressor": [[657, "huberregressor"]], "HuberRegressor vs Ridge on dataset with strong outliers": [[202, "huberregressor-vs-ridge-on-dataset-with-strong-outliers"]], "Hugging Face": [[1024, "id5"]], "Hyper-parameter optimizers": [[29, "hyper-parameter-optimizers"]], "Hyperparameter": [[625, "hyperparameter"]], "Hyperparameter Robustness": [[90, "hyperparameter-robustness"]], "ICE vs. PDP": [[193, "ice-vs-pdp"]], "INFONEA": [[1024, "id24"]], "Illustration of GPC on the XOR dataset": [[426, "illustration-of-gpc-on-the-xor-dataset"]], "Illustration of Gaussian process classification (GPC) on the XOR dataset": [[180, "illustration-of-gaussian-process-classification-gpc-on-the-xor-dataset"]], "Illustration of Pipeline and GridSearchCV": [[106, "illustration-of-pipeline-and-gridsearchcv"]], "Illustration of prior and posterior Gaussian process for different kernels": [[185, "illustration-of-prior-and-posterior-gaussian-process-for-different-kernels"]], "Image denoising using dictionary learning": [[128, "image-denoising-using-dictionary-learning"]], "Image denoising using kernel PCA": [[44, "image-denoising-using-kernel-pca"]], "Image feature extraction": [[424, "image-feature-extraction"]], "Implementation": [[1003, "implementation"]], "Implementation decisions": [[398, "implementation-decisions"]], "Implementation details": [[1014, "implementation-details"], [1015, "implementation-details"]], "Implementing your own scoring object": [[1000, "implementing-your-own-scoring-object"]], "Importance of Feature Scaling": [[324, "importance-of-feature-scaling"]], "Important notes regarding the internal cross-validation": [[415, "important-notes-regarding-the-internal-cross-validation"]], "Improved efficiency of many estimators": [[333, "improved-efficiency-of-many-estimators"]], "Improved memory and runtime efficiency for PCA on sparse data": [[335, "improved-memory-and-runtime-efficiency-for-pca-on-sparse-data"]], "Improved performances of HistGradientBoosting estimators": [[330, "improved-performances-of-histgradientboosting-estimators"]], "Improvements to the histogram-based Gradient Boosting estimators": [[329, "improvements-to-the-histogram-based-gradient-boosting-estimators"]], "Imputation of missing values": [[990, "imputation-of-missing-values"], [1010, "imputation-of-missing-values"]], "Impute missing values with mean": [[188, "impute-missing-values-with-mean"]], "Impute the missing data and score": [[188, "impute-the-missing-data-and-score"]], "Imputing missing values before building an estimator": [[188, "imputing-missing-values-before-building-an-estimator"]], "Imputing missing values with variants of IterativeImputer": [[187, "imputing-missing-values-with-variants-of-iterativeimputer"]], "In binary classification settings": [[285, "in-binary-classification-settings"]], "In multi-label settings": [[285, "in-multi-label-settings"]], "Income prediction with fully observed variables": [[191, "income-prediction-with-fully-observed-variables"]], "Income prediction with partial observations": [[191, "income-prediction-with-partial-observations"]], "Inconsistent preprocessing": [[369, "inconsistent-preprocessing"]], "InconsistentVersionWarning": [[584, "inconsistentversionwarning"]], "Incremental PCA": [[129, "incremental-pca"], [421, "incremental-pca"]], "Incremental learning": [[375, "incremental-learning"]], "IncrementalPCA": [[542, "incrementalpca"]], "Independent Component Analysis: ICA": [[1033, "independent-component-analysis-ica"]], "Independent component analysis (ICA)": [[421, "independent-component-analysis-ica"]], "Independent components - FastICA": [[125, "independent-components-fastica"]], "Individual Conditional Expectation plots": [[330, "individual-conditional-expectation-plots"]], "Individual conditional expectation (ICE) plot": [[1007, "individual-conditional-expectation-ice-plot"]], "Inductive Clustering": [[91, "inductive-clustering"]], "Influence of the Input Data Representation": [[373, "influence-of-the-input-data-representation"]], "Influence of the Model Complexity": [[373, "influence-of-the-model-complexity"]], "Influence of the Number of Features": [[373, "influence-of-the-number-of-features"]], "Information Criterion": [[989, "information-criterion"]], "Information-criteria based model selection": [[996, "information-criteria-based-model-selection"]], "Infrastructure support": [[0, "infrastructure-support"]], "Infrequent categories": [[1010, "infrequent-categories"]], "Input and parameter validation": [[41, "module-sklearn.utils.validation"]], "Input data": [[416, null]], "Input validation": [[388, "input-validation"]], "Inria": [[1024, "id3"]], "Inspection": [[189, "inspection"], [190, "inspection"], [403, "inspection"]], "Installing nightly builds": [[384, "installing-nightly-builds"]], "Installing scikit-learn": [[404, "installing-scikit-learn"]], "Installing the development version of scikit-learn": [[384, "installing-the-development-version-of-scikit-learn"]], "Installing the latest release": [[404, "installing-the-latest-release"]], "Instantiation": [[388, "instantiation"]], "Intel Extension for Scikit-learn": [[404, "intel-extension-for-scikit-learn"]], "Interaction constraints": [[423, "interaction-constraints"]], "Interaction constraints in Histogram-based Gradient Boosting Trees": [[333, "interaction-constraints-in-histogram-based-gradient-boosting-trees"]], "Interoperability and framework enhancements": [[1019, "interoperability-and-framework-enhancements"]], "Interpretation of kernel hyperparameters": [[181, "interpretation-of-kernel-hyperparameters"]], "Interpretation with feature importance": [[423, "interpretation-with-feature-importance"]], "Interpreting coefficients: being cautious about causality": [[192, "interpreting-coefficients-being-cautious-about-causality"]], "Interpreting coefficients: scale matters": [[192, "interpreting-coefficients-scale-matters"]], "Interpreting the plots": [[224, "interpreting-the-plots"]], "Introducing the set_output API": [[261, "introducing-the-set-output-api"]], "Introduction": [[997, "introduction"]], "Invariance with respect to prevalence": [[281, "invariance-with-respect-to-prevalence"]], "Inverse Transform": [[1012, "inverse-transform"]], "Iris plants dataset": [[383, "iris-plants-dataset"]], "Iso-probability lines for Gaussian Processes classification (GPC)": [[179, "iso-probability-lines-for-gaussian-processes-classification-gpc"]], "Isolation Forest": [[1006, "isolation-forest"]], "IsolationForest": [[571, "isolationforest"]], "IsolationForest example": [[156, "isolationforest-example"]], "Isomap": [[696, "isomap"], [997, "isomap"]], "Isomap Embedding": [[240, "isomap-embedding"]], "Isotonic": [[414, "isotonic"]], "Isotonic Regression": [[250, "isotonic-regression"]], "Isotonic regression": [[991, "isotonic-regression"]], "IsotonicRegression": [[643, "isotonicregression"]], "Issue Tracker Tags": [[386, "issue-tracker-tags"]], "Issues for New Contributors": [[386, "issues-for-new-contributors"]], "Iterative imputation of the missing values": [[188, "iterative-imputation-of-the-missing-values"]], "IterativeImputer": [[635, "iterativeimputer"]], "J.P.Morgan": [[1024, "id1"]], "Jaccard similarity coefficient score": [[1000, "jaccard-similarity-coefficient-score"]], "Joint feature selection with multi-task Lasso": [[214, "joint-feature-selection-with-multi-task-lasso"]], "K-D Tree": [[1003, "k-d-tree"]], "K-bins discretization": [[1010, "k-bins-discretization"]], "K-fold": [[420, "k-fold"]], "K-means": [[416, "k-means"]], "K-means Clustering": [[80, "k-means-clustering"]], "K-means clustering": [[1033, "k-means-clustering"]], "K-means clustering on text features": [[361, "k-means-clustering-on-text-features"]], "K-nearest neighbors classifier": [[302, "k-nearest-neighbors-classifier"]], "KBinsDiscretizer": [[877, "kbinsdiscretizer"]], "KDDCup99 - SA dataset": [[257, "kddcup99-sa-dataset"]], "KDTree": [[853, "kdtree"]], "KDTree and BallTree Classes": [[1003, "kdtree-and-balltree-classes"]], "KFold": [[813, "kfold"]], "KMeans": [[455, "kmeans"]], "KNN Based Imputation": [[328, "knn-based-imputation"]], "KNNImputer": [[636, "knnimputer"]], "KNeighborsClassifier": [[854, "kneighborsclassifier"]], "KNeighborsRegressor": [[855, "kneighborsregressor"]], "KNeighborsTransformer": [[856, "kneighborstransformer"]], "Kddcup 99 dataset": [[381, "kddcup-99-dataset"]], "Keeping the number of features constant": [[990, "keeping-the-number-of-features-constant"]], "Kernel": [[626, "kernel"]], "Kernel Approximation": [[189, "kernel-approximation"], [196, "kernel-approximation"], [992, "kernel-approximation"]], "Kernel Density Estimate of Species Distributions": [[312, "kernel-density-estimate-of-species-distributions"]], "Kernel Density Estimation": [[303, "kernel-density-estimation"], [422, "kernel-density-estimation"]], "Kernel PCA": [[130, "kernel-pca"]], "Kernel Principal Component Analysis (kPCA)": [[421, "kernel-principal-component-analysis-kpca"]], "Kernel cookbook": [[185, "kernel-cookbook"]], "Kernel functions": [[1015, "kernel-functions"]], "Kernel methods: kernel ridge and Gaussian process": [[176, "kernel-methods-kernel-ridge-and-gaussian-process"]], "Kernel operators": [[426, "kernel-operators"]], "Kernel ridge": [[176, "kernel-ridge"]], "Kernel ridge regression": [[993, "kernel-ridge-regression"]], "KernelCenterer": [[878, "kernelcenterer"]], "KernelDensity": [[857, "kerneldensity"]], "KernelPCA": [[543, "kernelpca"]], "KernelRidge": [[651, "kernelridge"]], "Kernels": [[19, "module-sklearn.gaussian_process.kernels"]], "Kernels for Gaussian Processes": [[426, "kernels-for-gaussian-processes"]], "Keyword and positional arguments": [[331, "keyword-and-positional-arguments"]], "Known Major Bugs": [[1049, "known-major-bugs"], [1050, "known-major-bugs"]], "L1 Penalty and Sparsity in Logistic Regression": [[211, "l1-penalty-and-sparsity-in-logistic-regression"]], "L1-based feature selection": [[425, "l1-based-feature-selection"]], "L1-based models for Sparse Signals": [[204, "l1-based-models-for-sparse-signals"]], "L1-penalty case": [[356, "l1-penalty-case"]], "L2-penalty case": [[356, "l2-penalty-case"]], "LARS Lasso": [[996, "lars-lasso"]], "LDA": [[994, "lda"]], "Label Propagation": [[1013, "label-propagation"]], "Label Propagation digits active learning": [[339, "label-propagation-digits-active-learning"]], "Label Propagation digits: Demonstrating performance": [[338, "label-propagation-digits-demonstrating-performance"]], "Label Propagation learning a complex structure": [[340, "label-propagation-learning-a-complex-structure"]], "Label binarization": [[1011, "label-binarization"]], "Label encoding": [[1011, "label-encoding"]], "Label ranking average precision": [[1000, "label-ranking-average-precision"]], "LabelBinarizer": [[879, "labelbinarizer"], [1011, "labelbinarizer"]], "LabelEncoder": [[880, "labelencoder"]], "LabelPropagation": [[907, "labelpropagation"]], "LabelSpreading": [[908, "labelspreading"]], "Lagged features for time series forecasting": [[52, "lagged-features-for-time-series-forecasting"]], "Laplacian kernel": [[998, "laplacian-kernel"]], "Lars": [[658, "lars"]], "LarsCV": [[659, "larscv"]], "Lasso": [[204, "lasso"], [660, "lasso"], [996, "lasso"]], "Lasso and Elastic Net": [[205, "lasso-and-elastic-net"]], "Lasso model selection via information criteria": [[208, "lasso-model-selection-via-information-criteria"]], "Lasso model selection: AIC-BIC / cross-validation": [[209, "lasso-model-selection-aic-bic-cross-validation"]], "Lasso on dense and sparse data": [[206, "lasso-on-dense-and-sparse-data"]], "Lasso path using LARS": [[207, "lasso-path-using-lars"]], "Lasso via coordinate descent": [[209, "lasso-via-coordinate-descent"]], "Lasso via least angle regression": [[209, "lasso-via-least-angle-regression"]], "LassoCV": [[661, "lassocv"]], "LassoLars": [[662, "lassolars"]], "LassoLarsCV": [[663, "lassolarscv"]], "LassoLarsIC": [[664, "lassolarsic"]], "Latent Dirichlet Allocation (LDA)": [[421, "latent-dirichlet-allocation-lda"]], "LatentDirichletAllocation": [[544, "latentdirichletallocation"]], "Learn the PCA basis": [[44, "learn-the-pca-basis"]], "Learn the dictionary from reference patches": [[128, "learn-the-dictionary-from-reference-patches"]], "Learn the dictionary of images": [[85, "learn-the-dictionary-of-images"]], "Learning Curve": [[280, "learning-curve"]], "Learning Git": [[386, null]], "Learning a graph structure": [[51, "learning-a-graph-structure"]], "Learning an embedding": [[309, "learning-an-embedding"]], "Learning and predicting": [[1025, "learning-and-predicting"]], "Learning curve": [[995, "learning-curve"]], "LearningCurveDisplay": [[814, "learningcurvedisplay"]], "Least Angle Regression": [[996, "least-angle-regression"]], "Leave One Group Out": [[420, "leave-one-group-out"]], "Leave One Out (LOO)": [[420, "leave-one-out-loo"]], "Leave P Groups Out": [[420, "leave-p-groups-out"]], "Leave P Out (LPO)": [[420, "leave-p-out-lpo"]], "LeaveOneGroupOut": [[815, "leaveonegroupout"]], "LeaveOneOut": [[816, "leaveoneout"]], "LeavePGroupsOut": [[817, "leavepgroupsout"]], "LeavePOut": [[818, "leavepout"]], "Ledoit-Wolf shrinkage": [[418, "ledoit-wolf-shrinkage"]], "Ledoit-Wolf vs OAS estimation": [[112, "ledoit-wolf-vs-oas-estimation"]], "LedoitWolf": [[481, "ledoitwolf"]], "Lessons learned": [[191, "lessons-learned"], [192, "lessons-learned"]], "Limitations of a simple linear model": [[176, "limitations-of-a-simple-linear-model"]], "Limitations of the Bag of Words representation": [[424, "limitations-of-the-bag-of-words-representation"]], "Limiting Working Memory": [[373, "limiting-working-memory"]], "Limiting the number of splits": [[149, "limiting-the-number-of-splits"]], "Linear Models": [[996, "linear-models"]], "Linear Regression Example": [[216, "linear-regression-example"]], "Linear SVMs": [[1032, "linear-svms"]], "Linear algebra libraries": [[373, "linear-algebra-libraries"]], "Linear and Quadratic Discriminant Analysis": [[994, "linear-and-quadratic-discriminant-analysis"]], "Linear and Quadratic Discriminant Analysis with covariance ellipsoid": [[70, "linear-and-quadratic-discriminant-analysis-with-covariance-ellipsoid"]], "Linear classifiers": [[25, "linear-classifiers"]], "Linear kernel": [[353, "linear-kernel"], [998, "linear-kernel"], [1032, "linear-kernel"]], "Linear model: from regression to sparsity": [[1032, "linear-model-from-regression-to-sparsity"]], "Linear models with regularization": [[192, "linear-models-with-regularization"]], "Linear models with sparse coefficients": [[192, "linear-models-with-sparse-coefficients"]], "Linear regression": [[1032, "linear-regression"]], "Linear support vector classifier": [[62, "linear-support-vector-classifier"]], "LinearDiscriminantAnalysis": [[557, "lineardiscriminantanalysis"]], "LinearRegression": [[665, "linearregression"]], "LinearSVC": [[912, "linearsvc"]], "LinearSVR": [[913, "linearsvr"]], "Link to R\u00b2 score, the coefficient of determination": [[1000, null]], "Links": [[373, "links"]], "Linnerrud dataset": [[383, "linnerrud-dataset"]], "Linux": [[384, "linux"]], "Linux compilers from conda-forge": [[384, "linux-compilers-from-conda-forge"]], "Linux compilers from the system": [[384, "linux-compilers-from-the-system"]], "Load Ames Housing dataset": [[149, "load-ames-housing-dataset"]], "Load Data": [[362, "load-data"]], "Load Data and Train a SVC": [[260, "load-data-and-train-a-svc"]], "Load Data and train model": [[248, "load-data-and-train-model"]], "Load and prepare data": [[287, "load-and-prepare-data"], [288, "load-and-prepare-data"], [324, "load-and-prepare-data"]], "Load and prepare data set": [[349, "load-and-prepare-data-set"]], "Load data": [[213, "load-data"]], "Load dataset": [[145, "load-dataset"]], "Load dataset and apply GridSearchCV": [[165, "load-dataset-and-apply-gridsearchcv"]], "Load digits dataset": [[241, "load-digits-dataset"]], "Load some data to play with": [[352, "load-some-data-to-play-with"]], "Load the data": [[46, "load-the-data"], [85, "load-the-data"], [153, "load-the-data"], [302, "load-the-data"]], "Load the dataset": [[93, "load-the-dataset"]], "Load the dataset via OpenML": [[44, "load-the-dataset-via-openml"]], "Loaders": [[10, "loaders"]], "Loading Data from OpenML": [[325, "loading-data-from-openml"]], "Loading a dataset": [[298, "loading-a-dataset"]], "Loading an example dataset": [[1025, "loading-an-example-dataset"]], "Loading and vectorizing the 20 newsgroups text dataset": [[360, "loading-and-vectorizing-the-20-newsgroups-text-dataset"]], "Loading datasets, basic feature extraction and target definitions": [[238, "loading-datasets-basic-feature-extraction-and-target-definitions"]], "Loading features from dicts": [[424, "loading-features-from-dicts"]], "Loading from external datasets": [[380, "loading-from-external-datasets"], [1025, null]], "Loading other datasets": [[380, "loading-other-datasets"]], "Loading text data": [[361, "loading-text-data"]], "Loading the 20 newsgroups dataset": [[1034, "loading-the-20-newsgroups-dataset"]], "Loading the data": [[174, "loading-the-data"]], "Loading the data and model fitting": [[147, "loading-the-data-and-model-fitting"]], "Loading the iris dataset": [[121, "loading-the-iris-dataset"]], "Loading the redirect files": [[55, "loading-the-redirect-files"]], "Local Outlier Factor": [[1006, "local-outlier-factor"]], "Local Tangent Space Alignment": [[997, "local-tangent-space-alignment"]], "LocalOutlierFactor": [[858, "localoutlierfactor"]], "Locally Linear Embedding": [[997, "locally-linear-embedding"]], "Locally Linear Embeddings": [[240, "locally-linear-embeddings"]], "LocallyLinearEmbedding": [[697, "locallylinearembedding"]], "Log loss": [[1000, "log-loss"]], "Logistic Regression 3-class Classifier": [[203, "logistic-regression-3-class-classifier"]], "Logistic function": [[210, "logistic-function"]], "Logistic regression": [[996, "logistic-regression"]], "LogisticRegression": [[666, "logisticregression"]], "LogisticRegression wrapped by OneVsRestClassifier": [[298, "logisticregression-wrapped-by-onevsrestclassifier"]], "LogisticRegressionCV": [[667, "logisticregressioncv"]], "Look at the results": [[253, "look-at-the-results"], [355, "look-at-the-results"]], "Loss Functions": [[423, "loss-functions"]], "Lovely": [[1024, "id20"]], "Low-level parallelism": [[416, "low-level-parallelism"], [423, "low-level-parallelism"]], "Lower-level parallelism with OpenMP": [[374, "lower-level-parallelism-with-openmp"]], "MARS": [[1024, "id28"]], "MDS": [[698, "mds"]], "MLPClassifier": [[869, "mlpclassifier"]], "MLPRegressor": [[870, "mlpregressor"]], "MNIST classification using multinomial logistic + L1": [[236, "mnist-classification-using-multinomial-logistic-l1"]], "MacPorts for Mac OSX": [[404, "macports-for-mac-osx"]], "Machinalis": [[1024, "id22"]], "Machine learning: the problem setting": [[1025, "machine-learning-the-problem-setting"]], "Mailing Lists": [[1023, "mailing-lists"]], "Main": [[47, "main"]], "Main takeaways": [[220, "main-takeaways"]], "Maintainer/Core-Developer Information": [[390, "maintainer-core-developer-information"]], "Maintainers Team": [[0, "maintainers-team"]], "Maintaining backwards compatibility": [[386, "maintaining-backwards-compatibility"]], "Major version release": [[390, "major-version-release"]], "Majority Class Labels (Majority/Hard Voting)": [[423, "majority-class-labels-majority-hard-voting"]], "Make pipeline to preprocess the data": [[160, "make-pipeline-to-preprocess-the-data"]], "Making a release": [[390, "making-a-release"]], "Making predictions": [[163, "making-predictions"]], "Manifold Learning methods on a severed sphere": [[242, "manifold-learning-methods-on-a-severed-sphere"]], "Manifold learning": [[189, "manifold-learning"], [239, "manifold-learning"], [997, "manifold-learning"]], "Manifold learning on handwritten digits: Locally Linear Embedding, Isomap\u2026": [[241, "manifold-learning-on-handwritten-digits-locally-linear-embedding-isomap"]], "Manually setting the decision threshold": [[415, "manually-setting-the-decision-threshold"]], "Manually setting the decision threshold instead of tuning it": [[272, "manually-setting-the-decision-threshold-instead-of-tuning-it"]], "Map data to a normal distribution": [[323, "map-data-to-a-normal-distribution"]], "Mapping to a Gaussian distribution": [[1010, "mapping-to-a-gaussian-distribution"]], "Mapping to a Uniform distribution": [[1010, "mapping-to-a-uniform-distribution"]], "Marking imputed values": [[990, "marking-imputed-values"]], "Matern": [[627, "matern"]], "Mathematical Definition": [[1007, "mathematical-definition"]], "Mathematical Details": [[992, "mathematical-details"]], "Mathematical formulation": [[413, "mathematical-formulation"], [413, "id3"], [423, "mathematical-formulation"], [1003, "mathematical-formulation"], [1014, "mathematical-formulation"], [1015, "mathematical-formulation"], [1016, "mathematical-formulation"]], "Mathematical formulation of LDA dimensionality reduction": [[994, "mathematical-formulation-of-lda-dimensionality-reduction"]], "Mathematical formulation of the LDA and QDA classifiers": [[994, "mathematical-formulation-of-the-lda-and-qda-classifiers"]], "Matthews correlation coefficient": [[1000, "matthews-correlation-coefficient"]], "Mat\u00e9rn kernel": [[185, "matern-kernel"], [426, "matern-kernel"]], "Max error": [[1000, "max-error"]], "MaxAbsScaler": [[319, "maxabsscaler"], [881, "maxabsscaler"]], "Mean Poisson, Gamma, and Tweedie deviances": [[1000, "mean-poisson-gamma-and-tweedie-deviances"]], "Mean Shift": [[416, "mean-shift"]], "Mean absolute error": [[1000, "mean-absolute-error"]], "Mean absolute percentage error": [[1000, "mean-absolute-percentage-error"]], "Mean squared error": [[1000, "mean-squared-error"]], "Mean squared logarithmic error": [[1000, "mean-squared-logarithmic-error"]], "MeanShift": [[456, "meanshift"]], "Measure and plot the results": [[160, "measure-and-plot-the-results"]], "Median absolute error": [[1000, "median-absolute-error"]], "Memory footprint": [[88, "memory-footprint"]], "Memory usage profiling": [[392, "memory-usage-profiling"]], "Merging Pull Requests": [[390, "merging-pull-requests"]], "Meta-estimators": [[41, "module-sklearn.utils.metaestimators"]], "MetaEstimatorMixin": [[436, "metaestimatormixin"]], "Metadata Routing": [[254, "metadata-routing"], [334, "metadata-routing"], [400, "metadata-routing"], [407, "metadata-routing"], [1058, "metadata-routing"], [1058, "id1"], [1059, "metadata-routing"], [1060, "metadata-routing"]], "Metadata Routing Support": [[335, "metadata-routing-support"]], "Metadata Routing Support Status": [[407, "metadata-routing-support-status"]], "Metadata routing": [[41, "module-sklearn.utils.metadata_routing"]], "MetadataRequest": [[956, "metadatarequest"]], "MetadataRouter": [[957, "metadatarouter"]], "MethodMapping": [[958, "methodmapping"]], "Methods": [[400, "methods"]], "Metrics": [[412, "metrics"]], "Metrics and scoring: quantifying the quality of predictions": [[1000, "metrics-and-scoring-quantifying-the-quality-of-predictions"]], "MinCovDet": [[482, "mincovdet"]], "MinMaxScaler": [[319, "minmaxscaler"], [882, "minmaxscaler"]], "Mini Batch K-Means": [[416, "mini-batch-k-means"]], "Mini-batch Non Negative Matrix Factorization": [[421, "mini-batch-non-negative-matrix-factorization"]], "Mini-batch dictionary learning": [[421, "mini-batch-dictionary-learning"]], "MiniBatchDictionaryLearning": [[545, "minibatchdictionarylearning"]], "MiniBatchKMeans": [[457, "minibatchkmeans"]], "MiniBatchNMF": [[546, "minibatchnmf"]], "MiniBatchNMF: an online version of NMF": [[332, "minibatchnmf-an-online-version-of-nmf"]], "MiniBatchSparsePCA": [[547, "minibatchsparsepca"]], "Minimal Cost-Complexity Pruning": [[1016, "minimal-cost-complexity-pruning"]], "Minimal dependencies": [[1054, "minimal-dependencies"], [1055, "minimal-dependencies"]], "Minimum Covariance Determinant": [[418, "minimum-covariance-determinant"]], "Minimum Covariance Determinant Estimator": [[114, "minimum-covariance-determinant-estimator"]], "Minor version release (also known as bug-fix release)": [[390, "minor-version-release-also-known-as-bug-fix-release"]], "Misc": [[1041, "misc"]], "Miscellaneous": [[25, "miscellaneous"], [189, "miscellaneous"], [246, "miscellaneous"], [1049, "miscellaneous"], [1049, "id40"], [1050, "miscellaneous"], [1051, "miscellaneous"], [1052, "miscellaneous"], [1052, "id13"], [1053, "miscellaneous"], [1054, "miscellaneous"], [1057, "miscellaneous"]], "Misleading values on strongly correlated features": [[1008, "misleading-values-on-strongly-correlated-features"]], "Missing Value Imputation": [[186, "missing-value-imputation"], [189, "missing-value-imputation"]], "Missing Values Support": [[1016, "missing-values-support"]], "Missing information": [[188, "missing-information"]], "Missing value support for Random Forest": [[335, "missing-value-support-for-random-forest"]], "Missing values support": [[423, "missing-values-support"]], "Missing values support in decision trees": [[334, "missing-values-support-in-decision-trees"]], "MissingIndicator": [[637, "missingindicator"]], "Model Complexity Influence": [[46, "model-complexity-influence"]], "Model Compression": [[373, "model-compression"]], "Model Reshaping": [[373, "model-reshaping"]], "Model Selection": [[189, "model-selection"], [270, "model-selection"]], "Model Selection Enhancements and API Changes": [[1047, "model-selection-enhancements-and-api-changes"]], "Model Training and Comparison": [[150, "model-training-and-comparison"]], "Model comparison": [[149, "model-comparison"]], "Model evaluation": [[399, "model-evaluation"]], "Model fitting and extrapolation": [[181, "model-fitting-and-extrapolation"]], "Model persistence": [[410, "model-persistence"]], "Model selection and evaluation": [[411, "model-selection-and-evaluation"]], "Model selection interface": [[27, "model-selection-interface"]], "Model selection with Probabilistic PCA and Factor Analysis (FA)": [[132, "model-selection-with-probabilistic-pca-and-factor-analysis-fa"]], "Model selection: choosing estimators and their parameters": [[1029, "model-selection-choosing-estimators-and-their-parameters"]], "Model selection: development and evaluation": [[989, "model-selection-development-and-evaluation"]], "Model specific cross-validation": [[989, "model-specific-cross-validation"]], "Model training and selection": [[173, "model-training-and-selection"], [268, "model-training-and-selection"]], "Model validation": [[29, "model-validation"]], "Model with metadata stripping": [[360, "model-with-metadata-stripping"]], "Model without metadata stripping": [[360, "model-without-metadata-stripping"]], "Model-based and sequential feature selection": [[174, "model-based-and-sequential-feature-selection"]], "Modeling non-linear feature interactions with kernels": [[43, "modeling-non-linear-feature-interactions-with-kernels"]], "Modeling pairwise interactions with splines and polynomial features": [[43, "modeling-pairwise-interactions-with-splines-and-polynomial-features"]], "Modeling predictive uncertainty via quantile regression": [[52, "modeling-predictive-uncertainty-via-quantile-regression"]], "Models definition": [[317, "models-definition"]], "Models robustness to recover the ground truth weights": [[199, "models-robustness-to-recover-the-ground-truth-weights"]], "Modified Locally Linear Embedding": [[997, "modified-locally-linear-embedding"]], "Monitoring performance": [[386, "monitoring-performance"]], "Monotonic Constraints": [[157, "monotonic-constraints"], [423, "monotonic-constraints"]], "Monotonic constraints": [[155, "monotonic-constraints"]], "More control with warm_start": [[1004, "more-control-with-warm-start"]], "Multi-Scale Clustering": [[90, "multi-scale-clustering"]], "Multi-class AdaBoosted Decision Trees": [[139, "multi-class-adaboosted-decision-trees"]], "Multi-class case": [[1000, "multi-class-case"]], "Multi-class classification": [[1015, "multi-class-classification"]], "Multi-core parallelism using joblib.Parallel": [[392, "multi-core-parallelism-using-joblib-parallel"]], "Multi-dimensional Scaling (MDS)": [[997, "multi-dimensional-scaling-mds"]], "Multi-dimensional scaling": [[243, "multi-dimensional-scaling"]], "Multi-label case": [[1000, "multi-label-case"]], "Multi-label confusion matrix": [[1000, "multi-label-confusion-matrix"]], "Multi-layer Perceptron": [[1004, "multi-layer-perceptron"]], "Multi-layer perceptron": [[193, "multi-layer-perceptron"]], "Multi-output Decision Tree Regression": [[367, "multi-output-decision-tree-regression"]], "Multi-output problems": [[1016, "multi-output-problems"]], "Multi-task Elastic-Net": [[996, "multi-task-elastic-net"]], "Multi-task Lasso": [[996, "multi-task-lasso"]], "Multi-task linear regressors with variable selection": [[25, "multi-task-linear-regressors-with-variable-selection"]], "MultiLabelBinarizer": [[883, "multilabelbinarizer"], [1011, "multilabelbinarizer"]], "MultiOutputClassifier": [[844, "multioutputclassifier"], [1001, "multioutputclassifier"]], "MultiOutputRegressor": [[845, "multioutputregressor"], [1001, "multioutputregressor"]], "MultiTaskElasticNet": [[668, "multitaskelasticnet"]], "MultiTaskElasticNetCV": [[669, "multitaskelasticnetcv"]], "MultiTaskLasso": [[670, "multitasklasso"]], "MultiTaskLassoCV": [[671, "multitasklassocv"]], "Multiclass Receiver Operating Characteristic (ROC)": [[287, "multiclass-receiver-operating-characteristic-roc"]], "Multiclass and multilabel classification": [[1000, "multiclass-and-multilabel-classification"]], "Multiclass and multilabel utility function": [[395, "multiclass-and-multilabel-utility-function"]], "Multiclass and multioutput algorithms": [[1001, "multiclass-and-multioutput-algorithms"]], "Multiclass classification": [[1001, "multiclass-classification"], [1032, null]], "Multiclass methods": [[189, "multiclass-methods"], [295, "multiclass-methods"]], "Multiclass sparse logistic regression on 20newgroups": [[235, "multiclass-sparse-logistic-regression-on-20newgroups"]], "Multiclass support": [[414, "multiclass-support"]], "Multiclass vs. multilabel fitting": [[1025, "multiclass-vs-multilabel-fitting"]], "Multiclass-multioutput classification": [[1001, "multiclass-multioutput-classification"]], "Multidimensional scaling": [[240, "multidimensional-scaling"]], "Multilabel": [[382, "multilabel"]], "Multilabel classification": [[255, "multilabel-classification"], [1001, "multilabel-classification"]], "Multilabel classification using a classifier chain": [[298, "multilabel-classification-using-a-classifier-chain"]], "Multilabel ranking metrics": [[27, "multilabel-ranking-metrics"], [1000, "multilabel-ranking-metrics"]], "Multinomial Case": [[996, "multinomial-case"]], "Multinomial Naive Bayes": [[1002, "multinomial-naive-bayes"]], "MultinomialNB": [[851, "multinomialnb"]], "Multioutput methods": [[189, "multioutput-methods"], [297, "multioutput-methods"]], "Multioutput regression": [[1001, "multioutput-regression"]], "Multiple modules": [[1049, "multiple-modules"], [1050, "multiple-modules"]], "Multiple vs. Single Imputation": [[990, "multiple-vs-single-imputation"]], "Multivariate feature imputation": [[990, "multivariate-feature-imputation"]], "Mutual Information based scores": [[416, "mutual-information-based-scores"]], "Mutual Reachability Graph": [[416, "mutual-reachability-graph"]], "NMF": [[548, "nmf"]], "NMF with a beta-divergence": [[421, "nmf-with-a-beta-divergence"]], "NMF with the Frobenius norm": [[421, "nmf-with-the-frobenius-norm"]], "Naive Bayes": [[1002, "naive-bayes"]], "Naive evaluation of the next hour bike demand regression": [[52, "naive-evaluation-of-the-next-hour-bike-demand-regression"]], "Naive linear regression": [[43, "naive-linear-regression"]], "Native Categorical Feature Support": [[325, "native-categorical-feature-support"]], "Native support for categorical features in HistGradientBoosting estimators": [[330, "native-support-for-categorical-features-in-histgradientboosting-estimators"]], "Native support for missing values for gradient boosting": [[328, "native-support-for-missing-values-for-gradient-boosting"]], "Nearest Centroid Classification": [[310, "nearest-centroid-classification"]], "Nearest Centroid Classifier": [[1003, "nearest-centroid-classifier"]], "Nearest Neighbor Algorithms": [[1003, "nearest-neighbor-algorithms"]], "Nearest Neighbors": [[189, "nearest-neighbors"], [300, "nearest-neighbors"], [1003, "nearest-neighbors"]], "Nearest Neighbors Classification": [[302, "nearest-neighbors-classification"], [1003, "nearest-neighbors-classification"]], "Nearest Neighbors Regression": [[1003, "nearest-neighbors-regression"]], "Nearest Neighbors Transformer": [[1003, "nearest-neighbors-transformer"]], "Nearest Neighbors regression": [[311, "nearest-neighbors-regression"]], "Nearest Shrunken Centroid": [[1003, "nearest-shrunken-centroid"]], "Nearest neighbor and the curse of dimensionality": [[1032, "nearest-neighbor-and-the-curse-of-dimensionality"]], "Nearest neighbors imputation": [[990, "nearest-neighbors-imputation"]], "NearestCentroid": [[859, "nearestcentroid"]], "NearestNeighbors": [[860, "nearestneighbors"]], "Neighborhood Components Analysis": [[1003, "neighborhood-components-analysis"]], "Neighborhood Components Analysis Illustration": [[309, "neighborhood-components-analysis-illustration"]], "NeighborhoodComponentsAnalysis": [[861, "neighborhoodcomponentsanalysis"]], "Nested cross-validation": [[1029, null]], "Nested versus non-nested cross-validation": [[283, "nested-versus-non-nested-cross-validation"]], "NetBSD": [[404, "netbsd"]], "Neural Networks": [[189, "neural-networks"], [313, "neural-networks"]], "Neural network models (supervised)": [[1004, "neural-network-models-supervised"]], "Neural network models (unsupervised)": [[1005, "neural-network-models-unsupervised"]], "New Estimator Classes": [[1042, "new-estimator-classes"]], "New Poisson splitting criterion for DecisionTreeRegressor": [[330, "new-poisson-splitting-criterion-for-decisiontreeregressor"]], "New PolynomialCountSketch kernel approximation function": [[330, "new-polynomialcountsketch-kernel-approximation-function"]], "New SequentialFeatureSelector transformer": [[330, "new-sequentialfeatureselector-transformer"]], "New and enhanced displays": [[333, "new-and-enhanced-displays"]], "New classes": [[1041, "new-classes"]], "New display ValidationCurveDisplay": [[334, "new-display-validationcurvedisplay"]], "New documentation improvements": [[330, "new-documentation-improvements"], [331, "new-documentation-improvements"]], "New features": [[1044, "new-features"], [1045, "new-features"], [1046, "new-features"], [1047, "new-features"], [1048, "new-features"]], "New plotting API": [[328, "new-plotting-api"]], "New self-training meta-estimator": [[330, "new-self-training-meta-estimator"]], "New to Scientific Python?": [[1018, "new-to-scientific-python"]], "Next steps": [[399, "next-steps"]], "Non-Negative Least Squares": [[996, "non-negative-least-squares"]], "Non-linear transformation": [[1010, "non-linear-transformation"]], "Non-negative components - NMF": [[125, "non-negative-components-nmf"]], "Non-negative least squares": [[215, "non-negative-least-squares"]], "Non-negative matrix factorization (NMF or NNMF)": [[421, "non-negative-matrix-factorization-nmf-or-nnmf"]], "Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification": [[69, "normal-ledoit-wolf-and-oas-linear-discriminant-analysis-for-classification"]], "Normalization": [[1010, "normalization"]], "Normalized Discounted Cumulative Gain": [[1000, "normalized-discounted-cumulative-gain"]], "Normalizer": [[319, "normalizer"], [884, "normalizer"]], "NotFittedError": [[585, "notfittederror"]], "Note on MPS device support": [[412, "note-on-mps-device-support"]], "Notes": [[375, "notes"]], "Novelty Detection": [[1006, "novelty-detection"]], "Novelty and Outlier Detection": [[1006, "novelty-and-outlier-detection"]], "Novelty detection with Local Outlier Factor": [[1006, "novelty-detection-with-local-outlier-factor"]], "Novelty detection with Local Outlier Factor (LOF)": [[305, "novelty-detection-with-local-outlier-factor-lof"]], "NuSVC": [[914, "nusvc"]], "NuSVR": [[915, "nusvr"]], "NumPy": [[391, "numpy"]], "Number of candidates and amount of resource at each iteration": [[290, "number-of-candidates-and-amount-of-resource-at-each-iteration"]], "Numerical assertions in tests": [[388, "numerical-assertions-in-tests"]], "Nystroem": [[647, "nystroem"]], "Nystroem Method for Kernel Approximation": [[992, "nystroem-method-for-kernel-approximation"]], "OAS": [[483, "oas"]], "ONNX": [[410, "onnx"]], "OOB Errors for Random Forests": [[143, "oob-errors-for-random-forests"]], "OPTICS": [[416, "optics"], [458, "optics"]], "Obtaining predictions by cross-validation": [[420, "obtaining-predictions-by-cross-validation"]], "OkCupid": [[1024, "id19"]], "Older Versions": [[1041, "older-versions"]], "One-Class SVM versus One-Class SVM using Stochastic Gradient Descent": [[234, "one-class-svm-versus-one-class-svm-using-stochastic-gradient-descent"]], "One-class SVM with non-linear kernel (RBF)": [[348, "one-class-svm-with-non-linear-kernel-rbf"]], "One-vs-One multiclass ROC": [[287, "one-vs-one-multiclass-roc"]], "One-vs-Rest multiclass ROC": [[287, "one-vs-rest-multiclass-roc"]], "OneClassSVM": [[916, "oneclasssvm"]], "OneHotEncoder": [[885, "onehotencoder"]], "OneToOneFeatureMixin": [[437, "onetoonefeaturemixin"]], "OneVsOneClassifier": [[840, "onevsoneclassifier"], [1001, "onevsoneclassifier"]], "OneVsRestClassifier": [[841, "onevsrestclassifier"], [1001, "onevsrestclassifier"]], "Online One-Class SVM": [[331, "online-one-class-svm"], [1014, "online-one-class-svm"]], "Online learning of a dictionary of parts of faces": [[85, "online-learning-of-a-dictionary-of-parts-of-faces"]], "Open problem: Stock Market Structure": [[1030, "open-problem-stock-market-structure"]], "Optical recognition of handwritten digits dataset": [[383, "optical-recognition-of-handwritten-digits-dataset"]], "Optimal mathematical operations": [[41, "module-sklearn.utils.extmath"]], "Optimisation of kernel hyperparameters in GPR": [[182, "optimisation-of-kernel-hyperparameters-in-gpr"]], "Optional Arguments": [[388, "optional-arguments"]], "Options to tune the decision threshold": [[415, "options-to-tune-the-decision-threshold"]], "Oracle Approximating Shrinkage": [[418, "oracle-approximating-shrinkage"]], "OrdinalEncoder": [[886, "ordinalencoder"]], "Ordinary Least Squares": [[996, "ordinary-least-squares"]], "Ordinary Least Squares Complexity": [[996, "ordinary-least-squares-complexity"]], "Ordinary Least Squares and Ridge Regression Variance": [[218, "ordinary-least-squares-and-ridge-regression-variance"]], "Original data": [[284, "original-data"], [319, "original-data"]], "Original image": [[88, "original-image"]], "Original points": [[309, "original-points"]], "Orthogonal Matching Pursuit": [[219, "orthogonal-matching-pursuit"]], "Orthogonal Matching Pursuit (OMP)": [[996, "orthogonal-matching-pursuit-omp"]], "OrthogonalMatchingPursuit": [[672, "orthogonalmatchingpursuit"]], "OrthogonalMatchingPursuitCV": [[673, "orthogonalmatchingpursuitcv"]], "Other changes": [[1041, "other-changes"]], "Other estimators and tasks": [[1019, "other-estimators-and-tasks"]], "Otto Group": [[1024, "id26"]], "Our community, our values": [[386, null]], "Our vanilla classifier": [[292, "our-vanilla-classifier"]], "Out of Bag Estimates": [[989, "out-of-bag-estimates"]], "Out-of-core classification of text documents": [[47, "out-of-core-classification-of-text-documents"]], "Out-of-core naive Bayes model fitting": [[1002, "out-of-core-naive-bayes-model-fitting"]], "Outlier Detection": [[1006, "id1"]], "Outlier detection on a real data set": [[48, "outlier-detection-on-a-real-data-set"]], "Outlier detection with Local Outlier Factor (LOF)": [[306, "outlier-detection-with-local-outlier-factor-lof"]], "Outlier-robust regressors": [[25, "outlier-robust-regressors"]], "OutlierMixin": [[438, "outliermixin"]], "Outliers in the X direction": [[237, "outliers-in-the-x-direction"]], "Outliers only in the y direction": [[237, "outliers-only-in-the-y-direction"]], "Outline of the permutation importance algorithm": [[1008, "outline-of-the-permutation-importance-algorithm"]], "OutputCodeClassifier": [[842, "outputcodeclassifier"], [1001, "outputcodeclassifier"]], "Oversubscription: spawning too many threads": [[374, "oversubscription-spawning-too-many-threads"]], "Overview of clustering methods": [[416, "overview-of-clustering-methods"]], "Overview of multiclass training meta-estimators": [[296, "overview-of-multiclass-training-meta-estimators"]], "Overview of outlier detection methods": [[1006, "overview-of-outlier-detection-methods"]], "PCA": [[549, "pca"]], "PCA example with Iris Data-set": [[131, "pca-example-with-iris-data-set"]], "PCA using randomized SVD": [[421, "pca-using-randomized-svd"]], "PCA: principal component analysis": [[1017, "pca-principal-component-analysis"]], "PHIMECA Engineering": [[1024, "id15"]], "PLS regression, with multivariate response, a.k.a. PLS2": [[117, "pls-regression-with-multivariate-response-a-k-a-pls2"]], "PLS regression, with univariate response, a.k.a. PLS1": [[117, "pls-regression-with-univariate-response-a-k-a-pls1"]], "PLSCanonical": [[419, "plscanonical"], [491, "plscanonical"]], "PLSRegression": [[419, "plsregression"], [492, "plsregression"]], "PLSSVD": [[419, "plssvd"], [493, "plssvd"]], "Packaging": [[1053, "packaging"]], "Pair Confusion Matrix": [[416, "pair-confusion-matrix"]], "Pairwise comparison of all models: Bayesian approach": [[278, "pairwise-comparison-of-all-models-bayesian-approach"]], "Pairwise comparison of all models: frequentist approach": [[278, "pairwise-comparison-of-all-models-frequentist-approach"]], "Pairwise distances with non-numeric arrays": [[336, "pairwise-distances-with-non-numeric-arrays"]], "Pairwise metrics": [[27, "module-sklearn.metrics.pairwise"]], "Pairwise metrics, Affinities and Kernels": [[998, "pairwise-metrics-affinities-and-kernels"]], "PairwiseKernel": [[628, "pairwisekernel"]], "Pandas": [[391, "pandas"]], "Pandas output with set_output API": [[333, "pandas-output-with-set-output-api"]], "Parallel": [[966, "parallel"]], "Parallel NumPy and SciPy routines from numerical libraries": [[374, "parallel-numpy-and-scipy-routines-from-numerical-libraries"]], "Parallel computing": [[41, "module-sklearn.utils.parallel"]], "Parallelism": [[374, "parallelism"], [989, "parallelism"]], "Parallelism, resource management, and configuration": [[374, "parallelism-resource-management-and-configuration"]], "Parallelization": [[423, "parallelization"]], "Parameter tuning using grid search": [[1034, "parameter-tuning-using-grid-search"]], "ParameterGrid": [[819, "parametergrid"]], "ParameterSampler": [[820, "parametersampler"]], "Parameters": [[400, "parameters"], [423, "parameters"]], "Parameters and init": [[388, "parameters-and-init"]], "Parameters of the RBF Kernel": [[1015, "parameters-of-the-rbf-kernel"]], "Partial Dependence and Individual Conditional Expectation Plots": [[193, "partial-dependence-and-individual-conditional-expectation-plots"]], "Partial Dependence and Individual Conditional Expectation plots": [[1007, "partial-dependence-and-individual-conditional-expectation-plots"]], "Partial dependence plots": [[1007, "partial-dependence-plots"]], "PartialDependenceDisplay": [[640, "partialdependencedisplay"]], "Partitioning the data": [[197, "partitioning-the-data"]], "Passive Aggressive Algorithms": [[996, "passive-aggressive-algorithms"]], "PassiveAggressiveClassifier": [[674, "passiveaggressiveclassifier"]], "PassiveAggressiveRegressor": [[675, "passiveaggressiveregressor"]], "Past Sponsors": [[0, "past-sponsors"]], "Patch extraction": [[424, "patch-extraction"]], "PatchExtractor": [[591, "patchextractor"]], "PeerIndex": [[1024, "id17"]], "People": [[1041, "people"], [1041, "id2"], [1041, "id5"], [1041, "id8"], [1041, "id11"], [1041, "id13"], [1041, "id15"], [1041, "id17"], [1042, "people"], [1042, "id3"], [1043, "people"], [1044, "people"]], "Perceptron": [[676, "perceptron"], [996, "perceptron"]], "Performance improvements": [[332, "performance-improvements"]], "Performance improvements in PCA": [[336, "performance-improvements-in-pca"]], "Performing dimensionality reduction using LSA": [[361, "performing-dimensionality-reduction-using-lsa"]], "Periodic Splines": [[221, "periodic-splines"]], "Periodic spline features": [[43, "periodic-spline-features"]], "Permutation Importance vs Random Forest Feature Importance (MDI)": [[194, "permutation-importance-vs-random-forest-feature-importance-mdi"]], "Permutation Importance with Multicollinear or Correlated Features": [[195, "permutation-importance-with-multicollinear-or-correlated-features"]], "Permutation feature importance": [[1008, "permutation-feature-importance"]], "Permutation test score": [[284, "permutation-test-score"], [420, "permutation-test-score"]], "Permutation-based feature importance": [[328, "permutation-based-feature-importance"]], "Pinball loss": [[1000, "pinball-loss"]], "Pipeline": [[872, "pipeline"]], "Pipeline ANOVA SVM": [[171, "pipeline-anova-svm"]], "Pipeline compatibility": [[388, "pipeline-compatibility"]], "Pipeline with hyperparameter tuning": [[279, "pipeline-with-hyperparameter-tuning"]], "Pipeline: chaining estimators": [[417, "pipeline-chaining-estimators"]], "Pipelines and composite estimators": [[103, "pipelines-and-composite-estimators"], [189, "pipelines-and-composite-estimators"], [417, "pipelines-and-composite-estimators"]], "Pipelines: chaining pre-processors and estimators": [[399, "pipelines-chaining-pre-processors-and-estimators"]], "Pipelining": [[1017, null], [1030, "pipelining"]], "Pipelining: chaining a PCA and a logistic regression": [[107, "pipelining-chaining-a-pca-and-a-logistic-regression"]], "Pixel importances with a parallel forest of trees": [[147, "pixel-importances-with-a-parallel-forest-of-trees"]], "Platform-specific instructions": [[384, "platform-specific-instructions"]], "Plot Hierarchical Clustering Dendrogram": [[76, "plot-hierarchical-clustering-dendrogram"]], "Plot Precision-Recall curve for each class and iso-f1 curves": [[285, "plot-precision-recall-curve-for-each-class-and-iso-f1-curves"]], "Plot ROC and DET curves": [[275, "plot-roc-and-det-curves"]], "Plot Ridge coefficients as a function of the regularization": [[225, "plot-ridge-coefficients-as-a-function-of-the-regularization"]], "Plot a PCA representation": [[121, "plot-a-pca-representation"]], "Plot accuracy, training and test time of each classifier": [[360, "plot-accuracy-training-and-test-time-of-each-classifier"]], "Plot all OvO ROC curves together": [[287, "plot-all-ovo-roc-curves-together"]], "Plot all OvR ROC curves together": [[287, "plot-all-ovr-roc-curves-together"]], "Plot and analysis of the results": [[204, "plot-and-analysis-of-the-results"]], "Plot and interpret results": [[257, "plot-and-interpret-results"]], "Plot class probabilities calculated by the VotingClassifier": [[162, "plot-class-probabilities-calculated-by-the-votingclassifier"]], "Plot classification boundaries with different SVM Kernels": [[353, "plot-classification-boundaries-with-different-svm-kernels"]], "Plot classification probability": [[66, "plot-classification-probability"]], "Plot data and the predicted probabilities": [[61, "plot-data-and-the-predicted-probabilities"]], "Plot different SVM classifiers in the iris dataset": [[346, "plot-different-svm-classifiers-in-the-iris-dataset"]], "Plot discrete decision boundary": [[156, "plot-discrete-decision-boundary"]], "Plot error lines showing +/- std. errors of the scores": [[165, "plot-error-lines-showing-std-errors-of-the-scores"]], "Plot feature importance": [[153, "plot-feature-importance"]], "Plot individual and voting regression predictions": [[163, "plot-individual-and-voting-regression-predictions"]], "Plot multi-class SGD on the iris dataset": [[229, "plot-multi-class-sgd-on-the-iris-dataset"]], "Plot multinomial and One-vs-Rest Logistic Regression": [[212, "plot-multinomial-and-one-vs-rest-logistic-regression"]], "Plot number of features VS. cross-validation scores": [[173, "plot-number-of-features-vs-cross-validation-scores"]], "Plot path length decision boundary": [[156, "plot-path-length-decision-boundary"]], "Plot randomly generated classification dataset": [[122, "plot-randomly-generated-classification-dataset"]], "Plot randomly generated multilabel dataset": [[123, "plot-randomly-generated-multilabel-dataset"]], "Plot regularization path": [[213, "plot-regularization-path"]], "Plot result": [[73, "plot-result"], [98, "plot-result"], [102, "plot-result"], [102, "id2"]], "Plot results": [[47, "plot-results"], [84, "plot-results"], [111, "plot-results"], [126, "plot-results"], [127, "plot-results"], [145, "plot-results"], [298, "plot-results"], [306, "plot-results"]], "Plot results functions": [[291, "plot-results-functions"]], "Plot support and time series": [[214, "plot-support-and-time-series"]], "Plot the BIC scores": [[268, "plot-the-bic-scores"]], "Plot the Precision-Recall curve": [[285, "plot-the-precision-recall-curve"]], "Plot the best model": [[268, "plot-the-best-model"]], "Plot the cross-validation score as a function of percentile of features": [[352, "plot-the-cross-validation-score-as-a-function-of-percentile-of-features"]], "Plot the decision boundaries of a VotingClassifier": [[161, "plot-the-decision-boundaries-of-a-votingclassifier"]], "Plot the decision surface of decision trees trained on the iris dataset": [[365, "plot-the-decision-surface-of-decision-trees-trained-on-the-iris-dataset"]], "Plot the decision surfaces of ensembles of trees on the iris dataset": [[148, "plot-the-decision-surfaces-of-ensembles-of-trees-on-the-iris-dataset"]], "Plot the marginal log-likelihood": [[199, "plot-the-marginal-log-likelihood"]], "Plot the micro-averaged Precision-Recall curve": [[285, "plot-the-micro-averaged-precision-recall-curve"]], "Plot the most uncertain predictions": [[338, "plot-the-most-uncertain-predictions"]], "Plot the results": [[85, "plot-the-results"], [115, "plot-the-results"], [163, "plot-the-results"], [188, "plot-the-results"]], "Plot the results on an image": [[82, "plot-the-results-on-an-image"]], "Plot the support vectors in LinearSVC": [[347, "plot-the-support-vectors-in-linearsvc"]], "Plot the true and estimated coefficients": [[199, "plot-the-true-and-estimated-coefficients"]], "Plot the true and predicted curves with log marginal likelihood (L)": [[200, "plot-the-true-and-predicted-curves-with-log-marginal-likelihood-l"]], "Plot training deviance": [[153, "plot-training-deviance"]], "Plotting": [[21, "plotting"], [27, "plotting"], [40, "plotting"], [317, "plotting"]], "Plotting API Overview": [[393, "plotting-api-overview"]], "Plotting Cross-Validated Predictions": [[274, "plotting-cross-validated-predictions"]], "Plotting Functions": [[70, "plotting-functions"]], "Plotting Learning Curves and Checking Models\u2019 Scalability": [[280, "plotting-learning-curves-and-checking-models-scalability"]], "Plotting Validation Curves": [[294, "plotting-validation-curves"]], "Plotting four circles": [[101, "plotting-four-circles"]], "Plotting partial dependence for one feature": [[258, "plotting-partial-dependence-for-one-feature"]], "Plotting partial dependence for two features": [[258, "plotting-partial-dependence-for-two-features"]], "Plotting partial dependence of the two models together": [[258, "plotting-partial-dependence-of-the-two-models-together"]], "Plotting polynomial regressions with std errors of the scores": [[199, "plotting-polynomial-regressions-with-std-errors-of-the-scores"]], "Plotting results": [[58, "plotting-results"]], "Plotting the ROC Curve": [[260, "plotting-the-roc-curve"]], "Plotting the Results": [[325, "plotting-the-results"]], "Plotting the result": [[282, "plotting-the-result"]], "Plotting the results": [[99, "plotting-the-results"], [140, "plotting-the-results"]], "Plotting trained Coefficients and Mean Squared Errors": [[224, "plotting-trained-coefficients-and-mean-squared-errors"]], "Plotting two circles": [[101, "plotting-two-circles"]], "Plotting with Multiple Axes": [[393, "plotting-with-multiple-axes"]], "Poisson regression and non-normal loss": [[220, "poisson-regression-and-non-normal-loss"]], "PoissonRegressor": [[677, "poissonregressor"]], "Polars output in set_output": [[335, "polars-output-in-set-output"]], "Polynomial Kernel Approximation via Tensor Sketch": [[992, "polynomial-kernel-approximation-via-tensor-sketch"]], "Polynomial and Spline interpolation": [[221, "polynomial-and-spline-interpolation"]], "Polynomial features": [[1010, "polynomial-features"]], "Polynomial kernel": [[353, "polynomial-kernel"], [998, "polynomial-kernel"], [1032, "polynomial-kernel"]], "Polynomial regression: extending linear models with basis functions": [[996, "polynomial-regression-extending-linear-models-with-basis-functions"]], "PolynomialCountSketch": [[648, "polynomialcountsketch"]], "PolynomialFeatures": [[887, "polynomialfeatures"]], "Possible solutions": [[92, "possible-solutions"]], "Post pruning decision trees with cost complexity pruning": [[364, "post-pruning-decision-trees-with-cost-complexity-pruning"]], "Post-fit model tuning": [[29, "post-fit-model-tuning"]], "Post-hoc tuning the cut-off point of decision function": [[292, "post-hoc-tuning-the-cut-off-point-of-decision-function"]], "Post-tuning the decision threshold": [[415, "post-tuning-the-decision-threshold"]], "Post-tuning the decision threshold for cost-sensitive learning": [[272, "post-tuning-the-decision-threshold-for-cost-sensitive-learning"]], "PowerTransformer": [[319, "powertransformer"], [888, "powertransformer"]], "Pre-test vs. post-test analysis": [[281, "pre-test-vs-post-test-analysis"]], "Precision, recall and F-measures": [[1000, "precision-recall-and-f-measures"]], "Precision-Recall": [[285, "precision-recall"]], "PrecisionRecallDisplay": [[708, "precisionrecalldisplay"]], "Precomputed sparse nearest neighbors graph": [[328, "precomputed-sparse-nearest-neighbors-graph"]], "Predefined fold-splits / Validation-sets": [[420, "predefined-fold-splits-validation-sets"]], "PredefinedSplit": [[821, "predefinedsplit"]], "Prediction Intervals for Gradient Boosting Regression": [[152, "prediction-intervals-for-gradient-boosting-regression"]], "Prediction Latency": [[49, "prediction-latency"], [373, "prediction-latency"]], "Prediction Throughput": [[373, "prediction-throughput"]], "PredictionErrorDisplay": [[709, "predictionerrordisplay"]], "Preparing a release PR": [[390, "preparing-a-release-pr"]], "Preparing the data": [[140, "preparing-the-data"], [155, "preparing-the-data"], [197, "preparing-the-data"]], "Preprocessing": [[189, "preprocessing"], [318, "preprocessing"]], "Preprocessing data": [[1010, "preprocessing-data"]], "Preprocessing numerical variables": [[192, "preprocessing-numerical-variables"]], "Preprocessor for machine-learning models": [[193, "preprocessor-for-machine-learning-models"]], "Preprocessor for the gradient boosting model": [[193, "preprocessor-for-the-gradient-boosting-model"]], "Preprocessor for the neural network model": [[193, "preprocessor-for-the-neural-network-model"]], "Principal Component Regression vs Partial Least Squares Regression": [[118, "principal-component-regression-vs-partial-least-squares-regression"]], "Principal component analysis (PCA)": [[421, "principal-component-analysis-pca"]], "Principal component analysis: PCA": [[1033, "principal-component-analysis-pca"]], "Private Loss Function Module": [[1058, "private-loss-function-module"]], "Probabilistic predictions with GPC": [[426, "probabilistic-predictions-with-gpc"]], "Probabilistic predictions with Gaussian process classification (GPC)": [[177, "probabilistic-predictions-with-gaussian-process-classification-gpc"]], "Probability Calibration curves": [[62, "probability-calibration-curves"]], "Probability Calibration for 3-class classification": [[63, "probability-calibration-for-3-class-classification"]], "Probability calibration": [[414, "probability-calibration"]], "Probability calibration of classifiers": [[61, "probability-calibration-of-classifiers"]], "Processing the dataset": [[192, "processing-the-dataset"]], "Product": [[629, "product"]], "Productivity and sanity-preserving tips": [[394, "productivity-and-sanity-preserving-tips"]], "Profiling Python code": [[392, "profiling-python-code"]], "Profiling compiled extensions": [[392, "profiling-compiled-extensions"]], "Project template:": [[388, null]], "Projecting data: PCA vs. KernelPCA": [[130, "projecting-data-pca-vs-kernelpca"]], "Projecting into the original feature space": [[130, "projecting-into-the-original-feature-space"]], "Projection on one component and predictive power": [[118, "projection-on-one-component-and-predictive-power"]], "Proper next hour forecasting evaluation": [[52, "proper-next-hour-forecasting-evaluation"]], "Provide a failing code example with minimal comments": [[391, "provide-a-failing-code-example-with-minimal-comments"]], "Pull request checklist": [[386, "pull-request-checklist"]], "Pure Premium Modeling via a Product Model vs single TweedieRegressor": [[238, "pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor"]], "Purpose of this document": [[1020, "purpose-of-this-document"]], "Purpose of this example": [[224, "purpose-of-this-example"]], "Putting it all together": [[1030, "putting-it-all-together"]], "PyTorch Support": [[412, "pytorch-support"]], "Python API": [[374, "python-api"]], "Python package and dataset imports, load dataset": [[252, "python-package-and-dataset-imports-load-dataset"]], "Python, Cython or C/C++?": [[392, "python-cython-or-c-c"]], "QDA": [[994, "qda"]], "QuadraticDiscriminantAnalysis": [[558, "quadraticdiscriminantanalysis"]], "Qualitative analysis of the impact of features on linear model predictions": [[43, "qualitative-analysis-of-the-impact-of-features-on-linear-model-predictions"]], "Quantifying the quality of clustering results": [[361, "quantifying-the-quality-of-clustering-results"]], "Quantile Regression": [[996, "quantile-regression"]], "Quantile Regressor": [[331, "quantile-regressor"]], "Quantile loss in HistGradientBoostingRegressor": [[332, "quantile-loss-in-histgradientboostingregressor"]], "Quantile regression": [[222, "quantile-regression"]], "QuantileRegressor": [[678, "quantileregressor"]], "QuantileTransformer": [[889, "quantiletransformer"]], "QuantileTransformer (Gaussian output)": [[319, "quantiletransformer-gaussian-output"]], "QuantileTransformer (uniform output)": [[319, "quantiletransformer-uniform-output"]], "RANSAC: RANdom SAmple Consensus": [[996, "ransac-random-sample-consensus"]], "RANSACRegressor": [[679, "ransacregressor"]], "RBF": [[630, "rbf"]], "RBF SVM parameters": [[349, "rbf-svm-parameters"]], "RBF kernel": [[353, "rbf-kernel"], [998, "rbf-kernel"]], "RBF kernel (Radial Basis Function)": [[1032, "rbf-kernel-radial-basis-function"]], "RBFSampler": [[649, "rbfsampler"]], "RCV1 dataset": [[381, "rcv1-dataset"]], "RFE": [[601, "rfe"]], "RFECV": [[602, "rfecv"]], "ROC AUC now supports multiclass classification": [[328, "roc-auc-now-supports-multiclass-classification"]], "ROC Curve with Visualization API": [[260, "roc-curve-with-visualization-api"]], "ROC curve showing a specific class": [[287, "roc-curve-showing-a-specific-class"]], "ROC curve using micro-averaged OvR": [[287, "roc-curve-using-micro-averaged-ovr"]], "ROC curve using the OvO macro-average": [[287, "roc-curve-using-the-ovo-macro-average"]], "ROC curve using the OvR macro-average": [[287, "roc-curve-using-the-ovr-macro-average"]], "Radial Basis Function Kernel": [[992, "radial-basis-function-kernel"]], "Radial Basis Function kernel": [[185, "radial-basis-function-kernel"]], "Radial basis function (RBF) kernel": [[426, "radial-basis-function-rbf-kernel"]], "RadiusNeighborsClassifier": [[862, "radiusneighborsclassifier"]], "RadiusNeighborsRegressor": [[863, "radiusneighborsregressor"]], "RadiusNeighborsTransformer": [[864, "radiusneighborstransformer"]], "Rand index": [[416, "rand-index"]], "Random Forest Feature Importance on Breast Cancer Data": [[195, "random-forest-feature-importance-on-breast-cancer-data"]], "Random Forests": [[423, "random-forests"]], "Random Numbers": [[388, "random-numbers"]], "Random Projection": [[1012, "random-projection"]], "Random data": [[284, "random-data"]], "Random forests and other randomized tree ensembles": [[423, "random-forests-and-other-randomized-tree-ensembles"]], "Random permutations cross-validation a.k.a. Shuffle & Split": [[420, "random-permutations-cross-validation-a-k-a-shuffle-split"]], "Random projections": [[1017, "random-projections"]], "Random sampling": [[41, "module-sklearn.utils.random"]], "RandomForestClassifier": [[572, "randomforestclassifier"]], "RandomForestRegressor": [[573, "randomforestregressor"]], "RandomTreesEmbedding": [[574, "randomtreesembedding"]], "Randomized Parameter Optimization": [[989, "randomized-parameter-optimization"]], "RandomizedSearchCV": [[822, "randomizedsearchcv"]], "Rangespan": [[1024, "id11"]], "Ranking loss": [[1000, "ranking-loss"]], "Rational Quadradtic kernel": [[185, "rational-quadradtic-kernel"]], "Rational quadratic kernel": [[426, "rational-quadratic-kernel"]], "RationalQuadratic": [[631, "rationalquadratic"]], "Reading the existing code base": [[386, "reading-the-existing-code-base"]], "Real world datasets": [[381, "real-world-datasets"]], "Real-world data set": [[109, "real-world-data-set"]], "Receiver Operating Characteristic (ROC) with cross validation": [[288, "receiver-operating-characteristic-roc-with-cross-validation"]], "Receiver operating characteristic (ROC)": [[1000, "receiver-operating-characteristic-roc"]], "Recently Deprecated": [[1, "recently-deprecated"]], "Recognizing hand-written digits": [[68, "recognizing-hand-written-digits"]], "Recommendation": [[381, null]], "Recommendation Engine packages": [[1019, "recommendation-engine-packages"]], "Reconstruct and denoise test images": [[44, "reconstruct-and-denoise-test-images"]], "Recursive feature elimination": [[172, "recursive-feature-elimination"], [425, "recursive-feature-elimination"]], "Recursive feature elimination with cross-validation": [[173, "recursive-feature-elimination-with-cross-validation"]], "References": [[50, "references"], [62, "references"], [64, "references"], [114, "references"], [142, "references"], [197, "references"], [204, "references"], [296, "references"], [312, "references"], [426, "references"], [990, "references"]], "Refitting and updating parameters": [[1025, "refitting-and-updating-parameters"]], "Region of Practical Equivalence": [[278, "region-of-practical-equivalence"]], "Regression": [[184, "regression"], [996, "regression"], [1004, "regression"], [1014, "regression"], [1015, "regression"], [1016, "regression"]], "Regression criteria": [[1016, "regression-criteria"]], "Regression metrics": [[27, "regression-metrics"], [1000, "regression-metrics"]], "RegressorChain": [[846, "regressorchain"], [1001, "regressorchain"]], "RegressorMixin": [[439, "regressormixin"]], "Regressors with variable selection": [[25, "regressors-with-variable-selection"]], "Regularization": [[1004, "regularization"]], "Regularization path of L1- Logistic Regression": [[213, "regularization-path-of-l1-logistic-regression"]], "Related Projects": [[1019, "related-projects"]], "Related changes": [[1048, "related-changes"]], "Relation to impurity-based importance in trees": [[1008, "relation-to-impurity-based-importance-in-trees"]], "Release Highlights": [[189, "release-highlights"], [327, "release-highlights"]], "Release Highlights for scikit-learn 0.22": [[328, "release-highlights-for-scikit-learn-0-22"]], "Release Highlights for scikit-learn 0.23": [[329, "release-highlights-for-scikit-learn-0-23"]], "Release Highlights for scikit-learn 0.24": [[330, "release-highlights-for-scikit-learn-0-24"]], "Release Highlights for scikit-learn 1.0": [[331, "release-highlights-for-scikit-learn-1-0"]], "Release Highlights for scikit-learn 1.1": [[332, "release-highlights-for-scikit-learn-1-1"]], "Release Highlights for scikit-learn 1.2": [[333, "release-highlights-for-scikit-learn-1-2"]], "Release Highlights for scikit-learn 1.3": [[334, "release-highlights-for-scikit-learn-1-3"]], "Release Highlights for scikit-learn 1.4": [[335, "release-highlights-for-scikit-learn-1-4"]], "Release Highlights for scikit-learn 1.5": [[336, "release-highlights-for-scikit-learn-1-5"]], "Release History": [[1039, "release-history"]], "Release checklist": [[390, "release-checklist"]], "Releasing": [[390, "releasing"]], "Remarks": [[251, "remarks"]], "Removed modules": [[1041, "removed-modules"]], "Removing features with low variance": [[425, "removing-features-with-low-variance"]], "Repeated K-Fold": [[420, "repeated-k-fold"]], "RepeatedKFold": [[823, "repeatedkfold"]], "RepeatedStratifiedKFold": [[824, "repeatedstratifiedkfold"]], "Replace missing values by 0": [[188, "replace-missing-values-by-0"]], "Replicating the training environment in production": [[410, "replicating-the-training-environment-in-production"]], "Restricted Boltzmann Machine features for digit classification": [[317, "restricted-boltzmann-machine-features-for-digit-classification"]], "Restricted Boltzmann machines": [[1005, "restricted-boltzmann-machines"]], "Results interpretation": [[298, "results-interpretation"]], "Retrieve dataframes from OpenML": [[328, "retrieve-dataframes-from-openml"]], "Retrieve the data from Internet": [[51, "retrieve-the-data-from-internet"]], "Reuters Dataset related routines": [[47, "reuters-dataset-related-routines"]], "Rich HTML representation": [[249, "rich-html-representation"]], "Rich visual representation of estimators": [[329, "rich-visual-representation-of-estimators"]], "Ridge": [[680, "ridge"]], "Ridge Complexity": [[996, "ridge-complexity"]], "Ridge coefficients as a function of the L2 Regularization": [[224, "ridge-coefficients-as-a-function-of-the-l2-regularization"]], "Ridge regression and classification": [[996, "ridge-regression-and-classification"]], "RidgeCV": [[681, "ridgecv"]], "RidgeClassifier": [[682, "ridgeclassifier"]], "RidgeClassifierCV": [[683, "ridgeclassifiercv"]], "Roadmap": [[1020, "roadmap"]], "Robust Covariance Estimation": [[418, "robust-covariance-estimation"]], "Robust covariance estimation and Mahalanobis distances relevance": [[113, "robust-covariance-estimation-and-mahalanobis-distances-relevance"]], "Robust linear estimator fitting": [[226, "robust-linear-estimator-fitting"]], "Robust linear model estimation using RANSAC": [[223, "robust-linear-model-estimation-using-ransac"]], "Robust vs Empirical covariance estimate": [[114, "robust-vs-empirical-covariance-estimate"]], "RobustScaler": [[319, "robustscaler"], [890, "robustscaler"]], "Robustness of cross-validation results": [[369, "robustness-of-cross-validation-results"]], "Robustness regression: outliers and modeling errors": [[996, "robustness-regression-outliers-and-modeling-errors"]], "Robustness to failure": [[989, "robustness-to-failure"]], "RocCurveDisplay": [[710, "roccurvedisplay"]], "Roles And Responsibilities": [[401, "roles-and-responsibilities"]], "Rolling your own estimator": [[388, "rolling-your-own-estimator"]], "Routing Meta-Estimator": [[254, "routing-meta-estimator"]], "Run the benchmark": [[93, "run-the-benchmark"]], "Run the code and plot the results": [[46, "run-the-code-and-plot-the-results"]], "Running GridSearchCV using multiple evaluation metrics": [[282, "running-gridsearchcv-using-multiple-evaluation-metrics"]], "Runtime dependencies": [[384, "runtime-dependencies"]], "R\u00b2 score, the coefficient of determination": [[1000, "r2-score-the-coefficient-of-determination"]], "SGD": [[1014, "id5"]], "SGD: Maximum margin separating hyperplane": [[232, "sgd-maximum-margin-separating-hyperplane"]], "SGD: Penalties": [[231, "sgd-penalties"]], "SGD: Weighted samples": [[233, "sgd-weighted-samples"]], "SGD: convex loss functions": [[230, "sgd-convex-loss-functions"]], "SGDClassifier": [[684, "sgdclassifier"]], "SGDOneClassSVM": [[685, "sgdoneclasssvm"]], "SGDRegressor": [[686, "sgdregressor"]], "SKLEARN_ASSUME_FINITE": [[374, "sklearn-assume-finite"]], "SKLEARN_BUILD_ENABLE_DEBUG_SYMBOLS": [[374, "sklearn-build-enable-debug-symbols"]], "SKLEARN_ENABLE_DEBUG_CYTHON_DIRECTIVES": [[374, "sklearn-enable-debug-cython-directives"]], "SKLEARN_PAIRWISE_DIST_CHUNK_SIZE": [[374, "sklearn-pairwise-dist-chunk-size"]], "SKLEARN_RUN_FLOAT32_TESTS": [[374, "sklearn-run-float32-tests"]], "SKLEARN_SEED": [[374, "sklearn-seed"]], "SKLEARN_SKIP_NETWORK_TESTS": [[374, "sklearn-skip-network-tests"]], "SKLEARN_TESTS_GLOBAL_RANDOM_SEED": [[374, "sklearn-tests-global-random-seed"]], "SKLEARN_WARNINGS_AS_ERRORS": [[374, "sklearn-warnings-as-errors"]], "SKLEARN_WORKING_MEMORY": [[374, "sklearn-working-memory"]], "SVC": [[917, "svc"], [1015, "svc"]], "SVM Exercise": [[167, "svm-exercise"]], "SVM Margins Example": [[354, "svm-margins-example"]], "SVM Tie Breaking Example": [[357, "svm-tie-breaking-example"]], "SVM with custom kernel": [[345, "svm-with-custom-kernel"]], "SVM-Anova: SVM with univariate feature selection": [[352, "svm-anova-svm-with-univariate-feature-selection"]], "SVM: Maximum margin separating hyperplane": [[350, "svm-maximum-margin-separating-hyperplane"]], "SVM: Separating hyperplane for unbalanced classes": [[351, "svm-separating-hyperplane-for-unbalanced-classes"]], "SVM: Weighted samples": [[358, "svm-weighted-samples"]], "SVR": [[918, "svr"], [1015, "svr"]], "Sample generators": [[10, "sample-generators"]], "Sample images": [[380, "sample-images"]], "Sample pipeline for text feature extraction and evaluation": [[279, "sample-pipeline-for-text-feature-extraction-and-evaluation"]], "Sample weight support": [[423, "sample-weight-support"]], "Sample-weight support for Lasso and ElasticNet": [[329, "sample-weight-support-for-lasso-and-elasticnet"]], "Scalability and stability improvements to KMeans": [[329, "scalability-and-stability-improvements-to-kmeans"]], "Scalable learning with polynomial kernel approximation": [[197, "scalable-learning-with-polynomial-kernel-approximation"]], "Scale Invariance": [[90, "scale-invariance"]], "Scaling data with outliers": [[1010, "scaling-data-with-outliers"]], "Scaling features to a range": [[1010, "scaling-features-to-a-range"]], "Scaling sparse data": [[1010, "scaling-sparse-data"]], "Scaling the regularization parameter for SVCs": [[356, "scaling-the-regularization-parameter-for-svcs"]], "Scaling up the One-Class SVM": [[1006, "scaling-up-the-one-class-svm"]], "Scaling with instances using out-of-core learning": [[375, "scaling-with-instances-using-out-of-core-learning"]], "Scatter Plot of the Iris dataset": [[121, "scatter-plot-of-the-iris-dataset"]], "Scatter plot of scores": [[117, "scatter-plot-of-scores"]], "Scikit-learn governance and decision-making": [[401, "scikit-learn-governance-and-decision-making"]], "Score, and cross-validated scores": [[1029, "score-and-cross-validated-scores"]], "Scores and probabilities": [[1015, "scores-and-probabilities"]], "Searching for optimal parameters with successive halving": [[989, "searching-for-optimal-parameters-with-successive-halving"]], "Second example": [[48, "second-example"]], "Second experiment: varying number of classes and clusters": [[72, "second-experiment-varying-number-of-classes-and-clusters"]], "Section contents": [[1025, null]], "Security": [[1059, "security"]], "Security & Maintainability Limitations": [[410, "security-maintainability-limitations"]], "Segmenting the picture of greek coins in regions": [[81, "segmenting-the-picture-of-greek-coins-in-regions"]], "SelectFdr": [[603, "selectfdr"]], "SelectFpr": [[604, "selectfpr"]], "SelectFromModel": [[605, "selectfrommodel"]], "SelectFwe": [[606, "selectfwe"]], "SelectKBest": [[607, "selectkbest"]], "SelectPercentile": [[608, "selectpercentile"]], "Selecting Lasso via an information criterion": [[209, "selecting-lasso-via-an-information-criterion"]], "Selecting Lasso via cross-validation": [[209, "selecting-lasso-via-cross-validation"]], "Selecting dimensionality reduction with Pipeline and GridSearchCV": [[106, "selecting-dimensionality-reduction-with-pipeline-and-gridsearchcv"]], "Selecting features based on importance": [[174, "selecting-features-based-on-importance"]], "Selecting features with Sequential Feature Selection": [[174, "selecting-features-with-sequential-feature-selection"]], "Selecting the number of clusters with silhouette analysis on KMeans clustering": [[95, "selecting-the-number-of-clusters-with-silhouette-analysis-on-kmeans-clustering"]], "SelectorMixin": [[609, "selectormixin"]], "Self Training": [[1013, "self-training"]], "SelfTrainingClassifier": [[909, "selftrainingclassifier"]], "Semi Supervised Classification": [[189, "semi-supervised-classification"], [337, "semi-supervised-classification"]], "Semi-supervised Classification on a Text Dataset": [[342, "semi-supervised-classification-on-a-text-dataset"]], "Semi-supervised learning": [[338, "semi-supervised-learning"], [1013, "semi-supervised-learning"]], "Sequence similarity matrix under the kernel": [[184, "sequence-similarity-matrix-under-the-kernel"]], "Sequential Feature Selection": [[425, "sequential-feature-selection"]], "SequentialFeatureSelector": [[610, "sequentialfeatureselector"]], "Serving the model artifact": [[410, "serving-the-model-artifact"]], "Setting regularization parameter": [[996, "setting-regularization-parameter"]], "Setting the regularization parameter: leave-one-out Cross-Validation": [[996, "setting-the-regularization-parameter-leave-one-out-cross-validation"]], "Severity Model -  Gamma distribution": [[238, "severity-model-gamma-distribution"]], "Shape of the data arrays": [[1025, null]], "Shrinkage": [[1032, "shrinkage"]], "Shrinkage and Covariance Estimator": [[994, "shrinkage-and-covariance-estimator"]], "Shrinkage and sparsity with logistic regression": [[1032, null]], "Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood": [[111, "shrinkage-covariance-estimation-ledoitwolf-vs-oas-and-max-likelihood"]], "Shrinkage via learning rate": [[423, "shrinkage-via-learning-rate"]], "Shrunk Covariance": [[418, "shrunk-covariance"]], "ShrunkCovariance": [[484, "shrunkcovariance"]], "ShuffleSplit": [[825, "shufflesplit"]], "Sigmoid": [[414, "sigmoid"]], "Sigmoid kernel": [[353, "sigmoid-kernel"], [998, "sigmoid-kernel"], [1032, "sigmoid-kernel"]], "Silhouette Coefficient": [[416, "silhouette-coefficient"]], "Simple 1D Kernel Density Estimation": [[304, "simple-1d-kernel-density-estimation"]], "Simple Pipeline": [[254, "simple-pipeline"]], "SimpleImputer": [[638, "simpleimputer"]], "Single estimator versus bagging: bias-variance decomposition": [[142, "single-estimator-versus-bagging-bias-variance-decomposition"]], "Single label": [[382, "single-label"]], "Skewed Chi Squared Kernel": [[992, "skewed-chi-squared-kernel"]], "SkewedChi2Sampler": [[650, "skewedchi2sampler"]], "Social Media": [[1023, "social-media"]], "Solvers": [[996, "solvers"]], "Sparse coding with a precomputed dictionary": [[134, "sparse-coding-with-a-precomputed-dictionary"], [421, "sparse-coding-with-a-precomputed-dictionary"]], "Sparse components - MiniBatchSparsePCA": [[125, "sparse-components-minibatchsparsepca"]], "Sparse input": [[1010, null]], "Sparse inverse covariance": [[418, "sparse-inverse-covariance"]], "Sparse inverse covariance estimation": [[115, "sparse-inverse-covariance-estimation"]], "Sparse principal components analysis (SparsePCA and MiniBatchSparsePCA)": [[421, "sparse-principal-components-analysis-sparsepca-and-minibatchsparsepca"]], "Sparse random projection": [[1012, "sparse-random-projection"]], "SparseCoder": [[550, "sparsecoder"]], "SparsePCA": [[551, "sparsepca"]], "SparseRandomProjection": [[905, "sparserandomprojection"]], "Sparsity": [[424, "sparsity"], [1032, "sparsity"]], "Sparsity Example: Fitting only features 1  and 2": [[217, "sparsity-example-fitting-only-features-1-and-2"]], "Species distribution dataset": [[381, "species-distribution-dataset"]], "Species distribution modeling": [[50, "species-distribution-modeling"]], "Specific models": [[388, "specific-models"]], "Specifying an objective metric": [[989, "specifying-an-objective-metric"]], "Specifying multiple metrics for evaluation": [[989, "specifying-multiple-metrics-for-evaluation"]], "Spectral Biclustering": [[413, "spectral-biclustering"]], "Spectral Clustering Graphs": [[416, "spectral-clustering-graphs"]], "Spectral Co-Clustering": [[413, "spectral-co-clustering"]], "Spectral Embedding": [[997, "spectral-embedding"]], "Spectral clustering": [[416, "spectral-clustering"]], "Spectral clustering for image segmentation": [[101, "spectral-clustering-for-image-segmentation"]], "Spectral embedding for non-linear dimensionality reduction": [[240, "spectral-embedding-for-non-linear-dimensionality-reduction"]], "SpectralBiclustering": [[459, "spectralbiclustering"]], "SpectralClustering": [[460, "spectralclustering"]], "SpectralCoclustering": [[461, "spectralcoclustering"]], "SpectralEmbedding": [[699, "spectralembedding"]], "Sphinx version": [[386, null]], "Spline Transformers": [[331, "spline-transformers"]], "Spline transformer": [[1010, "spline-transformer"]], "SplineTransformer": [[891, "splinetransformer"]], "Splitters": [[29, "splitters"]], "Spotify": [[1024, "id2"]], "Sprints": [[0, "sprints"]], "Stack of predictors on a single data set": [[160, "stack-of-predictors-on-a-single-data-set"]], "Stacked generalization": [[423, "stacked-generalization"]], "Stacking Classifier and Regressor": [[328, "stacking-classifier-and-regressor"]], "StackingClassifier": [[575, "stackingclassifier"]], "StackingRegressor": [[576, "stackingregressor"]], "Stalled and Unclaimed Issues": [[386, "stalled-and-unclaimed-issues"]], "Stalled pull requests": [[386, "stalled-pull-requests"]], "Standard replies for reviewing": [[394, "standard-replies-for-reviewing"]], "StandardScaler": [[319, "standardscaler"], [892, "standardscaler"]], "Standardization, or mean removal and variance scaling": [[1010, "standardization-or-mean-removal-and-variance-scaling"]], "Statement of purpose: Scikit-learn in 2018": [[1020, "statement-of-purpose-scikit-learn-in-2018"]], "Statistical comparison of models using grid search": [[278, "statistical-comparison-of-models-using-grid-search"]], "Statistical learning": [[1028, null]], "Statistical learning with Python": [[1019, "statistical-learning-with-python"]], "Statistical learning: the setting and the estimator object in scikit-learn": [[1031, "statistical-learning-the-setting-and-the-estimator-object-in-scikit-learn"]], "Stochastic Gradient Descent": [[1014, "stochastic-gradient-descent"]], "Stochastic Gradient Descent - SGD": [[996, "stochastic-gradient-descent-sgd"]], "Stochastic Gradient Descent for sparse data": [[1014, "stochastic-gradient-descent-for-sparse-data"]], "Stochastic Maximum Likelihood learning": [[1005, "stochastic-maximum-likelihood-learning"]], "Stopping criterion": [[1014, "stopping-criterion"]], "Strategies comparison": [[296, "strategies-comparison"]], "Strategies to scale computationally: bigger data": [[375, "strategies-to-scale-computationally-bigger-data"]], "Stratified Shuffle Split": [[420, "stratified-shuffle-split"]], "Stratified k-fold": [[420, "stratified-k-fold"]], "StratifiedGroupKFold": [[420, "stratifiedgroupkfold"], [826, "stratifiedgroupkfold"]], "StratifiedKFold": [[827, "stratifiedkfold"]], "StratifiedShuffleSplit": [[828, "stratifiedshufflesplit"]], "Streaming instances": [[375, "streaming-instances"]], "Submitting a bug report or a feature request": [[386, "submitting-a-bug-report-or-a-feature-request"]], "Subpackage-specific goals": [[1020, "subpackage-specific-goals"]], "Subsampling": [[423, "subsampling"]], "Successive Halving Iterations": [[290, "successive-halving-iterations"]], "Successive Halving estimators for tuning hyper-parameters": [[330, "successive-halving-estimators-for-tuning-hyper-parameters"]], "Sum": [[632, "sum"]], "Summarizing the key points": [[410, "summarizing-the-key-points"]], "Summary": [[62, "summary"], [150, "summary"], [362, "summary"]], "Summary of cross-validation approach": [[209, "summary-of-cross-validation-approach"]], "Supervised learning": [[1022, "supervised-learning"]], "Supervised learning: predicting an output variable from high-dimensional observations": [[1032, "supervised-learning-predicting-an-output-variable-from-high-dimensional-observations"]], "Support": [[1023, "support"]], "Support Vector Machines": [[189, "support-vector-machines"], [344, "support-vector-machines"], [1015, "support-vector-machines"]], "Support Vector Regression (SVR) using linear and non-linear kernels": [[355, "support-vector-regression-svr-using-linear-and-non-linear-kernels"]], "Support for Array API": [[1058, "support-for-array-api"], [1059, "support-for-array-api"], [1060, "support-for-array-api"]], "Support for Array API-compatible inputs": [[412, "support-for-array-api-compatible-inputs"]], "Support for SciPy sparse arrays": [[1058, "support-for-scipy-sparse-arrays"]], "Support for building with Meson": [[1059, "support-for-building-with-meson"]], "Support for missing values": [[155, "support-for-missing-values"]], "Support for quantile loss": [[155, "support-for-quantile-loss"]], "Support vector machines (SVMs)": [[1032, "support-vector-machines-svms"]], "Swiss Roll": [[244, "swiss-roll"]], "Swiss Roll And Swiss-Hole Reduction": [[244, "swiss-roll-and-swiss-hole-reduction"]], "Swiss-Hole": [[244, "swiss-hole"]], "Synthetic dataset": [[391, "synthetic-dataset"]], "Synthetic example": [[109, "synthetic-example"]], "T-distributed Stochastic Neighbor Embedding": [[240, "t-distributed-stochastic-neighbor-embedding"]], "TSNE": [[700, "tsne"]], "Table of Contents": [[398, "table-of-contents"]], "Take-home messages": [[278, "take-home-messages"]], "Target Encoder": [[1010, "target-encoder"]], "Target Encoder\u2019s Internal Cross fitting": [[326, "target-encoder-s-internal-cross-fitting"]], "Target Types": [[400, "target-types"]], "Target format": [[1001, "target-format"], [1001, "id5"], [1001, "id8"], [1001, "id10"]], "TargetEncoder": [[893, "targetencoder"]], "TargetEncoder: a new category encoding strategy": [[334, "targetencoder-a-new-category-encoding-strategy"]], "Technical Committee": [[401, "technical-committee"]], "Test dependencies": [[384, "test-dependencies"]], "Test with permutations the significance of a classification score": [[284, "test-with-permutations-the-significance-of-a-classification-score"]], "Testing Functions": [[395, "testing-functions"]], "Testing and improving test coverage": [[386, "testing-and-improving-test-coverage"]], "Text feature extraction": [[424, "text-feature-extraction"]], "TfidfTransformer": [[598, "tfidftransformer"]], "TfidfVectorizer": [[362, "tfidfvectorizer"], [599, "tfidfvectorizer"]], "Tf\u2013idf term weighting": [[424, "tfidf-term-weighting"]], "The 20 newsgroups text dataset": [[381, "the-20-newsgroups-text-dataset"]], "The Bag of Words representation": [[424, "the-bag-of-words-representation"]], "The Digit Dataset": [[120, "the-digit-dataset"]], "The Dirichlet Process": [[999, "the-dirichlet-process"]], "The French Motor Third-Party Liability Claims dataset": [[220, "the-french-motor-third-party-liability-claims-dataset"]], "The Iris Dataset": [[121, "the-iris-dataset"]], "The Johnson-Lindenstrauss bound for embedding with random projections": [[251, "the-johnson-lindenstrauss-bound-for-embedding-with-random-projections"]], "The Johnson-Lindenstrauss lemma": [[1012, "the-johnson-lindenstrauss-lemma"]], "The Labeled Faces in the Wild face recognition dataset": [[381, "the-labeled-faces-in-the-wild-face-recognition-dataset"]], "The Meson Build Backend": [[394, "the-meson-build-backend"]], "The Olivetti faces dataset": [[381, "the-olivetti-faces-dataset"]], "The Yeast UCI dataset": [[296, "the-yeast-uci-dataset"]], "The average precision score in multi-label settings": [[285, "the-average-precision-score-in-multi-label-settings"]], "The credit card dataset": [[272, "the-credit-card-dataset"]], "The cross_validate function and multiple metric evaluation": [[420, "the-cross-validate-function-and-multiple-metric-evaluation"]], "The curse of dimensionality": [[1032, "the-curse-of-dimensionality"]], "The data": [[118, "the-data"]], "The dataset": [[276, "the-dataset"]], "The dataset: simulated hourly wages": [[191, "the-dataset-simulated-hourly-wages"]], "The dataset: wages": [[192, "the-dataset-wages"]], "The diabetes dataset": [[292, "the-diabetes-dataset"]], "The importance of hyperparameters search": [[296, "the-importance-of-hyperparameters-search"]], "The machine-learning pipeline": [[192, "the-machine-learning-pipeline"]], "The people behind scikit-learn": [[0, "the-people-behind-scikit-learn"]], "The problem of correlated variables": [[192, "the-problem-of-correlated-variables"]], "The problem solved in clustering": [[1033, null]], "The problem solved in supervised learning": [[1032, null]], "The scikit-learn.org web site": [[390, "the-scikit-learn-org-web-site"]], "The scoring parameter: defining model evaluation rules": [[1000, "the-scoring-parameter-defining-model-evaluation-rules"]], "Theil-Sen Regression": [[237, "theil-sen-regression"]], "Theil-Sen estimator: generalized-median-based estimator": [[996, "theil-sen-estimator-generalized-median-based-estimator"]], "TheilSenRegressor": [[687, "theilsenregressor"]], "Theoretical bounds": [[251, "theoretical-bounds"]], "Third Party Development and scikit-learn Dependency": [[254, "third-party-development-and-scikit-learn-dependency"]], "Third party distributions of scikit-learn": [[404, "third-party-distributions-of-scikit-learn"]], "Time Series Split": [[420, "time-series-split"]], "Time-based cross-validation": [[43, "time-based-cross-validation"]], "Time-related feature engineering": [[43, "time-related-feature-engineering"]], "Time-steps as categories": [[43, "time-steps-as-categories"]], "TimeSeriesSplit": [[829, "timeseriessplit"]], "Timing and accuracy plots": [[252, "timing-and-accuracy-plots"]], "Tips and Tricks": [[373, "tips-and-tricks"]], "Tips for developing with Cython in scikit-learn": [[387, "tips-for-developing-with-cython-in-scikit-learn"]], "Tips for parameter search": [[989, "tips-for-parameter-search"]], "Tips for performance": [[387, "tips-for-performance"]], "Tips on Practical Use": [[1004, "tips-on-practical-use"], [1014, "tips-on-practical-use"], [1015, "tips-on-practical-use"]], "Tips on practical use": [[997, "tips-on-practical-use"], [1016, "tips-on-practical-use"]], "Tips to ease development": [[387, "tips-to-ease-development"]], "Tokenizing text with scikit-learn": [[1034, "tokenizing-text-with-scikit-learn"]], "Tools": [[412, "tools"]], "Top terms per cluster": [[361, "top-terms-per-cluster"]], "Top-k accuracy score": [[1000, "top-k-accuracy-score"]], "Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation": [[54, "topic-extraction-with-non-negative-matrix-factorization-and-latent-dirichlet-allocation"]], "Total impurity of leaves vs effective alphas of pruned tree": [[364, "total-impurity-of-leaves-vs-effective-alphas-of-pruned-tree"]], "Totally Random Trees Embedding": [[423, "totally-random-trees-embedding"]], "Toy datasets": [[383, "toy-datasets"]], "Tracking feature names in a pipeline": [[417, "tracking-feature-names-in-a-pipeline"]], "Trade-offs: which estimator ?": [[996, null]], "Train and Persist the Model": [[410, "train-and-persist-the-model"]], "Train classifiers": [[349, "train-classifiers"]], "Train error vs Test error": [[291, "train-error-vs-test-error"]], "Train models on the diabetes dataset": [[258, "train-models-on-the-diabetes-dataset"]], "Train tree classifier": [[368, "train-tree-classifier"]], "Training": [[317, "training"], [1003, "training"]], "Training SVC model and plotting decision boundaries": [[353, "training-svc-model-and-plotting-decision-boundaries"]], "Training a Random Forest and Plotting the ROC Curve": [[260, "training-a-random-forest-and-plotting-the-roc-curve"]], "Training a Ridge Regressor": [[326, "training-a-ridge-regressor"]], "Training a classifier": [[1034, "training-a-classifier"]], "Training and Evaluating Pipelines with Different Encoders": [[325, "training-and-evaluating-pipelines-with-different-encoders"]], "Training and prediction with DecisionTree and AdaBoost Regressors": [[140, "training-and-prediction-with-decisiontree-and-adaboost-regressors"]], "Training classifiers": [[163, "training-classifiers"]], "Training of the model": [[156, "training-of-the-model"]], "Training set and testing set": [[1025, null], [1032, null]], "Training the AdaBoostClassifier": [[139, "training-the-adaboostclassifier"]], "Training the Ridge Regressor": [[224, "training-the-ridge-regressor"]], "Transform": [[1003, "transform"]], "Transform data": [[117, "transform-data"]], "TransformedTargetRegressor": [[473, "transformedtargetregressor"]], "TransformerMixin": [[440, "transformermixin"]], "Transformers and pre-processors": [[399, "transformers-and-pre-processors"]], "Transforming target in regression": [[417, "transforming-target-in-regression"]], "Transforming the prediction target (y)": [[1011, "transforming-the-prediction-target-y"]], "Translations of scikit-learn documentation": [[1019, "translations-of-scikit-learn-documentation"]], "Tree algorithms: ID3, C4.5, C5.0 and CART": [[1016, "tree-algorithms-id3-c4-5-c5-0-and-cart"]], "Tree pruning": [[328, "tree-pruning"]], "Tree structure": [[368, "tree-structure"]], "Tree-based feature selection": [[425, "tree-based-feature-selection"]], "Tree\u2019s Feature Importance from Mean Decrease in Impurity (MDI)": [[194, "tree-s-feature-importance-from-mean-decrease-in-impurity-mdi"]], "Triaging operations for members of the core and contributor experience teams": [[385, "triaging-operations-for-members-of-the-core-and-contributor-experience-teams"]], "Trigonometric features": [[43, "trigonometric-features"]], "Troubleshooting": [[404, "troubleshooting"]], "Truncated singular value decomposition and latent semantic analysis": [[421, "truncated-singular-value-decomposition-and-latent-semantic-analysis"]], "TruncatedSVD": [[552, "truncatedsvd"]], "TunedThresholdClassifierCV": [[830, "tunedthresholdclassifiercv"]], "TunedThresholdClassifierCV: Tuning the decision threshold of a binary classifier": [[336, "tunedthresholdclassifiercv-tuning-the-decision-threshold-of-a-binary-classifier"]], "Tuning hyper-parameters": [[276, "tuning-hyper-parameters"]], "Tuning the cut-off point": [[272, "tuning-the-cut-off-point"]], "Tuning the decision threshold": [[272, "tuning-the-decision-threshold"], [292, "tuning-the-decision-threshold"]], "Tuning the decision threshold for class prediction": [[415, "tuning-the-decision-threshold-for-class-prediction"]], "Tuning the hyper-parameters of an estimator": [[989, "tuning-the-hyper-parameters-of-an-estimator"]], "Tuning the hyper-parameters of the quantile regressors": [[152, "tuning-the-hyper-parameters-of-the-quantile-regressors"]], "Tutorial exercises": [[164, "tutorial-exercises"], [189, "tutorial-exercises"]], "Tutorial setup": [[1034, "tutorial-setup"]], "Tweedie regression on insurance claims": [[238, "tweedie-regression-on-insurance-claims"]], "TweedieRegressor": [[688, "tweedieregressor"]], "Two-class AdaBoost": [[141, "two-class-adaboost"]], "Type casting": [[1025, "type-casting"]], "Type of return values and fitted attributes": [[412, "type-of-return-values-and-fitted-attributes"]], "Types": [[387, "types"]], "T\u00e9l\u00e9com ParisTech": [[1024, "id7"]], "Unbalanced problems": [[1015, "unbalanced-problems"]], "UndefinedMetricWarning": [[586, "undefinedmetricwarning"]], "Under Development": [[1036, "under-development"]], "Underfitting vs. Overfitting": [[293, "underfitting-vs-overfitting"]], "Understanding the decision tree structure": [[368, "understanding-the-decision-tree-structure"]], "Univariate Feature Selection": [[170, "univariate-feature-selection"]], "Univariate feature imputation": [[990, "univariate-feature-imputation"]], "Univariate feature selection": [[170, "id1"], [425, "univariate-feature-selection"]], "Univariate vs. Multivariate Imputation": [[990, "univariate-vs-multivariate-imputation"]], "Universal attributes": [[388, "universal-attributes"]], "Unlabeled entries in y": [[1013, null]], "Unsupervised Nearest Neighbors": [[1003, "unsupervised-nearest-neighbors"]], "Unsupervised dimensionality reduction": [[1017, "unsupervised-dimensionality-reduction"]], "Unsupervised learning": [[1035, "unsupervised-learning"]], "Unsupervised learning: seeking representations of the data": [[1033, "unsupervised-learning-seeking-representations-of-the-data"]], "Unweighted feature selection": [[407, "unweighted-feature-selection"]], "Usage": [[414, "usage"], [417, "usage"], [417, "id1"], [423, "usage"], [423, "id24"], [423, "id25"], [423, "id27"], [423, "id35"], [996, "usage"]], "Usage Examples": [[407, "usage-examples"]], "Use markdown formatting": [[391, "use-markdown-formatting"]], "Useful pytest aliases and flags": [[394, "useful-pytest-aliases-and-flags"]], "User Guide": [[1036, "user-guide"]], "User Questions": [[1023, "user-questions"]], "Using Cython": [[392, "using-cython"]], "Using KBinsDiscretizer to discretize continuous features": [[320, "using-kbinsdiscretizer-to-discretize-continuous-features"]], "Using None or RandomState instances, and repeated calls to fit and split": [[369, "using-none-or-randomstate-instances-and-repeated-calls-to-fit-and-split"]], "Using OpenMP": [[387, "using-openmp"]], "Using a debugger, gdb": [[392, "using-a-debugger-gdb"]], "Using cross-validation": [[996, "using-cross-validation"]], "Using cross-validation iterators to split train and test": [[420, "using-cross-validation-iterators-to-split-train-and-test"]], "Using feature names to specify monotonic constraints": [[157, "using-feature-names-to-specify-monotonic-constraints"]], "Using gprof": [[392, "using-gprof"]], "Using kernels": [[1032, "using-kernels"]], "Using multiple metric evaluation": [[1000, "using-multiple-metric-evaluation"]], "Using negative tolerance values": [[174, "using-negative-tolerance-values"]], "Using scikit-learn": [[398, "using-scikit-learn"]], "Using stop words": [[424, "using-stop-words"]], "Using valgrind / callgrind / kcachegrind": [[392, "using-valgrind-callgrind-kcachegrind"]], "Using yep and gperftools": [[392, "using-yep-and-gperftools"]], "Utilities for Developers": [[395, "utilities-for-developers"]], "Validation Tools": [[395, "validation-tools"]], "Validation curve": [[995, "validation-curve"]], "Validation curves: plotting scores to evaluate models": [[995, "validation-curves-plotting-scores-to-evaluate-models"]], "ValidationCurveDisplay": [[831, "validationcurvedisplay"]], "Vanilla predictive model": [[272, "vanilla-predictive-model"]], "VarianceThreshold": [[611, "variancethreshold"]], "Variational Bayesian Gaussian Mixture": [[999, "variational-bayesian-gaussian-mixture"]], "Various Agglomerative Clustering on a 2D embedding of digits": [[87, "various-agglomerative-clustering-on-a-2d-embedding-of-digits"]], "Varying regularization in Multi-layer Perceptron": [[314, "varying-regularization-in-multi-layer-perceptron"]], "Varying the metric": [[416, "varying-the-metric"]], "Vector Quantization Example": [[88, "vector-quantization-example"]], "Vectorizing a large text corpus with the hashing trick": [[424, "vectorizing-a-large-text-corpus-with-the-hashing-trick"]], "Version 0.10": [[1041, "version-0-10"]], "Version 0.11": [[1041, "version-0-11"]], "Version 0.12": [[1041, "version-0-12"]], "Version 0.12.1": [[1041, "version-0-12-1"]], "Version 0.13": [[1042, "version-0-13"], [1042, "changes-0-13"]], "Version 0.13.1": [[1042, "version-0-13-1"]], "Version 0.14": [[1043, "version-0-14"], [1043, "changes-0-14"]], "Version 0.15": [[1044, "version-0-15"], [1044, "changes-0-15"]], "Version 0.15.1": [[1044, "version-0-15-1"]], "Version 0.15.2": [[1044, "version-0-15-2"]], "Version 0.16": [[1045, "version-0-16"], [1045, "changes-0-16"]], "Version 0.16.1": [[1045, "version-0-16-1"]], "Version 0.17": [[1046, "version-0-17"], [1046, "changes-0-17"]], "Version 0.17.1": [[1046, "version-0-17-1"]], "Version 0.18": [[1047, "version-0-18"], [1047, "changes-0-18"]], "Version 0.18.1": [[1047, "version-0-18-1"]], "Version 0.18.2": [[1047, "version-0-18-2"]], "Version 0.19": [[1048, "version-0-19"], [1048, "id1"]], "Version 0.19.1": [[1048, "version-0-19-1"]], "Version 0.19.2": [[1048, "version-0-19-2"]], "Version 0.20": [[1049, "version-0-20"]], "Version 0.20.0": [[1049, "version-0-20-0"]], "Version 0.20.1": [[1049, "version-0-20-1"]], "Version 0.20.2": [[1049, "version-0-20-2"]], "Version 0.20.3": [[1049, "version-0-20-3"]], "Version 0.20.4": [[1049, "version-0-20-4"]], "Version 0.21": [[1050, "version-0-21"]], "Version 0.21.0": [[1050, "version-0-21-0"]], "Version 0.21.1": [[1050, "version-0-21-1"]], "Version 0.21.2": [[1050, "version-0-21-2"]], "Version 0.21.3": [[1050, "version-0-21-3"]], "Version 0.22": [[1051, "version-0-22"]], "Version 0.22.0": [[1051, "version-0-22-0"]], "Version 0.22.1": [[1051, "version-0-22-1"]], "Version 0.22.2.post1": [[1051, "version-0-22-2-post1"]], "Version 0.23": [[1052, "version-0-23"]], "Version 0.23.0": [[1052, "version-0-23-0"]], "Version 0.23.1": [[1052, "version-0-23-1"]], "Version 0.23.2": [[1052, "version-0-23-2"]], "Version 0.24": [[1053, "version-0-24"]], "Version 0.24.0": [[1053, "version-0-24-0"]], "Version 0.24.1": [[1053, "version-0-24-1"]], "Version 0.24.2": [[1053, "version-0-24-2"]], "Version 0.4": [[1041, "version-0-4"]], "Version 0.5": [[1041, "version-0-5"]], "Version 0.6": [[1041, "version-0-6"]], "Version 0.7": [[1041, "version-0-7"]], "Version 0.8": [[1041, "version-0-8"]], "Version 0.9": [[1041, "version-0-9"]], "Version 1.0": [[1054, "version-1-0"]], "Version 1.0.0": [[1054, "version-1-0-0"]], "Version 1.0.1": [[1054, "version-1-0-1"]], "Version 1.0.2": [[1054, "version-1-0-2"]], "Version 1.1": [[1055, "version-1-1"]], "Version 1.1.0": [[1055, "version-1-1-0"]], "Version 1.1.1": [[1055, "version-1-1-1"]], "Version 1.1.2": [[1055, "version-1-1-2"]], "Version 1.1.3": [[1055, "version-1-1-3"]], "Version 1.2": [[1056, "version-1-2"]], "Version 1.2.0": [[1056, "version-1-2-0"]], "Version 1.2.1": [[1056, "version-1-2-1"]], "Version 1.2.2": [[1056, "version-1-2-2"]], "Version 1.3": [[1057, "version-1-3"]], "Version 1.3.0": [[1057, "version-1-3-0"]], "Version 1.3.1": [[1057, "version-1-3-1"]], "Version 1.3.2": [[1057, "version-1-3-2"]], "Version 1.4": [[1058, "version-1-4"]], "Version 1.4.0": [[1058, "version-1-4-0"]], "Version 1.4.1": [[1058, "version-1-4-1"]], "Version 1.4.2": [[1058, "version-1-4-2"]], "Version 1.5": [[1059, "version-1-5"]], "Version 1.5.0": [[1059, "version-1-5-0"]], "Version 1.5.1": [[1059, "version-1-5-1"]], "Version 1.6": [[1060, "version-1-6"]], "Version 1.6.0": [[1060, "version-1-6-0"]], "Video resources": [[386, "video-resources"]], "Videos": [[1018, "videos"]], "Visual evaluation of regression models": [[1000, "visual-evaluation-of-regression-models"]], "Visualization": [[5, "visualization"], [29, "visualization"], [51, "visualization"], [349, "visualization"]], "Visualization of MLP weights on MNIST": [[316, "visualization-of-mlp-weights-on-mnist"]], "Visualization of cluster hierarchy": [[416, "visualization-of-cluster-hierarchy"]], "Visualizations": [[1038, "visualizations"]], "Visualizations with Display Objects": [[248, "visualizations-with-display-objects"]], "Visualize Comparison": [[150, "visualize-comparison"]], "Visualize cross-validation indices for many CV objects": [[273, "visualize-cross-validation-indices-for-many-cv-objects"]], "Visualize our data": [[273, "visualize-our-data"]], "Visualize the learning curves": [[253, "visualize-the-learning-curves"]], "Visualize the results on PCA-reduced data": [[93, "visualize-the-results-on-pca-reduced-data"]], "Visualize training and prediction times": [[253, "visualize-training-and-prediction-times"]], "Visualizing Composite Estimators": [[417, "visualizing-composite-estimators"]], "Visualizing cross-validation behavior in scikit-learn": [[273, "visualizing-cross-validation-behavior-in-scikit-learn"]], "Visualizing the stock market structure": [[51, "visualizing-the-stock-market-structure"]], "Vocabulary: classification and regression": [[1032, null]], "Voting Classifier": [[423, "voting-classifier"]], "Voting Regressor": [[423, "voting-regressor"]], "VotingClassifier": [[577, "votingclassifier"]], "VotingRegressor": [[578, "votingregressor"]], "Warnings and Exceptions": [[395, "warnings-and-exceptions"]], "Ways to contribute": [[386, "ways-to-contribute"]], "We are defining k-Nearest Neighbors with 10 neighbors": [[102, "we-are-defining-k-nearest-neighbors-with-10-neighbors"]], "Website update": [[1051, "website-update"]], "Weight handling based on class labels": [[41, "module-sklearn.utils.class_weight"]], "Weighted Average Probabilities (Soft Voting)": [[423, "weighted-average-probabilities-soft-voting"]], "Weighted scoring and fitting": [[407, "weighted-scoring-and-fitting"]], "Weighted scoring and unweighted fitting": [[407, "weighted-scoring-and-unweighted-fitting"]], "What are the inclusion criteria for new algorithms?": [[398, "what-are-the-inclusion-criteria-for-new-algorithms"]], "What is the project name (a lot of people get it wrong)?": [[398, "what-is-the-project-name-a-lot-of-people-get-it-wrong"]], "What is the values array used here?": [[368, "what-is-the-values-array-used-here"]], "What\u2019s the best way to get help on scikit-learn usage?": [[398, "what-s-the-best-way-to-get-help-on-scikit-learn-usage"]], "Where to from here": [[1034, "where-to-from-here"]], "WhiteKernel": [[633, "whitekernel"]], "Who is using scikit-learn?": [[1024, "who-is-using-scikit-learn"]], "Why are there so many different estimators for linear models?": [[398, "why-are-there-so-many-different-estimators-for-linear-models"]], "Why are you so selective on what algorithms you include in scikit-learn?": [[398, "why-are-you-so-selective-on-what-algorithms-you-include-in-scikit-learn"]], "Why did you remove HMMs from scikit-learn?": [[398, "why-did-you-remove-hmms-from-scikit-learn"]], "Why do I sometimes get a crash/freeze with n_jobs > 1 under OSX or Linux?": [[398, "why-do-i-sometimes-get-a-crash-freeze-with-n-jobs-1-under-osx-or-linux"]], "Why do categorical variables need preprocessing in scikit-learn, compared to other tools?": [[398, "why-do-categorical-variables-need-preprocessing-in-scikit-learn-compared-to-other-tools"]], "Why does my job use more cores than specified with n_jobs?": [[398, "why-does-my-job-use-more-cores-than-specified-with-n-jobs"]], "Why does scikit-learn not directly work with, for example, pandas.DataFrame?": [[398, "why-does-scikit-learn-not-directly-work-with-for-example-pandas-dataframe"]], "Why is my pull request not getting any attention?": [[398, "why-is-my-pull-request-not-getting-any-attention"]], "Why is there no support for deep or reinforcement learning? Will there be such support in the future?": [[398, "why-is-there-no-support-for-deep-or-reinforcement-learning-will-there-be-such-support-in-the-future"]], "Why it\u2019s faster": [[423, "why-it-s-faster"]], "Why scikit?": [[398, "why-scikit"]], "Wikipedia principal eigenvector": [[55, "wikipedia-principal-eigenvector"]], "Will you add GPU support?": [[398, "will-you-add-gpu-support"]], "Will you add graphical models or sequence prediction to scikit-learn?": [[398, "will-you-add-graphical-models-or-sequence-prediction-to-scikit-learn"]], "WinPython for Windows": [[404, "winpython-for-windows"]], "Windows": [[384, "windows"]], "Wine recognition dataset": [[383, "wine-recognition-dataset"]], "Workflow Overview": [[410, "workflow-overview"]], "Working With Text Data": [[1034, "working-with-text-data"]], "Working on PRs to help review": [[385, "working-on-prs-to-help-review"]], "Working on issues to improve them": [[385, "working-on-issues-to-improve-them"]], "Working with graphs": [[41, "module-sklearn.utils.graph"]], "Working with sparse matrices and arrays": [[41, "module-sklearn.utils.sparsefuncs"]], "Working with text documents": [[189, "working-with-text-documents"], [359, "working-with-text-documents"]], "Wrong causal interpretation": [[192, "wrong-causal-interpretation"]], "XOR dataset": [[353, "xor-dataset"]], "Yhat": [[1024, "id10"]], "Zero one loss": [[1000, "zero-one-loss"]], "Zopa": [[1024, "id27"]], "__sklearn_is_fitted__ as Developer API": [[137, "sklearn-is-fitted-as-developer-api"]], "_safe_indexing": [[928, "safe-indexing"]], "accuracy_score": [[711, "accuracy-score"]], "add_dummy_feature": [[894, "add-dummy-feature"]], "additive_chi2_kernel": [[766, "additive-chi2-kernel"]], "adjusted_mutual_info_score": [[712, "adjusted-mutual-info-score"]], "adjusted_rand_score": [[713, "adjusted-rand-score"]], "affinity_propagation": [[462, "affinity-propagation"]], "all_displays": [[940, "all-displays"]], "all_estimators": [[941, "all-estimators"]], "all_functions": [[942, "all-functions"]], "as_float_array": [[930, "as-float-array"]], "assert_all_finite": [[931, "assert-all-finite"]], "auc": [[714, "auc"]], "available_if": [[961, "available-if"]], "average_precision_score": [[715, "average-precision-score"]], "balanced_accuracy_score": [[716, "balanced-accuracy-score"]], "betaworks": [[1024, "id4"]], "binarize": [[895, "binarize"]], "brier_score_loss": [[717, "brier-score-loss"]], "calibration_curve": [[447, "calibration-curve"]], "calinski_harabasz_score": [[718, "calinski-harabasz-score"]], "check_X_y": [[932, "check-x-y"]], "check_array": [[933, "check-array"]], "check_consistent_length": [[934, "check-consistent-length"]], "check_cv": [[832, "check-cv"]], "check_estimator": [[943, "check-estimator"]], "check_increasing": [[644, "check-increasing"]], "check_is_fitted": [[984, "check-is-fitted"]], "check_memory": [[985, "check-memory"]], "check_random_state": [[935, "check-random-state"]], "check_scalar": [[936, "check-scalar"]], "check_scoring": [[719, "check-scoring"]], "check_symmetric": [[986, "check-symmetric"]], "chi2": [[612, "chi2"]], "chi2_kernel": [[767, "chi2-kernel"]], "class_likelihood_ratios": [[720, "class-likelihood-ratios"]], "classification_report": [[721, "classification-report"]], "clear_data_home": [[494, "clear-data-home"]], "clone": [[441, "clone"]], "cluster_optics_dbscan": [[463, "cluster-optics-dbscan"]], "cluster_optics_xi": [[464, "cluster-optics-xi"]], "cohen_kappa_score": [[724, "cohen-kappa-score"]], "column_or_1d": [[987, "column-or-1d"]], "completeness_score": [[725, "completeness-score"]], "compute_class_weight": [[937, "compute-class-weight"]], "compute_optics_graph": [[465, "compute-optics-graph"]], "compute_sample_weight": [[938, "compute-sample-weight"]], "config_context": [[476, "config-context"]], "confusion_matrix": [[726, "confusion-matrix"]], "consensus_score": [[727, "consensus-score"]], "contingency_matrix": [[722, "contingency-matrix"]], "cosine_distances": [[768, "cosine-distances"]], "cosine_similarity": [[769, "cosine-similarity"]], "coverage_error": [[728, "coverage-error"]], "cross_val_predict": [[833, "cross-val-predict"]], "cross_val_score": [[834, "cross-val-score"]], "cross_validate": [[835, "cross-validate"]], "d2_absolute_error_score": [[729, "d2-absolute-error-score"]], "d2_log_loss_score": [[730, "d2-log-loss-score"]], "d2_pinball_score": [[731, "d2-pinball-score"]], "d2_tweedie_score": [[732, "d2-tweedie-score"]], "davies_bouldin_score": [[733, "davies-bouldin-score"]], "dbscan": [[427, "dbscan"]], "dbscan_clustering": [[90, "dbscan-clustering"]], "dcg_score": [[734, "dcg-score"]], "delayed": [[967, "delayed"]], "density": [[946, "density"]], "deprecated": [[939, "deprecated"]], "det_curve": [[735, "det-curve"]], "dict_learning": [[553, "dict-learning"]], "dict_learning_online": [[554, "dict-learning-online"]], "distance_metrics": [[770, "distance-metrics"]], "dump_svmlight_file": [[495, "dump-svmlight-file"]], "empirical_covariance": [[485, "empirical-covariance"]], "enable_halving_search_cv": [[587, "module-sklearn.experimental.enable_halving_search_cv"]], "enable_iterative_imputer": [[588, "module-sklearn.experimental.enable_iterative_imputer"]], "enet_path": [[689, "enet-path"]], "estimate_bandwidth": [[466, "estimate-bandwidth"]], "estimator_html_repr": [[945, "estimator-html-repr"]], "euclidean_distances": [[771, "euclidean-distances"]], "explained_variance_score": [[736, "explained-variance-score"]], "export_graphviz": [[924, "export-graphviz"]], "export_text": [[925, "export-text"]], "extract_patches_2d": [[592, "extract-patches-2d"]], "f1_score": [[737, "f1-score"]], "f_classif": [[613, "f-classif"]], "f_regression": [[614, "f-regression"]], "fast_logdet": [[947, "fast-logdet"]], "fastica": [[428, "fastica"]], "fbeta_score": [[738, "fbeta-score"]], "fetch_20newsgroups": [[496, "fetch-20newsgroups"]], "fetch_20newsgroups_vectorized": [[497, "fetch-20newsgroups-vectorized"]], "fetch_california_housing": [[498, "fetch-california-housing"]], "fetch_covtype": [[499, "fetch-covtype"]], "fetch_kddcup99": [[500, "fetch-kddcup99"]], "fetch_lfw_pairs": [[501, "fetch-lfw-pairs"]], "fetch_lfw_people": [[502, "fetch-lfw-people"]], "fetch_olivetti_faces": [[503, "fetch-olivetti-faces"]], "fetch_openml": [[504, "fetch-openml"]], "fetch_rcv1": [[505, "fetch-rcv1"]], "fetch_species_distributions": [[506, "fetch-species-distributions"]], "fowlkes_mallows_score": [[739, "fowlkes-mallows-score"]], "gen_batches": [[952, "gen-batches"]], "gen_even_slices": [[953, "gen-even-slices"]], "get_config": [[634, "get-config"]], "get_data_home": [[507, "get-data-home"]], "get_feature_names_out Available in all Transformers": [[332, "get-feature-names-out-available-in-all-transformers"]], "get_params and set_params": [[388, "get-params-and-set-params"]], "get_routing_for_object": [[959, "get-routing-for-object"]], "get_scorer": [[740, "get-scorer"]], "get_scorer_names": [[741, "get-scorer-names"]], "graphical_lasso": [[486, "graphical-lasso"]], "grid_to_graph": [[593, "grid-to-graph"]], "hamming_loss": [[742, "hamming-loss"]], "has_fit_parameter": [[988, "has-fit-parameter"]], "haversine_distances": [[772, "haversine-distances"]], "hinge_loss": [[743, "hinge-loss"]], "homogeneity_completeness_v_measure": [[744, "homogeneity-completeness-v-measure"]], "homogeneity_score": [[745, "homogeneity-score"]], "img_to_graph": [[594, "img-to-graph"]], "incr_mean_variance_axis": [[975, "incr-mean-variance-axis"]], "indexable": [[955, "indexable"]], "inplace_column_scale": [[976, "inplace-column-scale"]], "inplace_csr_column_scale": [[977, "inplace-csr-column-scale"]], "inplace_csr_row_normalize_l1": [[982, "inplace-csr-row-normalize-l1"]], "inplace_csr_row_normalize_l2": [[983, "inplace-csr-row-normalize-l2"]], "inplace_row_scale": [[978, "inplace-row-scale"]], "inplace_swap_column": [[979, "inplace-swap-column"]], "inplace_swap_row": [[980, "inplace-swap-row"]], "is_classifier": [[442, "is-classifier"]], "is_clusterer": [[443, "is-clusterer"]], "is_multilabel": [[962, "is-multilabel"]], "is_regressor": [[444, "is-regressor"]], "isotonic_regression": [[645, "isotonic-regression"]], "jaccard_score": [[746, "jaccard-score"]], "johnson_lindenstrauss_min_dim": [[906, "johnson-lindenstrauss-min-dim"]], "k-Nearest neighbors classifier": [[1032, "k-nearest-neighbors-classifier"]], "kNN-imputation of the missing values": [[188, "knn-imputation-of-the-missing-values"]], "k_means": [[467, "k-means"]], "kcachegrind": [[392, "kcachegrind"]], "kernel_metrics": [[773, "kernel-metrics"]], "kmeans_plusplus": [[468, "kmeans-plusplus"]], "kneighbors_graph": [[865, "kneighbors-graph"]], "l1_min_c": [[919, "l1-min-c"]], "label_binarize": [[896, "label-binarize"]], "label_ranking_average_precision_score": [[747, "label-ranking-average-precision-score"]], "label_ranking_loss": [[748, "label-ranking-loss"]], "laplacian_kernel": [[774, "laplacian-kernel"]], "lars_path": [[690, "lars-path"]], "lars_path_gram": [[691, "lars-path-gram"]], "lasso_path": [[692, "lasso-path"]], "learning_curve": [[836, "learning-curve"]], "ledoit_wolf": [[487, "ledoit-wolf"]], "ledoit_wolf_shrinkage": [[488, "ledoit-wolf-shrinkage"]], "linear_kernel": [[775, "linear-kernel"]], "load_breast_cancer": [[508, "load-breast-cancer"]], "load_diabetes": [[509, "load-diabetes"]], "load_digits": [[510, "load-digits"]], "load_files": [[511, "load-files"]], "load_iris": [[512, "load-iris"]], "load_linnerud": [[513, "load-linnerud"]], "load_sample_image": [[514, "load-sample-image"]], "load_sample_images": [[515, "load-sample-images"]], "load_svmlight_file": [[516, "load-svmlight-file"]], "load_svmlight_files": [[517, "load-svmlight-files"]], "load_wine": [[518, "load-wine"]], "locally_linear_embedding": [[701, "locally-linear-embedding"]], "log_loss": [[749, "log-loss"]], "macOS": [[384, "macos"]], "macOS compilers from Homebrew": [[384, "macos-compilers-from-homebrew"]], "macOS compilers from conda-forge": [[384, "macos-compilers-from-conda-forge"]], "make_biclusters": [[519, "make-biclusters"]], "make_blobs": [[391, "make-blobs"], [520, "make-blobs"]], "make_checkerboard": [[521, "make-checkerboard"]], "make_circles": [[522, "make-circles"]], "make_classification": [[391, "make-classification"], [523, "make-classification"]], "make_column_selector": [[474, "make-column-selector"]], "make_column_transformer": [[475, "make-column-transformer"]], "make_friedman1": [[524, "make-friedman1"]], "make_friedman2": [[525, "make-friedman2"]], "make_friedman3": [[526, "make-friedman3"]], "make_gaussian_quantiles": [[527, "make-gaussian-quantiles"]], "make_hastie_10_2": [[528, "make-hastie-10-2"]], "make_low_rank_matrix": [[529, "make-low-rank-matrix"]], "make_moons": [[530, "make-moons"]], "make_multilabel_classification": [[531, "make-multilabel-classification"]], "make_pipeline": [[873, "make-pipeline"]], "make_regression": [[391, "make-regression"], [532, "make-regression"]], "make_s_curve": [[533, "make-s-curve"]], "make_scorer": [[750, "make-scorer"]], "make_sparse_coded_signal": [[534, "make-sparse-coded-signal"]], "make_sparse_spd_matrix": [[535, "make-sparse-spd-matrix"]], "make_sparse_uncorrelated": [[536, "make-sparse-uncorrelated"]], "make_spd_matrix": [[537, "make-spd-matrix"]], "make_swiss_roll": [[538, "make-swiss-roll"]], "make_union": [[874, "make-union"]], "manhattan_distances": [[776, "manhattan-distances"]], "matthews_corrcoef": [[751, "matthews-corrcoef"]], "max_error": [[752, "max-error"]], "maxabs_scale": [[897, "maxabs-scale"]], "mean_absolute_error": [[753, "mean-absolute-error"]], "mean_absolute_percentage_error": [[754, "mean-absolute-percentage-error"]], "mean_gamma_deviance": [[755, "mean-gamma-deviance"]], "mean_pinball_loss": [[756, "mean-pinball-loss"]], "mean_poisson_deviance": [[757, "mean-poisson-deviance"]], "mean_shift": [[469, "mean-shift"]], "mean_squared_error": [[758, "mean-squared-error"]], "mean_squared_log_error": [[759, "mean-squared-log-error"]], "mean_tweedie_deviance": [[760, "mean-tweedie-deviance"]], "mean_variance_axis": [[981, "mean-variance-axis"]], "median_absolute_error": [[761, "median-absolute-error"]], "min_cluster_size": [[90, "min-cluster-size"]], "min_pos": [[929, "min-pos"]], "min_samples": [[90, "min-samples"]], "minmax_scale": [[898, "minmax-scale"]], "multilabel_confusion_matrix": [[762, "multilabel-confusion-matrix"]], "murmurhash3_32": [[965, "murmurhash3-32"]], "mutual_info_classif": [[615, "mutual-info-classif"]], "mutual_info_regression": [[616, "mutual-info-regression"]], "mutual_info_score": [[763, "mutual-info-score"]], "nan_euclidean_distances": [[777, "nan-euclidean-distances"]], "ndcg_score": [[764, "ndcg-score"]], "non_negative_factorization": [[555, "non-negative-factorization"]], "normalize": [[899, "normalize"]], "normalized_mutual_info_score": [[765, "normalized-mutual-info-score"]], "oas": [[429, "oas"]], "orthogonal_mp": [[693, "orthogonal-mp"]], "orthogonal_mp_gram": [[694, "orthogonal-mp-gram"]], "pair_confusion_matrix": [[723, "pair-confusion-matrix"]], "paired_cosine_distances": [[778, "paired-cosine-distances"]], "paired_distances": [[779, "paired-distances"]], "paired_euclidean_distances": [[780, "paired-euclidean-distances"]], "paired_manhattan_distances": [[781, "paired-manhattan-distances"]], "pairwise_distances": [[786, "pairwise-distances"]], "pairwise_distances_argmin": [[787, "pairwise-distances-argmin"]], "pairwise_distances_argmin_min": [[788, "pairwise-distances-argmin-min"]], "pairwise_distances_chunked": [[789, "pairwise-distances-chunked"]], "pairwise_kernels": [[782, "pairwise-kernels"]], "parallel_backend": [[968, "parallel-backend"]], "parametrize_with_checks": [[944, "parametrize-with-checks"]], "partial_dependence": [[641, "partial-dependence"]], "permutation_importance": [[642, "permutation-importance"]], "permutation_test_score": [[837, "permutation-test-score"]], "pickle, joblib, and cloudpickle": [[410, "pickle-joblib-and-cloudpickle"]], "plot_tree": [[926, "plot-tree"]], "polynomial_kernel": [[783, "polynomial-kernel"]], "power_transform": [[900, "power-transform"]], "precision_recall_curve": [[790, "precision-recall-curve"]], "precision_recall_fscore_support": [[791, "precision-recall-fscore-support"]], "precision_score": [[792, "precision-score"]], "process_routing": [[960, "process-routing"]], "quantile_transform": [[901, "quantile-transform"]], "r2_score": [[793, "r2-score"]], "r_regression": [[617, "r-regression"]], "radius_neighbors_graph": [[866, "radius-neighbors-graph"]], "rand_score": [[794, "rand-score"]], "randomized_range_finder": [[948, "randomized-range-finder"]], "randomized_svd": [[949, "randomized-svd"]], "rbf_kernel": [[784, "rbf-kernel"]], "recall_score": [[795, "recall-score"]], "reconstruct_from_patches_2d": [[595, "reconstruct-from-patches-2d"]], "register_parallel_backend": [[970, "register-parallel-backend"]], "resample": [[971, "resample"]], "ridge_regression": [[695, "ridge-regression"]], "robust_scale": [[902, "robust-scale"]], "roc_auc_score": [[796, "roc-auc-score"]], "roc_curve": [[797, "roc-curve"]], "root_mean_squared_error": [[798, "root-mean-squared-error"]], "root_mean_squared_log_error": [[799, "root-mean-squared-log-error"]], "safe_mask": [[972, "safe-mask"]], "safe_sparse_dot": [[950, "safe-sparse-dot"]], "safe_sqr": [[973, "safe-sqr"]], "sample_without_replacement": [[969, "sample-without-replacement"]], "scale": [[903, "scale"]], "scikit-learn Tutorials": [[1026, "scikit-learn-tutorials"]], "set_config": [[910, "set-config"]], "show_versions": [[911, "show-versions"]], "shrunk_covariance": [[489, "shrunk-covariance"]], "shuffle": [[974, "shuffle"]], "sigmoid_kernel": [[785, "sigmoid-kernel"]], "silhouette_samples": [[800, "silhouette-samples"]], "silhouette_score": [[801, "silhouette-score"]], "single_source_shortest_path_length": [[954, "single-source-shortest-path-length"]], "sklearn": [[3, "module-sklearn"], [1057, "sklearn"]], "sklearn.base": [[4, "module-sklearn.base"], [1050, "sklearn-base"], [1051, "sklearn-base"], [1053, "sklearn-base"], [1054, "sklearn-base"], [1055, "sklearn-base"], [1056, "sklearn-base"], [1056, "id2"], [1056, "id10"], [1057, "sklearn-base"], [1058, "sklearn-base"], [1060, "sklearn-base"]], "sklearn.calibration": [[5, "module-sklearn.calibration"], [1050, "sklearn-calibration"], [1051, "sklearn-calibration"], [1053, "sklearn-calibration"], [1054, "sklearn-calibration"], [1054, "id7"], [1055, "sklearn-calibration"], [1056, "sklearn-calibration"], [1056, "id11"], [1057, "sklearn-calibration"], [1057, "id7"], [1058, "sklearn-calibration"], [1058, "id3"], [1059, "sklearn-calibration"]], "sklearn.cluster": [[6, "module-sklearn.cluster"], [1049, "sklearn-cluster"], [1049, "id2"], [1049, "id11"], [1049, "id24"], [1050, "sklearn-cluster"], [1050, "id8"], [1051, "sklearn-cluster"], [1051, "id5"], [1052, "sklearn-cluster"], [1052, "id2"], [1052, "id5"], [1053, "sklearn-cluster"], [1054, "sklearn-cluster"], [1054, "id1"], [1054, "id8"], [1055, "sklearn-cluster"], [1055, "id8"], [1056, "sklearn-cluster"], [1056, "id12"], [1057, "sklearn-cluster"], [1057, "id8"], [1058, "sklearn-cluster"], [1058, "id4"], [1059, "sklearn-cluster"]], "sklearn.compose": [[7, "module-sklearn.compose"], [1049, "sklearn-compose"], [1049, "id3"], [1049, "id6"], [1049, "id12"], [1049, "id25"], [1050, "sklearn-compose"], [1050, "id9"], [1051, "sklearn-compose"], [1052, "sklearn-compose"], [1053, "sklearn-compose"], [1053, "id5"], [1054, "sklearn-compose"], [1055, "sklearn-compose"], [1056, "sklearn-compose"], [1057, "sklearn-compose"], [1058, "sklearn-compose"], [1058, "id5"], [1059, "sklearn-compose"]], "sklearn.covariance": [[8, "module-sklearn.covariance"], [1049, "sklearn-covariance"], [1049, "id26"], [1053, "sklearn-covariance"], [1054, "sklearn-covariance"], [1055, "sklearn-covariance"], [1057, "sklearn-covariance"], [1058, "sklearn-covariance"]], "sklearn.cross_decomposition": [[9, "module-sklearn.cross_decomposition"], [1051, "sklearn-cross-decomposition"], [1053, "sklearn-cross-decomposition"], [1053, "id6"], [1055, "sklearn-cross-decomposition"], [1057, "sklearn-cross-decomposition"], [1059, "sklearn-cross-decomposition"]], "sklearn.datasets": [[10, "module-sklearn.datasets"], [1049, "sklearn-datasets"], [1049, "id13"], [1049, "id27"], [1050, "sklearn-datasets"], [1050, "id10"], [1051, "sklearn-datasets"], [1052, "sklearn-datasets"], [1053, "sklearn-datasets"], [1054, "sklearn-datasets"], [1054, "id9"], [1055, "sklearn-datasets"], [1055, "id9"], [1056, "sklearn-datasets"], [1056, "id13"], [1057, "sklearn-datasets"], [1057, "id9"], [1058, "sklearn-datasets"], [1059, "sklearn-datasets"]], "sklearn.decomposition": [[11, "module-sklearn.decomposition"], [1049, "sklearn-decomposition"], [1049, "id4"], [1049, "id14"], [1049, "id28"], [1050, "sklearn-decomposition"], [1050, "id11"], [1051, "sklearn-decomposition"], [1052, "sklearn-decomposition"], [1052, "id6"], [1053, "sklearn-decomposition"], [1053, "id7"], [1054, "sklearn-decomposition"], [1054, "id10"], [1055, "sklearn-decomposition"], [1055, "id10"], [1056, "sklearn-decomposition"], [1056, "id14"], [1057, "sklearn-decomposition"], [1057, "id10"], [1058, "sklearn-decomposition"], [1059, "sklearn-decomposition"]], "sklearn.discriminant_analysis": [[12, "module-sklearn.discriminant_analysis"], [1049, "sklearn-discriminant-analysis"], [1050, "sklearn-discriminant-analysis"], [1053, "sklearn-discriminant-analysis"], [1055, "sklearn-discriminant-analysis"], [1056, "sklearn-discriminant-analysis"], [1057, "sklearn-discriminant-analysis"]], "sklearn.dummy": [[13, "module-sklearn.dummy"], [1049, "sklearn-dummy"], [1050, "sklearn-dummy"], [1051, "sklearn-dummy"], [1054, "sklearn-dummy"], [1055, "sklearn-dummy"], [1059, "sklearn-dummy"]], "sklearn.ensemble": [[14, "module-sklearn.ensemble"], [1049, "sklearn-ensemble"], [1049, "id29"], [1050, "sklearn-ensemble"], [1050, "id12"], [1051, "sklearn-ensemble"], [1052, "sklearn-ensemble"], [1052, "id7"], [1053, "sklearn-ensemble"], [1053, "id8"], [1054, "sklearn-ensemble"], [1054, "id2"], [1054, "id11"], [1055, "sklearn-ensemble"], [1056, "sklearn-ensemble"], [1056, "id3"], [1056, "id15"], [1057, "sklearn-ensemble"], [1057, "id11"], [1058, "sklearn-ensemble"], [1058, "id6"], [1059, "sklearn-ensemble"]], "sklearn.exceptions": [[15, "module-sklearn.exceptions"], [1053, "sklearn-exceptions"], [1057, "sklearn-exceptions"]], "sklearn.experimental": [[16, "module-sklearn.experimental"]], "sklearn.externals": [[1050, "sklearn-externals"]], "sklearn.feature_extraction": [[17, "module-sklearn.feature_extraction"], [1049, "sklearn-feature-extraction"], [1049, "id15"], [1049, "id30"], [1050, "sklearn-feature-extraction"], [1051, "sklearn-feature-extraction"], [1052, "sklearn-feature-extraction"], [1052, "id8"], [1053, "sklearn-feature-extraction"], [1053, "id9"], [1054, "sklearn-feature-extraction"], [1054, "id12"], [1055, "sklearn-feature-extraction"], [1056, "sklearn-feature-extraction"], [1057, "sklearn-feature-extraction"], [1058, "sklearn-feature-extraction"], [1059, "sklearn-feature-extraction"]], "sklearn.feature_selection": [[18, "module-sklearn.feature_selection"], [1049, "sklearn-feature-selection"], [1051, "sklearn-feature-selection"], [1052, "sklearn-feature-selection"], [1053, "sklearn-feature-selection"], [1054, "sklearn-feature-selection"], [1054, "id13"], [1055, "sklearn-feature-selection"], [1055, "id2"], [1055, "id11"], [1056, "sklearn-feature-selection"], [1056, "id16"], [1057, "sklearn-feature-selection"], [1057, "id12"], [1058, "sklearn-feature-selection"], [1059, "sklearn-feature-selection"]], "sklearn.gaussian_process": [[19, "module-sklearn.gaussian_process"], [1049, "sklearn-gaussian-process"], [1051, "sklearn-gaussian-process"], [1052, "sklearn-gaussian-process"], [1053, "sklearn-gaussian-process"], [1053, "id10"], [1054, "sklearn-gaussian-process"], [1055, "sklearn-gaussian-process"], [1056, "sklearn-gaussian-process"], [1057, "sklearn-gaussian-process"]], "sklearn.impute": [[20, "module-sklearn.impute"], [1049, "sklearn-impute"], [1049, "id31"], [1050, "sklearn-impute"], [1050, "id13"], [1051, "sklearn-impute"], [1051, "id6"], [1052, "sklearn-impute"], [1053, "sklearn-impute"], [1054, "sklearn-impute"], [1055, "sklearn-impute"], [1055, "id12"], [1056, "sklearn-impute"], [1057, "sklearn-impute"], [1057, "id13"], [1058, "sklearn-impute"], [1059, "sklearn-impute"]], "sklearn.inspection": [[21, "module-sklearn.inspection"], [1050, "sklearn-inspection"], [1050, "id3"], [1050, "id14"], [1051, "sklearn-inspection"], [1051, "id7"], [1052, "sklearn-inspection"], [1052, "id11"], [1053, "sklearn-inspection"], [1054, "sklearn-inspection"], [1055, "sklearn-inspection"], [1056, "sklearn-inspection"], [1056, "id17"], [1057, "sklearn-inspection"], [1058, "sklearn-inspection"], [1058, "id7"], [1059, "sklearn-inspection"]], "sklearn.isotonic": [[22, "module-sklearn.isotonic"], [1049, "sklearn-isotonic"], [1050, "sklearn-isotonic"], [1051, "sklearn-isotonic"], [1053, "sklearn-isotonic"], [1055, "sklearn-isotonic"], [1056, "sklearn-isotonic"]], "sklearn.kernel_approximation": [[23, "module-sklearn.kernel_approximation"], [1051, "sklearn-kernel-approximation"], [1053, "sklearn-kernel-approximation"], [1054, "sklearn-kernel-approximation"], [1055, "sklearn-kernel-approximation"], [1056, "sklearn-kernel-approximation"], [1057, "sklearn-kernel-approximation"]], "sklearn.kernel_ridge": [[24, "module-sklearn.kernel_ridge"], [1058, "sklearn-kernel-ridge"]], "sklearn.linear_model": [[25, "module-sklearn.linear_model"], [1049, "sklearn-linear-model"], [1049, "id16"], [1049, "id32"], [1050, "sklearn-linear-model"], [1050, "id15"], [1051, "sklearn-linear-model"], [1052, "sklearn-linear-model"], [1052, "id9"], [1053, "sklearn-linear-model"], [1053, "id11"], [1054, "sklearn-linear-model"], [1054, "id3"], [1054, "id14"], [1055, "sklearn-linear-model"], [1055, "id13"], [1056, "sklearn-linear-model"], [1056, "id18"], [1057, "sklearn-linear-model"], [1058, "sklearn-linear-model"], [1058, "id8"], [1059, "sklearn-linear-model"], [1060, "sklearn-linear-model"]], "sklearn.manifold": [[26, "module-sklearn.manifold"], [1049, "sklearn-manifold"], [1050, "sklearn-manifold"], [1051, "sklearn-manifold"], [1052, "sklearn-manifold"], [1053, "sklearn-manifold"], [1054, "sklearn-manifold"], [1054, "id15"], [1055, "sklearn-manifold"], [1055, "id14"], [1056, "sklearn-manifold"], [1056, "id19"], [1057, "sklearn-manifold"], [1059, "sklearn-manifold"]], "sklearn.metrics": [[27, "module-sklearn.metrics"], [1049, "sklearn-metrics"], [1049, "id17"], [1049, "id33"], [1050, "sklearn-metrics"], [1050, "id4"], [1050, "id16"], [1051, "sklearn-metrics"], [1051, "id2"], [1051, "id8"], [1052, "sklearn-metrics"], [1052, "id10"], [1053, "sklearn-metrics"], [1053, "id2"], [1053, "id12"], [1054, "sklearn-metrics"], [1054, "id16"], [1055, "sklearn-metrics"], [1055, "id3"], [1055, "id15"], [1056, "sklearn-metrics"], [1057, "sklearn-metrics"], [1057, "id2"], [1057, "id14"], [1058, "sklearn-metrics"], [1059, "sklearn-metrics"], [1059, "id2"], [1060, "sklearn-metrics"]], "sklearn.mixture": [[28, "module-sklearn.mixture"], [1049, "sklearn-mixture"], [1049, "id34"], [1050, "sklearn-mixture"], [1054, "sklearn-mixture"], [1055, "sklearn-mixture"], [1057, "sklearn-mixture"], [1057, "id15"], [1059, "sklearn-mixture"]], "sklearn.model_selection": [[29, "module-sklearn.model_selection"], [1049, "sklearn-model-selection"], [1049, "id35"], [1050, "sklearn-model-selection"], [1051, "sklearn-model-selection"], [1051, "id9"], [1051, "id13"], [1052, "sklearn-model-selection"], [1053, "sklearn-model-selection"], [1053, "id13"], [1054, "sklearn-model-selection"], [1055, "sklearn-model-selection"], [1056, "sklearn-model-selection"], [1056, "id20"], [1057, "sklearn-model-selection"], [1058, "sklearn-model-selection"], [1059, "sklearn-model-selection"], [1059, "id3"], [1060, "sklearn-model-selection"]], "sklearn.multiclass": [[30, "module-sklearn.multiclass"], [1050, "sklearn-multiclass"], [1053, "sklearn-multiclass"], [1054, "sklearn-multiclass"], [1055, "sklearn-multiclass"]], "sklearn.multioutput": [[31, "module-sklearn.multioutput"], [1049, "sklearn-multioutput"], [1050, "sklearn-multioutput"], [1051, "sklearn-multioutput"], [1052, "sklearn-multioutput"], [1053, "sklearn-multioutput"], [1053, "id14"], [1056, "sklearn-multioutput"], [1057, "sklearn-multioutput"], [1058, "sklearn-multioutput"], [1059, "sklearn-multioutput"]], "sklearn.naive_bayes": [[32, "module-sklearn.naive_bayes"], [1049, "sklearn-naive-bayes"], [1051, "sklearn-naive-bayes"], [1051, "id10"], [1052, "sklearn-naive-bayes"], [1053, "sklearn-naive-bayes"], [1054, "sklearn-naive-bayes"], [1056, "sklearn-naive-bayes"], [1057, "sklearn-naive-bayes"]], "sklearn.neighbors": [[33, "module-sklearn.neighbors"], [1049, "sklearn-neighbors"], [1049, "id7"], [1049, "id18"], [1049, "id36"], [1050, "sklearn-neighbors"], [1050, "id5"], [1050, "id17"], [1051, "sklearn-neighbors"], [1051, "id11"], [1053, "sklearn-neighbors"], [1054, "sklearn-neighbors"], [1054, "id4"], [1054, "id17"], [1055, "sklearn-neighbors"], [1056, "sklearn-neighbors"], [1057, "sklearn-neighbors"], [1057, "id16"], [1058, "sklearn-neighbors"], [1059, "sklearn-neighbors"], [1060, "sklearn-neighbors"]], "sklearn.neural_network": [[34, "module-sklearn.neural_network"], [1049, "sklearn-neural-network"], [1050, "sklearn-neural-network"], [1051, "sklearn-neural-network"], [1052, "sklearn-neural-network"], [1053, "sklearn-neural-network"], [1054, "sklearn-neural-network"], [1055, "sklearn-neural-network"], [1056, "sklearn-neural-network"], [1056, "id21"], [1057, "sklearn-neural-network"]], "sklearn.pipeline": [[35, "module-sklearn.pipeline"], [1049, "sklearn-pipeline"], [1050, "sklearn-pipeline"], [1051, "sklearn-pipeline"], [1052, "sklearn-pipeline"], [1053, "sklearn-pipeline"], [1054, "sklearn-pipeline"], [1054, "id18"], [1055, "sklearn-pipeline"], [1056, "sklearn-pipeline"], [1057, "sklearn-pipeline"], [1059, "sklearn-pipeline"]], "sklearn.preprocessing": [[36, "module-sklearn.preprocessing"], [1049, "sklearn-preprocessing"], [1049, "id19"], [1049, "id37"], [1050, "sklearn-preprocessing"], [1050, "id18"], [1051, "sklearn-preprocessing"], [1051, "id12"], [1052, "sklearn-preprocessing"], [1053, "sklearn-preprocessing"], [1053, "id15"], [1054, "sklearn-preprocessing"], [1054, "id19"], [1055, "sklearn-preprocessing"], [1055, "id4"], [1055, "id16"], [1056, "sklearn-preprocessing"], [1056, "id4"], [1056, "id22"], [1057, "sklearn-preprocessing"], [1057, "id17"], [1058, "sklearn-preprocessing"], [1058, "id9"], [1059, "sklearn-preprocessing"]], "sklearn.random_projection": [[37, "module-sklearn.random_projection"], [1055, "sklearn-random-projection"]], "sklearn.semi_supervised": [[38, "module-sklearn.semi_supervised"], [1051, "sklearn-semi-supervised"], [1052, "sklearn-semi-supervised"], [1053, "sklearn-semi-supervised"], [1053, "id3"], [1053, "id16"], [1057, "sklearn-semi-supervised"]], "sklearn.svm": [[39, "module-sklearn.svm"], [1049, "sklearn-svm"], [1049, "id38"], [1050, "sklearn-svm"], [1051, "sklearn-svm"], [1052, "sklearn-svm"], [1053, "sklearn-svm"], [1054, "sklearn-svm"], [1054, "id20"], [1055, "sklearn-svm"], [1056, "sklearn-svm"], [1057, "sklearn-svm"]], "sklearn.tree": [[40, "module-sklearn.tree"], [1049, "sklearn-tree"], [1050, "sklearn-tree"], [1050, "id19"], [1051, "sklearn-tree"], [1052, "sklearn-tree"], [1053, "sklearn-tree"], [1053, "id17"], [1054, "sklearn-tree"], [1054, "id21"], [1055, "sklearn-tree"], [1055, "id5"], [1055, "id17"], [1056, "sklearn-tree"], [1056, "id5"], [1056, "id23"], [1057, "sklearn-tree"], [1057, "id3"], [1057, "id18"], [1058, "sklearn-tree"], [1058, "id10"], [1059, "sklearn-tree"]], "sklearn.utils": [[41, "module-sklearn.utils"], [1049, "sklearn-utils"], [1049, "id20"], [1049, "id39"], [1050, "sklearn-utils"], [1051, "sklearn-utils"], [1051, "id14"], [1052, "sklearn-utils"], [1052, "id12"], [1053, "sklearn-utils"], [1053, "id18"], [1054, "sklearn-utils"], [1054, "id5"], [1054, "id22"], [1055, "sklearn-utils"], [1055, "id18"], [1056, "sklearn-utils"], [1056, "id6"], [1056, "id24"], [1057, "sklearn-utils"], [1058, "sklearn-utils"], [1058, "id11"], [1059, "sklearn-utils"]], "sklearn.utils.sparsefuncs": [[1050, "sklearn-utils-sparsefuncs"]], "skops.io": [[410, "skops-io"]], "smacof": [[702, "smacof"]], "solido": [[1024, "id23"]], "sort_graph_by_row_values": [[867, "sort-graph-by-row-values"]], "sparse_encode": [[556, "sparse-encode"]], "spectral_clustering": [[470, "spectral-clustering"]], "spectral_embedding": [[703, "spectral-embedding"]], "t-SNE: The effect of various perplexity values on the shape": [[245, "t-sne-the-effect-of-various-perplexity-values-on-the-shape"]], "t-distributed Stochastic Neighbor Embedding (t-SNE)": [[997, "t-distributed-stochastic-neighbor-embedding-t-sne"]], "top_k_accuracy_score": [[802, "top-k-accuracy-score"]], "train_test_split": [[838, "train-test-split"]], "transform and inverse_transform methods": [[1033, null]], "trustworthiness": [[704, "trustworthiness"]], "type_of_target": [[963, "type-of-target"]], "unique_labels": [[964, "unique-labels"]], "v_measure_score": [[803, "v-measure-score"]], "validation_curve": [[839, "validation-curve"]], "ward_tree": [[471, "ward-tree"]], "weighted_mode": [[951, "weighted-mode"]], "zero_one_loss": [[804, "zero-one-loss"]], "\u201cStatlog\u201d German credit dataset": [[272, "statlog-german-credit-dataset"]]}, "docnames": ["about", "api/deprecated", "api/index", "api/sklearn", "api/sklearn.base", "api/sklearn.calibration", "api/sklearn.cluster", "api/sklearn.compose", "api/sklearn.covariance", "api/sklearn.cross_decomposition", "api/sklearn.datasets", "api/sklearn.decomposition", "api/sklearn.discriminant_analysis", "api/sklearn.dummy", "api/sklearn.ensemble", "api/sklearn.exceptions", "api/sklearn.experimental", "api/sklearn.feature_extraction", "api/sklearn.feature_selection", "api/sklearn.gaussian_process", "api/sklearn.impute", "api/sklearn.inspection", "api/sklearn.isotonic", "api/sklearn.kernel_approximation", "api/sklearn.kernel_ridge", "api/sklearn.linear_model", "api/sklearn.manifold", "api/sklearn.metrics", "api/sklearn.mixture", "api/sklearn.model_selection", "api/sklearn.multiclass", "api/sklearn.multioutput", "api/sklearn.naive_bayes", "api/sklearn.neighbors", "api/sklearn.neural_network", "api/sklearn.pipeline", "api/sklearn.preprocessing", "api/sklearn.random_projection", "api/sklearn.semi_supervised", "api/sklearn.svm", "api/sklearn.tree", "api/sklearn.utils", "auto_examples/applications/index", "auto_examples/applications/plot_cyclical_feature_engineering", "auto_examples/applications/plot_digits_denoising", "auto_examples/applications/plot_face_recognition", "auto_examples/applications/plot_model_complexity_influence", "auto_examples/applications/plot_out_of_core_classification", "auto_examples/applications/plot_outlier_detection_wine", "auto_examples/applications/plot_prediction_latency", "auto_examples/applications/plot_species_distribution_modeling", "auto_examples/applications/plot_stock_market", "auto_examples/applications/plot_time_series_lagged_features", "auto_examples/applications/plot_tomography_l1_reconstruction", "auto_examples/applications/plot_topics_extraction_with_nmf_lda", "auto_examples/applications/wikipedia_principal_eigenvector", "auto_examples/bicluster/index", "auto_examples/bicluster/plot_bicluster_newsgroups", "auto_examples/bicluster/plot_spectral_biclustering", "auto_examples/bicluster/plot_spectral_coclustering", "auto_examples/calibration/index", "auto_examples/calibration/plot_calibration", "auto_examples/calibration/plot_calibration_curve", "auto_examples/calibration/plot_calibration_multiclass", "auto_examples/calibration/plot_compare_calibration", "auto_examples/classification/index", "auto_examples/classification/plot_classification_probability", "auto_examples/classification/plot_classifier_comparison", "auto_examples/classification/plot_digits_classification", "auto_examples/classification/plot_lda", "auto_examples/classification/plot_lda_qda", "auto_examples/cluster/index", "auto_examples/cluster/plot_adjusted_for_chance_measures", "auto_examples/cluster/plot_affinity_propagation", "auto_examples/cluster/plot_agglomerative_clustering", "auto_examples/cluster/plot_agglomerative_clustering_metrics", "auto_examples/cluster/plot_agglomerative_dendrogram", "auto_examples/cluster/plot_birch_vs_minibatchkmeans", "auto_examples/cluster/plot_bisect_kmeans", "auto_examples/cluster/plot_cluster_comparison", "auto_examples/cluster/plot_cluster_iris", "auto_examples/cluster/plot_coin_segmentation", "auto_examples/cluster/plot_coin_ward_segmentation", "auto_examples/cluster/plot_color_quantization", "auto_examples/cluster/plot_dbscan", "auto_examples/cluster/plot_dict_face_patches", "auto_examples/cluster/plot_digits_agglomeration", "auto_examples/cluster/plot_digits_linkage", "auto_examples/cluster/plot_face_compress", "auto_examples/cluster/plot_feature_agglomeration_vs_univariate_selection", "auto_examples/cluster/plot_hdbscan", "auto_examples/cluster/plot_inductive_clustering", "auto_examples/cluster/plot_kmeans_assumptions", "auto_examples/cluster/plot_kmeans_digits", "auto_examples/cluster/plot_kmeans_plusplus", "auto_examples/cluster/plot_kmeans_silhouette_analysis", "auto_examples/cluster/plot_kmeans_stability_low_dim_dense", "auto_examples/cluster/plot_linkage_comparison", "auto_examples/cluster/plot_mean_shift", "auto_examples/cluster/plot_mini_batch_kmeans", "auto_examples/cluster/plot_optics", "auto_examples/cluster/plot_segmentation_toy", "auto_examples/cluster/plot_ward_structured_vs_unstructured", "auto_examples/compose/index", "auto_examples/compose/plot_column_transformer", "auto_examples/compose/plot_column_transformer_mixed_types", "auto_examples/compose/plot_compare_reduction", "auto_examples/compose/plot_digits_pipe", "auto_examples/compose/plot_feature_union", "auto_examples/compose/plot_transformed_target", "auto_examples/covariance/index", "auto_examples/covariance/plot_covariance_estimation", "auto_examples/covariance/plot_lw_vs_oas", "auto_examples/covariance/plot_mahalanobis_distances", "auto_examples/covariance/plot_robust_vs_empirical_covariance", "auto_examples/covariance/plot_sparse_cov", "auto_examples/cross_decomposition/index", "auto_examples/cross_decomposition/plot_compare_cross_decomposition", "auto_examples/cross_decomposition/plot_pcr_vs_pls", "auto_examples/datasets/index", "auto_examples/datasets/plot_digits_last_image", "auto_examples/datasets/plot_iris_dataset", "auto_examples/datasets/plot_random_dataset", "auto_examples/datasets/plot_random_multilabel_dataset", "auto_examples/decomposition/index", "auto_examples/decomposition/plot_faces_decomposition", "auto_examples/decomposition/plot_ica_blind_source_separation", "auto_examples/decomposition/plot_ica_vs_pca", "auto_examples/decomposition/plot_image_denoising", "auto_examples/decomposition/plot_incremental_pca", "auto_examples/decomposition/plot_kernel_pca", "auto_examples/decomposition/plot_pca_iris", "auto_examples/decomposition/plot_pca_vs_fa_model_selection", "auto_examples/decomposition/plot_pca_vs_lda", "auto_examples/decomposition/plot_sparse_coding", "auto_examples/decomposition/plot_varimax_fa", "auto_examples/developing_estimators/index", "auto_examples/developing_estimators/sklearn_is_fitted", "auto_examples/ensemble/index", "auto_examples/ensemble/plot_adaboost_multiclass", "auto_examples/ensemble/plot_adaboost_regression", "auto_examples/ensemble/plot_adaboost_twoclass", "auto_examples/ensemble/plot_bias_variance", "auto_examples/ensemble/plot_ensemble_oob", "auto_examples/ensemble/plot_feature_transformation", "auto_examples/ensemble/plot_forest_hist_grad_boosting_comparison", "auto_examples/ensemble/plot_forest_importances", "auto_examples/ensemble/plot_forest_importances_faces", "auto_examples/ensemble/plot_forest_iris", "auto_examples/ensemble/plot_gradient_boosting_categorical", "auto_examples/ensemble/plot_gradient_boosting_early_stopping", "auto_examples/ensemble/plot_gradient_boosting_oob", "auto_examples/ensemble/plot_gradient_boosting_quantile", "auto_examples/ensemble/plot_gradient_boosting_regression", "auto_examples/ensemble/plot_gradient_boosting_regularization", "auto_examples/ensemble/plot_hgbt_regression", "auto_examples/ensemble/plot_isolation_forest", "auto_examples/ensemble/plot_monotonic_constraints", "auto_examples/ensemble/plot_random_forest_embedding", "auto_examples/ensemble/plot_random_forest_regression_multioutput", "auto_examples/ensemble/plot_stack_predictors", "auto_examples/ensemble/plot_voting_decision_regions", "auto_examples/ensemble/plot_voting_probas", "auto_examples/ensemble/plot_voting_regressor", "auto_examples/exercises/index", "auto_examples/exercises/plot_cv_diabetes", "auto_examples/exercises/plot_digits_classification_exercise", "auto_examples/exercises/plot_iris_exercise", "auto_examples/feature_selection/index", "auto_examples/feature_selection/plot_f_test_vs_mi", "auto_examples/feature_selection/plot_feature_selection", "auto_examples/feature_selection/plot_feature_selection_pipeline", "auto_examples/feature_selection/plot_rfe_digits", "auto_examples/feature_selection/plot_rfe_with_cross_validation", "auto_examples/feature_selection/plot_select_from_model_diabetes", "auto_examples/gaussian_process/index", "auto_examples/gaussian_process/plot_compare_gpr_krr", "auto_examples/gaussian_process/plot_gpc", "auto_examples/gaussian_process/plot_gpc_iris", "auto_examples/gaussian_process/plot_gpc_isoprobability", "auto_examples/gaussian_process/plot_gpc_xor", "auto_examples/gaussian_process/plot_gpr_co2", "auto_examples/gaussian_process/plot_gpr_noisy", "auto_examples/gaussian_process/plot_gpr_noisy_targets", "auto_examples/gaussian_process/plot_gpr_on_structured_data", "auto_examples/gaussian_process/plot_gpr_prior_posterior", "auto_examples/impute/index", "auto_examples/impute/plot_iterative_imputer_variants_comparison", "auto_examples/impute/plot_missing_values", "auto_examples/index", "auto_examples/inspection/index", "auto_examples/inspection/plot_causal_interpretation", "auto_examples/inspection/plot_linear_model_coefficient_interpretation", "auto_examples/inspection/plot_partial_dependence", "auto_examples/inspection/plot_permutation_importance", "auto_examples/inspection/plot_permutation_importance_multicollinear", "auto_examples/kernel_approximation/index", "auto_examples/kernel_approximation/plot_scalable_poly_kernels", "auto_examples/linear_model/index", "auto_examples/linear_model/plot_ard", "auto_examples/linear_model/plot_bayesian_ridge_curvefit", "auto_examples/linear_model/plot_elastic_net_precomputed_gram_matrix_with_weighted_samples", "auto_examples/linear_model/plot_huber_vs_ridge", "auto_examples/linear_model/plot_iris_logistic", "auto_examples/linear_model/plot_lasso_and_elasticnet", "auto_examples/linear_model/plot_lasso_coordinate_descent_path", "auto_examples/linear_model/plot_lasso_dense_vs_sparse_data", "auto_examples/linear_model/plot_lasso_lars", "auto_examples/linear_model/plot_lasso_lars_ic", "auto_examples/linear_model/plot_lasso_model_selection", "auto_examples/linear_model/plot_logistic", "auto_examples/linear_model/plot_logistic_l1_l2_sparsity", "auto_examples/linear_model/plot_logistic_multinomial", "auto_examples/linear_model/plot_logistic_path", "auto_examples/linear_model/plot_multi_task_lasso_support", "auto_examples/linear_model/plot_nnls", "auto_examples/linear_model/plot_ols", "auto_examples/linear_model/plot_ols_3d", "auto_examples/linear_model/plot_ols_ridge_variance", "auto_examples/linear_model/plot_omp", "auto_examples/linear_model/plot_poisson_regression_non_normal_loss", "auto_examples/linear_model/plot_polynomial_interpolation", "auto_examples/linear_model/plot_quantile_regression", "auto_examples/linear_model/plot_ransac", "auto_examples/linear_model/plot_ridge_coeffs", "auto_examples/linear_model/plot_ridge_path", "auto_examples/linear_model/plot_robust_fit", "auto_examples/linear_model/plot_sgd_comparison", "auto_examples/linear_model/plot_sgd_early_stopping", "auto_examples/linear_model/plot_sgd_iris", "auto_examples/linear_model/plot_sgd_loss_functions", "auto_examples/linear_model/plot_sgd_penalties", "auto_examples/linear_model/plot_sgd_separating_hyperplane", "auto_examples/linear_model/plot_sgd_weighted_samples", "auto_examples/linear_model/plot_sgdocsvm_vs_ocsvm", "auto_examples/linear_model/plot_sparse_logistic_regression_20newsgroups", "auto_examples/linear_model/plot_sparse_logistic_regression_mnist", "auto_examples/linear_model/plot_theilsen", "auto_examples/linear_model/plot_tweedie_regression_insurance_claims", "auto_examples/manifold/index", "auto_examples/manifold/plot_compare_methods", "auto_examples/manifold/plot_lle_digits", "auto_examples/manifold/plot_manifold_sphere", "auto_examples/manifold/plot_mds", "auto_examples/manifold/plot_swissroll", "auto_examples/manifold/plot_t_sne_perplexity", "auto_examples/miscellaneous/index", "auto_examples/miscellaneous/plot_anomaly_comparison", "auto_examples/miscellaneous/plot_display_object_visualization", "auto_examples/miscellaneous/plot_estimator_representation", "auto_examples/miscellaneous/plot_isotonic_regression", "auto_examples/miscellaneous/plot_johnson_lindenstrauss_bound", "auto_examples/miscellaneous/plot_kernel_approximation", "auto_examples/miscellaneous/plot_kernel_ridge_regression", "auto_examples/miscellaneous/plot_metadata_routing", "auto_examples/miscellaneous/plot_multilabel", "auto_examples/miscellaneous/plot_multioutput_face_completion", "auto_examples/miscellaneous/plot_outlier_detection_bench", "auto_examples/miscellaneous/plot_partial_dependence_visualization_api", "auto_examples/miscellaneous/plot_pipeline_display", "auto_examples/miscellaneous/plot_roc_curve_visualization_api", "auto_examples/miscellaneous/plot_set_output", "auto_examples/mixture/index", "auto_examples/mixture/plot_concentration_prior", "auto_examples/mixture/plot_gmm", "auto_examples/mixture/plot_gmm_covariances", "auto_examples/mixture/plot_gmm_init", "auto_examples/mixture/plot_gmm_pdf", "auto_examples/mixture/plot_gmm_selection", "auto_examples/mixture/plot_gmm_sin", "auto_examples/model_selection/index", "auto_examples/model_selection/plot_confusion_matrix", "auto_examples/model_selection/plot_cost_sensitive_learning", "auto_examples/model_selection/plot_cv_indices", "auto_examples/model_selection/plot_cv_predict", "auto_examples/model_selection/plot_det", "auto_examples/model_selection/plot_grid_search_digits", "auto_examples/model_selection/plot_grid_search_refit_callable", "auto_examples/model_selection/plot_grid_search_stats", "auto_examples/model_selection/plot_grid_search_text_feature_extraction", "auto_examples/model_selection/plot_learning_curve", "auto_examples/model_selection/plot_likelihood_ratios", "auto_examples/model_selection/plot_multi_metric_evaluation", "auto_examples/model_selection/plot_nested_cross_validation_iris", "auto_examples/model_selection/plot_permutation_tests_for_classification", "auto_examples/model_selection/plot_precision_recall", "auto_examples/model_selection/plot_randomized_search", "auto_examples/model_selection/plot_roc", "auto_examples/model_selection/plot_roc_crossval", "auto_examples/model_selection/plot_successive_halving_heatmap", "auto_examples/model_selection/plot_successive_halving_iterations", "auto_examples/model_selection/plot_train_error_vs_test_error", "auto_examples/model_selection/plot_tuned_decision_threshold", "auto_examples/model_selection/plot_underfitting_overfitting", "auto_examples/model_selection/plot_validation_curve", "auto_examples/multiclass/index", "auto_examples/multiclass/plot_multiclass_overview", "auto_examples/multioutput/index", "auto_examples/multioutput/plot_classifier_chain_yeast", "auto_examples/neighbors/approximate_nearest_neighbors", "auto_examples/neighbors/index", "auto_examples/neighbors/plot_caching_nearest_neighbors", "auto_examples/neighbors/plot_classification", "auto_examples/neighbors/plot_digits_kde_sampling", "auto_examples/neighbors/plot_kde_1d", "auto_examples/neighbors/plot_lof_novelty_detection", "auto_examples/neighbors/plot_lof_outlier_detection", "auto_examples/neighbors/plot_nca_classification", "auto_examples/neighbors/plot_nca_dim_reduction", "auto_examples/neighbors/plot_nca_illustration", "auto_examples/neighbors/plot_nearest_centroid", "auto_examples/neighbors/plot_regression", "auto_examples/neighbors/plot_species_kde", "auto_examples/neural_networks/index", "auto_examples/neural_networks/plot_mlp_alpha", "auto_examples/neural_networks/plot_mlp_training_curves", "auto_examples/neural_networks/plot_mnist_filters", "auto_examples/neural_networks/plot_rbm_logistic_classification", "auto_examples/preprocessing/index", "auto_examples/preprocessing/plot_all_scaling", "auto_examples/preprocessing/plot_discretization", "auto_examples/preprocessing/plot_discretization_classification", "auto_examples/preprocessing/plot_discretization_strategies", "auto_examples/preprocessing/plot_map_data_to_normal", "auto_examples/preprocessing/plot_scaling_importance", "auto_examples/preprocessing/plot_target_encoder", "auto_examples/preprocessing/plot_target_encoder_cross_val", "auto_examples/release_highlights/index", "auto_examples/release_highlights/plot_release_highlights_0_22_0", "auto_examples/release_highlights/plot_release_highlights_0_23_0", "auto_examples/release_highlights/plot_release_highlights_0_24_0", "auto_examples/release_highlights/plot_release_highlights_1_0_0", "auto_examples/release_highlights/plot_release_highlights_1_1_0", "auto_examples/release_highlights/plot_release_highlights_1_2_0", "auto_examples/release_highlights/plot_release_highlights_1_3_0", "auto_examples/release_highlights/plot_release_highlights_1_4_0", "auto_examples/release_highlights/plot_release_highlights_1_5_0", "auto_examples/semi_supervised/index", "auto_examples/semi_supervised/plot_label_propagation_digits", "auto_examples/semi_supervised/plot_label_propagation_digits_active_learning", "auto_examples/semi_supervised/plot_label_propagation_structure", "auto_examples/semi_supervised/plot_self_training_varying_threshold", "auto_examples/semi_supervised/plot_semi_supervised_newsgroups", "auto_examples/semi_supervised/plot_semi_supervised_versus_svm_iris", "auto_examples/svm/index", "auto_examples/svm/plot_custom_kernel", "auto_examples/svm/plot_iris_svc", "auto_examples/svm/plot_linearsvc_support_vectors", "auto_examples/svm/plot_oneclass", "auto_examples/svm/plot_rbf_parameters", "auto_examples/svm/plot_separating_hyperplane", "auto_examples/svm/plot_separating_hyperplane_unbalanced", "auto_examples/svm/plot_svm_anova", "auto_examples/svm/plot_svm_kernels", "auto_examples/svm/plot_svm_margin", "auto_examples/svm/plot_svm_regression", "auto_examples/svm/plot_svm_scale_c", "auto_examples/svm/plot_svm_tie_breaking", "auto_examples/svm/plot_weighted_samples", "auto_examples/text/index", "auto_examples/text/plot_document_classification_20newsgroups", "auto_examples/text/plot_document_clustering", "auto_examples/text/plot_hashing_vs_dict_vectorizer", "auto_examples/tree/index", "auto_examples/tree/plot_cost_complexity_pruning", "auto_examples/tree/plot_iris_dtc", "auto_examples/tree/plot_tree_regression", "auto_examples/tree/plot_tree_regression_multioutput", "auto_examples/tree/plot_unveil_tree_structure", "common_pitfalls", "communication_team", "communication_team_emeritus", "computing", "computing/computational_performance", "computing/parallelism", "computing/scaling_strategies", "contributor_experience_team", "contributor_experience_team_emeritus", "data_transforms", "datasets", "datasets/loading_other_datasets", "datasets/real_world", "datasets/sample_generators", "datasets/toy_dataset", "developers/advanced_installation", "developers/bug_triaging", "developers/contributing", "developers/cython", "developers/develop", "developers/index", "developers/maintainer", "developers/minimal_reproducer", "developers/performance", "developers/plotting", "developers/tips", "developers/utilities", "dispatching", "documentation_team", "faq", "getting_started", "glossary", "governance", "index", "inspection", "install", "maintainers", "maintainers_emeritus", "metadata_routing", "min_dependency_substitutions", "min_dependency_table", "model_persistence", "model_selection", "modules/array_api", "modules/biclustering", "modules/calibration", "modules/classification_threshold", "modules/clustering", "modules/compose", "modules/covariance", "modules/cross_decomposition", "modules/cross_validation", "modules/decomposition", "modules/density", "modules/ensemble", "modules/feature_extraction", "modules/feature_selection", "modules/gaussian_process", "modules/generated/dbscan-function", "modules/generated/fastica-function", "modules/generated/oas-function", "modules/generated/sklearn.base.BaseEstimator", "modules/generated/sklearn.base.BiclusterMixin", "modules/generated/sklearn.base.ClassNamePrefixFeaturesOutMixin", "modules/generated/sklearn.base.ClassifierMixin", "modules/generated/sklearn.base.ClusterMixin", "modules/generated/sklearn.base.DensityMixin", "modules/generated/sklearn.base.MetaEstimatorMixin", "modules/generated/sklearn.base.OneToOneFeatureMixin", "modules/generated/sklearn.base.OutlierMixin", "modules/generated/sklearn.base.RegressorMixin", "modules/generated/sklearn.base.TransformerMixin", "modules/generated/sklearn.base.clone", "modules/generated/sklearn.base.is_classifier", "modules/generated/sklearn.base.is_clusterer", "modules/generated/sklearn.base.is_regressor", "modules/generated/sklearn.calibration.CalibratedClassifierCV", "modules/generated/sklearn.calibration.CalibrationDisplay", "modules/generated/sklearn.calibration.calibration_curve", "modules/generated/sklearn.cluster.AffinityPropagation", "modules/generated/sklearn.cluster.AgglomerativeClustering", "modules/generated/sklearn.cluster.Birch", "modules/generated/sklearn.cluster.BisectingKMeans", "modules/generated/sklearn.cluster.DBSCAN", "modules/generated/sklearn.cluster.FeatureAgglomeration", "modules/generated/sklearn.cluster.HDBSCAN", "modules/generated/sklearn.cluster.KMeans", "modules/generated/sklearn.cluster.MeanShift", "modules/generated/sklearn.cluster.MiniBatchKMeans", "modules/generated/sklearn.cluster.OPTICS", "modules/generated/sklearn.cluster.SpectralBiclustering", "modules/generated/sklearn.cluster.SpectralClustering", "modules/generated/sklearn.cluster.SpectralCoclustering", "modules/generated/sklearn.cluster.affinity_propagation", "modules/generated/sklearn.cluster.cluster_optics_dbscan", "modules/generated/sklearn.cluster.cluster_optics_xi", "modules/generated/sklearn.cluster.compute_optics_graph", "modules/generated/sklearn.cluster.estimate_bandwidth", "modules/generated/sklearn.cluster.k_means", "modules/generated/sklearn.cluster.kmeans_plusplus", "modules/generated/sklearn.cluster.mean_shift", "modules/generated/sklearn.cluster.spectral_clustering", "modules/generated/sklearn.cluster.ward_tree", "modules/generated/sklearn.compose.ColumnTransformer", "modules/generated/sklearn.compose.TransformedTargetRegressor", "modules/generated/sklearn.compose.make_column_selector", "modules/generated/sklearn.compose.make_column_transformer", "modules/generated/sklearn.config_context", "modules/generated/sklearn.covariance.EllipticEnvelope", "modules/generated/sklearn.covariance.EmpiricalCovariance", "modules/generated/sklearn.covariance.GraphicalLasso", "modules/generated/sklearn.covariance.GraphicalLassoCV", "modules/generated/sklearn.covariance.LedoitWolf", "modules/generated/sklearn.covariance.MinCovDet", "modules/generated/sklearn.covariance.OAS", "modules/generated/sklearn.covariance.ShrunkCovariance", "modules/generated/sklearn.covariance.empirical_covariance", "modules/generated/sklearn.covariance.graphical_lasso", "modules/generated/sklearn.covariance.ledoit_wolf", "modules/generated/sklearn.covariance.ledoit_wolf_shrinkage", "modules/generated/sklearn.covariance.shrunk_covariance", "modules/generated/sklearn.cross_decomposition.CCA", "modules/generated/sklearn.cross_decomposition.PLSCanonical", "modules/generated/sklearn.cross_decomposition.PLSRegression", "modules/generated/sklearn.cross_decomposition.PLSSVD", "modules/generated/sklearn.datasets.clear_data_home", "modules/generated/sklearn.datasets.dump_svmlight_file", "modules/generated/sklearn.datasets.fetch_20newsgroups", "modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized", "modules/generated/sklearn.datasets.fetch_california_housing", "modules/generated/sklearn.datasets.fetch_covtype", "modules/generated/sklearn.datasets.fetch_kddcup99", "modules/generated/sklearn.datasets.fetch_lfw_pairs", "modules/generated/sklearn.datasets.fetch_lfw_people", "modules/generated/sklearn.datasets.fetch_olivetti_faces", "modules/generated/sklearn.datasets.fetch_openml", "modules/generated/sklearn.datasets.fetch_rcv1", "modules/generated/sklearn.datasets.fetch_species_distributions", "modules/generated/sklearn.datasets.get_data_home", "modules/generated/sklearn.datasets.load_breast_cancer", "modules/generated/sklearn.datasets.load_diabetes", "modules/generated/sklearn.datasets.load_digits", "modules/generated/sklearn.datasets.load_files", "modules/generated/sklearn.datasets.load_iris", "modules/generated/sklearn.datasets.load_linnerud", "modules/generated/sklearn.datasets.load_sample_image", "modules/generated/sklearn.datasets.load_sample_images", "modules/generated/sklearn.datasets.load_svmlight_file", "modules/generated/sklearn.datasets.load_svmlight_files", "modules/generated/sklearn.datasets.load_wine", "modules/generated/sklearn.datasets.make_biclusters", "modules/generated/sklearn.datasets.make_blobs", "modules/generated/sklearn.datasets.make_checkerboard", "modules/generated/sklearn.datasets.make_circles", "modules/generated/sklearn.datasets.make_classification", "modules/generated/sklearn.datasets.make_friedman1", "modules/generated/sklearn.datasets.make_friedman2", "modules/generated/sklearn.datasets.make_friedman3", "modules/generated/sklearn.datasets.make_gaussian_quantiles", "modules/generated/sklearn.datasets.make_hastie_10_2", "modules/generated/sklearn.datasets.make_low_rank_matrix", "modules/generated/sklearn.datasets.make_moons", "modules/generated/sklearn.datasets.make_multilabel_classification", "modules/generated/sklearn.datasets.make_regression", "modules/generated/sklearn.datasets.make_s_curve", "modules/generated/sklearn.datasets.make_sparse_coded_signal", "modules/generated/sklearn.datasets.make_sparse_spd_matrix", "modules/generated/sklearn.datasets.make_sparse_uncorrelated", "modules/generated/sklearn.datasets.make_spd_matrix", "modules/generated/sklearn.datasets.make_swiss_roll", "modules/generated/sklearn.decomposition.DictionaryLearning", "modules/generated/sklearn.decomposition.FactorAnalysis", "modules/generated/sklearn.decomposition.FastICA", "modules/generated/sklearn.decomposition.IncrementalPCA", "modules/generated/sklearn.decomposition.KernelPCA", "modules/generated/sklearn.decomposition.LatentDirichletAllocation", "modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning", "modules/generated/sklearn.decomposition.MiniBatchNMF", "modules/generated/sklearn.decomposition.MiniBatchSparsePCA", "modules/generated/sklearn.decomposition.NMF", "modules/generated/sklearn.decomposition.PCA", "modules/generated/sklearn.decomposition.SparseCoder", "modules/generated/sklearn.decomposition.SparsePCA", "modules/generated/sklearn.decomposition.TruncatedSVD", "modules/generated/sklearn.decomposition.dict_learning", "modules/generated/sklearn.decomposition.dict_learning_online", "modules/generated/sklearn.decomposition.non_negative_factorization", "modules/generated/sklearn.decomposition.sparse_encode", "modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis", "modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis", "modules/generated/sklearn.dummy.DummyClassifier", "modules/generated/sklearn.dummy.DummyRegressor", "modules/generated/sklearn.ensemble.AdaBoostClassifier", "modules/generated/sklearn.ensemble.AdaBoostRegressor", "modules/generated/sklearn.ensemble.BaggingClassifier", "modules/generated/sklearn.ensemble.BaggingRegressor", "modules/generated/sklearn.ensemble.ExtraTreesClassifier", "modules/generated/sklearn.ensemble.ExtraTreesRegressor", "modules/generated/sklearn.ensemble.GradientBoostingClassifier", "modules/generated/sklearn.ensemble.GradientBoostingRegressor", "modules/generated/sklearn.ensemble.HistGradientBoostingClassifier", "modules/generated/sklearn.ensemble.HistGradientBoostingRegressor", "modules/generated/sklearn.ensemble.IsolationForest", "modules/generated/sklearn.ensemble.RandomForestClassifier", "modules/generated/sklearn.ensemble.RandomForestRegressor", "modules/generated/sklearn.ensemble.RandomTreesEmbedding", "modules/generated/sklearn.ensemble.StackingClassifier", "modules/generated/sklearn.ensemble.StackingRegressor", "modules/generated/sklearn.ensemble.VotingClassifier", "modules/generated/sklearn.ensemble.VotingRegressor", "modules/generated/sklearn.exceptions.ConvergenceWarning", "modules/generated/sklearn.exceptions.DataConversionWarning", "modules/generated/sklearn.exceptions.DataDimensionalityWarning", "modules/generated/sklearn.exceptions.EfficiencyWarning", "modules/generated/sklearn.exceptions.FitFailedWarning", "modules/generated/sklearn.exceptions.InconsistentVersionWarning", "modules/generated/sklearn.exceptions.NotFittedError", "modules/generated/sklearn.exceptions.UndefinedMetricWarning", "modules/generated/sklearn.experimental.enable_halving_search_cv", "modules/generated/sklearn.experimental.enable_iterative_imputer", "modules/generated/sklearn.feature_extraction.DictVectorizer", "modules/generated/sklearn.feature_extraction.FeatureHasher", "modules/generated/sklearn.feature_extraction.image.PatchExtractor", "modules/generated/sklearn.feature_extraction.image.extract_patches_2d", "modules/generated/sklearn.feature_extraction.image.grid_to_graph", "modules/generated/sklearn.feature_extraction.image.img_to_graph", "modules/generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d", "modules/generated/sklearn.feature_extraction.text.CountVectorizer", "modules/generated/sklearn.feature_extraction.text.HashingVectorizer", "modules/generated/sklearn.feature_extraction.text.TfidfTransformer", "modules/generated/sklearn.feature_extraction.text.TfidfVectorizer", "modules/generated/sklearn.feature_selection.GenericUnivariateSelect", "modules/generated/sklearn.feature_selection.RFE", "modules/generated/sklearn.feature_selection.RFECV", "modules/generated/sklearn.feature_selection.SelectFdr", "modules/generated/sklearn.feature_selection.SelectFpr", "modules/generated/sklearn.feature_selection.SelectFromModel", "modules/generated/sklearn.feature_selection.SelectFwe", "modules/generated/sklearn.feature_selection.SelectKBest", "modules/generated/sklearn.feature_selection.SelectPercentile", "modules/generated/sklearn.feature_selection.SelectorMixin", "modules/generated/sklearn.feature_selection.SequentialFeatureSelector", "modules/generated/sklearn.feature_selection.VarianceThreshold", "modules/generated/sklearn.feature_selection.chi2", "modules/generated/sklearn.feature_selection.f_classif", "modules/generated/sklearn.feature_selection.f_regression", "modules/generated/sklearn.feature_selection.mutual_info_classif", "modules/generated/sklearn.feature_selection.mutual_info_regression", "modules/generated/sklearn.feature_selection.r_regression", "modules/generated/sklearn.gaussian_process.GaussianProcessClassifier", "modules/generated/sklearn.gaussian_process.GaussianProcessRegressor", "modules/generated/sklearn.gaussian_process.kernels.CompoundKernel", "modules/generated/sklearn.gaussian_process.kernels.ConstantKernel", "modules/generated/sklearn.gaussian_process.kernels.DotProduct", "modules/generated/sklearn.gaussian_process.kernels.ExpSineSquared", "modules/generated/sklearn.gaussian_process.kernels.Exponentiation", "modules/generated/sklearn.gaussian_process.kernels.Hyperparameter", "modules/generated/sklearn.gaussian_process.kernels.Kernel", "modules/generated/sklearn.gaussian_process.kernels.Matern", "modules/generated/sklearn.gaussian_process.kernels.PairwiseKernel", "modules/generated/sklearn.gaussian_process.kernels.Product", "modules/generated/sklearn.gaussian_process.kernels.RBF", "modules/generated/sklearn.gaussian_process.kernels.RationalQuadratic", "modules/generated/sklearn.gaussian_process.kernels.Sum", "modules/generated/sklearn.gaussian_process.kernels.WhiteKernel", "modules/generated/sklearn.get_config", "modules/generated/sklearn.impute.IterativeImputer", "modules/generated/sklearn.impute.KNNImputer", "modules/generated/sklearn.impute.MissingIndicator", "modules/generated/sklearn.impute.SimpleImputer", "modules/generated/sklearn.inspection.DecisionBoundaryDisplay", "modules/generated/sklearn.inspection.PartialDependenceDisplay", "modules/generated/sklearn.inspection.partial_dependence", "modules/generated/sklearn.inspection.permutation_importance", "modules/generated/sklearn.isotonic.IsotonicRegression", "modules/generated/sklearn.isotonic.check_increasing", "modules/generated/sklearn.isotonic.isotonic_regression", "modules/generated/sklearn.kernel_approximation.AdditiveChi2Sampler", "modules/generated/sklearn.kernel_approximation.Nystroem", "modules/generated/sklearn.kernel_approximation.PolynomialCountSketch", "modules/generated/sklearn.kernel_approximation.RBFSampler", "modules/generated/sklearn.kernel_approximation.SkewedChi2Sampler", "modules/generated/sklearn.kernel_ridge.KernelRidge", "modules/generated/sklearn.linear_model.ARDRegression", "modules/generated/sklearn.linear_model.BayesianRidge", "modules/generated/sklearn.linear_model.ElasticNet", "modules/generated/sklearn.linear_model.ElasticNetCV", "modules/generated/sklearn.linear_model.GammaRegressor", "modules/generated/sklearn.linear_model.HuberRegressor", "modules/generated/sklearn.linear_model.Lars", "modules/generated/sklearn.linear_model.LarsCV", "modules/generated/sklearn.linear_model.Lasso", "modules/generated/sklearn.linear_model.LassoCV", "modules/generated/sklearn.linear_model.LassoLars", "modules/generated/sklearn.linear_model.LassoLarsCV", "modules/generated/sklearn.linear_model.LassoLarsIC", "modules/generated/sklearn.linear_model.LinearRegression", "modules/generated/sklearn.linear_model.LogisticRegression", "modules/generated/sklearn.linear_model.LogisticRegressionCV", "modules/generated/sklearn.linear_model.MultiTaskElasticNet", "modules/generated/sklearn.linear_model.MultiTaskElasticNetCV", "modules/generated/sklearn.linear_model.MultiTaskLasso", "modules/generated/sklearn.linear_model.MultiTaskLassoCV", "modules/generated/sklearn.linear_model.OrthogonalMatchingPursuit", "modules/generated/sklearn.linear_model.OrthogonalMatchingPursuitCV", "modules/generated/sklearn.linear_model.PassiveAggressiveClassifier", "modules/generated/sklearn.linear_model.PassiveAggressiveRegressor", "modules/generated/sklearn.linear_model.Perceptron", "modules/generated/sklearn.linear_model.PoissonRegressor", "modules/generated/sklearn.linear_model.QuantileRegressor", "modules/generated/sklearn.linear_model.RANSACRegressor", "modules/generated/sklearn.linear_model.Ridge", "modules/generated/sklearn.linear_model.RidgeCV", "modules/generated/sklearn.linear_model.RidgeClassifier", "modules/generated/sklearn.linear_model.RidgeClassifierCV", "modules/generated/sklearn.linear_model.SGDClassifier", "modules/generated/sklearn.linear_model.SGDOneClassSVM", "modules/generated/sklearn.linear_model.SGDRegressor", "modules/generated/sklearn.linear_model.TheilSenRegressor", "modules/generated/sklearn.linear_model.TweedieRegressor", "modules/generated/sklearn.linear_model.enet_path", "modules/generated/sklearn.linear_model.lars_path", "modules/generated/sklearn.linear_model.lars_path_gram", "modules/generated/sklearn.linear_model.lasso_path", "modules/generated/sklearn.linear_model.orthogonal_mp", "modules/generated/sklearn.linear_model.orthogonal_mp_gram", "modules/generated/sklearn.linear_model.ridge_regression", "modules/generated/sklearn.manifold.Isomap", "modules/generated/sklearn.manifold.LocallyLinearEmbedding", "modules/generated/sklearn.manifold.MDS", "modules/generated/sklearn.manifold.SpectralEmbedding", "modules/generated/sklearn.manifold.TSNE", "modules/generated/sklearn.manifold.locally_linear_embedding", "modules/generated/sklearn.manifold.smacof", "modules/generated/sklearn.manifold.spectral_embedding", "modules/generated/sklearn.manifold.trustworthiness", "modules/generated/sklearn.metrics.ConfusionMatrixDisplay", "modules/generated/sklearn.metrics.DetCurveDisplay", "modules/generated/sklearn.metrics.DistanceMetric", "modules/generated/sklearn.metrics.PrecisionRecallDisplay", "modules/generated/sklearn.metrics.PredictionErrorDisplay", "modules/generated/sklearn.metrics.RocCurveDisplay", "modules/generated/sklearn.metrics.accuracy_score", "modules/generated/sklearn.metrics.adjusted_mutual_info_score", "modules/generated/sklearn.metrics.adjusted_rand_score", "modules/generated/sklearn.metrics.auc", "modules/generated/sklearn.metrics.average_precision_score", "modules/generated/sklearn.metrics.balanced_accuracy_score", "modules/generated/sklearn.metrics.brier_score_loss", "modules/generated/sklearn.metrics.calinski_harabasz_score", "modules/generated/sklearn.metrics.check_scoring", "modules/generated/sklearn.metrics.class_likelihood_ratios", "modules/generated/sklearn.metrics.classification_report", "modules/generated/sklearn.metrics.cluster.contingency_matrix", "modules/generated/sklearn.metrics.cluster.pair_confusion_matrix", "modules/generated/sklearn.metrics.cohen_kappa_score", "modules/generated/sklearn.metrics.completeness_score", "modules/generated/sklearn.metrics.confusion_matrix", "modules/generated/sklearn.metrics.consensus_score", "modules/generated/sklearn.metrics.coverage_error", "modules/generated/sklearn.metrics.d2_absolute_error_score", "modules/generated/sklearn.metrics.d2_log_loss_score", "modules/generated/sklearn.metrics.d2_pinball_score", "modules/generated/sklearn.metrics.d2_tweedie_score", "modules/generated/sklearn.metrics.davies_bouldin_score", "modules/generated/sklearn.metrics.dcg_score", "modules/generated/sklearn.metrics.det_curve", "modules/generated/sklearn.metrics.explained_variance_score", "modules/generated/sklearn.metrics.f1_score", "modules/generated/sklearn.metrics.fbeta_score", "modules/generated/sklearn.metrics.fowlkes_mallows_score", "modules/generated/sklearn.metrics.get_scorer", "modules/generated/sklearn.metrics.get_scorer_names", "modules/generated/sklearn.metrics.hamming_loss", "modules/generated/sklearn.metrics.hinge_loss", "modules/generated/sklearn.metrics.homogeneity_completeness_v_measure", "modules/generated/sklearn.metrics.homogeneity_score", "modules/generated/sklearn.metrics.jaccard_score", "modules/generated/sklearn.metrics.label_ranking_average_precision_score", "modules/generated/sklearn.metrics.label_ranking_loss", "modules/generated/sklearn.metrics.log_loss", "modules/generated/sklearn.metrics.make_scorer", "modules/generated/sklearn.metrics.matthews_corrcoef", "modules/generated/sklearn.metrics.max_error", "modules/generated/sklearn.metrics.mean_absolute_error", "modules/generated/sklearn.metrics.mean_absolute_percentage_error", "modules/generated/sklearn.metrics.mean_gamma_deviance", "modules/generated/sklearn.metrics.mean_pinball_loss", "modules/generated/sklearn.metrics.mean_poisson_deviance", "modules/generated/sklearn.metrics.mean_squared_error", "modules/generated/sklearn.metrics.mean_squared_log_error", "modules/generated/sklearn.metrics.mean_tweedie_deviance", "modules/generated/sklearn.metrics.median_absolute_error", "modules/generated/sklearn.metrics.multilabel_confusion_matrix", "modules/generated/sklearn.metrics.mutual_info_score", "modules/generated/sklearn.metrics.ndcg_score", "modules/generated/sklearn.metrics.normalized_mutual_info_score", "modules/generated/sklearn.metrics.pairwise.additive_chi2_kernel", "modules/generated/sklearn.metrics.pairwise.chi2_kernel", "modules/generated/sklearn.metrics.pairwise.cosine_distances", "modules/generated/sklearn.metrics.pairwise.cosine_similarity", "modules/generated/sklearn.metrics.pairwise.distance_metrics", "modules/generated/sklearn.metrics.pairwise.euclidean_distances", "modules/generated/sklearn.metrics.pairwise.haversine_distances", "modules/generated/sklearn.metrics.pairwise.kernel_metrics", "modules/generated/sklearn.metrics.pairwise.laplacian_kernel", "modules/generated/sklearn.metrics.pairwise.linear_kernel", "modules/generated/sklearn.metrics.pairwise.manhattan_distances", "modules/generated/sklearn.metrics.pairwise.nan_euclidean_distances", "modules/generated/sklearn.metrics.pairwise.paired_cosine_distances", "modules/generated/sklearn.metrics.pairwise.paired_distances", "modules/generated/sklearn.metrics.pairwise.paired_euclidean_distances", "modules/generated/sklearn.metrics.pairwise.paired_manhattan_distances", "modules/generated/sklearn.metrics.pairwise.pairwise_kernels", "modules/generated/sklearn.metrics.pairwise.polynomial_kernel", "modules/generated/sklearn.metrics.pairwise.rbf_kernel", "modules/generated/sklearn.metrics.pairwise.sigmoid_kernel", "modules/generated/sklearn.metrics.pairwise_distances", "modules/generated/sklearn.metrics.pairwise_distances_argmin", "modules/generated/sklearn.metrics.pairwise_distances_argmin_min", "modules/generated/sklearn.metrics.pairwise_distances_chunked", "modules/generated/sklearn.metrics.precision_recall_curve", "modules/generated/sklearn.metrics.precision_recall_fscore_support", "modules/generated/sklearn.metrics.precision_score", "modules/generated/sklearn.metrics.r2_score", "modules/generated/sklearn.metrics.rand_score", "modules/generated/sklearn.metrics.recall_score", "modules/generated/sklearn.metrics.roc_auc_score", "modules/generated/sklearn.metrics.roc_curve", "modules/generated/sklearn.metrics.root_mean_squared_error", "modules/generated/sklearn.metrics.root_mean_squared_log_error", "modules/generated/sklearn.metrics.silhouette_samples", "modules/generated/sklearn.metrics.silhouette_score", "modules/generated/sklearn.metrics.top_k_accuracy_score", "modules/generated/sklearn.metrics.v_measure_score", "modules/generated/sklearn.metrics.zero_one_loss", "modules/generated/sklearn.mixture.BayesianGaussianMixture", "modules/generated/sklearn.mixture.GaussianMixture", "modules/generated/sklearn.model_selection.FixedThresholdClassifier", "modules/generated/sklearn.model_selection.GridSearchCV", "modules/generated/sklearn.model_selection.GroupKFold", "modules/generated/sklearn.model_selection.GroupShuffleSplit", "modules/generated/sklearn.model_selection.HalvingGridSearchCV", "modules/generated/sklearn.model_selection.HalvingRandomSearchCV", "modules/generated/sklearn.model_selection.KFold", "modules/generated/sklearn.model_selection.LearningCurveDisplay", "modules/generated/sklearn.model_selection.LeaveOneGroupOut", "modules/generated/sklearn.model_selection.LeaveOneOut", "modules/generated/sklearn.model_selection.LeavePGroupsOut", "modules/generated/sklearn.model_selection.LeavePOut", "modules/generated/sklearn.model_selection.ParameterGrid", "modules/generated/sklearn.model_selection.ParameterSampler", "modules/generated/sklearn.model_selection.PredefinedSplit", "modules/generated/sklearn.model_selection.RandomizedSearchCV", "modules/generated/sklearn.model_selection.RepeatedKFold", "modules/generated/sklearn.model_selection.RepeatedStratifiedKFold", "modules/generated/sklearn.model_selection.ShuffleSplit", "modules/generated/sklearn.model_selection.StratifiedGroupKFold", "modules/generated/sklearn.model_selection.StratifiedKFold", "modules/generated/sklearn.model_selection.StratifiedShuffleSplit", "modules/generated/sklearn.model_selection.TimeSeriesSplit", "modules/generated/sklearn.model_selection.TunedThresholdClassifierCV", "modules/generated/sklearn.model_selection.ValidationCurveDisplay", "modules/generated/sklearn.model_selection.check_cv", "modules/generated/sklearn.model_selection.cross_val_predict", "modules/generated/sklearn.model_selection.cross_val_score", "modules/generated/sklearn.model_selection.cross_validate", "modules/generated/sklearn.model_selection.learning_curve", "modules/generated/sklearn.model_selection.permutation_test_score", "modules/generated/sklearn.model_selection.train_test_split", "modules/generated/sklearn.model_selection.validation_curve", "modules/generated/sklearn.multiclass.OneVsOneClassifier", "modules/generated/sklearn.multiclass.OneVsRestClassifier", "modules/generated/sklearn.multiclass.OutputCodeClassifier", "modules/generated/sklearn.multioutput.ClassifierChain", "modules/generated/sklearn.multioutput.MultiOutputClassifier", "modules/generated/sklearn.multioutput.MultiOutputRegressor", "modules/generated/sklearn.multioutput.RegressorChain", "modules/generated/sklearn.naive_bayes.BernoulliNB", "modules/generated/sklearn.naive_bayes.CategoricalNB", "modules/generated/sklearn.naive_bayes.ComplementNB", "modules/generated/sklearn.naive_bayes.GaussianNB", "modules/generated/sklearn.naive_bayes.MultinomialNB", "modules/generated/sklearn.neighbors.BallTree", "modules/generated/sklearn.neighbors.KDTree", "modules/generated/sklearn.neighbors.KNeighborsClassifier", "modules/generated/sklearn.neighbors.KNeighborsRegressor", "modules/generated/sklearn.neighbors.KNeighborsTransformer", "modules/generated/sklearn.neighbors.KernelDensity", "modules/generated/sklearn.neighbors.LocalOutlierFactor", "modules/generated/sklearn.neighbors.NearestCentroid", "modules/generated/sklearn.neighbors.NearestNeighbors", "modules/generated/sklearn.neighbors.NeighborhoodComponentsAnalysis", "modules/generated/sklearn.neighbors.RadiusNeighborsClassifier", "modules/generated/sklearn.neighbors.RadiusNeighborsRegressor", "modules/generated/sklearn.neighbors.RadiusNeighborsTransformer", "modules/generated/sklearn.neighbors.kneighbors_graph", "modules/generated/sklearn.neighbors.radius_neighbors_graph", "modules/generated/sklearn.neighbors.sort_graph_by_row_values", "modules/generated/sklearn.neural_network.BernoulliRBM", "modules/generated/sklearn.neural_network.MLPClassifier", "modules/generated/sklearn.neural_network.MLPRegressor", "modules/generated/sklearn.pipeline.FeatureUnion", "modules/generated/sklearn.pipeline.Pipeline", "modules/generated/sklearn.pipeline.make_pipeline", "modules/generated/sklearn.pipeline.make_union", "modules/generated/sklearn.preprocessing.Binarizer", "modules/generated/sklearn.preprocessing.FunctionTransformer", "modules/generated/sklearn.preprocessing.KBinsDiscretizer", "modules/generated/sklearn.preprocessing.KernelCenterer", "modules/generated/sklearn.preprocessing.LabelBinarizer", "modules/generated/sklearn.preprocessing.LabelEncoder", "modules/generated/sklearn.preprocessing.MaxAbsScaler", "modules/generated/sklearn.preprocessing.MinMaxScaler", "modules/generated/sklearn.preprocessing.MultiLabelBinarizer", "modules/generated/sklearn.preprocessing.Normalizer", "modules/generated/sklearn.preprocessing.OneHotEncoder", "modules/generated/sklearn.preprocessing.OrdinalEncoder", "modules/generated/sklearn.preprocessing.PolynomialFeatures", "modules/generated/sklearn.preprocessing.PowerTransformer", "modules/generated/sklearn.preprocessing.QuantileTransformer", "modules/generated/sklearn.preprocessing.RobustScaler", "modules/generated/sklearn.preprocessing.SplineTransformer", "modules/generated/sklearn.preprocessing.StandardScaler", "modules/generated/sklearn.preprocessing.TargetEncoder", "modules/generated/sklearn.preprocessing.add_dummy_feature", "modules/generated/sklearn.preprocessing.binarize", "modules/generated/sklearn.preprocessing.label_binarize", "modules/generated/sklearn.preprocessing.maxabs_scale", "modules/generated/sklearn.preprocessing.minmax_scale", "modules/generated/sklearn.preprocessing.normalize", "modules/generated/sklearn.preprocessing.power_transform", "modules/generated/sklearn.preprocessing.quantile_transform", "modules/generated/sklearn.preprocessing.robust_scale", "modules/generated/sklearn.preprocessing.scale", "modules/generated/sklearn.random_projection.GaussianRandomProjection", "modules/generated/sklearn.random_projection.SparseRandomProjection", "modules/generated/sklearn.random_projection.johnson_lindenstrauss_min_dim", "modules/generated/sklearn.semi_supervised.LabelPropagation", "modules/generated/sklearn.semi_supervised.LabelSpreading", "modules/generated/sklearn.semi_supervised.SelfTrainingClassifier", "modules/generated/sklearn.set_config", "modules/generated/sklearn.show_versions", "modules/generated/sklearn.svm.LinearSVC", "modules/generated/sklearn.svm.LinearSVR", "modules/generated/sklearn.svm.NuSVC", "modules/generated/sklearn.svm.NuSVR", "modules/generated/sklearn.svm.OneClassSVM", "modules/generated/sklearn.svm.SVC", "modules/generated/sklearn.svm.SVR", "modules/generated/sklearn.svm.l1_min_c", "modules/generated/sklearn.tree.DecisionTreeClassifier", "modules/generated/sklearn.tree.DecisionTreeRegressor", "modules/generated/sklearn.tree.ExtraTreeClassifier", "modules/generated/sklearn.tree.ExtraTreeRegressor", "modules/generated/sklearn.tree.export_graphviz", "modules/generated/sklearn.tree.export_text", "modules/generated/sklearn.tree.plot_tree", "modules/generated/sklearn.utils.Bunch", "modules/generated/sklearn.utils._safe_indexing", "modules/generated/sklearn.utils.arrayfuncs.min_pos", "modules/generated/sklearn.utils.as_float_array", "modules/generated/sklearn.utils.assert_all_finite", "modules/generated/sklearn.utils.check_X_y", "modules/generated/sklearn.utils.check_array", "modules/generated/sklearn.utils.check_consistent_length", "modules/generated/sklearn.utils.check_random_state", "modules/generated/sklearn.utils.check_scalar", "modules/generated/sklearn.utils.class_weight.compute_class_weight", "modules/generated/sklearn.utils.class_weight.compute_sample_weight", "modules/generated/sklearn.utils.deprecated", "modules/generated/sklearn.utils.discovery.all_displays", "modules/generated/sklearn.utils.discovery.all_estimators", "modules/generated/sklearn.utils.discovery.all_functions", "modules/generated/sklearn.utils.estimator_checks.check_estimator", "modules/generated/sklearn.utils.estimator_checks.parametrize_with_checks", "modules/generated/sklearn.utils.estimator_html_repr", "modules/generated/sklearn.utils.extmath.density", "modules/generated/sklearn.utils.extmath.fast_logdet", "modules/generated/sklearn.utils.extmath.randomized_range_finder", "modules/generated/sklearn.utils.extmath.randomized_svd", "modules/generated/sklearn.utils.extmath.safe_sparse_dot", "modules/generated/sklearn.utils.extmath.weighted_mode", "modules/generated/sklearn.utils.gen_batches", "modules/generated/sklearn.utils.gen_even_slices", "modules/generated/sklearn.utils.graph.single_source_shortest_path_length", "modules/generated/sklearn.utils.indexable", "modules/generated/sklearn.utils.metadata_routing.MetadataRequest", "modules/generated/sklearn.utils.metadata_routing.MetadataRouter", "modules/generated/sklearn.utils.metadata_routing.MethodMapping", "modules/generated/sklearn.utils.metadata_routing.get_routing_for_object", "modules/generated/sklearn.utils.metadata_routing.process_routing", "modules/generated/sklearn.utils.metaestimators.available_if", "modules/generated/sklearn.utils.multiclass.is_multilabel", "modules/generated/sklearn.utils.multiclass.type_of_target", "modules/generated/sklearn.utils.multiclass.unique_labels", "modules/generated/sklearn.utils.murmurhash3_32", "modules/generated/sklearn.utils.parallel.Parallel", "modules/generated/sklearn.utils.parallel.delayed", "modules/generated/sklearn.utils.parallel_backend", "modules/generated/sklearn.utils.random.sample_without_replacement", "modules/generated/sklearn.utils.register_parallel_backend", "modules/generated/sklearn.utils.resample", "modules/generated/sklearn.utils.safe_mask", "modules/generated/sklearn.utils.safe_sqr", "modules/generated/sklearn.utils.shuffle", "modules/generated/sklearn.utils.sparsefuncs.incr_mean_variance_axis", "modules/generated/sklearn.utils.sparsefuncs.inplace_column_scale", "modules/generated/sklearn.utils.sparsefuncs.inplace_csr_column_scale", "modules/generated/sklearn.utils.sparsefuncs.inplace_row_scale", "modules/generated/sklearn.utils.sparsefuncs.inplace_swap_column", "modules/generated/sklearn.utils.sparsefuncs.inplace_swap_row", "modules/generated/sklearn.utils.sparsefuncs.mean_variance_axis", "modules/generated/sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l1", "modules/generated/sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l2", "modules/generated/sklearn.utils.validation.check_is_fitted", "modules/generated/sklearn.utils.validation.check_memory", "modules/generated/sklearn.utils.validation.check_symmetric", "modules/generated/sklearn.utils.validation.column_or_1d", "modules/generated/sklearn.utils.validation.has_fit_parameter", "modules/grid_search", "modules/impute", "modules/isotonic", "modules/kernel_approximation", "modules/kernel_ridge", "modules/lda_qda", "modules/learning_curve", "modules/linear_model", "modules/manifold", "modules/metrics", "modules/mixture", "modules/model_evaluation", "modules/multiclass", "modules/naive_bayes", "modules/neighbors", "modules/neural_networks_supervised", "modules/neural_networks_unsupervised", "modules/outlier_detection", "modules/partial_dependence", "modules/permutation_importance", "modules/pipeline", "modules/preprocessing", "modules/preprocessing_targets", "modules/random_projection", "modules/semi_supervised", "modules/sgd", "modules/svm", "modules/tree", "modules/unsupervised_reduction", "presentations", "related_projects", "roadmap", "sg_execution_times", "supervised_learning", "support", "testimonials/testimonials", "tutorial/basic/tutorial", "tutorial/index", "tutorial/machine_learning_map/index", "tutorial/statistical_inference/index", "tutorial/statistical_inference/model_selection", "tutorial/statistical_inference/putting_together", "tutorial/statistical_inference/settings", "tutorial/statistical_inference/supervised_learning", "tutorial/statistical_inference/unsupervised_learning", "tutorial/text_analytics/working_with_text_data", "unsupervised_learning", "user_guide", "versions", "visualizations", "whats_new", "whats_new/_contributors", "whats_new/older_versions", "whats_new/v0.13", "whats_new/v0.14", "whats_new/v0.15", "whats_new/v0.16", "whats_new/v0.17", "whats_new/v0.18", "whats_new/v0.19", "whats_new/v0.20", "whats_new/v0.21", "whats_new/v0.22", "whats_new/v0.23", "whats_new/v0.24", "whats_new/v1.0", "whats_new/v1.1", "whats_new/v1.2", "whats_new/v1.3", "whats_new/v1.4", "whats_new/v1.5", "whats_new/v1.6"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["about.rst", "api/deprecated.rst", "api/index.rst", "api/sklearn.rst", "api/sklearn.base.rst", "api/sklearn.calibration.rst", "api/sklearn.cluster.rst", "api/sklearn.compose.rst", "api/sklearn.covariance.rst", "api/sklearn.cross_decomposition.rst", "api/sklearn.datasets.rst", "api/sklearn.decomposition.rst", "api/sklearn.discriminant_analysis.rst", "api/sklearn.dummy.rst", "api/sklearn.ensemble.rst", "api/sklearn.exceptions.rst", "api/sklearn.experimental.rst", "api/sklearn.feature_extraction.rst", "api/sklearn.feature_selection.rst", "api/sklearn.gaussian_process.rst", "api/sklearn.impute.rst", "api/sklearn.inspection.rst", "api/sklearn.isotonic.rst", "api/sklearn.kernel_approximation.rst", "api/sklearn.kernel_ridge.rst", "api/sklearn.linear_model.rst", "api/sklearn.manifold.rst", "api/sklearn.metrics.rst", "api/sklearn.mixture.rst", "api/sklearn.model_selection.rst", "api/sklearn.multiclass.rst", "api/sklearn.multioutput.rst", "api/sklearn.naive_bayes.rst", "api/sklearn.neighbors.rst", "api/sklearn.neural_network.rst", "api/sklearn.pipeline.rst", "api/sklearn.preprocessing.rst", "api/sklearn.random_projection.rst", "api/sklearn.semi_supervised.rst", "api/sklearn.svm.rst", "api/sklearn.tree.rst", "api/sklearn.utils.rst", "auto_examples/applications/index.rst", "auto_examples/applications/plot_cyclical_feature_engineering.rst", "auto_examples/applications/plot_digits_denoising.rst", "auto_examples/applications/plot_face_recognition.rst", "auto_examples/applications/plot_model_complexity_influence.rst", "auto_examples/applications/plot_out_of_core_classification.rst", "auto_examples/applications/plot_outlier_detection_wine.rst", "auto_examples/applications/plot_prediction_latency.rst", "auto_examples/applications/plot_species_distribution_modeling.rst", "auto_examples/applications/plot_stock_market.rst", "auto_examples/applications/plot_time_series_lagged_features.rst", "auto_examples/applications/plot_tomography_l1_reconstruction.rst", "auto_examples/applications/plot_topics_extraction_with_nmf_lda.rst", "auto_examples/applications/wikipedia_principal_eigenvector.rst", "auto_examples/bicluster/index.rst", "auto_examples/bicluster/plot_bicluster_newsgroups.rst", "auto_examples/bicluster/plot_spectral_biclustering.rst", "auto_examples/bicluster/plot_spectral_coclustering.rst", "auto_examples/calibration/index.rst", "auto_examples/calibration/plot_calibration.rst", "auto_examples/calibration/plot_calibration_curve.rst", "auto_examples/calibration/plot_calibration_multiclass.rst", "auto_examples/calibration/plot_compare_calibration.rst", "auto_examples/classification/index.rst", "auto_examples/classification/plot_classification_probability.rst", "auto_examples/classification/plot_classifier_comparison.rst", "auto_examples/classification/plot_digits_classification.rst", "auto_examples/classification/plot_lda.rst", "auto_examples/classification/plot_lda_qda.rst", "auto_examples/cluster/index.rst", "auto_examples/cluster/plot_adjusted_for_chance_measures.rst", "auto_examples/cluster/plot_affinity_propagation.rst", "auto_examples/cluster/plot_agglomerative_clustering.rst", "auto_examples/cluster/plot_agglomerative_clustering_metrics.rst", "auto_examples/cluster/plot_agglomerative_dendrogram.rst", "auto_examples/cluster/plot_birch_vs_minibatchkmeans.rst", "auto_examples/cluster/plot_bisect_kmeans.rst", "auto_examples/cluster/plot_cluster_comparison.rst", "auto_examples/cluster/plot_cluster_iris.rst", "auto_examples/cluster/plot_coin_segmentation.rst", "auto_examples/cluster/plot_coin_ward_segmentation.rst", "auto_examples/cluster/plot_color_quantization.rst", "auto_examples/cluster/plot_dbscan.rst", "auto_examples/cluster/plot_dict_face_patches.rst", "auto_examples/cluster/plot_digits_agglomeration.rst", "auto_examples/cluster/plot_digits_linkage.rst", "auto_examples/cluster/plot_face_compress.rst", "auto_examples/cluster/plot_feature_agglomeration_vs_univariate_selection.rst", "auto_examples/cluster/plot_hdbscan.rst", "auto_examples/cluster/plot_inductive_clustering.rst", "auto_examples/cluster/plot_kmeans_assumptions.rst", "auto_examples/cluster/plot_kmeans_digits.rst", "auto_examples/cluster/plot_kmeans_plusplus.rst", "auto_examples/cluster/plot_kmeans_silhouette_analysis.rst", "auto_examples/cluster/plot_kmeans_stability_low_dim_dense.rst", "auto_examples/cluster/plot_linkage_comparison.rst", "auto_examples/cluster/plot_mean_shift.rst", "auto_examples/cluster/plot_mini_batch_kmeans.rst", "auto_examples/cluster/plot_optics.rst", "auto_examples/cluster/plot_segmentation_toy.rst", "auto_examples/cluster/plot_ward_structured_vs_unstructured.rst", "auto_examples/compose/index.rst", "auto_examples/compose/plot_column_transformer.rst", "auto_examples/compose/plot_column_transformer_mixed_types.rst", "auto_examples/compose/plot_compare_reduction.rst", "auto_examples/compose/plot_digits_pipe.rst", "auto_examples/compose/plot_feature_union.rst", "auto_examples/compose/plot_transformed_target.rst", "auto_examples/covariance/index.rst", "auto_examples/covariance/plot_covariance_estimation.rst", "auto_examples/covariance/plot_lw_vs_oas.rst", "auto_examples/covariance/plot_mahalanobis_distances.rst", "auto_examples/covariance/plot_robust_vs_empirical_covariance.rst", "auto_examples/covariance/plot_sparse_cov.rst", "auto_examples/cross_decomposition/index.rst", "auto_examples/cross_decomposition/plot_compare_cross_decomposition.rst", "auto_examples/cross_decomposition/plot_pcr_vs_pls.rst", "auto_examples/datasets/index.rst", "auto_examples/datasets/plot_digits_last_image.rst", "auto_examples/datasets/plot_iris_dataset.rst", "auto_examples/datasets/plot_random_dataset.rst", "auto_examples/datasets/plot_random_multilabel_dataset.rst", "auto_examples/decomposition/index.rst", "auto_examples/decomposition/plot_faces_decomposition.rst", "auto_examples/decomposition/plot_ica_blind_source_separation.rst", "auto_examples/decomposition/plot_ica_vs_pca.rst", "auto_examples/decomposition/plot_image_denoising.rst", "auto_examples/decomposition/plot_incremental_pca.rst", "auto_examples/decomposition/plot_kernel_pca.rst", "auto_examples/decomposition/plot_pca_iris.rst", "auto_examples/decomposition/plot_pca_vs_fa_model_selection.rst", "auto_examples/decomposition/plot_pca_vs_lda.rst", "auto_examples/decomposition/plot_sparse_coding.rst", "auto_examples/decomposition/plot_varimax_fa.rst", "auto_examples/developing_estimators/index.rst", "auto_examples/developing_estimators/sklearn_is_fitted.rst", "auto_examples/ensemble/index.rst", "auto_examples/ensemble/plot_adaboost_multiclass.rst", "auto_examples/ensemble/plot_adaboost_regression.rst", "auto_examples/ensemble/plot_adaboost_twoclass.rst", "auto_examples/ensemble/plot_bias_variance.rst", "auto_examples/ensemble/plot_ensemble_oob.rst", "auto_examples/ensemble/plot_feature_transformation.rst", "auto_examples/ensemble/plot_forest_hist_grad_boosting_comparison.rst", "auto_examples/ensemble/plot_forest_importances.rst", "auto_examples/ensemble/plot_forest_importances_faces.rst", "auto_examples/ensemble/plot_forest_iris.rst", "auto_examples/ensemble/plot_gradient_boosting_categorical.rst", "auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst", "auto_examples/ensemble/plot_gradient_boosting_oob.rst", "auto_examples/ensemble/plot_gradient_boosting_quantile.rst", "auto_examples/ensemble/plot_gradient_boosting_regression.rst", "auto_examples/ensemble/plot_gradient_boosting_regularization.rst", "auto_examples/ensemble/plot_hgbt_regression.rst", "auto_examples/ensemble/plot_isolation_forest.rst", "auto_examples/ensemble/plot_monotonic_constraints.rst", "auto_examples/ensemble/plot_random_forest_embedding.rst", "auto_examples/ensemble/plot_random_forest_regression_multioutput.rst", "auto_examples/ensemble/plot_stack_predictors.rst", "auto_examples/ensemble/plot_voting_decision_regions.rst", "auto_examples/ensemble/plot_voting_probas.rst", "auto_examples/ensemble/plot_voting_regressor.rst", "auto_examples/exercises/index.rst", "auto_examples/exercises/plot_cv_diabetes.rst", "auto_examples/exercises/plot_digits_classification_exercise.rst", "auto_examples/exercises/plot_iris_exercise.rst", "auto_examples/feature_selection/index.rst", "auto_examples/feature_selection/plot_f_test_vs_mi.rst", "auto_examples/feature_selection/plot_feature_selection.rst", "auto_examples/feature_selection/plot_feature_selection_pipeline.rst", "auto_examples/feature_selection/plot_rfe_digits.rst", "auto_examples/feature_selection/plot_rfe_with_cross_validation.rst", "auto_examples/feature_selection/plot_select_from_model_diabetes.rst", "auto_examples/gaussian_process/index.rst", "auto_examples/gaussian_process/plot_compare_gpr_krr.rst", "auto_examples/gaussian_process/plot_gpc.rst", "auto_examples/gaussian_process/plot_gpc_iris.rst", "auto_examples/gaussian_process/plot_gpc_isoprobability.rst", "auto_examples/gaussian_process/plot_gpc_xor.rst", "auto_examples/gaussian_process/plot_gpr_co2.rst", "auto_examples/gaussian_process/plot_gpr_noisy.rst", "auto_examples/gaussian_process/plot_gpr_noisy_targets.rst", "auto_examples/gaussian_process/plot_gpr_on_structured_data.rst", "auto_examples/gaussian_process/plot_gpr_prior_posterior.rst", "auto_examples/impute/index.rst", "auto_examples/impute/plot_iterative_imputer_variants_comparison.rst", "auto_examples/impute/plot_missing_values.rst", "auto_examples/index.rst", "auto_examples/inspection/index.rst", "auto_examples/inspection/plot_causal_interpretation.rst", "auto_examples/inspection/plot_linear_model_coefficient_interpretation.rst", "auto_examples/inspection/plot_partial_dependence.rst", "auto_examples/inspection/plot_permutation_importance.rst", "auto_examples/inspection/plot_permutation_importance_multicollinear.rst", "auto_examples/kernel_approximation/index.rst", "auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst", "auto_examples/linear_model/index.rst", "auto_examples/linear_model/plot_ard.rst", "auto_examples/linear_model/plot_bayesian_ridge_curvefit.rst", "auto_examples/linear_model/plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.rst", "auto_examples/linear_model/plot_huber_vs_ridge.rst", "auto_examples/linear_model/plot_iris_logistic.rst", "auto_examples/linear_model/plot_lasso_and_elasticnet.rst", "auto_examples/linear_model/plot_lasso_coordinate_descent_path.rst", "auto_examples/linear_model/plot_lasso_dense_vs_sparse_data.rst", "auto_examples/linear_model/plot_lasso_lars.rst", "auto_examples/linear_model/plot_lasso_lars_ic.rst", "auto_examples/linear_model/plot_lasso_model_selection.rst", "auto_examples/linear_model/plot_logistic.rst", "auto_examples/linear_model/plot_logistic_l1_l2_sparsity.rst", "auto_examples/linear_model/plot_logistic_multinomial.rst", "auto_examples/linear_model/plot_logistic_path.rst", "auto_examples/linear_model/plot_multi_task_lasso_support.rst", "auto_examples/linear_model/plot_nnls.rst", "auto_examples/linear_model/plot_ols.rst", "auto_examples/linear_model/plot_ols_3d.rst", "auto_examples/linear_model/plot_ols_ridge_variance.rst", "auto_examples/linear_model/plot_omp.rst", "auto_examples/linear_model/plot_poisson_regression_non_normal_loss.rst", "auto_examples/linear_model/plot_polynomial_interpolation.rst", "auto_examples/linear_model/plot_quantile_regression.rst", "auto_examples/linear_model/plot_ransac.rst", "auto_examples/linear_model/plot_ridge_coeffs.rst", "auto_examples/linear_model/plot_ridge_path.rst", "auto_examples/linear_model/plot_robust_fit.rst", "auto_examples/linear_model/plot_sgd_comparison.rst", "auto_examples/linear_model/plot_sgd_early_stopping.rst", "auto_examples/linear_model/plot_sgd_iris.rst", "auto_examples/linear_model/plot_sgd_loss_functions.rst", "auto_examples/linear_model/plot_sgd_penalties.rst", "auto_examples/linear_model/plot_sgd_separating_hyperplane.rst", "auto_examples/linear_model/plot_sgd_weighted_samples.rst", "auto_examples/linear_model/plot_sgdocsvm_vs_ocsvm.rst", "auto_examples/linear_model/plot_sparse_logistic_regression_20newsgroups.rst", "auto_examples/linear_model/plot_sparse_logistic_regression_mnist.rst", "auto_examples/linear_model/plot_theilsen.rst", "auto_examples/linear_model/plot_tweedie_regression_insurance_claims.rst", "auto_examples/manifold/index.rst", "auto_examples/manifold/plot_compare_methods.rst", "auto_examples/manifold/plot_lle_digits.rst", "auto_examples/manifold/plot_manifold_sphere.rst", "auto_examples/manifold/plot_mds.rst", "auto_examples/manifold/plot_swissroll.rst", "auto_examples/manifold/plot_t_sne_perplexity.rst", "auto_examples/miscellaneous/index.rst", "auto_examples/miscellaneous/plot_anomaly_comparison.rst", "auto_examples/miscellaneous/plot_display_object_visualization.rst", "auto_examples/miscellaneous/plot_estimator_representation.rst", "auto_examples/miscellaneous/plot_isotonic_regression.rst", "auto_examples/miscellaneous/plot_johnson_lindenstrauss_bound.rst", "auto_examples/miscellaneous/plot_kernel_approximation.rst", "auto_examples/miscellaneous/plot_kernel_ridge_regression.rst", "auto_examples/miscellaneous/plot_metadata_routing.rst", "auto_examples/miscellaneous/plot_multilabel.rst", "auto_examples/miscellaneous/plot_multioutput_face_completion.rst", "auto_examples/miscellaneous/plot_outlier_detection_bench.rst", "auto_examples/miscellaneous/plot_partial_dependence_visualization_api.rst", "auto_examples/miscellaneous/plot_pipeline_display.rst", "auto_examples/miscellaneous/plot_roc_curve_visualization_api.rst", "auto_examples/miscellaneous/plot_set_output.rst", "auto_examples/mixture/index.rst", "auto_examples/mixture/plot_concentration_prior.rst", "auto_examples/mixture/plot_gmm.rst", "auto_examples/mixture/plot_gmm_covariances.rst", "auto_examples/mixture/plot_gmm_init.rst", "auto_examples/mixture/plot_gmm_pdf.rst", "auto_examples/mixture/plot_gmm_selection.rst", "auto_examples/mixture/plot_gmm_sin.rst", "auto_examples/model_selection/index.rst", "auto_examples/model_selection/plot_confusion_matrix.rst", "auto_examples/model_selection/plot_cost_sensitive_learning.rst", "auto_examples/model_selection/plot_cv_indices.rst", "auto_examples/model_selection/plot_cv_predict.rst", "auto_examples/model_selection/plot_det.rst", "auto_examples/model_selection/plot_grid_search_digits.rst", "auto_examples/model_selection/plot_grid_search_refit_callable.rst", "auto_examples/model_selection/plot_grid_search_stats.rst", "auto_examples/model_selection/plot_grid_search_text_feature_extraction.rst", "auto_examples/model_selection/plot_learning_curve.rst", "auto_examples/model_selection/plot_likelihood_ratios.rst", "auto_examples/model_selection/plot_multi_metric_evaluation.rst", "auto_examples/model_selection/plot_nested_cross_validation_iris.rst", "auto_examples/model_selection/plot_permutation_tests_for_classification.rst", "auto_examples/model_selection/plot_precision_recall.rst", "auto_examples/model_selection/plot_randomized_search.rst", "auto_examples/model_selection/plot_roc.rst", "auto_examples/model_selection/plot_roc_crossval.rst", "auto_examples/model_selection/plot_successive_halving_heatmap.rst", "auto_examples/model_selection/plot_successive_halving_iterations.rst", "auto_examples/model_selection/plot_train_error_vs_test_error.rst", "auto_examples/model_selection/plot_tuned_decision_threshold.rst", "auto_examples/model_selection/plot_underfitting_overfitting.rst", "auto_examples/model_selection/plot_validation_curve.rst", "auto_examples/multiclass/index.rst", "auto_examples/multiclass/plot_multiclass_overview.rst", "auto_examples/multioutput/index.rst", "auto_examples/multioutput/plot_classifier_chain_yeast.rst", "auto_examples/neighbors/approximate_nearest_neighbors.rst", "auto_examples/neighbors/index.rst", "auto_examples/neighbors/plot_caching_nearest_neighbors.rst", "auto_examples/neighbors/plot_classification.rst", "auto_examples/neighbors/plot_digits_kde_sampling.rst", "auto_examples/neighbors/plot_kde_1d.rst", "auto_examples/neighbors/plot_lof_novelty_detection.rst", "auto_examples/neighbors/plot_lof_outlier_detection.rst", "auto_examples/neighbors/plot_nca_classification.rst", "auto_examples/neighbors/plot_nca_dim_reduction.rst", "auto_examples/neighbors/plot_nca_illustration.rst", "auto_examples/neighbors/plot_nearest_centroid.rst", "auto_examples/neighbors/plot_regression.rst", "auto_examples/neighbors/plot_species_kde.rst", "auto_examples/neural_networks/index.rst", "auto_examples/neural_networks/plot_mlp_alpha.rst", "auto_examples/neural_networks/plot_mlp_training_curves.rst", "auto_examples/neural_networks/plot_mnist_filters.rst", "auto_examples/neural_networks/plot_rbm_logistic_classification.rst", "auto_examples/preprocessing/index.rst", "auto_examples/preprocessing/plot_all_scaling.rst", "auto_examples/preprocessing/plot_discretization.rst", "auto_examples/preprocessing/plot_discretization_classification.rst", "auto_examples/preprocessing/plot_discretization_strategies.rst", "auto_examples/preprocessing/plot_map_data_to_normal.rst", "auto_examples/preprocessing/plot_scaling_importance.rst", "auto_examples/preprocessing/plot_target_encoder.rst", "auto_examples/preprocessing/plot_target_encoder_cross_val.rst", "auto_examples/release_highlights/index.rst", "auto_examples/release_highlights/plot_release_highlights_0_22_0.rst", "auto_examples/release_highlights/plot_release_highlights_0_23_0.rst", "auto_examples/release_highlights/plot_release_highlights_0_24_0.rst", "auto_examples/release_highlights/plot_release_highlights_1_0_0.rst", "auto_examples/release_highlights/plot_release_highlights_1_1_0.rst", "auto_examples/release_highlights/plot_release_highlights_1_2_0.rst", "auto_examples/release_highlights/plot_release_highlights_1_3_0.rst", "auto_examples/release_highlights/plot_release_highlights_1_4_0.rst", "auto_examples/release_highlights/plot_release_highlights_1_5_0.rst", "auto_examples/semi_supervised/index.rst", "auto_examples/semi_supervised/plot_label_propagation_digits.rst", "auto_examples/semi_supervised/plot_label_propagation_digits_active_learning.rst", "auto_examples/semi_supervised/plot_label_propagation_structure.rst", "auto_examples/semi_supervised/plot_self_training_varying_threshold.rst", "auto_examples/semi_supervised/plot_semi_supervised_newsgroups.rst", "auto_examples/semi_supervised/plot_semi_supervised_versus_svm_iris.rst", "auto_examples/svm/index.rst", "auto_examples/svm/plot_custom_kernel.rst", "auto_examples/svm/plot_iris_svc.rst", "auto_examples/svm/plot_linearsvc_support_vectors.rst", "auto_examples/svm/plot_oneclass.rst", "auto_examples/svm/plot_rbf_parameters.rst", "auto_examples/svm/plot_separating_hyperplane.rst", "auto_examples/svm/plot_separating_hyperplane_unbalanced.rst", "auto_examples/svm/plot_svm_anova.rst", "auto_examples/svm/plot_svm_kernels.rst", "auto_examples/svm/plot_svm_margin.rst", "auto_examples/svm/plot_svm_regression.rst", "auto_examples/svm/plot_svm_scale_c.rst", "auto_examples/svm/plot_svm_tie_breaking.rst", "auto_examples/svm/plot_weighted_samples.rst", "auto_examples/text/index.rst", "auto_examples/text/plot_document_classification_20newsgroups.rst", "auto_examples/text/plot_document_clustering.rst", "auto_examples/text/plot_hashing_vs_dict_vectorizer.rst", "auto_examples/tree/index.rst", "auto_examples/tree/plot_cost_complexity_pruning.rst", "auto_examples/tree/plot_iris_dtc.rst", "auto_examples/tree/plot_tree_regression.rst", "auto_examples/tree/plot_tree_regression_multioutput.rst", "auto_examples/tree/plot_unveil_tree_structure.rst", "common_pitfalls.rst", "communication_team.rst", "communication_team_emeritus.rst", "computing.rst", "computing/computational_performance.rst", "computing/parallelism.rst", "computing/scaling_strategies.rst", "contributor_experience_team.rst", "contributor_experience_team_emeritus.rst", "data_transforms.rst", "datasets.rst", "datasets/loading_other_datasets.rst", "datasets/real_world.rst", "datasets/sample_generators.rst", "datasets/toy_dataset.rst", "developers/advanced_installation.rst", "developers/bug_triaging.rst", "developers/contributing.rst", "developers/cython.rst", "developers/develop.rst", "developers/index.rst", "developers/maintainer.rst", "developers/minimal_reproducer.rst", "developers/performance.rst", "developers/plotting.rst", "developers/tips.rst", "developers/utilities.rst", "dispatching.rst", "documentation_team.rst", "faq.rst", "getting_started.rst", "glossary.rst", "governance.rst", "index.rst", "inspection.rst", "install.rst", "maintainers.rst", "maintainers_emeritus.rst", "metadata_routing.rst", "min_dependency_substitutions.rst", "min_dependency_table.rst", "model_persistence.rst", "model_selection.rst", "modules/array_api.rst", "modules/biclustering.rst", "modules/calibration.rst", "modules/classification_threshold.rst", "modules/clustering.rst", "modules/compose.rst", "modules/covariance.rst", "modules/cross_decomposition.rst", "modules/cross_validation.rst", "modules/decomposition.rst", "modules/density.rst", "modules/ensemble.rst", "modules/feature_extraction.rst", "modules/feature_selection.rst", "modules/gaussian_process.rst", "modules/generated/dbscan-function.rst", "modules/generated/fastica-function.rst", "modules/generated/oas-function.rst", "modules/generated/sklearn.base.BaseEstimator.rst", "modules/generated/sklearn.base.BiclusterMixin.rst", "modules/generated/sklearn.base.ClassNamePrefixFeaturesOutMixin.rst", "modules/generated/sklearn.base.ClassifierMixin.rst", "modules/generated/sklearn.base.ClusterMixin.rst", "modules/generated/sklearn.base.DensityMixin.rst", "modules/generated/sklearn.base.MetaEstimatorMixin.rst", "modules/generated/sklearn.base.OneToOneFeatureMixin.rst", "modules/generated/sklearn.base.OutlierMixin.rst", "modules/generated/sklearn.base.RegressorMixin.rst", "modules/generated/sklearn.base.TransformerMixin.rst", "modules/generated/sklearn.base.clone.rst", "modules/generated/sklearn.base.is_classifier.rst", "modules/generated/sklearn.base.is_clusterer.rst", "modules/generated/sklearn.base.is_regressor.rst", "modules/generated/sklearn.calibration.CalibratedClassifierCV.rst", "modules/generated/sklearn.calibration.CalibrationDisplay.rst", "modules/generated/sklearn.calibration.calibration_curve.rst", "modules/generated/sklearn.cluster.AffinityPropagation.rst", "modules/generated/sklearn.cluster.AgglomerativeClustering.rst", "modules/generated/sklearn.cluster.Birch.rst", "modules/generated/sklearn.cluster.BisectingKMeans.rst", "modules/generated/sklearn.cluster.DBSCAN.rst", "modules/generated/sklearn.cluster.FeatureAgglomeration.rst", "modules/generated/sklearn.cluster.HDBSCAN.rst", "modules/generated/sklearn.cluster.KMeans.rst", "modules/generated/sklearn.cluster.MeanShift.rst", "modules/generated/sklearn.cluster.MiniBatchKMeans.rst", "modules/generated/sklearn.cluster.OPTICS.rst", "modules/generated/sklearn.cluster.SpectralBiclustering.rst", "modules/generated/sklearn.cluster.SpectralClustering.rst", "modules/generated/sklearn.cluster.SpectralCoclustering.rst", "modules/generated/sklearn.cluster.affinity_propagation.rst", "modules/generated/sklearn.cluster.cluster_optics_dbscan.rst", "modules/generated/sklearn.cluster.cluster_optics_xi.rst", "modules/generated/sklearn.cluster.compute_optics_graph.rst", "modules/generated/sklearn.cluster.estimate_bandwidth.rst", "modules/generated/sklearn.cluster.k_means.rst", "modules/generated/sklearn.cluster.kmeans_plusplus.rst", "modules/generated/sklearn.cluster.mean_shift.rst", "modules/generated/sklearn.cluster.spectral_clustering.rst", "modules/generated/sklearn.cluster.ward_tree.rst", "modules/generated/sklearn.compose.ColumnTransformer.rst", "modules/generated/sklearn.compose.TransformedTargetRegressor.rst", "modules/generated/sklearn.compose.make_column_selector.rst", "modules/generated/sklearn.compose.make_column_transformer.rst", "modules/generated/sklearn.config_context.rst", "modules/generated/sklearn.covariance.EllipticEnvelope.rst", "modules/generated/sklearn.covariance.EmpiricalCovariance.rst", "modules/generated/sklearn.covariance.GraphicalLasso.rst", "modules/generated/sklearn.covariance.GraphicalLassoCV.rst", "modules/generated/sklearn.covariance.LedoitWolf.rst", "modules/generated/sklearn.covariance.MinCovDet.rst", "modules/generated/sklearn.covariance.OAS.rst", "modules/generated/sklearn.covariance.ShrunkCovariance.rst", "modules/generated/sklearn.covariance.empirical_covariance.rst", "modules/generated/sklearn.covariance.graphical_lasso.rst", "modules/generated/sklearn.covariance.ledoit_wolf.rst", "modules/generated/sklearn.covariance.ledoit_wolf_shrinkage.rst", "modules/generated/sklearn.covariance.shrunk_covariance.rst", "modules/generated/sklearn.cross_decomposition.CCA.rst", "modules/generated/sklearn.cross_decomposition.PLSCanonical.rst", "modules/generated/sklearn.cross_decomposition.PLSRegression.rst", "modules/generated/sklearn.cross_decomposition.PLSSVD.rst", "modules/generated/sklearn.datasets.clear_data_home.rst", "modules/generated/sklearn.datasets.dump_svmlight_file.rst", "modules/generated/sklearn.datasets.fetch_20newsgroups.rst", "modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.rst", "modules/generated/sklearn.datasets.fetch_california_housing.rst", "modules/generated/sklearn.datasets.fetch_covtype.rst", "modules/generated/sklearn.datasets.fetch_kddcup99.rst", "modules/generated/sklearn.datasets.fetch_lfw_pairs.rst", "modules/generated/sklearn.datasets.fetch_lfw_people.rst", "modules/generated/sklearn.datasets.fetch_olivetti_faces.rst", "modules/generated/sklearn.datasets.fetch_openml.rst", "modules/generated/sklearn.datasets.fetch_rcv1.rst", "modules/generated/sklearn.datasets.fetch_species_distributions.rst", "modules/generated/sklearn.datasets.get_data_home.rst", "modules/generated/sklearn.datasets.load_breast_cancer.rst", "modules/generated/sklearn.datasets.load_diabetes.rst", "modules/generated/sklearn.datasets.load_digits.rst", "modules/generated/sklearn.datasets.load_files.rst", "modules/generated/sklearn.datasets.load_iris.rst", "modules/generated/sklearn.datasets.load_linnerud.rst", "modules/generated/sklearn.datasets.load_sample_image.rst", "modules/generated/sklearn.datasets.load_sample_images.rst", "modules/generated/sklearn.datasets.load_svmlight_file.rst", "modules/generated/sklearn.datasets.load_svmlight_files.rst", "modules/generated/sklearn.datasets.load_wine.rst", "modules/generated/sklearn.datasets.make_biclusters.rst", "modules/generated/sklearn.datasets.make_blobs.rst", "modules/generated/sklearn.datasets.make_checkerboard.rst", "modules/generated/sklearn.datasets.make_circles.rst", "modules/generated/sklearn.datasets.make_classification.rst", "modules/generated/sklearn.datasets.make_friedman1.rst", "modules/generated/sklearn.datasets.make_friedman2.rst", "modules/generated/sklearn.datasets.make_friedman3.rst", "modules/generated/sklearn.datasets.make_gaussian_quantiles.rst", "modules/generated/sklearn.datasets.make_hastie_10_2.rst", "modules/generated/sklearn.datasets.make_low_rank_matrix.rst", "modules/generated/sklearn.datasets.make_moons.rst", "modules/generated/sklearn.datasets.make_multilabel_classification.rst", "modules/generated/sklearn.datasets.make_regression.rst", "modules/generated/sklearn.datasets.make_s_curve.rst", "modules/generated/sklearn.datasets.make_sparse_coded_signal.rst", "modules/generated/sklearn.datasets.make_sparse_spd_matrix.rst", "modules/generated/sklearn.datasets.make_sparse_uncorrelated.rst", "modules/generated/sklearn.datasets.make_spd_matrix.rst", "modules/generated/sklearn.datasets.make_swiss_roll.rst", "modules/generated/sklearn.decomposition.DictionaryLearning.rst", "modules/generated/sklearn.decomposition.FactorAnalysis.rst", "modules/generated/sklearn.decomposition.FastICA.rst", "modules/generated/sklearn.decomposition.IncrementalPCA.rst", "modules/generated/sklearn.decomposition.KernelPCA.rst", "modules/generated/sklearn.decomposition.LatentDirichletAllocation.rst", "modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.rst", "modules/generated/sklearn.decomposition.MiniBatchNMF.rst", "modules/generated/sklearn.decomposition.MiniBatchSparsePCA.rst", "modules/generated/sklearn.decomposition.NMF.rst", "modules/generated/sklearn.decomposition.PCA.rst", "modules/generated/sklearn.decomposition.SparseCoder.rst", "modules/generated/sklearn.decomposition.SparsePCA.rst", "modules/generated/sklearn.decomposition.TruncatedSVD.rst", "modules/generated/sklearn.decomposition.dict_learning.rst", "modules/generated/sklearn.decomposition.dict_learning_online.rst", "modules/generated/sklearn.decomposition.non_negative_factorization.rst", "modules/generated/sklearn.decomposition.sparse_encode.rst", "modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.rst", "modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.rst", "modules/generated/sklearn.dummy.DummyClassifier.rst", "modules/generated/sklearn.dummy.DummyRegressor.rst", "modules/generated/sklearn.ensemble.AdaBoostClassifier.rst", "modules/generated/sklearn.ensemble.AdaBoostRegressor.rst", "modules/generated/sklearn.ensemble.BaggingClassifier.rst", "modules/generated/sklearn.ensemble.BaggingRegressor.rst", "modules/generated/sklearn.ensemble.ExtraTreesClassifier.rst", "modules/generated/sklearn.ensemble.ExtraTreesRegressor.rst", "modules/generated/sklearn.ensemble.GradientBoostingClassifier.rst", "modules/generated/sklearn.ensemble.GradientBoostingRegressor.rst", "modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.rst", "modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.rst", "modules/generated/sklearn.ensemble.IsolationForest.rst", "modules/generated/sklearn.ensemble.RandomForestClassifier.rst", "modules/generated/sklearn.ensemble.RandomForestRegressor.rst", "modules/generated/sklearn.ensemble.RandomTreesEmbedding.rst", "modules/generated/sklearn.ensemble.StackingClassifier.rst", "modules/generated/sklearn.ensemble.StackingRegressor.rst", "modules/generated/sklearn.ensemble.VotingClassifier.rst", "modules/generated/sklearn.ensemble.VotingRegressor.rst", "modules/generated/sklearn.exceptions.ConvergenceWarning.rst", "modules/generated/sklearn.exceptions.DataConversionWarning.rst", "modules/generated/sklearn.exceptions.DataDimensionalityWarning.rst", "modules/generated/sklearn.exceptions.EfficiencyWarning.rst", "modules/generated/sklearn.exceptions.FitFailedWarning.rst", "modules/generated/sklearn.exceptions.InconsistentVersionWarning.rst", "modules/generated/sklearn.exceptions.NotFittedError.rst", "modules/generated/sklearn.exceptions.UndefinedMetricWarning.rst", "modules/generated/sklearn.experimental.enable_halving_search_cv.rst", "modules/generated/sklearn.experimental.enable_iterative_imputer.rst", "modules/generated/sklearn.feature_extraction.DictVectorizer.rst", "modules/generated/sklearn.feature_extraction.FeatureHasher.rst", "modules/generated/sklearn.feature_extraction.image.PatchExtractor.rst", "modules/generated/sklearn.feature_extraction.image.extract_patches_2d.rst", "modules/generated/sklearn.feature_extraction.image.grid_to_graph.rst", "modules/generated/sklearn.feature_extraction.image.img_to_graph.rst", "modules/generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d.rst", "modules/generated/sklearn.feature_extraction.text.CountVectorizer.rst", "modules/generated/sklearn.feature_extraction.text.HashingVectorizer.rst", "modules/generated/sklearn.feature_extraction.text.TfidfTransformer.rst", "modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.rst", "modules/generated/sklearn.feature_selection.GenericUnivariateSelect.rst", "modules/generated/sklearn.feature_selection.RFE.rst", "modules/generated/sklearn.feature_selection.RFECV.rst", "modules/generated/sklearn.feature_selection.SelectFdr.rst", "modules/generated/sklearn.feature_selection.SelectFpr.rst", "modules/generated/sklearn.feature_selection.SelectFromModel.rst", "modules/generated/sklearn.feature_selection.SelectFwe.rst", "modules/generated/sklearn.feature_selection.SelectKBest.rst", "modules/generated/sklearn.feature_selection.SelectPercentile.rst", "modules/generated/sklearn.feature_selection.SelectorMixin.rst", "modules/generated/sklearn.feature_selection.SequentialFeatureSelector.rst", "modules/generated/sklearn.feature_selection.VarianceThreshold.rst", "modules/generated/sklearn.feature_selection.chi2.rst", "modules/generated/sklearn.feature_selection.f_classif.rst", "modules/generated/sklearn.feature_selection.f_regression.rst", "modules/generated/sklearn.feature_selection.mutual_info_classif.rst", "modules/generated/sklearn.feature_selection.mutual_info_regression.rst", "modules/generated/sklearn.feature_selection.r_regression.rst", "modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.rst", "modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.rst", "modules/generated/sklearn.gaussian_process.kernels.CompoundKernel.rst", "modules/generated/sklearn.gaussian_process.kernels.ConstantKernel.rst", "modules/generated/sklearn.gaussian_process.kernels.DotProduct.rst", "modules/generated/sklearn.gaussian_process.kernels.ExpSineSquared.rst", "modules/generated/sklearn.gaussian_process.kernels.Exponentiation.rst", "modules/generated/sklearn.gaussian_process.kernels.Hyperparameter.rst", "modules/generated/sklearn.gaussian_process.kernels.Kernel.rst", "modules/generated/sklearn.gaussian_process.kernels.Matern.rst", "modules/generated/sklearn.gaussian_process.kernels.PairwiseKernel.rst", "modules/generated/sklearn.gaussian_process.kernels.Product.rst", "modules/generated/sklearn.gaussian_process.kernels.RBF.rst", "modules/generated/sklearn.gaussian_process.kernels.RationalQuadratic.rst", "modules/generated/sklearn.gaussian_process.kernels.Sum.rst", "modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.rst", "modules/generated/sklearn.get_config.rst", "modules/generated/sklearn.impute.IterativeImputer.rst", "modules/generated/sklearn.impute.KNNImputer.rst", "modules/generated/sklearn.impute.MissingIndicator.rst", "modules/generated/sklearn.impute.SimpleImputer.rst", "modules/generated/sklearn.inspection.DecisionBoundaryDisplay.rst", "modules/generated/sklearn.inspection.PartialDependenceDisplay.rst", "modules/generated/sklearn.inspection.partial_dependence.rst", "modules/generated/sklearn.inspection.permutation_importance.rst", "modules/generated/sklearn.isotonic.IsotonicRegression.rst", "modules/generated/sklearn.isotonic.check_increasing.rst", "modules/generated/sklearn.isotonic.isotonic_regression.rst", "modules/generated/sklearn.kernel_approximation.AdditiveChi2Sampler.rst", "modules/generated/sklearn.kernel_approximation.Nystroem.rst", "modules/generated/sklearn.kernel_approximation.PolynomialCountSketch.rst", "modules/generated/sklearn.kernel_approximation.RBFSampler.rst", "modules/generated/sklearn.kernel_approximation.SkewedChi2Sampler.rst", "modules/generated/sklearn.kernel_ridge.KernelRidge.rst", "modules/generated/sklearn.linear_model.ARDRegression.rst", "modules/generated/sklearn.linear_model.BayesianRidge.rst", "modules/generated/sklearn.linear_model.ElasticNet.rst", "modules/generated/sklearn.linear_model.ElasticNetCV.rst", "modules/generated/sklearn.linear_model.GammaRegressor.rst", "modules/generated/sklearn.linear_model.HuberRegressor.rst", "modules/generated/sklearn.linear_model.Lars.rst", "modules/generated/sklearn.linear_model.LarsCV.rst", "modules/generated/sklearn.linear_model.Lasso.rst", "modules/generated/sklearn.linear_model.LassoCV.rst", "modules/generated/sklearn.linear_model.LassoLars.rst", "modules/generated/sklearn.linear_model.LassoLarsCV.rst", "modules/generated/sklearn.linear_model.LassoLarsIC.rst", "modules/generated/sklearn.linear_model.LinearRegression.rst", "modules/generated/sklearn.linear_model.LogisticRegression.rst", "modules/generated/sklearn.linear_model.LogisticRegressionCV.rst", "modules/generated/sklearn.linear_model.MultiTaskElasticNet.rst", "modules/generated/sklearn.linear_model.MultiTaskElasticNetCV.rst", "modules/generated/sklearn.linear_model.MultiTaskLasso.rst", "modules/generated/sklearn.linear_model.MultiTaskLassoCV.rst", "modules/generated/sklearn.linear_model.OrthogonalMatchingPursuit.rst", "modules/generated/sklearn.linear_model.OrthogonalMatchingPursuitCV.rst", "modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.rst", "modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.rst", "modules/generated/sklearn.linear_model.Perceptron.rst", "modules/generated/sklearn.linear_model.PoissonRegressor.rst", "modules/generated/sklearn.linear_model.QuantileRegressor.rst", "modules/generated/sklearn.linear_model.RANSACRegressor.rst", "modules/generated/sklearn.linear_model.Ridge.rst", "modules/generated/sklearn.linear_model.RidgeCV.rst", "modules/generated/sklearn.linear_model.RidgeClassifier.rst", "modules/generated/sklearn.linear_model.RidgeClassifierCV.rst", "modules/generated/sklearn.linear_model.SGDClassifier.rst", "modules/generated/sklearn.linear_model.SGDOneClassSVM.rst", "modules/generated/sklearn.linear_model.SGDRegressor.rst", "modules/generated/sklearn.linear_model.TheilSenRegressor.rst", "modules/generated/sklearn.linear_model.TweedieRegressor.rst", "modules/generated/sklearn.linear_model.enet_path.rst", "modules/generated/sklearn.linear_model.lars_path.rst", "modules/generated/sklearn.linear_model.lars_path_gram.rst", "modules/generated/sklearn.linear_model.lasso_path.rst", "modules/generated/sklearn.linear_model.orthogonal_mp.rst", "modules/generated/sklearn.linear_model.orthogonal_mp_gram.rst", "modules/generated/sklearn.linear_model.ridge_regression.rst", "modules/generated/sklearn.manifold.Isomap.rst", "modules/generated/sklearn.manifold.LocallyLinearEmbedding.rst", "modules/generated/sklearn.manifold.MDS.rst", "modules/generated/sklearn.manifold.SpectralEmbedding.rst", "modules/generated/sklearn.manifold.TSNE.rst", "modules/generated/sklearn.manifold.locally_linear_embedding.rst", "modules/generated/sklearn.manifold.smacof.rst", "modules/generated/sklearn.manifold.spectral_embedding.rst", "modules/generated/sklearn.manifold.trustworthiness.rst", "modules/generated/sklearn.metrics.ConfusionMatrixDisplay.rst", "modules/generated/sklearn.metrics.DetCurveDisplay.rst", "modules/generated/sklearn.metrics.DistanceMetric.rst", "modules/generated/sklearn.metrics.PrecisionRecallDisplay.rst", "modules/generated/sklearn.metrics.PredictionErrorDisplay.rst", "modules/generated/sklearn.metrics.RocCurveDisplay.rst", "modules/generated/sklearn.metrics.accuracy_score.rst", "modules/generated/sklearn.metrics.adjusted_mutual_info_score.rst", "modules/generated/sklearn.metrics.adjusted_rand_score.rst", "modules/generated/sklearn.metrics.auc.rst", "modules/generated/sklearn.metrics.average_precision_score.rst", "modules/generated/sklearn.metrics.balanced_accuracy_score.rst", "modules/generated/sklearn.metrics.brier_score_loss.rst", "modules/generated/sklearn.metrics.calinski_harabasz_score.rst", "modules/generated/sklearn.metrics.check_scoring.rst", "modules/generated/sklearn.metrics.class_likelihood_ratios.rst", "modules/generated/sklearn.metrics.classification_report.rst", "modules/generated/sklearn.metrics.cluster.contingency_matrix.rst", "modules/generated/sklearn.metrics.cluster.pair_confusion_matrix.rst", "modules/generated/sklearn.metrics.cohen_kappa_score.rst", "modules/generated/sklearn.metrics.completeness_score.rst", "modules/generated/sklearn.metrics.confusion_matrix.rst", "modules/generated/sklearn.metrics.consensus_score.rst", "modules/generated/sklearn.metrics.coverage_error.rst", "modules/generated/sklearn.metrics.d2_absolute_error_score.rst", "modules/generated/sklearn.metrics.d2_log_loss_score.rst", "modules/generated/sklearn.metrics.d2_pinball_score.rst", "modules/generated/sklearn.metrics.d2_tweedie_score.rst", "modules/generated/sklearn.metrics.davies_bouldin_score.rst", "modules/generated/sklearn.metrics.dcg_score.rst", "modules/generated/sklearn.metrics.det_curve.rst", "modules/generated/sklearn.metrics.explained_variance_score.rst", "modules/generated/sklearn.metrics.f1_score.rst", "modules/generated/sklearn.metrics.fbeta_score.rst", "modules/generated/sklearn.metrics.fowlkes_mallows_score.rst", "modules/generated/sklearn.metrics.get_scorer.rst", "modules/generated/sklearn.metrics.get_scorer_names.rst", "modules/generated/sklearn.metrics.hamming_loss.rst", "modules/generated/sklearn.metrics.hinge_loss.rst", "modules/generated/sklearn.metrics.homogeneity_completeness_v_measure.rst", "modules/generated/sklearn.metrics.homogeneity_score.rst", "modules/generated/sklearn.metrics.jaccard_score.rst", "modules/generated/sklearn.metrics.label_ranking_average_precision_score.rst", "modules/generated/sklearn.metrics.label_ranking_loss.rst", "modules/generated/sklearn.metrics.log_loss.rst", "modules/generated/sklearn.metrics.make_scorer.rst", "modules/generated/sklearn.metrics.matthews_corrcoef.rst", "modules/generated/sklearn.metrics.max_error.rst", "modules/generated/sklearn.metrics.mean_absolute_error.rst", "modules/generated/sklearn.metrics.mean_absolute_percentage_error.rst", "modules/generated/sklearn.metrics.mean_gamma_deviance.rst", "modules/generated/sklearn.metrics.mean_pinball_loss.rst", "modules/generated/sklearn.metrics.mean_poisson_deviance.rst", "modules/generated/sklearn.metrics.mean_squared_error.rst", "modules/generated/sklearn.metrics.mean_squared_log_error.rst", "modules/generated/sklearn.metrics.mean_tweedie_deviance.rst", "modules/generated/sklearn.metrics.median_absolute_error.rst", "modules/generated/sklearn.metrics.multilabel_confusion_matrix.rst", "modules/generated/sklearn.metrics.mutual_info_score.rst", "modules/generated/sklearn.metrics.ndcg_score.rst", "modules/generated/sklearn.metrics.normalized_mutual_info_score.rst", "modules/generated/sklearn.metrics.pairwise.additive_chi2_kernel.rst", "modules/generated/sklearn.metrics.pairwise.chi2_kernel.rst", "modules/generated/sklearn.metrics.pairwise.cosine_distances.rst", "modules/generated/sklearn.metrics.pairwise.cosine_similarity.rst", "modules/generated/sklearn.metrics.pairwise.distance_metrics.rst", "modules/generated/sklearn.metrics.pairwise.euclidean_distances.rst", "modules/generated/sklearn.metrics.pairwise.haversine_distances.rst", "modules/generated/sklearn.metrics.pairwise.kernel_metrics.rst", "modules/generated/sklearn.metrics.pairwise.laplacian_kernel.rst", "modules/generated/sklearn.metrics.pairwise.linear_kernel.rst", "modules/generated/sklearn.metrics.pairwise.manhattan_distances.rst", "modules/generated/sklearn.metrics.pairwise.nan_euclidean_distances.rst", "modules/generated/sklearn.metrics.pairwise.paired_cosine_distances.rst", "modules/generated/sklearn.metrics.pairwise.paired_distances.rst", "modules/generated/sklearn.metrics.pairwise.paired_euclidean_distances.rst", "modules/generated/sklearn.metrics.pairwise.paired_manhattan_distances.rst", "modules/generated/sklearn.metrics.pairwise.pairwise_kernels.rst", "modules/generated/sklearn.metrics.pairwise.polynomial_kernel.rst", "modules/generated/sklearn.metrics.pairwise.rbf_kernel.rst", "modules/generated/sklearn.metrics.pairwise.sigmoid_kernel.rst", "modules/generated/sklearn.metrics.pairwise_distances.rst", "modules/generated/sklearn.metrics.pairwise_distances_argmin.rst", "modules/generated/sklearn.metrics.pairwise_distances_argmin_min.rst", "modules/generated/sklearn.metrics.pairwise_distances_chunked.rst", "modules/generated/sklearn.metrics.precision_recall_curve.rst", "modules/generated/sklearn.metrics.precision_recall_fscore_support.rst", "modules/generated/sklearn.metrics.precision_score.rst", "modules/generated/sklearn.metrics.r2_score.rst", "modules/generated/sklearn.metrics.rand_score.rst", "modules/generated/sklearn.metrics.recall_score.rst", "modules/generated/sklearn.metrics.roc_auc_score.rst", "modules/generated/sklearn.metrics.roc_curve.rst", "modules/generated/sklearn.metrics.root_mean_squared_error.rst", "modules/generated/sklearn.metrics.root_mean_squared_log_error.rst", "modules/generated/sklearn.metrics.silhouette_samples.rst", "modules/generated/sklearn.metrics.silhouette_score.rst", "modules/generated/sklearn.metrics.top_k_accuracy_score.rst", "modules/generated/sklearn.metrics.v_measure_score.rst", "modules/generated/sklearn.metrics.zero_one_loss.rst", "modules/generated/sklearn.mixture.BayesianGaussianMixture.rst", "modules/generated/sklearn.mixture.GaussianMixture.rst", "modules/generated/sklearn.model_selection.FixedThresholdClassifier.rst", "modules/generated/sklearn.model_selection.GridSearchCV.rst", "modules/generated/sklearn.model_selection.GroupKFold.rst", "modules/generated/sklearn.model_selection.GroupShuffleSplit.rst", "modules/generated/sklearn.model_selection.HalvingGridSearchCV.rst", "modules/generated/sklearn.model_selection.HalvingRandomSearchCV.rst", "modules/generated/sklearn.model_selection.KFold.rst", "modules/generated/sklearn.model_selection.LearningCurveDisplay.rst", "modules/generated/sklearn.model_selection.LeaveOneGroupOut.rst", "modules/generated/sklearn.model_selection.LeaveOneOut.rst", "modules/generated/sklearn.model_selection.LeavePGroupsOut.rst", "modules/generated/sklearn.model_selection.LeavePOut.rst", "modules/generated/sklearn.model_selection.ParameterGrid.rst", "modules/generated/sklearn.model_selection.ParameterSampler.rst", "modules/generated/sklearn.model_selection.PredefinedSplit.rst", "modules/generated/sklearn.model_selection.RandomizedSearchCV.rst", "modules/generated/sklearn.model_selection.RepeatedKFold.rst", "modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.rst", "modules/generated/sklearn.model_selection.ShuffleSplit.rst", "modules/generated/sklearn.model_selection.StratifiedGroupKFold.rst", "modules/generated/sklearn.model_selection.StratifiedKFold.rst", "modules/generated/sklearn.model_selection.StratifiedShuffleSplit.rst", "modules/generated/sklearn.model_selection.TimeSeriesSplit.rst", "modules/generated/sklearn.model_selection.TunedThresholdClassifierCV.rst", "modules/generated/sklearn.model_selection.ValidationCurveDisplay.rst", "modules/generated/sklearn.model_selection.check_cv.rst", "modules/generated/sklearn.model_selection.cross_val_predict.rst", "modules/generated/sklearn.model_selection.cross_val_score.rst", "modules/generated/sklearn.model_selection.cross_validate.rst", "modules/generated/sklearn.model_selection.learning_curve.rst", "modules/generated/sklearn.model_selection.permutation_test_score.rst", "modules/generated/sklearn.model_selection.train_test_split.rst", "modules/generated/sklearn.model_selection.validation_curve.rst", "modules/generated/sklearn.multiclass.OneVsOneClassifier.rst", "modules/generated/sklearn.multiclass.OneVsRestClassifier.rst", "modules/generated/sklearn.multiclass.OutputCodeClassifier.rst", "modules/generated/sklearn.multioutput.ClassifierChain.rst", "modules/generated/sklearn.multioutput.MultiOutputClassifier.rst", "modules/generated/sklearn.multioutput.MultiOutputRegressor.rst", "modules/generated/sklearn.multioutput.RegressorChain.rst", "modules/generated/sklearn.naive_bayes.BernoulliNB.rst", "modules/generated/sklearn.naive_bayes.CategoricalNB.rst", "modules/generated/sklearn.naive_bayes.ComplementNB.rst", "modules/generated/sklearn.naive_bayes.GaussianNB.rst", "modules/generated/sklearn.naive_bayes.MultinomialNB.rst", "modules/generated/sklearn.neighbors.BallTree.rst", "modules/generated/sklearn.neighbors.KDTree.rst", "modules/generated/sklearn.neighbors.KNeighborsClassifier.rst", "modules/generated/sklearn.neighbors.KNeighborsRegressor.rst", "modules/generated/sklearn.neighbors.KNeighborsTransformer.rst", "modules/generated/sklearn.neighbors.KernelDensity.rst", "modules/generated/sklearn.neighbors.LocalOutlierFactor.rst", "modules/generated/sklearn.neighbors.NearestCentroid.rst", "modules/generated/sklearn.neighbors.NearestNeighbors.rst", "modules/generated/sklearn.neighbors.NeighborhoodComponentsAnalysis.rst", "modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.rst", "modules/generated/sklearn.neighbors.RadiusNeighborsRegressor.rst", "modules/generated/sklearn.neighbors.RadiusNeighborsTransformer.rst", "modules/generated/sklearn.neighbors.kneighbors_graph.rst", "modules/generated/sklearn.neighbors.radius_neighbors_graph.rst", "modules/generated/sklearn.neighbors.sort_graph_by_row_values.rst", "modules/generated/sklearn.neural_network.BernoulliRBM.rst", "modules/generated/sklearn.neural_network.MLPClassifier.rst", "modules/generated/sklearn.neural_network.MLPRegressor.rst", "modules/generated/sklearn.pipeline.FeatureUnion.rst", "modules/generated/sklearn.pipeline.Pipeline.rst", "modules/generated/sklearn.pipeline.make_pipeline.rst", "modules/generated/sklearn.pipeline.make_union.rst", "modules/generated/sklearn.preprocessing.Binarizer.rst", "modules/generated/sklearn.preprocessing.FunctionTransformer.rst", "modules/generated/sklearn.preprocessing.KBinsDiscretizer.rst", "modules/generated/sklearn.preprocessing.KernelCenterer.rst", "modules/generated/sklearn.preprocessing.LabelBinarizer.rst", "modules/generated/sklearn.preprocessing.LabelEncoder.rst", "modules/generated/sklearn.preprocessing.MaxAbsScaler.rst", "modules/generated/sklearn.preprocessing.MinMaxScaler.rst", "modules/generated/sklearn.preprocessing.MultiLabelBinarizer.rst", "modules/generated/sklearn.preprocessing.Normalizer.rst", "modules/generated/sklearn.preprocessing.OneHotEncoder.rst", "modules/generated/sklearn.preprocessing.OrdinalEncoder.rst", "modules/generated/sklearn.preprocessing.PolynomialFeatures.rst", "modules/generated/sklearn.preprocessing.PowerTransformer.rst", "modules/generated/sklearn.preprocessing.QuantileTransformer.rst", "modules/generated/sklearn.preprocessing.RobustScaler.rst", "modules/generated/sklearn.preprocessing.SplineTransformer.rst", "modules/generated/sklearn.preprocessing.StandardScaler.rst", "modules/generated/sklearn.preprocessing.TargetEncoder.rst", "modules/generated/sklearn.preprocessing.add_dummy_feature.rst", "modules/generated/sklearn.preprocessing.binarize.rst", "modules/generated/sklearn.preprocessing.label_binarize.rst", "modules/generated/sklearn.preprocessing.maxabs_scale.rst", "modules/generated/sklearn.preprocessing.minmax_scale.rst", "modules/generated/sklearn.preprocessing.normalize.rst", "modules/generated/sklearn.preprocessing.power_transform.rst", "modules/generated/sklearn.preprocessing.quantile_transform.rst", "modules/generated/sklearn.preprocessing.robust_scale.rst", "modules/generated/sklearn.preprocessing.scale.rst", "modules/generated/sklearn.random_projection.GaussianRandomProjection.rst", "modules/generated/sklearn.random_projection.SparseRandomProjection.rst", "modules/generated/sklearn.random_projection.johnson_lindenstrauss_min_dim.rst", "modules/generated/sklearn.semi_supervised.LabelPropagation.rst", "modules/generated/sklearn.semi_supervised.LabelSpreading.rst", "modules/generated/sklearn.semi_supervised.SelfTrainingClassifier.rst", "modules/generated/sklearn.set_config.rst", "modules/generated/sklearn.show_versions.rst", "modules/generated/sklearn.svm.LinearSVC.rst", "modules/generated/sklearn.svm.LinearSVR.rst", "modules/generated/sklearn.svm.NuSVC.rst", "modules/generated/sklearn.svm.NuSVR.rst", "modules/generated/sklearn.svm.OneClassSVM.rst", "modules/generated/sklearn.svm.SVC.rst", "modules/generated/sklearn.svm.SVR.rst", "modules/generated/sklearn.svm.l1_min_c.rst", "modules/generated/sklearn.tree.DecisionTreeClassifier.rst", "modules/generated/sklearn.tree.DecisionTreeRegressor.rst", "modules/generated/sklearn.tree.ExtraTreeClassifier.rst", "modules/generated/sklearn.tree.ExtraTreeRegressor.rst", "modules/generated/sklearn.tree.export_graphviz.rst", "modules/generated/sklearn.tree.export_text.rst", "modules/generated/sklearn.tree.plot_tree.rst", "modules/generated/sklearn.utils.Bunch.rst", "modules/generated/sklearn.utils._safe_indexing.rst", "modules/generated/sklearn.utils.arrayfuncs.min_pos.rst", "modules/generated/sklearn.utils.as_float_array.rst", "modules/generated/sklearn.utils.assert_all_finite.rst", "modules/generated/sklearn.utils.check_X_y.rst", "modules/generated/sklearn.utils.check_array.rst", "modules/generated/sklearn.utils.check_consistent_length.rst", "modules/generated/sklearn.utils.check_random_state.rst", "modules/generated/sklearn.utils.check_scalar.rst", "modules/generated/sklearn.utils.class_weight.compute_class_weight.rst", "modules/generated/sklearn.utils.class_weight.compute_sample_weight.rst", "modules/generated/sklearn.utils.deprecated.rst", "modules/generated/sklearn.utils.discovery.all_displays.rst", "modules/generated/sklearn.utils.discovery.all_estimators.rst", "modules/generated/sklearn.utils.discovery.all_functions.rst", "modules/generated/sklearn.utils.estimator_checks.check_estimator.rst", "modules/generated/sklearn.utils.estimator_checks.parametrize_with_checks.rst", "modules/generated/sklearn.utils.estimator_html_repr.rst", "modules/generated/sklearn.utils.extmath.density.rst", "modules/generated/sklearn.utils.extmath.fast_logdet.rst", "modules/generated/sklearn.utils.extmath.randomized_range_finder.rst", "modules/generated/sklearn.utils.extmath.randomized_svd.rst", "modules/generated/sklearn.utils.extmath.safe_sparse_dot.rst", "modules/generated/sklearn.utils.extmath.weighted_mode.rst", "modules/generated/sklearn.utils.gen_batches.rst", "modules/generated/sklearn.utils.gen_even_slices.rst", "modules/generated/sklearn.utils.graph.single_source_shortest_path_length.rst", "modules/generated/sklearn.utils.indexable.rst", "modules/generated/sklearn.utils.metadata_routing.MetadataRequest.rst", "modules/generated/sklearn.utils.metadata_routing.MetadataRouter.rst", "modules/generated/sklearn.utils.metadata_routing.MethodMapping.rst", "modules/generated/sklearn.utils.metadata_routing.get_routing_for_object.rst", "modules/generated/sklearn.utils.metadata_routing.process_routing.rst", "modules/generated/sklearn.utils.metaestimators.available_if.rst", "modules/generated/sklearn.utils.multiclass.is_multilabel.rst", "modules/generated/sklearn.utils.multiclass.type_of_target.rst", "modules/generated/sklearn.utils.multiclass.unique_labels.rst", "modules/generated/sklearn.utils.murmurhash3_32.rst", "modules/generated/sklearn.utils.parallel.Parallel.rst", "modules/generated/sklearn.utils.parallel.delayed.rst", "modules/generated/sklearn.utils.parallel_backend.rst", "modules/generated/sklearn.utils.random.sample_without_replacement.rst", "modules/generated/sklearn.utils.register_parallel_backend.rst", "modules/generated/sklearn.utils.resample.rst", "modules/generated/sklearn.utils.safe_mask.rst", "modules/generated/sklearn.utils.safe_sqr.rst", "modules/generated/sklearn.utils.shuffle.rst", "modules/generated/sklearn.utils.sparsefuncs.incr_mean_variance_axis.rst", "modules/generated/sklearn.utils.sparsefuncs.inplace_column_scale.rst", "modules/generated/sklearn.utils.sparsefuncs.inplace_csr_column_scale.rst", "modules/generated/sklearn.utils.sparsefuncs.inplace_row_scale.rst", "modules/generated/sklearn.utils.sparsefuncs.inplace_swap_column.rst", "modules/generated/sklearn.utils.sparsefuncs.inplace_swap_row.rst", "modules/generated/sklearn.utils.sparsefuncs.mean_variance_axis.rst", "modules/generated/sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l1.rst", "modules/generated/sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l2.rst", "modules/generated/sklearn.utils.validation.check_is_fitted.rst", "modules/generated/sklearn.utils.validation.check_memory.rst", "modules/generated/sklearn.utils.validation.check_symmetric.rst", "modules/generated/sklearn.utils.validation.column_or_1d.rst", "modules/generated/sklearn.utils.validation.has_fit_parameter.rst", "modules/grid_search.rst", "modules/impute.rst", "modules/isotonic.rst", "modules/kernel_approximation.rst", "modules/kernel_ridge.rst", "modules/lda_qda.rst", "modules/learning_curve.rst", "modules/linear_model.rst", "modules/manifold.rst", "modules/metrics.rst", "modules/mixture.rst", "modules/model_evaluation.rst", "modules/multiclass.rst", "modules/naive_bayes.rst", "modules/neighbors.rst", "modules/neural_networks_supervised.rst", "modules/neural_networks_unsupervised.rst", "modules/outlier_detection.rst", "modules/partial_dependence.rst", "modules/permutation_importance.rst", "modules/pipeline.rst", "modules/preprocessing.rst", "modules/preprocessing_targets.rst", "modules/random_projection.rst", "modules/semi_supervised.rst", "modules/sgd.rst", "modules/svm.rst", "modules/tree.rst", "modules/unsupervised_reduction.rst", "presentations.rst", "related_projects.rst", "roadmap.rst", "sg_execution_times.rst", "supervised_learning.rst", "support.rst", "testimonials/testimonials.rst", "tutorial/basic/tutorial.rst", "tutorial/index.rst", "tutorial/machine_learning_map/index.rst", "tutorial/statistical_inference/index.rst", "tutorial/statistical_inference/model_selection.rst", "tutorial/statistical_inference/putting_together.rst", "tutorial/statistical_inference/settings.rst", "tutorial/statistical_inference/supervised_learning.rst", "tutorial/statistical_inference/unsupervised_learning.rst", "tutorial/text_analytics/working_with_text_data.rst", "unsupervised_learning.rst", "user_guide.rst", "versions.rst", "visualizations.rst", "whats_new.rst", "whats_new/_contributors.rst", "whats_new/older_versions.rst", "whats_new/v0.13.rst", "whats_new/v0.14.rst", "whats_new/v0.15.rst", "whats_new/v0.16.rst", "whats_new/v0.17.rst", "whats_new/v0.18.rst", "whats_new/v0.19.rst", "whats_new/v0.20.rst", "whats_new/v0.21.rst", "whats_new/v0.22.rst", "whats_new/v0.23.rst", "whats_new/v0.24.rst", "whats_new/v1.0.rst", "whats_new/v1.1.rst", "whats_new/v1.2.rst", "whats_new/v1.3.rst", "whats_new/v1.4.rst", "whats_new/v1.5.rst", "whats_new/v1.6.rst"], "indexentries": {"1d": [[400, "term-1d", true]], "1d array": [[400, "term-1d-array", true]], "2d": [[400, "term-2d", true]], "2d array": [[400, "term-2d-array", true]], "__call__() (sklearn.compose.make_column_selector method)": [[474, "sklearn.compose.make_column_selector.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.compoundkernel method)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.constantkernel method)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.dotproduct method)": [[622, "sklearn.gaussian_process.kernels.DotProduct.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.exponentiation method)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.expsinesquared method)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.kernel method)": [[626, "sklearn.gaussian_process.kernels.Kernel.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.matern method)": [[627, "sklearn.gaussian_process.kernels.Matern.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.pairwisekernel method)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.product method)": [[629, "sklearn.gaussian_process.kernels.Product.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.rationalquadratic method)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.rbf method)": [[630, "sklearn.gaussian_process.kernels.RBF.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.sum method)": [[632, "sklearn.gaussian_process.kernels.Sum.__call__", false]], "__call__() (sklearn.gaussian_process.kernels.whitekernel method)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.__call__", false]], "__call__() (sklearn.utils.deprecated method)": [[939, "sklearn.utils.deprecated.__call__", false]], "__call__() (sklearn.utils.parallel.parallel method)": [[966, "sklearn.utils.parallel.Parallel.__call__", false]], "_estimator_type": [[400, "term-_estimator_type", true]], "_safe_indexing() (in module sklearn.utils)": [[928, "sklearn.utils._safe_indexing", false]], "accuracy_score() (in module sklearn.metrics)": [[711, "sklearn.metrics.accuracy_score", false]], "adaboostclassifier (class in sklearn.ensemble)": [[561, "sklearn.ensemble.AdaBoostClassifier", false]], "adaboostregressor (class in sklearn.ensemble)": [[562, "sklearn.ensemble.AdaBoostRegressor", false]], "add() (sklearn.utils.metadata_routing.metadatarouter method)": [[957, "sklearn.utils.metadata_routing.MetadataRouter.add", false]], "add() (sklearn.utils.metadata_routing.methodmapping method)": [[958, "sklearn.utils.metadata_routing.MethodMapping.add", false]], "add_dummy_feature() (in module sklearn.preprocessing)": [[894, "sklearn.preprocessing.add_dummy_feature", false]], "add_self_request() (sklearn.utils.metadata_routing.metadatarouter method)": [[957, "sklearn.utils.metadata_routing.MetadataRouter.add_self_request", false]], "additive_chi2_kernel() (in module sklearn.metrics.pairwise)": [[766, "sklearn.metrics.pairwise.additive_chi2_kernel", false]], "additivechi2sampler (class in sklearn.kernel_approximation)": [[646, "sklearn.kernel_approximation.AdditiveChi2Sampler", false]], "adjusted_mutual_info_score() (in module sklearn.metrics)": [[712, "sklearn.metrics.adjusted_mutual_info_score", false]], "adjusted_rand_score() (in module sklearn.metrics)": [[713, "sklearn.metrics.adjusted_rand_score", false]], "affinity_propagation() (in module sklearn.cluster)": [[462, "sklearn.cluster.affinity_propagation", false]], "affinitypropagation (class in sklearn.cluster)": [[448, "sklearn.cluster.AffinityPropagation", false]], "agglomerativeclustering (class in sklearn.cluster)": [[449, "sklearn.cluster.AgglomerativeClustering", false]], "aic() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.aic", false]], "all_displays() (in module sklearn.utils.discovery)": [[940, "sklearn.utils.discovery.all_displays", false]], "all_estimators() (in module sklearn.utils.discovery)": [[941, "sklearn.utils.discovery.all_estimators", false]], "all_functions() (in module sklearn.utils.discovery)": [[942, "sklearn.utils.discovery.all_functions", false]], "api": [[400, "term-API", true]], "apply() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.apply", false]], "apply() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.apply", false]], "apply() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.apply", false]], "apply() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.apply", false]], "apply() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.apply", false]], "apply() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.apply", false]], "apply() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.apply", false]], "apply() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.apply", false]], "apply() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.apply", false]], "apply() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.apply", false]], "apply() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.apply", false]], "ardregression (class in sklearn.linear_model)": [[652, "sklearn.linear_model.ARDRegression", false]], "array-like": [[400, "term-array-like", true]], "as_float_array() (in module sklearn.utils)": [[930, "sklearn.utils.as_float_array", false]], "assert_all_finite() (in module sklearn.utils)": [[931, "sklearn.utils.assert_all_finite", false]], "attribute": [[400, "term-attribute", true]], "attributes": [[400, "term-attributes", true]], "auc() (in module sklearn.metrics)": [[714, "sklearn.metrics.auc", false]], "available_if() (in module sklearn.utils.metaestimators)": [[961, "sklearn.utils.metaestimators.available_if", false]], "average_precision_score() (in module sklearn.metrics)": [[715, "sklearn.metrics.average_precision_score", false]], "backwards compatibility": [[400, "term-backwards-compatibility", true]], "baggingclassifier (class in sklearn.ensemble)": [[563, "sklearn.ensemble.BaggingClassifier", false]], "baggingregressor (class in sklearn.ensemble)": [[564, "sklearn.ensemble.BaggingRegressor", false]], "balanced_accuracy_score() (in module sklearn.metrics)": [[716, "sklearn.metrics.balanced_accuracy_score", false]], "balltree (class in sklearn.neighbors)": [[852, "sklearn.neighbors.BallTree", false]], "baseestimator (class in sklearn.base)": [[430, "sklearn.base.BaseEstimator", false]], "bayesiangaussianmixture (class in sklearn.mixture)": [[805, "sklearn.mixture.BayesianGaussianMixture", false]], "bayesianridge (class in sklearn.linear_model)": [[653, "sklearn.linear_model.BayesianRidge", false]], "bernoullinb (class in sklearn.naive_bayes)": [[847, "sklearn.naive_bayes.BernoulliNB", false]], "bernoullirbm (class in sklearn.neural_network)": [[868, "sklearn.neural_network.BernoulliRBM", false]], "bic() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.bic", false]], "biclustermixin (class in sklearn.base)": [[431, "sklearn.base.BiclusterMixin", false]], "biclusters_ (sklearn.base.biclustermixin property)": [[431, "sklearn.base.BiclusterMixin.biclusters_", false]], "biclusters_ (sklearn.cluster.spectralbiclustering property)": [[459, "sklearn.cluster.SpectralBiclustering.biclusters_", false]], "biclusters_ (sklearn.cluster.spectralcoclustering property)": [[461, "sklearn.cluster.SpectralCoclustering.biclusters_", false]], "binarize() (in module sklearn.preprocessing)": [[895, "sklearn.preprocessing.binarize", false]], "binarizer (class in sklearn.preprocessing)": [[875, "sklearn.preprocessing.Binarizer", false]], "binary": [[400, "term-binary", true]], "birch (class in sklearn.cluster)": [[450, "sklearn.cluster.Birch", false]], "bisectingkmeans (class in sklearn.cluster)": [[451, "sklearn.cluster.BisectingKMeans", false]], "bounds (sklearn.gaussian_process.kernels.compoundkernel property)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.bounds", false]], "bounds (sklearn.gaussian_process.kernels.constantkernel property)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.bounds", false]], "bounds (sklearn.gaussian_process.kernels.dotproduct property)": [[622, "sklearn.gaussian_process.kernels.DotProduct.bounds", false]], "bounds (sklearn.gaussian_process.kernels.exponentiation property)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.bounds", false]], "bounds (sklearn.gaussian_process.kernels.expsinesquared property)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.bounds", false]], "bounds (sklearn.gaussian_process.kernels.hyperparameter attribute)": [[625, "sklearn.gaussian_process.kernels.Hyperparameter.bounds", false]], "bounds (sklearn.gaussian_process.kernels.kernel property)": [[626, "sklearn.gaussian_process.kernels.Kernel.bounds", false]], "bounds (sklearn.gaussian_process.kernels.matern property)": [[627, "sklearn.gaussian_process.kernels.Matern.bounds", false]], "bounds (sklearn.gaussian_process.kernels.pairwisekernel property)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.bounds", false]], "bounds (sklearn.gaussian_process.kernels.product property)": [[629, "sklearn.gaussian_process.kernels.Product.bounds", false]], "bounds (sklearn.gaussian_process.kernels.rationalquadratic property)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.bounds", false]], "bounds (sklearn.gaussian_process.kernels.rbf property)": [[630, "sklearn.gaussian_process.kernels.RBF.bounds", false]], "bounds (sklearn.gaussian_process.kernels.sum property)": [[632, "sklearn.gaussian_process.kernels.Sum.bounds", false]], "bounds (sklearn.gaussian_process.kernels.whitekernel property)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.bounds", false]], "brier_score_loss() (in module sklearn.metrics)": [[717, "sklearn.metrics.brier_score_loss", false]], "build_analyzer() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.build_analyzer", false]], "build_analyzer() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.build_analyzer", false]], "build_analyzer() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.build_analyzer", false]], "build_preprocessor() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.build_preprocessor", false]], "build_preprocessor() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.build_preprocessor", false]], "build_preprocessor() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.build_preprocessor", false]], "build_tokenizer() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.build_tokenizer", false]], "build_tokenizer() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.build_tokenizer", false]], "build_tokenizer() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.build_tokenizer", false]], "bunch (class in sklearn.utils)": [[927, "sklearn.utils.Bunch", false]], "calibratedclassifiercv (class in sklearn.calibration)": [[445, "sklearn.calibration.CalibratedClassifierCV", false]], "calibration_curve() (in module sklearn.calibration)": [[447, "sklearn.calibration.calibration_curve", false]], "calibrationdisplay (class in sklearn.calibration)": [[446, "sklearn.calibration.CalibrationDisplay", false]], "calinski_harabasz_score() (in module sklearn.metrics)": [[718, "sklearn.metrics.calinski_harabasz_score", false]], "callable": [[400, "term-callable", true]], "categorical feature": [[400, "term-categorical-feature", true]], "categoricalnb (class in sklearn.naive_bayes)": [[848, "sklearn.naive_bayes.CategoricalNB", false]], "cca (class in sklearn.cross_decomposition)": [[490, "sklearn.cross_decomposition.CCA", false]], "check_array() (in module sklearn.utils)": [[933, "sklearn.utils.check_array", false]], "check_consistent_length() (in module sklearn.utils)": [[934, "sklearn.utils.check_consistent_length", false]], "check_cv() (in module sklearn.model_selection)": [[832, "sklearn.model_selection.check_cv", false]], "check_estimator() (in module sklearn.utils.estimator_checks)": [[943, "sklearn.utils.estimator_checks.check_estimator", false]], "check_increasing() (in module sklearn.isotonic)": [[644, "sklearn.isotonic.check_increasing", false]], "check_is_fitted() (in module sklearn.utils.validation)": [[984, "sklearn.utils.validation.check_is_fitted", false]], "check_memory() (in module sklearn.utils.validation)": [[985, "sklearn.utils.validation.check_memory", false]], "check_random_state() (in module sklearn.utils)": [[935, "sklearn.utils.check_random_state", false]], "check_scalar() (in module sklearn.utils)": [[936, "sklearn.utils.check_scalar", false]], "check_scoring() (in module sklearn.metrics)": [[719, "sklearn.metrics.check_scoring", false]], "check_symmetric() (in module sklearn.utils.validation)": [[986, "sklearn.utils.validation.check_symmetric", false]], "check_x_y() (in module sklearn.utils)": [[932, "sklearn.utils.check_X_y", false]], "chi2() (in module sklearn.feature_selection)": [[612, "sklearn.feature_selection.chi2", false]], "chi2_kernel() (in module sklearn.metrics.pairwise)": [[767, "sklearn.metrics.pairwise.chi2_kernel", false]], "class_likelihood_ratios() (in module sklearn.metrics)": [[720, "sklearn.metrics.class_likelihood_ratios", false]], "class_weight": [[400, "term-class_weight", true]], "classes_": [[400, "term-classes_", true]], "classes_ (sklearn.feature_selection.rfe property)": [[601, "sklearn.feature_selection.RFE.classes_", false]], "classes_ (sklearn.feature_selection.rfecv property)": [[602, "sklearn.feature_selection.RFECV.classes_", false]], "classes_ (sklearn.linear_model.ridgeclassifier property)": [[682, "sklearn.linear_model.RidgeClassifier.classes_", false]], "classes_ (sklearn.linear_model.ridgeclassifiercv property)": [[683, "sklearn.linear_model.RidgeClassifierCV.classes_", false]], "classes_ (sklearn.model_selection.fixedthresholdclassifier property)": [[807, "sklearn.model_selection.FixedThresholdClassifier.classes_", false]], "classes_ (sklearn.model_selection.gridsearchcv property)": [[808, "sklearn.model_selection.GridSearchCV.classes_", false]], "classes_ (sklearn.model_selection.halvinggridsearchcv property)": [[811, "sklearn.model_selection.HalvingGridSearchCV.classes_", false]], "classes_ (sklearn.model_selection.halvingrandomsearchcv property)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.classes_", false]], "classes_ (sklearn.model_selection.randomizedsearchcv property)": [[822, "sklearn.model_selection.RandomizedSearchCV.classes_", false]], "classes_ (sklearn.model_selection.tunedthresholdclassifiercv property)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.classes_", false]], "classes_ (sklearn.pipeline.pipeline property)": [[872, "sklearn.pipeline.Pipeline.classes_", false]], "classification_report() (in module sklearn.metrics)": [[721, "sklearn.metrics.classification_report", false]], "classifier": [[400, "term-classifier", true]], "classifierchain (class in sklearn.multioutput)": [[843, "sklearn.multioutput.ClassifierChain", false]], "classifiermixin (class in sklearn.base)": [[433, "sklearn.base.ClassifierMixin", false]], "classifiers": [[400, "term-classifiers", true]], "classnameprefixfeaturesoutmixin (class in sklearn.base)": [[432, "sklearn.base.ClassNamePrefixFeaturesOutMixin", false]], "clear() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.clear", false]], "clear_data_home() (in module sklearn.datasets)": [[494, "sklearn.datasets.clear_data_home", false]], "clone": [[400, "term-clone", true]], "clone() (in module sklearn.base)": [[441, "sklearn.base.clone", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.compoundkernel method)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.constantkernel method)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.dotproduct method)": [[622, "sklearn.gaussian_process.kernels.DotProduct.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.exponentiation method)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.expsinesquared method)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.kernel method)": [[626, "sklearn.gaussian_process.kernels.Kernel.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.matern method)": [[627, "sklearn.gaussian_process.kernels.Matern.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.pairwisekernel method)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.product method)": [[629, "sklearn.gaussian_process.kernels.Product.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.rationalquadratic method)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.rbf method)": [[630, "sklearn.gaussian_process.kernels.RBF.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.sum method)": [[632, "sklearn.gaussian_process.kernels.Sum.clone_with_theta", false]], "clone_with_theta() (sklearn.gaussian_process.kernels.whitekernel method)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.clone_with_theta", false]], "cloned": [[400, "term-cloned", true]], "cluster_optics_dbscan() (in module sklearn.cluster)": [[463, "sklearn.cluster.cluster_optics_dbscan", false]], "cluster_optics_xi() (in module sklearn.cluster)": [[464, "sklearn.cluster.cluster_optics_xi", false]], "clusterer": [[400, "term-clusterer", true]], "clusterers": [[400, "term-clusterers", true]], "clustermixin (class in sklearn.base)": [[434, "sklearn.base.ClusterMixin", false]], "coef_": [[400, "term-coef_", true]], "coef_ (sklearn.svm.nusvc property)": [[914, "sklearn.svm.NuSVC.coef_", false]], "coef_ (sklearn.svm.nusvr property)": [[915, "sklearn.svm.NuSVR.coef_", false]], "coef_ (sklearn.svm.oneclasssvm property)": [[916, "sklearn.svm.OneClassSVM.coef_", false]], "coef_ (sklearn.svm.svc property)": [[917, "sklearn.svm.SVC.coef_", false]], "coef_ (sklearn.svm.svr property)": [[918, "sklearn.svm.SVR.coef_", false]], "cohen_kappa_score() (in module sklearn.metrics)": [[724, "sklearn.metrics.cohen_kappa_score", false]], "column_or_1d() (in module sklearn.utils.validation)": [[987, "sklearn.utils.validation.column_or_1d", false]], "columntransformer (class in sklearn.compose)": [[472, "sklearn.compose.ColumnTransformer", false]], "common tests": [[400, "term-common-tests", true]], "complementnb (class in sklearn.naive_bayes)": [[849, "sklearn.naive_bayes.ComplementNB", false]], "completeness_score() (in module sklearn.metrics)": [[725, "sklearn.metrics.completeness_score", false]], "components_": [[400, "term-components_", true]], "compoundkernel (class in sklearn.gaussian_process.kernels)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel", false]], "compute_class_weight() (in module sklearn.utils.class_weight)": [[937, "sklearn.utils.class_weight.compute_class_weight", false]], "compute_optics_graph() (in module sklearn.cluster)": [[465, "sklearn.cluster.compute_optics_graph", false]], "compute_sample_weight() (in module sklearn.utils.class_weight)": [[938, "sklearn.utils.class_weight.compute_sample_weight", false]], "config_context() (in module sklearn)": [[476, "sklearn.config_context", false]], "confusion_matrix() (in module sklearn.metrics)": [[726, "sklearn.metrics.confusion_matrix", false]], "confusionmatrixdisplay (class in sklearn.metrics)": [[705, "sklearn.metrics.ConfusionMatrixDisplay", false]], "consensus_score() (in module sklearn.metrics)": [[727, "sklearn.metrics.consensus_score", false]], "constantkernel (class in sklearn.gaussian_process.kernels)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel", false]], "consumer": [[400, "term-consumer", true]], "consumes() (sklearn.utils.metadata_routing.metadatarequest method)": [[956, "sklearn.utils.metadata_routing.MetadataRequest.consumes", false]], "consumes() (sklearn.utils.metadata_routing.metadatarouter method)": [[957, "sklearn.utils.metadata_routing.MetadataRouter.consumes", false]], "contingency_matrix() (in module sklearn.metrics.cluster)": [[722, "sklearn.metrics.cluster.contingency_matrix", false]], "continuous": [[400, "term-continuous", true]], "continuous multi-output": [[400, "term-continuous-multi-output", true]], "continuous multioutput": [[400, "term-continuous-multioutput", true]], "convergencewarning": [[579, "sklearn.exceptions.ConvergenceWarning", false]], "copy() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.copy", false]], "correct_covariance() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.correct_covariance", false]], "correct_covariance() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.correct_covariance", false]], "cosine_distances() (in module sklearn.metrics.pairwise)": [[768, "sklearn.metrics.pairwise.cosine_distances", false]], "cosine_similarity() (in module sklearn.metrics.pairwise)": [[769, "sklearn.metrics.pairwise.cosine_similarity", false]], "cost_complexity_pruning_path() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.cost_complexity_pruning_path", false]], "cost_complexity_pruning_path() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.cost_complexity_pruning_path", false]], "cost_complexity_pruning_path() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.cost_complexity_pruning_path", false]], "cost_complexity_pruning_path() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.cost_complexity_pruning_path", false]], "count() (sklearn.gaussian_process.kernels.hyperparameter method)": [[625, "sklearn.gaussian_process.kernels.Hyperparameter.count", false]], "countvectorizer (class in sklearn.feature_extraction.text)": [[596, "sklearn.feature_extraction.text.CountVectorizer", false]], "coverage_error() (in module sklearn.metrics)": [[728, "sklearn.metrics.coverage_error", false]], "cross fitting": [[400, "term-0", true]], "cross validation": [[400, "term-1", true]], "cross-fitting": [[400, "term-cross-fitting", true]], "cross-validation": [[400, "term-cross-validation", true]], "cross-validation estimator": [[400, "term-cross-validation-estimator", true]], "cross-validation generator": [[400, "term-cross-validation-generator", true]], "cross-validation splitter": [[400, "term-cross-validation-splitter", true]], "cross_val_predict() (in module sklearn.model_selection)": [[833, "sklearn.model_selection.cross_val_predict", false]], "cross_val_score() (in module sklearn.model_selection)": [[834, "sklearn.model_selection.cross_val_score", false]], "cross_validate() (in module sklearn.model_selection)": [[835, "sklearn.model_selection.cross_validate", false]], "cv": [[400, "term-cv", true]], "cv splitter": [[400, "term-CV-splitter", true]], "d2_absolute_error_score() (in module sklearn.metrics)": [[729, "sklearn.metrics.d2_absolute_error_score", false]], "d2_log_loss_score() (in module sklearn.metrics)": [[730, "sklearn.metrics.d2_log_loss_score", false]], "d2_pinball_score() (in module sklearn.metrics)": [[731, "sklearn.metrics.d2_pinball_score", false]], "d2_tweedie_score() (in module sklearn.metrics)": [[732, "sklearn.metrics.d2_tweedie_score", false]], "data leakage": [[400, "term-data-leakage", true]], "data type": [[400, "term-data-type", true]], "dataconversionwarning": [[580, "sklearn.exceptions.DataConversionWarning", false]], "datadimensionalitywarning": [[581, "sklearn.exceptions.DataDimensionalityWarning", false]], "davies_bouldin_score() (in module sklearn.metrics)": [[733, "sklearn.metrics.davies_bouldin_score", false]], "dbscan (class in sklearn.cluster)": [[452, "sklearn.cluster.DBSCAN", false]], "dbscan() (in module sklearn.cluster)": [[427, "sklearn.cluster.dbscan", false]], "dbscan_clustering() (sklearn.cluster.hdbscan method)": [[454, "sklearn.cluster.HDBSCAN.dbscan_clustering", false]], "dcg_score() (in module sklearn.metrics)": [[734, "sklearn.metrics.dcg_score", false]], "decision_function": [[400, "term-decision_function", true]], "decision_function() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.decision_function", false]], "decision_function() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function", false]], "decision_function() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.decision_function", false]], "decision_function() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.decision_function", false]], "decision_function() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.decision_function", false]], "decision_function() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.decision_function", false]], "decision_function() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.decision_function", false]], "decision_function() (sklearn.ensemble.isolationforest method)": [[571, "sklearn.ensemble.IsolationForest.decision_function", false]], "decision_function() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.decision_function", false]], "decision_function() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.decision_function", false]], "decision_function() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.decision_function", false]], "decision_function() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.decision_function", false]], "decision_function() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.decision_function", false]], "decision_function() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.decision_function", false]], "decision_function() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.decision_function", false]], "decision_function() (sklearn.linear_model.ridgeclassifier method)": [[682, "sklearn.linear_model.RidgeClassifier.decision_function", false]], "decision_function() (sklearn.linear_model.ridgeclassifiercv method)": [[683, "sklearn.linear_model.RidgeClassifierCV.decision_function", false]], "decision_function() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.decision_function", false]], "decision_function() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.decision_function", false]], "decision_function() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.decision_function", false]], "decision_function() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.decision_function", false]], "decision_function() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.decision_function", false]], "decision_function() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.decision_function", false]], "decision_function() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.decision_function", false]], "decision_function() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.decision_function", false]], "decision_function() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.decision_function", false]], "decision_function() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.decision_function", false]], "decision_function() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.decision_function", false]], "decision_function() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.decision_function", false]], "decision_function() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.decision_function", false]], "decision_function() (sklearn.semi_supervised.selftrainingclassifier method)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier.decision_function", false]], "decision_function() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.decision_function", false]], "decision_function() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.decision_function", false]], "decision_function() (sklearn.svm.oneclasssvm method)": [[916, "sklearn.svm.OneClassSVM.decision_function", false]], "decision_function() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.decision_function", false]], "decision_path() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.decision_path", false]], "decision_path() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.decision_path", false]], "decision_path() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.decision_path", false]], "decision_path() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.decision_path", false]], "decision_path() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.decision_path", false]], "decision_path() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.decision_path", false]], "decision_path() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.decision_path", false]], "decision_path() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.decision_path", false]], "decision_path() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.decision_path", false]], "decisionboundarydisplay (class in sklearn.inspection)": [[639, "sklearn.inspection.DecisionBoundaryDisplay", false]], "decisiontreeclassifier (class in sklearn.tree)": [[920, "sklearn.tree.DecisionTreeClassifier", false]], "decisiontreeregressor (class in sklearn.tree)": [[921, "sklearn.tree.DecisionTreeRegressor", false]], "decode() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.decode", false]], "decode() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.decode", false]], "decode() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.decode", false]], "delayed() (in module sklearn.utils.parallel)": [[967, "sklearn.utils.parallel.delayed", false]], "densify() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.densify", false]], "densify() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.densify", false]], "densify() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.densify", false]], "densify() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.densify", false]], "densify() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.densify", false]], "densify() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.densify", false]], "densify() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.densify", false]], "densify() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.densify", false]], "densify() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.densify", false]], "density estimator": [[400, "term-density-estimator", true]], "density() (in module sklearn.utils.extmath)": [[946, "sklearn.utils.extmath.density", false]], "densitymixin (class in sklearn.base)": [[435, "sklearn.base.DensityMixin", false]], "deprecated (class in sklearn.utils)": [[939, "sklearn.utils.deprecated", false]], "deprecation": [[400, "term-deprecation", true]], "det_curve() (in module sklearn.metrics)": [[735, "sklearn.metrics.det_curve", false]], "detcurvedisplay (class in sklearn.metrics)": [[706, "sklearn.metrics.DetCurveDisplay", false]], "diag() (sklearn.gaussian_process.kernels.compoundkernel method)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.diag", false]], "diag() (sklearn.gaussian_process.kernels.constantkernel method)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.diag", false]], "diag() (sklearn.gaussian_process.kernels.dotproduct method)": [[622, "sklearn.gaussian_process.kernels.DotProduct.diag", false]], "diag() (sklearn.gaussian_process.kernels.exponentiation method)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.diag", false]], "diag() (sklearn.gaussian_process.kernels.expsinesquared method)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.diag", false]], "diag() (sklearn.gaussian_process.kernels.kernel method)": [[626, "sklearn.gaussian_process.kernels.Kernel.diag", false]], "diag() (sklearn.gaussian_process.kernels.matern method)": [[627, "sklearn.gaussian_process.kernels.Matern.diag", false]], "diag() (sklearn.gaussian_process.kernels.pairwisekernel method)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.diag", false]], "diag() (sklearn.gaussian_process.kernels.product method)": [[629, "sklearn.gaussian_process.kernels.Product.diag", false]], "diag() (sklearn.gaussian_process.kernels.rationalquadratic method)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.diag", false]], "diag() (sklearn.gaussian_process.kernels.rbf method)": [[630, "sklearn.gaussian_process.kernels.RBF.diag", false]], "diag() (sklearn.gaussian_process.kernels.sum method)": [[632, "sklearn.gaussian_process.kernels.Sum.diag", false]], "diag() (sklearn.gaussian_process.kernels.whitekernel method)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.diag", false]], "dict_learning() (in module sklearn.decomposition)": [[553, "sklearn.decomposition.dict_learning", false]], "dict_learning_online() (in module sklearn.decomposition)": [[554, "sklearn.decomposition.dict_learning_online", false]], "dictionarylearning (class in sklearn.decomposition)": [[539, "sklearn.decomposition.DictionaryLearning", false]], "dictvectorizer (class in sklearn.feature_extraction)": [[589, "sklearn.feature_extraction.DictVectorizer", false]], "dimensionality": [[400, "term-dimensionality", true]], "dispatch_next() (sklearn.utils.parallel.parallel method)": [[966, "sklearn.utils.parallel.Parallel.dispatch_next", false]], "dispatch_one_batch() (sklearn.utils.parallel.parallel method)": [[966, "sklearn.utils.parallel.Parallel.dispatch_one_batch", false]], "distance_metrics() (in module sklearn.metrics.pairwise)": [[770, "sklearn.metrics.pairwise.distance_metrics", false]], "distancemetric (class in sklearn.metrics)": [[707, "sklearn.metrics.DistanceMetric", false]], "docstring": [[400, "term-docstring", true]], "dotproduct (class in sklearn.gaussian_process.kernels)": [[622, "sklearn.gaussian_process.kernels.DotProduct", false]], "double underscore": [[400, "term-double-underscore", true]], "double underscore notation": [[400, "term-double-underscore-notation", true]], "dtype": [[400, "term-dtype", true]], "duck typing": [[400, "term-duck-typing", true]], "dummyclassifier (class in sklearn.dummy)": [[559, "sklearn.dummy.DummyClassifier", false]], "dummyregressor (class in sklearn.dummy)": [[560, "sklearn.dummy.DummyRegressor", false]], "dump_svmlight_file() (in module sklearn.datasets)": [[495, "sklearn.datasets.dump_svmlight_file", false]], "early stopping": [[400, "term-early-stopping", true]], "efficiencywarning": [[582, "sklearn.exceptions.EfficiencyWarning", false]], "elasticnet (class in sklearn.linear_model)": [[654, "sklearn.linear_model.ElasticNet", false]], "elasticnetcv (class in sklearn.linear_model)": [[655, "sklearn.linear_model.ElasticNetCV", false]], "ellipticenvelope (class in sklearn.covariance)": [[477, "sklearn.covariance.EllipticEnvelope", false]], "embedding_": [[400, "term-embedding_", true]], "empirical_covariance() (in module sklearn.covariance)": [[485, "sklearn.covariance.empirical_covariance", false]], "empiricalcovariance (class in sklearn.covariance)": [[478, "sklearn.covariance.EmpiricalCovariance", false]], "enet_path() (in module sklearn.linear_model)": [[689, "sklearn.linear_model.enet_path", false]], "error_norm() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.error_norm", false]], "error_norm() (sklearn.covariance.empiricalcovariance method)": [[478, "sklearn.covariance.EmpiricalCovariance.error_norm", false]], "error_norm() (sklearn.covariance.graphicallasso method)": [[479, "sklearn.covariance.GraphicalLasso.error_norm", false]], "error_norm() (sklearn.covariance.graphicallassocv method)": [[480, "sklearn.covariance.GraphicalLassoCV.error_norm", false]], "error_norm() (sklearn.covariance.ledoitwolf method)": [[481, "sklearn.covariance.LedoitWolf.error_norm", false]], "error_norm() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.error_norm", false]], "error_norm() (sklearn.covariance.oas method)": [[483, "sklearn.covariance.OAS.error_norm", false]], "error_norm() (sklearn.covariance.shrunkcovariance method)": [[484, "sklearn.covariance.ShrunkCovariance.error_norm", false]], "estimate_bandwidth() (in module sklearn.cluster)": [[466, "sklearn.cluster.estimate_bandwidth", false]], "estimator": [[400, "term-estimator", true]], "estimator instance": [[400, "term-estimator-instance", true]], "estimator tags": [[400, "term-estimator-tags", true]], "estimator_html_repr() (in module sklearn.utils)": [[945, "sklearn.utils.estimator_html_repr", false]], "estimators": [[400, "term-estimators", true]], "estimators_samples_ (sklearn.ensemble.baggingclassifier property)": [[563, "sklearn.ensemble.BaggingClassifier.estimators_samples_", false]], "estimators_samples_ (sklearn.ensemble.baggingregressor property)": [[564, "sklearn.ensemble.BaggingRegressor.estimators_samples_", false]], "estimators_samples_ (sklearn.ensemble.extratreesclassifier property)": [[565, "sklearn.ensemble.ExtraTreesClassifier.estimators_samples_", false]], "estimators_samples_ (sklearn.ensemble.extratreesregressor property)": [[566, "sklearn.ensemble.ExtraTreesRegressor.estimators_samples_", false]], "estimators_samples_ (sklearn.ensemble.isolationforest property)": [[571, "sklearn.ensemble.IsolationForest.estimators_samples_", false]], "estimators_samples_ (sklearn.ensemble.randomforestclassifier property)": [[572, "sklearn.ensemble.RandomForestClassifier.estimators_samples_", false]], "estimators_samples_ (sklearn.ensemble.randomforestregressor property)": [[573, "sklearn.ensemble.RandomForestRegressor.estimators_samples_", false]], "estimators_samples_ (sklearn.ensemble.randomtreesembedding property)": [[574, "sklearn.ensemble.RandomTreesEmbedding.estimators_samples_", false]], "euclidean_distances() (in module sklearn.metrics.pairwise)": [[771, "sklearn.metrics.pairwise.euclidean_distances", false]], "evaluation metric": [[400, "term-evaluation-metric", true]], "evaluation metrics": [[400, "term-evaluation-metrics", true]], "examples": [[400, "term-examples", true]], "experimental": [[400, "term-experimental", true]], "explained_variance_score() (in module sklearn.metrics)": [[736, "sklearn.metrics.explained_variance_score", false]], "exponentiation (class in sklearn.gaussian_process.kernels)": [[624, "sklearn.gaussian_process.kernels.Exponentiation", false]], "export_graphviz() (in module sklearn.tree)": [[924, "sklearn.tree.export_graphviz", false]], "export_text() (in module sklearn.tree)": [[925, "sklearn.tree.export_text", false]], "expsinesquared (class in sklearn.gaussian_process.kernels)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared", false]], "extract_patches_2d() (in module sklearn.feature_extraction.image)": [[592, "sklearn.feature_extraction.image.extract_patches_2d", false]], "extratreeclassifier (class in sklearn.tree)": [[922, "sklearn.tree.ExtraTreeClassifier", false]], "extratreeregressor (class in sklearn.tree)": [[923, "sklearn.tree.ExtraTreeRegressor", false]], "extratreesclassifier (class in sklearn.ensemble)": [[565, "sklearn.ensemble.ExtraTreesClassifier", false]], "extratreesregressor (class in sklearn.ensemble)": [[566, "sklearn.ensemble.ExtraTreesRegressor", false]], "f1_score() (in module sklearn.metrics)": [[737, "sklearn.metrics.f1_score", false]], "f_classif() (in module sklearn.feature_selection)": [[613, "sklearn.feature_selection.f_classif", false]], "f_regression() (in module sklearn.feature_selection)": [[614, "sklearn.feature_selection.f_regression", false]], "factoranalysis (class in sklearn.decomposition)": [[540, "sklearn.decomposition.FactorAnalysis", false]], "fast_logdet() (in module sklearn.utils.extmath)": [[947, "sklearn.utils.extmath.fast_logdet", false]], "fastica (class in sklearn.decomposition)": [[541, "sklearn.decomposition.FastICA", false]], "fastica() (in module sklearn.decomposition)": [[428, "sklearn.decomposition.fastica", false]], "fbeta_score() (in module sklearn.metrics)": [[738, "sklearn.metrics.fbeta_score", false]], "feature": [[400, "term-feature", true]], "feature extractor": [[400, "term-feature-extractor", true]], "feature extractors": [[400, "term-feature-extractors", true]], "feature vector": [[400, "term-feature-vector", true]], "feature_importances_": [[400, "term-feature_importances_", true]], "feature_importances_ (sklearn.ensemble.adaboostclassifier property)": [[561, "sklearn.ensemble.AdaBoostClassifier.feature_importances_", false]], "feature_importances_ (sklearn.ensemble.adaboostregressor property)": [[562, "sklearn.ensemble.AdaBoostRegressor.feature_importances_", false]], "feature_importances_ (sklearn.ensemble.extratreesclassifier property)": [[565, "sklearn.ensemble.ExtraTreesClassifier.feature_importances_", false]], "feature_importances_ (sklearn.ensemble.extratreesregressor property)": [[566, "sklearn.ensemble.ExtraTreesRegressor.feature_importances_", false]], "feature_importances_ (sklearn.ensemble.gradientboostingclassifier property)": [[567, "sklearn.ensemble.GradientBoostingClassifier.feature_importances_", false]], "feature_importances_ (sklearn.ensemble.gradientboostingregressor property)": [[568, "sklearn.ensemble.GradientBoostingRegressor.feature_importances_", false]], "feature_importances_ (sklearn.ensemble.randomforestclassifier property)": [[572, "sklearn.ensemble.RandomForestClassifier.feature_importances_", false]], "feature_importances_ (sklearn.ensemble.randomforestregressor property)": [[573, "sklearn.ensemble.RandomForestRegressor.feature_importances_", false]], "feature_importances_ (sklearn.ensemble.randomtreesembedding property)": [[574, "sklearn.ensemble.RandomTreesEmbedding.feature_importances_", false]], "feature_importances_ (sklearn.tree.decisiontreeclassifier property)": [[920, "sklearn.tree.DecisionTreeClassifier.feature_importances_", false]], "feature_importances_ (sklearn.tree.decisiontreeregressor property)": [[921, "sklearn.tree.DecisionTreeRegressor.feature_importances_", false]], "feature_importances_ (sklearn.tree.extratreeclassifier property)": [[922, "sklearn.tree.ExtraTreeClassifier.feature_importances_", false]], "feature_importances_ (sklearn.tree.extratreeregressor property)": [[923, "sklearn.tree.ExtraTreeRegressor.feature_importances_", false]], "feature_names_in_ (sklearn.pipeline.featureunion property)": [[871, "sklearn.pipeline.FeatureUnion.feature_names_in_", false]], "feature_names_in_ (sklearn.pipeline.pipeline property)": [[872, "sklearn.pipeline.Pipeline.feature_names_in_", false]], "featureagglomeration (class in sklearn.cluster)": [[453, "sklearn.cluster.FeatureAgglomeration", false]], "featurehasher (class in sklearn.feature_extraction)": [[590, "sklearn.feature_extraction.FeatureHasher", false]], "features": [[400, "term-features", true]], "featureunion (class in sklearn.pipeline)": [[871, "sklearn.pipeline.FeatureUnion", false]], "fetch_20newsgroups() (in module sklearn.datasets)": [[496, "sklearn.datasets.fetch_20newsgroups", false]], "fetch_20newsgroups_vectorized() (in module sklearn.datasets)": [[497, "sklearn.datasets.fetch_20newsgroups_vectorized", false]], "fetch_california_housing() (in module sklearn.datasets)": [[498, "sklearn.datasets.fetch_california_housing", false]], "fetch_covtype() (in module sklearn.datasets)": [[499, "sklearn.datasets.fetch_covtype", false]], "fetch_kddcup99() (in module sklearn.datasets)": [[500, "sklearn.datasets.fetch_kddcup99", false]], "fetch_lfw_pairs() (in module sklearn.datasets)": [[501, "sklearn.datasets.fetch_lfw_pairs", false]], "fetch_lfw_people() (in module sklearn.datasets)": [[502, "sklearn.datasets.fetch_lfw_people", false]], "fetch_olivetti_faces() (in module sklearn.datasets)": [[503, "sklearn.datasets.fetch_olivetti_faces", false]], "fetch_openml() (in module sklearn.datasets)": [[504, "sklearn.datasets.fetch_openml", false]], "fetch_rcv1() (in module sklearn.datasets)": [[505, "sklearn.datasets.fetch_rcv1", false]], "fetch_species_distributions() (in module sklearn.datasets)": [[506, "sklearn.datasets.fetch_species_distributions", false]], "fit": [[400, "term-fit", true]], "fit() (sklearn.calibration.calibratedclassifiercv method)": [[445, "sklearn.calibration.CalibratedClassifierCV.fit", false]], "fit() (sklearn.cluster.affinitypropagation method)": [[448, "sklearn.cluster.AffinityPropagation.fit", false]], "fit() (sklearn.cluster.agglomerativeclustering method)": [[449, "sklearn.cluster.AgglomerativeClustering.fit", false]], "fit() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.fit", false]], "fit() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.fit", false]], "fit() (sklearn.cluster.dbscan method)": [[452, "sklearn.cluster.DBSCAN.fit", false]], "fit() (sklearn.cluster.featureagglomeration method)": [[453, "sklearn.cluster.FeatureAgglomeration.fit", false]], "fit() (sklearn.cluster.hdbscan method)": [[454, "sklearn.cluster.HDBSCAN.fit", false]], "fit() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.fit", false]], "fit() (sklearn.cluster.meanshift method)": [[456, "sklearn.cluster.MeanShift.fit", false]], "fit() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.fit", false]], "fit() (sklearn.cluster.optics method)": [[458, "sklearn.cluster.OPTICS.fit", false]], "fit() (sklearn.cluster.spectralbiclustering method)": [[459, "sklearn.cluster.SpectralBiclustering.fit", false]], "fit() (sklearn.cluster.spectralclustering method)": [[460, "sklearn.cluster.SpectralClustering.fit", false]], "fit() (sklearn.cluster.spectralcoclustering method)": [[461, "sklearn.cluster.SpectralCoclustering.fit", false]], "fit() (sklearn.compose.columntransformer method)": [[472, "sklearn.compose.ColumnTransformer.fit", false]], "fit() (sklearn.compose.transformedtargetregressor method)": [[473, "sklearn.compose.TransformedTargetRegressor.fit", false]], "fit() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.fit", false]], "fit() (sklearn.covariance.empiricalcovariance method)": [[478, "sklearn.covariance.EmpiricalCovariance.fit", false]], "fit() (sklearn.covariance.graphicallasso method)": [[479, "sklearn.covariance.GraphicalLasso.fit", false]], "fit() (sklearn.covariance.graphicallassocv method)": [[480, "sklearn.covariance.GraphicalLassoCV.fit", false]], "fit() (sklearn.covariance.ledoitwolf method)": [[481, "sklearn.covariance.LedoitWolf.fit", false]], "fit() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.fit", false]], "fit() (sklearn.covariance.oas method)": [[483, "sklearn.covariance.OAS.fit", false]], "fit() (sklearn.covariance.shrunkcovariance method)": [[484, "sklearn.covariance.ShrunkCovariance.fit", false]], "fit() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.fit", false]], "fit() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.fit", false]], "fit() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.fit", false]], "fit() (sklearn.cross_decomposition.plssvd method)": [[493, "sklearn.cross_decomposition.PLSSVD.fit", false]], "fit() (sklearn.decomposition.dictionarylearning method)": [[539, "sklearn.decomposition.DictionaryLearning.fit", false]], "fit() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.fit", false]], "fit() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.fit", false]], "fit() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.fit", false]], "fit() (sklearn.decomposition.kernelpca method)": [[543, "sklearn.decomposition.KernelPCA.fit", false]], "fit() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.fit", false]], "fit() (sklearn.decomposition.minibatchdictionarylearning method)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning.fit", false]], "fit() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.fit", false]], "fit() (sklearn.decomposition.minibatchsparsepca method)": [[547, "sklearn.decomposition.MiniBatchSparsePCA.fit", false]], "fit() (sklearn.decomposition.nmf method)": [[548, "sklearn.decomposition.NMF.fit", false]], "fit() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.fit", false]], "fit() (sklearn.decomposition.sparsecoder method)": [[550, "sklearn.decomposition.SparseCoder.fit", false]], "fit() (sklearn.decomposition.sparsepca method)": [[551, "sklearn.decomposition.SparsePCA.fit", false]], "fit() (sklearn.decomposition.truncatedsvd method)": [[552, "sklearn.decomposition.TruncatedSVD.fit", false]], "fit() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit", false]], "fit() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.fit", false]], "fit() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.fit", false]], "fit() (sklearn.dummy.dummyregressor method)": [[560, "sklearn.dummy.DummyRegressor.fit", false]], "fit() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.fit", false]], "fit() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.fit", false]], "fit() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.fit", false]], "fit() (sklearn.ensemble.baggingregressor method)": [[564, "sklearn.ensemble.BaggingRegressor.fit", false]], "fit() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.fit", false]], "fit() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.fit", false]], "fit() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.fit", false]], "fit() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.fit", false]], "fit() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.fit", false]], "fit() (sklearn.ensemble.histgradientboostingregressor method)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.fit", false]], "fit() (sklearn.ensemble.isolationforest method)": [[571, "sklearn.ensemble.IsolationForest.fit", false]], "fit() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.fit", false]], "fit() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.fit", false]], "fit() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.fit", false]], "fit() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.fit", false]], "fit() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.fit", false]], "fit() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.fit", false]], "fit() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.fit", false]], "fit() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.fit", false]], "fit() (sklearn.feature_extraction.featurehasher method)": [[590, "sklearn.feature_extraction.FeatureHasher.fit", false]], "fit() (sklearn.feature_extraction.image.patchextractor method)": [[591, "sklearn.feature_extraction.image.PatchExtractor.fit", false]], "fit() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.fit", false]], "fit() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.fit", false]], "fit() (sklearn.feature_extraction.text.tfidftransformer method)": [[598, "sklearn.feature_extraction.text.TfidfTransformer.fit", false]], "fit() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.fit", false]], "fit() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.fit", false]], "fit() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.fit", false]], "fit() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.fit", false]], "fit() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.fit", false]], "fit() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.fit", false]], "fit() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.fit", false]], "fit() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.fit", false]], "fit() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.fit", false]], "fit() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.fit", false]], "fit() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.fit", false]], "fit() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.fit", false]], "fit() (sklearn.gaussian_process.gaussianprocessclassifier method)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.fit", false]], "fit() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.fit", false]], "fit() (sklearn.impute.iterativeimputer method)": [[635, "sklearn.impute.IterativeImputer.fit", false]], "fit() (sklearn.impute.knnimputer method)": [[636, "sklearn.impute.KNNImputer.fit", false]], "fit() (sklearn.impute.missingindicator method)": [[637, "sklearn.impute.MissingIndicator.fit", false]], "fit() (sklearn.impute.simpleimputer method)": [[638, "sklearn.impute.SimpleImputer.fit", false]], "fit() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.fit", false]], "fit() (sklearn.kernel_approximation.additivechi2sampler method)": [[646, "sklearn.kernel_approximation.AdditiveChi2Sampler.fit", false]], "fit() (sklearn.kernel_approximation.nystroem method)": [[647, "sklearn.kernel_approximation.Nystroem.fit", false]], "fit() (sklearn.kernel_approximation.polynomialcountsketch method)": [[648, "sklearn.kernel_approximation.PolynomialCountSketch.fit", false]], "fit() (sklearn.kernel_approximation.rbfsampler method)": [[649, "sklearn.kernel_approximation.RBFSampler.fit", false]], "fit() (sklearn.kernel_approximation.skewedchi2sampler method)": [[650, "sklearn.kernel_approximation.SkewedChi2Sampler.fit", false]], "fit() (sklearn.kernel_ridge.kernelridge method)": [[651, "sklearn.kernel_ridge.KernelRidge.fit", false]], "fit() (sklearn.linear_model.ardregression method)": [[652, "sklearn.linear_model.ARDRegression.fit", false]], "fit() (sklearn.linear_model.bayesianridge method)": [[653, "sklearn.linear_model.BayesianRidge.fit", false]], "fit() (sklearn.linear_model.elasticnet method)": [[654, "sklearn.linear_model.ElasticNet.fit", false]], "fit() (sklearn.linear_model.elasticnetcv method)": [[655, "sklearn.linear_model.ElasticNetCV.fit", false]], "fit() (sklearn.linear_model.gammaregressor method)": [[656, "sklearn.linear_model.GammaRegressor.fit", false]], "fit() (sklearn.linear_model.huberregressor method)": [[657, "sklearn.linear_model.HuberRegressor.fit", false]], "fit() (sklearn.linear_model.lars method)": [[658, "sklearn.linear_model.Lars.fit", false]], "fit() (sklearn.linear_model.larscv method)": [[659, "sklearn.linear_model.LarsCV.fit", false]], "fit() (sklearn.linear_model.lasso method)": [[660, "sklearn.linear_model.Lasso.fit", false]], "fit() (sklearn.linear_model.lassocv method)": [[661, "sklearn.linear_model.LassoCV.fit", false]], "fit() (sklearn.linear_model.lassolars method)": [[662, "sklearn.linear_model.LassoLars.fit", false]], "fit() (sklearn.linear_model.lassolarscv method)": [[663, "sklearn.linear_model.LassoLarsCV.fit", false]], "fit() (sklearn.linear_model.lassolarsic method)": [[664, "sklearn.linear_model.LassoLarsIC.fit", false]], "fit() (sklearn.linear_model.linearregression method)": [[665, "sklearn.linear_model.LinearRegression.fit", false]], "fit() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.fit", false]], "fit() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.fit", false]], "fit() (sklearn.linear_model.multitaskelasticnet method)": [[668, "sklearn.linear_model.MultiTaskElasticNet.fit", false]], "fit() (sklearn.linear_model.multitaskelasticnetcv method)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV.fit", false]], "fit() (sklearn.linear_model.multitasklasso method)": [[670, "sklearn.linear_model.MultiTaskLasso.fit", false]], "fit() (sklearn.linear_model.multitasklassocv method)": [[671, "sklearn.linear_model.MultiTaskLassoCV.fit", false]], "fit() (sklearn.linear_model.orthogonalmatchingpursuit method)": [[672, "sklearn.linear_model.OrthogonalMatchingPursuit.fit", false]], "fit() (sklearn.linear_model.orthogonalmatchingpursuitcv method)": [[673, "sklearn.linear_model.OrthogonalMatchingPursuitCV.fit", false]], "fit() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.fit", false]], "fit() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.fit", false]], "fit() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.fit", false]], "fit() (sklearn.linear_model.poissonregressor method)": [[677, "sklearn.linear_model.PoissonRegressor.fit", false]], "fit() (sklearn.linear_model.quantileregressor method)": [[678, "sklearn.linear_model.QuantileRegressor.fit", false]], "fit() (sklearn.linear_model.ransacregressor method)": [[679, "sklearn.linear_model.RANSACRegressor.fit", false]], "fit() (sklearn.linear_model.ridge method)": [[680, "sklearn.linear_model.Ridge.fit", false]], "fit() (sklearn.linear_model.ridgeclassifier method)": [[682, "sklearn.linear_model.RidgeClassifier.fit", false]], "fit() (sklearn.linear_model.ridgeclassifiercv method)": [[683, "sklearn.linear_model.RidgeClassifierCV.fit", false]], "fit() (sklearn.linear_model.ridgecv method)": [[681, "sklearn.linear_model.RidgeCV.fit", false]], "fit() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.fit", false]], "fit() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.fit", false]], "fit() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.fit", false]], "fit() (sklearn.linear_model.theilsenregressor method)": [[687, "sklearn.linear_model.TheilSenRegressor.fit", false]], "fit() (sklearn.linear_model.tweedieregressor method)": [[688, "sklearn.linear_model.TweedieRegressor.fit", false]], "fit() (sklearn.manifold.isomap method)": [[696, "sklearn.manifold.Isomap.fit", false]], "fit() (sklearn.manifold.locallylinearembedding method)": [[697, "sklearn.manifold.LocallyLinearEmbedding.fit", false]], "fit() (sklearn.manifold.mds method)": [[698, "sklearn.manifold.MDS.fit", false]], "fit() (sklearn.manifold.spectralembedding method)": [[699, "sklearn.manifold.SpectralEmbedding.fit", false]], "fit() (sklearn.manifold.tsne method)": [[700, "sklearn.manifold.TSNE.fit", false]], "fit() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.fit", false]], "fit() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.fit", false]], "fit() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.fit", false]], "fit() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.fit", false]], "fit() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.fit", false]], "fit() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.fit", false]], "fit() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.fit", false]], "fit() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.fit", false]], "fit() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.fit", false]], "fit() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.fit", false]], "fit() (sklearn.multiclass.outputcodeclassifier method)": [[842, "sklearn.multiclass.OutputCodeClassifier.fit", false]], "fit() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.fit", false]], "fit() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.fit", false]], "fit() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.fit", false]], "fit() (sklearn.multioutput.regressorchain method)": [[846, "sklearn.multioutput.RegressorChain.fit", false]], "fit() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.fit", false]], "fit() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.fit", false]], "fit() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.fit", false]], "fit() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.fit", false]], "fit() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.fit", false]], "fit() (sklearn.neighbors.kerneldensity method)": [[857, "sklearn.neighbors.KernelDensity.fit", false]], "fit() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.fit", false]], "fit() (sklearn.neighbors.kneighborsregressor method)": [[855, "sklearn.neighbors.KNeighborsRegressor.fit", false]], "fit() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.fit", false]], "fit() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.fit", false]], "fit() (sklearn.neighbors.nearestcentroid method)": [[859, "sklearn.neighbors.NearestCentroid.fit", false]], "fit() (sklearn.neighbors.nearestneighbors method)": [[860, "sklearn.neighbors.NearestNeighbors.fit", false]], "fit() (sklearn.neighbors.neighborhoodcomponentsanalysis method)": [[861, "sklearn.neighbors.NeighborhoodComponentsAnalysis.fit", false]], "fit() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.fit", false]], "fit() (sklearn.neighbors.radiusneighborsregressor method)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor.fit", false]], "fit() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.fit", false]], "fit() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.fit", false]], "fit() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.fit", false]], "fit() (sklearn.neural_network.mlpregressor method)": [[870, "sklearn.neural_network.MLPRegressor.fit", false]], "fit() (sklearn.pipeline.featureunion method)": [[871, "sklearn.pipeline.FeatureUnion.fit", false]], "fit() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.fit", false]], "fit() (sklearn.preprocessing.binarizer method)": [[875, "sklearn.preprocessing.Binarizer.fit", false]], "fit() (sklearn.preprocessing.functiontransformer method)": [[876, "sklearn.preprocessing.FunctionTransformer.fit", false]], "fit() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.fit", false]], "fit() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.fit", false]], "fit() (sklearn.preprocessing.labelbinarizer method)": [[879, "sklearn.preprocessing.LabelBinarizer.fit", false]], "fit() (sklearn.preprocessing.labelencoder method)": [[880, "sklearn.preprocessing.LabelEncoder.fit", false]], "fit() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.fit", false]], "fit() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.fit", false]], "fit() (sklearn.preprocessing.multilabelbinarizer method)": [[883, "sklearn.preprocessing.MultiLabelBinarizer.fit", false]], "fit() (sklearn.preprocessing.normalizer method)": [[884, "sklearn.preprocessing.Normalizer.fit", false]], "fit() (sklearn.preprocessing.onehotencoder method)": [[885, "sklearn.preprocessing.OneHotEncoder.fit", false]], "fit() (sklearn.preprocessing.ordinalencoder method)": [[886, "sklearn.preprocessing.OrdinalEncoder.fit", false]], "fit() (sklearn.preprocessing.polynomialfeatures method)": [[887, "sklearn.preprocessing.PolynomialFeatures.fit", false]], "fit() (sklearn.preprocessing.powertransformer method)": [[888, "sklearn.preprocessing.PowerTransformer.fit", false]], "fit() (sklearn.preprocessing.quantiletransformer method)": [[889, "sklearn.preprocessing.QuantileTransformer.fit", false]], "fit() (sklearn.preprocessing.robustscaler method)": [[890, "sklearn.preprocessing.RobustScaler.fit", false]], "fit() (sklearn.preprocessing.splinetransformer method)": [[891, "sklearn.preprocessing.SplineTransformer.fit", false]], "fit() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.fit", false]], "fit() (sklearn.preprocessing.targetencoder method)": [[893, "sklearn.preprocessing.TargetEncoder.fit", false]], "fit() (sklearn.random_projection.gaussianrandomprojection method)": [[904, "sklearn.random_projection.GaussianRandomProjection.fit", false]], "fit() (sklearn.random_projection.sparserandomprojection method)": [[905, "sklearn.random_projection.SparseRandomProjection.fit", false]], "fit() (sklearn.semi_supervised.labelpropagation method)": [[907, "sklearn.semi_supervised.LabelPropagation.fit", false]], "fit() (sklearn.semi_supervised.labelspreading method)": [[908, "sklearn.semi_supervised.LabelSpreading.fit", false]], "fit() (sklearn.semi_supervised.selftrainingclassifier method)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier.fit", false]], "fit() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.fit", false]], "fit() (sklearn.svm.linearsvr method)": [[913, "sklearn.svm.LinearSVR.fit", false]], "fit() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.fit", false]], "fit() (sklearn.svm.nusvr method)": [[915, "sklearn.svm.NuSVR.fit", false]], "fit() (sklearn.svm.oneclasssvm method)": [[916, "sklearn.svm.OneClassSVM.fit", false]], "fit() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.fit", false]], "fit() (sklearn.svm.svr method)": [[918, "sklearn.svm.SVR.fit", false]], "fit() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.fit", false]], "fit() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.fit", false]], "fit() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.fit", false]], "fit() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.fit", false]], "fit_predict": [[400, "term-fit_predict", true]], "fit_predict (sklearn.cluster.featureagglomeration property)": [[453, "sklearn.cluster.FeatureAgglomeration.fit_predict", false]], "fit_predict() (sklearn.base.clustermixin method)": [[434, "sklearn.base.ClusterMixin.fit_predict", false]], "fit_predict() (sklearn.base.outliermixin method)": [[438, "sklearn.base.OutlierMixin.fit_predict", false]], "fit_predict() (sklearn.cluster.affinitypropagation method)": [[448, "sklearn.cluster.AffinityPropagation.fit_predict", false]], "fit_predict() (sklearn.cluster.agglomerativeclustering method)": [[449, "sklearn.cluster.AgglomerativeClustering.fit_predict", false]], "fit_predict() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.fit_predict", false]], "fit_predict() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.fit_predict", false]], "fit_predict() (sklearn.cluster.dbscan method)": [[452, "sklearn.cluster.DBSCAN.fit_predict", false]], "fit_predict() (sklearn.cluster.hdbscan method)": [[454, "sklearn.cluster.HDBSCAN.fit_predict", false]], "fit_predict() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.fit_predict", false]], "fit_predict() (sklearn.cluster.meanshift method)": [[456, "sklearn.cluster.MeanShift.fit_predict", false]], "fit_predict() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.fit_predict", false]], "fit_predict() (sklearn.cluster.optics method)": [[458, "sklearn.cluster.OPTICS.fit_predict", false]], "fit_predict() (sklearn.cluster.spectralclustering method)": [[460, "sklearn.cluster.SpectralClustering.fit_predict", false]], "fit_predict() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.fit_predict", false]], "fit_predict() (sklearn.ensemble.isolationforest method)": [[571, "sklearn.ensemble.IsolationForest.fit_predict", false]], "fit_predict() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.fit_predict", false]], "fit_predict() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.fit_predict", false]], "fit_predict() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.fit_predict", false]], "fit_predict() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.fit_predict", false]], "fit_predict() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.fit_predict", false]], "fit_predict() (sklearn.svm.oneclasssvm method)": [[916, "sklearn.svm.OneClassSVM.fit_predict", false]], "fit_transform": [[400, "term-fit_transform", true]], "fit_transform() (sklearn.base.transformermixin method)": [[440, "sklearn.base.TransformerMixin.fit_transform", false]], "fit_transform() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.fit_transform", false]], "fit_transform() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.fit_transform", false]], "fit_transform() (sklearn.cluster.featureagglomeration method)": [[453, "sklearn.cluster.FeatureAgglomeration.fit_transform", false]], "fit_transform() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.fit_transform", false]], "fit_transform() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.fit_transform", false]], "fit_transform() (sklearn.compose.columntransformer method)": [[472, "sklearn.compose.ColumnTransformer.fit_transform", false]], "fit_transform() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.fit_transform", false]], "fit_transform() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.fit_transform", false]], "fit_transform() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.fit_transform", false]], "fit_transform() (sklearn.cross_decomposition.plssvd method)": [[493, "sklearn.cross_decomposition.PLSSVD.fit_transform", false]], "fit_transform() (sklearn.decomposition.dictionarylearning method)": [[539, "sklearn.decomposition.DictionaryLearning.fit_transform", false]], "fit_transform() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.fit_transform", false]], "fit_transform() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.fit_transform", false]], "fit_transform() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.fit_transform", false]], "fit_transform() (sklearn.decomposition.kernelpca method)": [[543, "sklearn.decomposition.KernelPCA.fit_transform", false]], "fit_transform() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.fit_transform", false]], "fit_transform() (sklearn.decomposition.minibatchdictionarylearning method)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning.fit_transform", false]], "fit_transform() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.fit_transform", false]], "fit_transform() (sklearn.decomposition.minibatchsparsepca method)": [[547, "sklearn.decomposition.MiniBatchSparsePCA.fit_transform", false]], "fit_transform() (sklearn.decomposition.nmf method)": [[548, "sklearn.decomposition.NMF.fit_transform", false]], "fit_transform() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.fit_transform", false]], "fit_transform() (sklearn.decomposition.sparsecoder method)": [[550, "sklearn.decomposition.SparseCoder.fit_transform", false]], "fit_transform() (sklearn.decomposition.sparsepca method)": [[551, "sklearn.decomposition.SparsePCA.fit_transform", false]], "fit_transform() (sklearn.decomposition.truncatedsvd method)": [[552, "sklearn.decomposition.TruncatedSVD.fit_transform", false]], "fit_transform() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform", false]], "fit_transform() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.fit_transform", false]], "fit_transform() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.fit_transform", false]], "fit_transform() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.fit_transform", false]], "fit_transform() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.fit_transform", false]], "fit_transform() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.fit_transform", false]], "fit_transform() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.fit_transform", false]], "fit_transform() (sklearn.feature_extraction.featurehasher method)": [[590, "sklearn.feature_extraction.FeatureHasher.fit_transform", false]], "fit_transform() (sklearn.feature_extraction.image.patchextractor method)": [[591, "sklearn.feature_extraction.image.PatchExtractor.fit_transform", false]], "fit_transform() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.fit_transform", false]], "fit_transform() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.fit_transform", false]], "fit_transform() (sklearn.feature_extraction.text.tfidftransformer method)": [[598, "sklearn.feature_extraction.text.TfidfTransformer.fit_transform", false]], "fit_transform() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform", false]], "fit_transform() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.fit_transform", false]], "fit_transform() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.fit_transform", false]], "fit_transform() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.fit_transform", false]], "fit_transform() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.fit_transform", false]], "fit_transform() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.fit_transform", false]], "fit_transform() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.fit_transform", false]], "fit_transform() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.fit_transform", false]], "fit_transform() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.fit_transform", false]], "fit_transform() (sklearn.feature_selection.selectormixin method)": [[609, "sklearn.feature_selection.SelectorMixin.fit_transform", false]], "fit_transform() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.fit_transform", false]], "fit_transform() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.fit_transform", false]], "fit_transform() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.fit_transform", false]], "fit_transform() (sklearn.impute.iterativeimputer method)": [[635, "sklearn.impute.IterativeImputer.fit_transform", false]], "fit_transform() (sklearn.impute.knnimputer method)": [[636, "sklearn.impute.KNNImputer.fit_transform", false]], "fit_transform() (sklearn.impute.missingindicator method)": [[637, "sklearn.impute.MissingIndicator.fit_transform", false]], "fit_transform() (sklearn.impute.simpleimputer method)": [[638, "sklearn.impute.SimpleImputer.fit_transform", false]], "fit_transform() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.fit_transform", false]], "fit_transform() (sklearn.kernel_approximation.additivechi2sampler method)": [[646, "sklearn.kernel_approximation.AdditiveChi2Sampler.fit_transform", false]], "fit_transform() (sklearn.kernel_approximation.nystroem method)": [[647, "sklearn.kernel_approximation.Nystroem.fit_transform", false]], "fit_transform() (sklearn.kernel_approximation.polynomialcountsketch method)": [[648, "sklearn.kernel_approximation.PolynomialCountSketch.fit_transform", false]], "fit_transform() (sklearn.kernel_approximation.rbfsampler method)": [[649, "sklearn.kernel_approximation.RBFSampler.fit_transform", false]], "fit_transform() (sklearn.kernel_approximation.skewedchi2sampler method)": [[650, "sklearn.kernel_approximation.SkewedChi2Sampler.fit_transform", false]], "fit_transform() (sklearn.manifold.isomap method)": [[696, "sklearn.manifold.Isomap.fit_transform", false]], "fit_transform() (sklearn.manifold.locallylinearembedding method)": [[697, "sklearn.manifold.LocallyLinearEmbedding.fit_transform", false]], "fit_transform() (sklearn.manifold.mds method)": [[698, "sklearn.manifold.MDS.fit_transform", false]], "fit_transform() (sklearn.manifold.spectralembedding method)": [[699, "sklearn.manifold.SpectralEmbedding.fit_transform", false]], "fit_transform() (sklearn.manifold.tsne method)": [[700, "sklearn.manifold.TSNE.fit_transform", false]], "fit_transform() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.fit_transform", false]], "fit_transform() (sklearn.neighbors.neighborhoodcomponentsanalysis method)": [[861, "sklearn.neighbors.NeighborhoodComponentsAnalysis.fit_transform", false]], "fit_transform() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.fit_transform", false]], "fit_transform() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.fit_transform", false]], "fit_transform() (sklearn.pipeline.featureunion method)": [[871, "sklearn.pipeline.FeatureUnion.fit_transform", false]], "fit_transform() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.fit_transform", false]], "fit_transform() (sklearn.preprocessing.binarizer method)": [[875, "sklearn.preprocessing.Binarizer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.functiontransformer method)": [[876, "sklearn.preprocessing.FunctionTransformer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.labelbinarizer method)": [[879, "sklearn.preprocessing.LabelBinarizer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.labelencoder method)": [[880, "sklearn.preprocessing.LabelEncoder.fit_transform", false]], "fit_transform() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.fit_transform", false]], "fit_transform() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.fit_transform", false]], "fit_transform() (sklearn.preprocessing.multilabelbinarizer method)": [[883, "sklearn.preprocessing.MultiLabelBinarizer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.normalizer method)": [[884, "sklearn.preprocessing.Normalizer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.onehotencoder method)": [[885, "sklearn.preprocessing.OneHotEncoder.fit_transform", false]], "fit_transform() (sklearn.preprocessing.ordinalencoder method)": [[886, "sklearn.preprocessing.OrdinalEncoder.fit_transform", false]], "fit_transform() (sklearn.preprocessing.polynomialfeatures method)": [[887, "sklearn.preprocessing.PolynomialFeatures.fit_transform", false]], "fit_transform() (sklearn.preprocessing.powertransformer method)": [[888, "sklearn.preprocessing.PowerTransformer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.quantiletransformer method)": [[889, "sklearn.preprocessing.QuantileTransformer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.robustscaler method)": [[890, "sklearn.preprocessing.RobustScaler.fit_transform", false]], "fit_transform() (sklearn.preprocessing.splinetransformer method)": [[891, "sklearn.preprocessing.SplineTransformer.fit_transform", false]], "fit_transform() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.fit_transform", false]], "fit_transform() (sklearn.preprocessing.targetencoder method)": [[893, "sklearn.preprocessing.TargetEncoder.fit_transform", false]], "fit_transform() (sklearn.random_projection.gaussianrandomprojection method)": [[904, "sklearn.random_projection.GaussianRandomProjection.fit_transform", false]], "fit_transform() (sklearn.random_projection.sparserandomprojection method)": [[905, "sklearn.random_projection.SparseRandomProjection.fit_transform", false]], "fitfailedwarning": [[583, "sklearn.exceptions.FitFailedWarning", false]], "fitted": [[400, "term-fitted", true]], "fitting": [[400, "term-fitting", true]], "fixed (sklearn.gaussian_process.kernels.hyperparameter attribute)": [[625, "sklearn.gaussian_process.kernels.Hyperparameter.fixed", false]], "fixedthresholdclassifier (class in sklearn.model_selection)": [[807, "sklearn.model_selection.FixedThresholdClassifier", false]], "format() (sklearn.utils.parallel.parallel method)": [[966, "sklearn.utils.parallel.Parallel.format", false]], "fowlkes_mallows_score() (in module sklearn.metrics)": [[739, "sklearn.metrics.fowlkes_mallows_score", false]], "from_estimator() (sklearn.calibration.calibrationdisplay class method)": [[446, "sklearn.calibration.CalibrationDisplay.from_estimator", false]], "from_estimator() (sklearn.inspection.decisionboundarydisplay class method)": [[639, "sklearn.inspection.DecisionBoundaryDisplay.from_estimator", false]], "from_estimator() (sklearn.inspection.partialdependencedisplay class method)": [[640, "sklearn.inspection.PartialDependenceDisplay.from_estimator", false]], "from_estimator() (sklearn.metrics.confusionmatrixdisplay class method)": [[705, "sklearn.metrics.ConfusionMatrixDisplay.from_estimator", false]], "from_estimator() (sklearn.metrics.detcurvedisplay class method)": [[706, "sklearn.metrics.DetCurveDisplay.from_estimator", false]], "from_estimator() (sklearn.metrics.precisionrecalldisplay class method)": [[708, "sklearn.metrics.PrecisionRecallDisplay.from_estimator", false]], "from_estimator() (sklearn.metrics.predictionerrordisplay class method)": [[709, "sklearn.metrics.PredictionErrorDisplay.from_estimator", false]], "from_estimator() (sklearn.metrics.roccurvedisplay class method)": [[710, "sklearn.metrics.RocCurveDisplay.from_estimator", false]], "from_estimator() (sklearn.model_selection.learningcurvedisplay class method)": [[814, "sklearn.model_selection.LearningCurveDisplay.from_estimator", false]], "from_estimator() (sklearn.model_selection.validationcurvedisplay class method)": [[831, "sklearn.model_selection.ValidationCurveDisplay.from_estimator", false]], "from_predictions() (sklearn.calibration.calibrationdisplay class method)": [[446, "sklearn.calibration.CalibrationDisplay.from_predictions", false]], "from_predictions() (sklearn.metrics.confusionmatrixdisplay class method)": [[705, "sklearn.metrics.ConfusionMatrixDisplay.from_predictions", false]], "from_predictions() (sklearn.metrics.detcurvedisplay class method)": [[706, "sklearn.metrics.DetCurveDisplay.from_predictions", false]], "from_predictions() (sklearn.metrics.precisionrecalldisplay class method)": [[708, "sklearn.metrics.PrecisionRecallDisplay.from_predictions", false]], "from_predictions() (sklearn.metrics.predictionerrordisplay class method)": [[709, "sklearn.metrics.PredictionErrorDisplay.from_predictions", false]], "from_predictions() (sklearn.metrics.roccurvedisplay class method)": [[710, "sklearn.metrics.RocCurveDisplay.from_predictions", false]], "fromkeys() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.fromkeys", false]], "function": [[400, "term-function", true]], "functiontransformer (class in sklearn.preprocessing)": [[876, "sklearn.preprocessing.FunctionTransformer", false]], "gallery": [[400, "term-gallery", true]], "gammaregressor (class in sklearn.linear_model)": [[656, "sklearn.linear_model.GammaRegressor", false]], "gaussianmixture (class in sklearn.mixture)": [[806, "sklearn.mixture.GaussianMixture", false]], "gaussiannb (class in sklearn.naive_bayes)": [[850, "sklearn.naive_bayes.GaussianNB", false]], "gaussianprocessclassifier (class in sklearn.gaussian_process)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier", false]], "gaussianprocessregressor (class in sklearn.gaussian_process)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor", false]], "gaussianrandomprojection (class in sklearn.random_projection)": [[904, "sklearn.random_projection.GaussianRandomProjection", false]], "gen_batches() (in module sklearn.utils)": [[952, "sklearn.utils.gen_batches", false]], "gen_even_slices() (in module sklearn.utils)": [[953, "sklearn.utils.gen_even_slices", false]], "genericunivariateselect (class in sklearn.feature_selection)": [[600, "sklearn.feature_selection.GenericUnivariateSelect", false]], "get() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.get", false]], "get_arrays() (sklearn.neighbors.balltree method)": [[852, "sklearn.neighbors.BallTree.get_arrays", false]], "get_arrays() (sklearn.neighbors.kdtree method)": [[853, "sklearn.neighbors.KDTree.get_arrays", false]], "get_config() (in module sklearn)": [[634, "sklearn.get_config", false]], "get_covariance() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.get_covariance", false]], "get_covariance() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.get_covariance", false]], "get_covariance() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.get_covariance", false]], "get_data_home() (in module sklearn.datasets)": [[507, "sklearn.datasets.get_data_home", false]], "get_depth() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.get_depth", false]], "get_depth() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.get_depth", false]], "get_depth() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.get_depth", false]], "get_depth() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.get_depth", false]], "get_feature_names_out": [[400, "term-get_feature_names_out", true]], "get_feature_names_out() (sklearn.base.classnameprefixfeaturesoutmixin method)": [[432, "sklearn.base.ClassNamePrefixFeaturesOutMixin.get_feature_names_out", false]], "get_feature_names_out() (sklearn.base.onetoonefeaturemixin method)": [[437, "sklearn.base.OneToOneFeatureMixin.get_feature_names_out", false]], "get_feature_names_out() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.get_feature_names_out", false]], "get_feature_names_out() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.get_feature_names_out", false]], "get_feature_names_out() (sklearn.cluster.featureagglomeration method)": [[453, "sklearn.cluster.FeatureAgglomeration.get_feature_names_out", false]], "get_feature_names_out() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.get_feature_names_out", false]], "get_feature_names_out() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.get_feature_names_out", false]], "get_feature_names_out() (sklearn.compose.columntransformer method)": [[472, "sklearn.compose.ColumnTransformer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.get_feature_names_out", false]], "get_feature_names_out() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.get_feature_names_out", false]], "get_feature_names_out() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.get_feature_names_out", false]], "get_feature_names_out() (sklearn.cross_decomposition.plssvd method)": [[493, "sklearn.cross_decomposition.PLSSVD.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.dictionarylearning method)": [[539, "sklearn.decomposition.DictionaryLearning.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.kernelpca method)": [[543, "sklearn.decomposition.KernelPCA.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.minibatchdictionarylearning method)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.minibatchsparsepca method)": [[547, "sklearn.decomposition.MiniBatchSparsePCA.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.nmf method)": [[548, "sklearn.decomposition.NMF.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.sparsecoder method)": [[550, "sklearn.decomposition.SparseCoder.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.sparsepca method)": [[551, "sklearn.decomposition.SparsePCA.get_feature_names_out", false]], "get_feature_names_out() (sklearn.decomposition.truncatedsvd method)": [[552, "sklearn.decomposition.TruncatedSVD.get_feature_names_out", false]], "get_feature_names_out() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_feature_names_out", false]], "get_feature_names_out() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.get_feature_names_out", false]], "get_feature_names_out() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.get_feature_names_out", false]], "get_feature_names_out() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.get_feature_names_out", false]], "get_feature_names_out() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.get_feature_names_out", false]], "get_feature_names_out() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_extraction.text.tfidftransformer method)": [[598, "sklearn.feature_extraction.text.TfidfTransformer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.selectormixin method)": [[609, "sklearn.feature_selection.SelectorMixin.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.get_feature_names_out", false]], "get_feature_names_out() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.get_feature_names_out", false]], "get_feature_names_out() (sklearn.impute.iterativeimputer method)": [[635, "sklearn.impute.IterativeImputer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.impute.knnimputer method)": [[636, "sklearn.impute.KNNImputer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.impute.missingindicator method)": [[637, "sklearn.impute.MissingIndicator.get_feature_names_out", false]], "get_feature_names_out() (sklearn.impute.simpleimputer method)": [[638, "sklearn.impute.SimpleImputer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.get_feature_names_out", false]], "get_feature_names_out() (sklearn.kernel_approximation.additivechi2sampler method)": [[646, "sklearn.kernel_approximation.AdditiveChi2Sampler.get_feature_names_out", false]], "get_feature_names_out() (sklearn.kernel_approximation.nystroem method)": [[647, "sklearn.kernel_approximation.Nystroem.get_feature_names_out", false]], "get_feature_names_out() (sklearn.kernel_approximation.polynomialcountsketch method)": [[648, "sklearn.kernel_approximation.PolynomialCountSketch.get_feature_names_out", false]], "get_feature_names_out() (sklearn.kernel_approximation.rbfsampler method)": [[649, "sklearn.kernel_approximation.RBFSampler.get_feature_names_out", false]], "get_feature_names_out() (sklearn.kernel_approximation.skewedchi2sampler method)": [[650, "sklearn.kernel_approximation.SkewedChi2Sampler.get_feature_names_out", false]], "get_feature_names_out() (sklearn.manifold.isomap method)": [[696, "sklearn.manifold.Isomap.get_feature_names_out", false]], "get_feature_names_out() (sklearn.manifold.locallylinearembedding method)": [[697, "sklearn.manifold.LocallyLinearEmbedding.get_feature_names_out", false]], "get_feature_names_out() (sklearn.manifold.tsne method)": [[700, "sklearn.manifold.TSNE.get_feature_names_out", false]], "get_feature_names_out() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.neighbors.neighborhoodcomponentsanalysis method)": [[861, "sklearn.neighbors.NeighborhoodComponentsAnalysis.get_feature_names_out", false]], "get_feature_names_out() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.get_feature_names_out", false]], "get_feature_names_out() (sklearn.pipeline.featureunion method)": [[871, "sklearn.pipeline.FeatureUnion.get_feature_names_out", false]], "get_feature_names_out() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.binarizer method)": [[875, "sklearn.preprocessing.Binarizer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.functiontransformer method)": [[876, "sklearn.preprocessing.FunctionTransformer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.normalizer method)": [[884, "sklearn.preprocessing.Normalizer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.onehotencoder method)": [[885, "sklearn.preprocessing.OneHotEncoder.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.ordinalencoder method)": [[886, "sklearn.preprocessing.OrdinalEncoder.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.polynomialfeatures method)": [[887, "sklearn.preprocessing.PolynomialFeatures.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.powertransformer method)": [[888, "sklearn.preprocessing.PowerTransformer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.quantiletransformer method)": [[889, "sklearn.preprocessing.QuantileTransformer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.robustscaler method)": [[890, "sklearn.preprocessing.RobustScaler.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.splinetransformer method)": [[891, "sklearn.preprocessing.SplineTransformer.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.get_feature_names_out", false]], "get_feature_names_out() (sklearn.preprocessing.targetencoder method)": [[893, "sklearn.preprocessing.TargetEncoder.get_feature_names_out", false]], "get_feature_names_out() (sklearn.random_projection.gaussianrandomprojection method)": [[904, "sklearn.random_projection.GaussianRandomProjection.get_feature_names_out", false]], "get_feature_names_out() (sklearn.random_projection.sparserandomprojection method)": [[905, "sklearn.random_projection.SparseRandomProjection.get_feature_names_out", false]], "get_indices() (sklearn.base.biclustermixin method)": [[431, "sklearn.base.BiclusterMixin.get_indices", false]], "get_indices() (sklearn.cluster.spectralbiclustering method)": [[459, "sklearn.cluster.SpectralBiclustering.get_indices", false]], "get_indices() (sklearn.cluster.spectralcoclustering method)": [[461, "sklearn.cluster.SpectralCoclustering.get_indices", false]], "get_metadata_routing() (sklearn.base.baseestimator method)": [[430, "sklearn.base.BaseEstimator.get_metadata_routing", false]], "get_metadata_routing() (sklearn.calibration.calibratedclassifiercv method)": [[445, "sklearn.calibration.CalibratedClassifierCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.affinitypropagation method)": [[448, "sklearn.cluster.AffinityPropagation.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.agglomerativeclustering method)": [[449, "sklearn.cluster.AgglomerativeClustering.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.dbscan method)": [[452, "sklearn.cluster.DBSCAN.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.featureagglomeration method)": [[453, "sklearn.cluster.FeatureAgglomeration.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.hdbscan method)": [[454, "sklearn.cluster.HDBSCAN.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.meanshift method)": [[456, "sklearn.cluster.MeanShift.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.optics method)": [[458, "sklearn.cluster.OPTICS.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.spectralbiclustering method)": [[459, "sklearn.cluster.SpectralBiclustering.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.spectralclustering method)": [[460, "sklearn.cluster.SpectralClustering.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cluster.spectralcoclustering method)": [[461, "sklearn.cluster.SpectralCoclustering.get_metadata_routing", false]], "get_metadata_routing() (sklearn.compose.columntransformer method)": [[472, "sklearn.compose.ColumnTransformer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.compose.transformedtargetregressor method)": [[473, "sklearn.compose.TransformedTargetRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.get_metadata_routing", false]], "get_metadata_routing() (sklearn.covariance.empiricalcovariance method)": [[478, "sklearn.covariance.EmpiricalCovariance.get_metadata_routing", false]], "get_metadata_routing() (sklearn.covariance.graphicallasso method)": [[479, "sklearn.covariance.GraphicalLasso.get_metadata_routing", false]], "get_metadata_routing() (sklearn.covariance.graphicallassocv method)": [[480, "sklearn.covariance.GraphicalLassoCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.covariance.ledoitwolf method)": [[481, "sklearn.covariance.LedoitWolf.get_metadata_routing", false]], "get_metadata_routing() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.get_metadata_routing", false]], "get_metadata_routing() (sklearn.covariance.oas method)": [[483, "sklearn.covariance.OAS.get_metadata_routing", false]], "get_metadata_routing() (sklearn.covariance.shrunkcovariance method)": [[484, "sklearn.covariance.ShrunkCovariance.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.get_metadata_routing", false]], "get_metadata_routing() (sklearn.cross_decomposition.plssvd method)": [[493, "sklearn.cross_decomposition.PLSSVD.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.dictionarylearning method)": [[539, "sklearn.decomposition.DictionaryLearning.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.kernelpca method)": [[543, "sklearn.decomposition.KernelPCA.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.minibatchdictionarylearning method)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.minibatchsparsepca method)": [[547, "sklearn.decomposition.MiniBatchSparsePCA.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.nmf method)": [[548, "sklearn.decomposition.NMF.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.sparsecoder method)": [[550, "sklearn.decomposition.SparseCoder.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.sparsepca method)": [[551, "sklearn.decomposition.SparsePCA.get_metadata_routing", false]], "get_metadata_routing() (sklearn.decomposition.truncatedsvd method)": [[552, "sklearn.decomposition.TruncatedSVD.get_metadata_routing", false]], "get_metadata_routing() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_metadata_routing", false]], "get_metadata_routing() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.get_metadata_routing", false]], "get_metadata_routing() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.dummy.dummyregressor method)": [[560, "sklearn.dummy.DummyRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.baggingregressor method)": [[564, "sklearn.ensemble.BaggingRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.histgradientboostingregressor method)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.isolationforest method)": [[571, "sklearn.ensemble.IsolationForest.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_extraction.featurehasher method)": [[590, "sklearn.feature_extraction.FeatureHasher.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_extraction.image.patchextractor method)": [[591, "sklearn.feature_extraction.image.PatchExtractor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_extraction.text.tfidftransformer method)": [[598, "sklearn.feature_extraction.text.TfidfTransformer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.get_metadata_routing", false]], "get_metadata_routing() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.get_metadata_routing", false]], "get_metadata_routing() (sklearn.gaussian_process.gaussianprocessclassifier method)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.impute.iterativeimputer method)": [[635, "sklearn.impute.IterativeImputer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.impute.knnimputer method)": [[636, "sklearn.impute.KNNImputer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.impute.missingindicator method)": [[637, "sklearn.impute.MissingIndicator.get_metadata_routing", false]], "get_metadata_routing() (sklearn.impute.simpleimputer method)": [[638, "sklearn.impute.SimpleImputer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.get_metadata_routing", false]], "get_metadata_routing() (sklearn.kernel_approximation.additivechi2sampler method)": [[646, "sklearn.kernel_approximation.AdditiveChi2Sampler.get_metadata_routing", false]], "get_metadata_routing() (sklearn.kernel_approximation.nystroem method)": [[647, "sklearn.kernel_approximation.Nystroem.get_metadata_routing", false]], "get_metadata_routing() (sklearn.kernel_approximation.polynomialcountsketch method)": [[648, "sklearn.kernel_approximation.PolynomialCountSketch.get_metadata_routing", false]], "get_metadata_routing() (sklearn.kernel_approximation.rbfsampler method)": [[649, "sklearn.kernel_approximation.RBFSampler.get_metadata_routing", false]], "get_metadata_routing() (sklearn.kernel_approximation.skewedchi2sampler method)": [[650, "sklearn.kernel_approximation.SkewedChi2Sampler.get_metadata_routing", false]], "get_metadata_routing() (sklearn.kernel_ridge.kernelridge method)": [[651, "sklearn.kernel_ridge.KernelRidge.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.ardregression method)": [[652, "sklearn.linear_model.ARDRegression.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.bayesianridge method)": [[653, "sklearn.linear_model.BayesianRidge.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.elasticnet method)": [[654, "sklearn.linear_model.ElasticNet.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.elasticnetcv method)": [[655, "sklearn.linear_model.ElasticNetCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.gammaregressor method)": [[656, "sklearn.linear_model.GammaRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.huberregressor method)": [[657, "sklearn.linear_model.HuberRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.lars method)": [[658, "sklearn.linear_model.Lars.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.larscv method)": [[659, "sklearn.linear_model.LarsCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.lasso method)": [[660, "sklearn.linear_model.Lasso.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.lassocv method)": [[661, "sklearn.linear_model.LassoCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.lassolars method)": [[662, "sklearn.linear_model.LassoLars.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.lassolarscv method)": [[663, "sklearn.linear_model.LassoLarsCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.lassolarsic method)": [[664, "sklearn.linear_model.LassoLarsIC.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.linearregression method)": [[665, "sklearn.linear_model.LinearRegression.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.multitaskelasticnet method)": [[668, "sklearn.linear_model.MultiTaskElasticNet.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.multitaskelasticnetcv method)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.multitasklasso method)": [[670, "sklearn.linear_model.MultiTaskLasso.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.multitasklassocv method)": [[671, "sklearn.linear_model.MultiTaskLassoCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.orthogonalmatchingpursuit method)": [[672, "sklearn.linear_model.OrthogonalMatchingPursuit.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.orthogonalmatchingpursuitcv method)": [[673, "sklearn.linear_model.OrthogonalMatchingPursuitCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.poissonregressor method)": [[677, "sklearn.linear_model.PoissonRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.quantileregressor method)": [[678, "sklearn.linear_model.QuantileRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.ransacregressor method)": [[679, "sklearn.linear_model.RANSACRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.ridge method)": [[680, "sklearn.linear_model.Ridge.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.ridgeclassifier method)": [[682, "sklearn.linear_model.RidgeClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.ridgeclassifiercv method)": [[683, "sklearn.linear_model.RidgeClassifierCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.ridgecv method)": [[681, "sklearn.linear_model.RidgeCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.theilsenregressor method)": [[687, "sklearn.linear_model.TheilSenRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.linear_model.tweedieregressor method)": [[688, "sklearn.linear_model.TweedieRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.manifold.isomap method)": [[696, "sklearn.manifold.Isomap.get_metadata_routing", false]], "get_metadata_routing() (sklearn.manifold.locallylinearembedding method)": [[697, "sklearn.manifold.LocallyLinearEmbedding.get_metadata_routing", false]], "get_metadata_routing() (sklearn.manifold.mds method)": [[698, "sklearn.manifold.MDS.get_metadata_routing", false]], "get_metadata_routing() (sklearn.manifold.spectralembedding method)": [[699, "sklearn.manifold.SpectralEmbedding.get_metadata_routing", false]], "get_metadata_routing() (sklearn.manifold.tsne method)": [[700, "sklearn.manifold.TSNE.get_metadata_routing", false]], "get_metadata_routing() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.get_metadata_routing", false]], "get_metadata_routing() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.groupkfold method)": [[809, "sklearn.model_selection.GroupKFold.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.groupshufflesplit method)": [[810, "sklearn.model_selection.GroupShuffleSplit.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.kfold method)": [[813, "sklearn.model_selection.KFold.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.leaveonegroupout method)": [[815, "sklearn.model_selection.LeaveOneGroupOut.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.leaveoneout method)": [[816, "sklearn.model_selection.LeaveOneOut.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.leavepgroupsout method)": [[817, "sklearn.model_selection.LeavePGroupsOut.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.leavepout method)": [[818, "sklearn.model_selection.LeavePOut.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.predefinedsplit method)": [[821, "sklearn.model_selection.PredefinedSplit.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.repeatedkfold method)": [[823, "sklearn.model_selection.RepeatedKFold.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.repeatedstratifiedkfold method)": [[824, "sklearn.model_selection.RepeatedStratifiedKFold.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.shufflesplit method)": [[825, "sklearn.model_selection.ShuffleSplit.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.stratifiedgroupkfold method)": [[826, "sklearn.model_selection.StratifiedGroupKFold.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.stratifiedkfold method)": [[827, "sklearn.model_selection.StratifiedKFold.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.stratifiedshufflesplit method)": [[828, "sklearn.model_selection.StratifiedShuffleSplit.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.timeseriessplit method)": [[829, "sklearn.model_selection.TimeSeriesSplit.get_metadata_routing", false]], "get_metadata_routing() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.get_metadata_routing", false]], "get_metadata_routing() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.multiclass.outputcodeclassifier method)": [[842, "sklearn.multiclass.OutputCodeClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.get_metadata_routing", false]], "get_metadata_routing() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.multioutput.regressorchain method)": [[846, "sklearn.multioutput.RegressorChain.get_metadata_routing", false]], "get_metadata_routing() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.get_metadata_routing", false]], "get_metadata_routing() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.get_metadata_routing", false]], "get_metadata_routing() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.get_metadata_routing", false]], "get_metadata_routing() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.get_metadata_routing", false]], "get_metadata_routing() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.kerneldensity method)": [[857, "sklearn.neighbors.KernelDensity.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.kneighborsregressor method)": [[855, "sklearn.neighbors.KNeighborsRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.nearestcentroid method)": [[859, "sklearn.neighbors.NearestCentroid.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.nearestneighbors method)": [[860, "sklearn.neighbors.NearestNeighbors.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.neighborhoodcomponentsanalysis method)": [[861, "sklearn.neighbors.NeighborhoodComponentsAnalysis.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.radiusneighborsregressor method)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.neural_network.mlpregressor method)": [[870, "sklearn.neural_network.MLPRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.pipeline.featureunion method)": [[871, "sklearn.pipeline.FeatureUnion.get_metadata_routing", false]], "get_metadata_routing() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.binarizer method)": [[875, "sklearn.preprocessing.Binarizer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.functiontransformer method)": [[876, "sklearn.preprocessing.FunctionTransformer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.labelbinarizer method)": [[879, "sklearn.preprocessing.LabelBinarizer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.labelencoder method)": [[880, "sklearn.preprocessing.LabelEncoder.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.multilabelbinarizer method)": [[883, "sklearn.preprocessing.MultiLabelBinarizer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.normalizer method)": [[884, "sklearn.preprocessing.Normalizer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.onehotencoder method)": [[885, "sklearn.preprocessing.OneHotEncoder.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.ordinalencoder method)": [[886, "sklearn.preprocessing.OrdinalEncoder.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.polynomialfeatures method)": [[887, "sklearn.preprocessing.PolynomialFeatures.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.powertransformer method)": [[888, "sklearn.preprocessing.PowerTransformer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.quantiletransformer method)": [[889, "sklearn.preprocessing.QuantileTransformer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.robustscaler method)": [[890, "sklearn.preprocessing.RobustScaler.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.splinetransformer method)": [[891, "sklearn.preprocessing.SplineTransformer.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.get_metadata_routing", false]], "get_metadata_routing() (sklearn.preprocessing.targetencoder method)": [[893, "sklearn.preprocessing.TargetEncoder.get_metadata_routing", false]], "get_metadata_routing() (sklearn.random_projection.gaussianrandomprojection method)": [[904, "sklearn.random_projection.GaussianRandomProjection.get_metadata_routing", false]], "get_metadata_routing() (sklearn.random_projection.sparserandomprojection method)": [[905, "sklearn.random_projection.SparseRandomProjection.get_metadata_routing", false]], "get_metadata_routing() (sklearn.semi_supervised.labelpropagation method)": [[907, "sklearn.semi_supervised.LabelPropagation.get_metadata_routing", false]], "get_metadata_routing() (sklearn.semi_supervised.labelspreading method)": [[908, "sklearn.semi_supervised.LabelSpreading.get_metadata_routing", false]], "get_metadata_routing() (sklearn.semi_supervised.selftrainingclassifier method)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.get_metadata_routing", false]], "get_metadata_routing() (sklearn.svm.linearsvr method)": [[913, "sklearn.svm.LinearSVR.get_metadata_routing", false]], "get_metadata_routing() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.get_metadata_routing", false]], "get_metadata_routing() (sklearn.svm.nusvr method)": [[915, "sklearn.svm.NuSVR.get_metadata_routing", false]], "get_metadata_routing() (sklearn.svm.oneclasssvm method)": [[916, "sklearn.svm.OneClassSVM.get_metadata_routing", false]], "get_metadata_routing() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.get_metadata_routing", false]], "get_metadata_routing() (sklearn.svm.svr method)": [[918, "sklearn.svm.SVR.get_metadata_routing", false]], "get_metadata_routing() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.get_metadata_routing", false]], "get_metadata_routing() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.get_metadata_routing", false]], "get_metadata_routing() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.get_metadata_routing", false]], "get_metric() (sklearn.metrics.distancemetric class method)": [[707, "sklearn.metrics.DistanceMetric.get_metric", false]], "get_n_calls() (sklearn.neighbors.balltree method)": [[852, "sklearn.neighbors.BallTree.get_n_calls", false]], "get_n_calls() (sklearn.neighbors.kdtree method)": [[853, "sklearn.neighbors.KDTree.get_n_calls", false]], "get_n_leaves() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.get_n_leaves", false]], "get_n_leaves() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.get_n_leaves", false]], "get_n_leaves() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.get_n_leaves", false]], "get_n_leaves() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.get_n_leaves", false]], "get_n_splits": [[400, "term-get_n_splits", true]], "get_n_splits() (sklearn.model_selection.groupkfold method)": [[809, "sklearn.model_selection.GroupKFold.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.groupshufflesplit method)": [[810, "sklearn.model_selection.GroupShuffleSplit.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.kfold method)": [[813, "sklearn.model_selection.KFold.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.leaveonegroupout method)": [[815, "sklearn.model_selection.LeaveOneGroupOut.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.leaveoneout method)": [[816, "sklearn.model_selection.LeaveOneOut.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.leavepgroupsout method)": [[817, "sklearn.model_selection.LeavePGroupsOut.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.leavepout method)": [[818, "sklearn.model_selection.LeavePOut.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.predefinedsplit method)": [[821, "sklearn.model_selection.PredefinedSplit.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.repeatedkfold method)": [[823, "sklearn.model_selection.RepeatedKFold.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.repeatedstratifiedkfold method)": [[824, "sklearn.model_selection.RepeatedStratifiedKFold.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.shufflesplit method)": [[825, "sklearn.model_selection.ShuffleSplit.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.stratifiedgroupkfold method)": [[826, "sklearn.model_selection.StratifiedGroupKFold.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.stratifiedkfold method)": [[827, "sklearn.model_selection.StratifiedKFold.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.stratifiedshufflesplit method)": [[828, "sklearn.model_selection.StratifiedShuffleSplit.get_n_splits", false]], "get_n_splits() (sklearn.model_selection.timeseriessplit method)": [[829, "sklearn.model_selection.TimeSeriesSplit.get_n_splits", false]], "get_params": [[400, "term-get_params", true]], "get_params() (sklearn.base.baseestimator method)": [[430, "sklearn.base.BaseEstimator.get_params", false]], "get_params() (sklearn.calibration.calibratedclassifiercv method)": [[445, "sklearn.calibration.CalibratedClassifierCV.get_params", false]], "get_params() (sklearn.cluster.affinitypropagation method)": [[448, "sklearn.cluster.AffinityPropagation.get_params", false]], "get_params() (sklearn.cluster.agglomerativeclustering method)": [[449, "sklearn.cluster.AgglomerativeClustering.get_params", false]], "get_params() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.get_params", false]], "get_params() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.get_params", false]], "get_params() (sklearn.cluster.dbscan method)": [[452, "sklearn.cluster.DBSCAN.get_params", false]], "get_params() (sklearn.cluster.featureagglomeration method)": [[453, "sklearn.cluster.FeatureAgglomeration.get_params", false]], "get_params() (sklearn.cluster.hdbscan method)": [[454, "sklearn.cluster.HDBSCAN.get_params", false]], "get_params() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.get_params", false]], "get_params() (sklearn.cluster.meanshift method)": [[456, "sklearn.cluster.MeanShift.get_params", false]], "get_params() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.get_params", false]], "get_params() (sklearn.cluster.optics method)": [[458, "sklearn.cluster.OPTICS.get_params", false]], "get_params() (sklearn.cluster.spectralbiclustering method)": [[459, "sklearn.cluster.SpectralBiclustering.get_params", false]], "get_params() (sklearn.cluster.spectralclustering method)": [[460, "sklearn.cluster.SpectralClustering.get_params", false]], "get_params() (sklearn.cluster.spectralcoclustering method)": [[461, "sklearn.cluster.SpectralCoclustering.get_params", false]], "get_params() (sklearn.compose.columntransformer method)": [[472, "sklearn.compose.ColumnTransformer.get_params", false]], "get_params() (sklearn.compose.transformedtargetregressor method)": [[473, "sklearn.compose.TransformedTargetRegressor.get_params", false]], "get_params() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.get_params", false]], "get_params() (sklearn.covariance.empiricalcovariance method)": [[478, "sklearn.covariance.EmpiricalCovariance.get_params", false]], "get_params() (sklearn.covariance.graphicallasso method)": [[479, "sklearn.covariance.GraphicalLasso.get_params", false]], "get_params() (sklearn.covariance.graphicallassocv method)": [[480, "sklearn.covariance.GraphicalLassoCV.get_params", false]], "get_params() (sklearn.covariance.ledoitwolf method)": [[481, "sklearn.covariance.LedoitWolf.get_params", false]], "get_params() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.get_params", false]], "get_params() (sklearn.covariance.oas method)": [[483, "sklearn.covariance.OAS.get_params", false]], "get_params() (sklearn.covariance.shrunkcovariance method)": [[484, "sklearn.covariance.ShrunkCovariance.get_params", false]], "get_params() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.get_params", false]], "get_params() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.get_params", false]], "get_params() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.get_params", false]], "get_params() (sklearn.cross_decomposition.plssvd method)": [[493, "sklearn.cross_decomposition.PLSSVD.get_params", false]], "get_params() (sklearn.decomposition.dictionarylearning method)": [[539, "sklearn.decomposition.DictionaryLearning.get_params", false]], "get_params() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.get_params", false]], "get_params() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.get_params", false]], "get_params() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.get_params", false]], "get_params() (sklearn.decomposition.kernelpca method)": [[543, "sklearn.decomposition.KernelPCA.get_params", false]], "get_params() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.get_params", false]], "get_params() (sklearn.decomposition.minibatchdictionarylearning method)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning.get_params", false]], "get_params() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.get_params", false]], "get_params() (sklearn.decomposition.minibatchsparsepca method)": [[547, "sklearn.decomposition.MiniBatchSparsePCA.get_params", false]], "get_params() (sklearn.decomposition.nmf method)": [[548, "sklearn.decomposition.NMF.get_params", false]], "get_params() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.get_params", false]], "get_params() (sklearn.decomposition.sparsecoder method)": [[550, "sklearn.decomposition.SparseCoder.get_params", false]], "get_params() (sklearn.decomposition.sparsepca method)": [[551, "sklearn.decomposition.SparsePCA.get_params", false]], "get_params() (sklearn.decomposition.truncatedsvd method)": [[552, "sklearn.decomposition.TruncatedSVD.get_params", false]], "get_params() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_params", false]], "get_params() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.get_params", false]], "get_params() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.get_params", false]], "get_params() (sklearn.dummy.dummyregressor method)": [[560, "sklearn.dummy.DummyRegressor.get_params", false]], "get_params() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.get_params", false]], "get_params() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.get_params", false]], "get_params() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.get_params", false]], "get_params() (sklearn.ensemble.baggingregressor method)": [[564, "sklearn.ensemble.BaggingRegressor.get_params", false]], "get_params() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.get_params", false]], "get_params() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.get_params", false]], "get_params() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.get_params", false]], "get_params() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.get_params", false]], "get_params() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.get_params", false]], "get_params() (sklearn.ensemble.histgradientboostingregressor method)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.get_params", false]], "get_params() (sklearn.ensemble.isolationforest method)": [[571, "sklearn.ensemble.IsolationForest.get_params", false]], "get_params() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.get_params", false]], "get_params() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.get_params", false]], "get_params() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.get_params", false]], "get_params() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.get_params", false]], "get_params() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.get_params", false]], "get_params() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.get_params", false]], "get_params() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.get_params", false]], "get_params() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.get_params", false]], "get_params() (sklearn.feature_extraction.featurehasher method)": [[590, "sklearn.feature_extraction.FeatureHasher.get_params", false]], "get_params() (sklearn.feature_extraction.image.patchextractor method)": [[591, "sklearn.feature_extraction.image.PatchExtractor.get_params", false]], "get_params() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.get_params", false]], "get_params() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.get_params", false]], "get_params() (sklearn.feature_extraction.text.tfidftransformer method)": [[598, "sklearn.feature_extraction.text.TfidfTransformer.get_params", false]], "get_params() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.get_params", false]], "get_params() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.get_params", false]], "get_params() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.get_params", false]], "get_params() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.get_params", false]], "get_params() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.get_params", false]], "get_params() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.get_params", false]], "get_params() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.get_params", false]], "get_params() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.get_params", false]], "get_params() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.get_params", false]], "get_params() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.get_params", false]], "get_params() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.get_params", false]], "get_params() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.get_params", false]], "get_params() (sklearn.gaussian_process.gaussianprocessclassifier method)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.get_params", false]], "get_params() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.compoundkernel method)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.constantkernel method)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.dotproduct method)": [[622, "sklearn.gaussian_process.kernels.DotProduct.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.exponentiation method)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.expsinesquared method)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.kernel method)": [[626, "sklearn.gaussian_process.kernels.Kernel.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.matern method)": [[627, "sklearn.gaussian_process.kernels.Matern.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.pairwisekernel method)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.product method)": [[629, "sklearn.gaussian_process.kernels.Product.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.rationalquadratic method)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.rbf method)": [[630, "sklearn.gaussian_process.kernels.RBF.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.sum method)": [[632, "sklearn.gaussian_process.kernels.Sum.get_params", false]], "get_params() (sklearn.gaussian_process.kernels.whitekernel method)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.get_params", false]], "get_params() (sklearn.impute.iterativeimputer method)": [[635, "sklearn.impute.IterativeImputer.get_params", false]], "get_params() (sklearn.impute.knnimputer method)": [[636, "sklearn.impute.KNNImputer.get_params", false]], "get_params() (sklearn.impute.missingindicator method)": [[637, "sklearn.impute.MissingIndicator.get_params", false]], "get_params() (sklearn.impute.simpleimputer method)": [[638, "sklearn.impute.SimpleImputer.get_params", false]], "get_params() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.get_params", false]], "get_params() (sklearn.kernel_approximation.additivechi2sampler method)": [[646, "sklearn.kernel_approximation.AdditiveChi2Sampler.get_params", false]], "get_params() (sklearn.kernel_approximation.nystroem method)": [[647, "sklearn.kernel_approximation.Nystroem.get_params", false]], "get_params() (sklearn.kernel_approximation.polynomialcountsketch method)": [[648, "sklearn.kernel_approximation.PolynomialCountSketch.get_params", false]], "get_params() (sklearn.kernel_approximation.rbfsampler method)": [[649, "sklearn.kernel_approximation.RBFSampler.get_params", false]], "get_params() (sklearn.kernel_approximation.skewedchi2sampler method)": [[650, "sklearn.kernel_approximation.SkewedChi2Sampler.get_params", false]], "get_params() (sklearn.kernel_ridge.kernelridge method)": [[651, "sklearn.kernel_ridge.KernelRidge.get_params", false]], "get_params() (sklearn.linear_model.ardregression method)": [[652, "sklearn.linear_model.ARDRegression.get_params", false]], "get_params() (sklearn.linear_model.bayesianridge method)": [[653, "sklearn.linear_model.BayesianRidge.get_params", false]], "get_params() (sklearn.linear_model.elasticnet method)": [[654, "sklearn.linear_model.ElasticNet.get_params", false]], "get_params() (sklearn.linear_model.elasticnetcv method)": [[655, "sklearn.linear_model.ElasticNetCV.get_params", false]], "get_params() (sklearn.linear_model.gammaregressor method)": [[656, "sklearn.linear_model.GammaRegressor.get_params", false]], "get_params() (sklearn.linear_model.huberregressor method)": [[657, "sklearn.linear_model.HuberRegressor.get_params", false]], "get_params() (sklearn.linear_model.lars method)": [[658, "sklearn.linear_model.Lars.get_params", false]], "get_params() (sklearn.linear_model.larscv method)": [[659, "sklearn.linear_model.LarsCV.get_params", false]], "get_params() (sklearn.linear_model.lasso method)": [[660, "sklearn.linear_model.Lasso.get_params", false]], "get_params() (sklearn.linear_model.lassocv method)": [[661, "sklearn.linear_model.LassoCV.get_params", false]], "get_params() (sklearn.linear_model.lassolars method)": [[662, "sklearn.linear_model.LassoLars.get_params", false]], "get_params() (sklearn.linear_model.lassolarscv method)": [[663, "sklearn.linear_model.LassoLarsCV.get_params", false]], "get_params() (sklearn.linear_model.lassolarsic method)": [[664, "sklearn.linear_model.LassoLarsIC.get_params", false]], "get_params() (sklearn.linear_model.linearregression method)": [[665, "sklearn.linear_model.LinearRegression.get_params", false]], "get_params() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.get_params", false]], "get_params() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.get_params", false]], "get_params() (sklearn.linear_model.multitaskelasticnet method)": [[668, "sklearn.linear_model.MultiTaskElasticNet.get_params", false]], "get_params() (sklearn.linear_model.multitaskelasticnetcv method)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV.get_params", false]], "get_params() (sklearn.linear_model.multitasklasso method)": [[670, "sklearn.linear_model.MultiTaskLasso.get_params", false]], "get_params() (sklearn.linear_model.multitasklassocv method)": [[671, "sklearn.linear_model.MultiTaskLassoCV.get_params", false]], "get_params() (sklearn.linear_model.orthogonalmatchingpursuit method)": [[672, "sklearn.linear_model.OrthogonalMatchingPursuit.get_params", false]], "get_params() (sklearn.linear_model.orthogonalmatchingpursuitcv method)": [[673, "sklearn.linear_model.OrthogonalMatchingPursuitCV.get_params", false]], "get_params() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.get_params", false]], "get_params() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.get_params", false]], "get_params() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.get_params", false]], "get_params() (sklearn.linear_model.poissonregressor method)": [[677, "sklearn.linear_model.PoissonRegressor.get_params", false]], "get_params() (sklearn.linear_model.quantileregressor method)": [[678, "sklearn.linear_model.QuantileRegressor.get_params", false]], "get_params() (sklearn.linear_model.ransacregressor method)": [[679, "sklearn.linear_model.RANSACRegressor.get_params", false]], "get_params() (sklearn.linear_model.ridge method)": [[680, "sklearn.linear_model.Ridge.get_params", false]], "get_params() (sklearn.linear_model.ridgeclassifier method)": [[682, "sklearn.linear_model.RidgeClassifier.get_params", false]], "get_params() (sklearn.linear_model.ridgeclassifiercv method)": [[683, "sklearn.linear_model.RidgeClassifierCV.get_params", false]], "get_params() (sklearn.linear_model.ridgecv method)": [[681, "sklearn.linear_model.RidgeCV.get_params", false]], "get_params() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.get_params", false]], "get_params() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.get_params", false]], "get_params() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.get_params", false]], "get_params() (sklearn.linear_model.theilsenregressor method)": [[687, "sklearn.linear_model.TheilSenRegressor.get_params", false]], "get_params() (sklearn.linear_model.tweedieregressor method)": [[688, "sklearn.linear_model.TweedieRegressor.get_params", false]], "get_params() (sklearn.manifold.isomap method)": [[696, "sklearn.manifold.Isomap.get_params", false]], "get_params() (sklearn.manifold.locallylinearembedding method)": [[697, "sklearn.manifold.LocallyLinearEmbedding.get_params", false]], "get_params() (sklearn.manifold.mds method)": [[698, "sklearn.manifold.MDS.get_params", false]], "get_params() (sklearn.manifold.spectralembedding method)": [[699, "sklearn.manifold.SpectralEmbedding.get_params", false]], "get_params() (sklearn.manifold.tsne method)": [[700, "sklearn.manifold.TSNE.get_params", false]], "get_params() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.get_params", false]], "get_params() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.get_params", false]], "get_params() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.get_params", false]], "get_params() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.get_params", false]], "get_params() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.get_params", false]], "get_params() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.get_params", false]], "get_params() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.get_params", false]], "get_params() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.get_params", false]], "get_params() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.get_params", false]], "get_params() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.get_params", false]], "get_params() (sklearn.multiclass.outputcodeclassifier method)": [[842, "sklearn.multiclass.OutputCodeClassifier.get_params", false]], "get_params() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.get_params", false]], "get_params() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.get_params", false]], "get_params() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.get_params", false]], "get_params() (sklearn.multioutput.regressorchain method)": [[846, "sklearn.multioutput.RegressorChain.get_params", false]], "get_params() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.get_params", false]], "get_params() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.get_params", false]], "get_params() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.get_params", false]], "get_params() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.get_params", false]], "get_params() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.get_params", false]], "get_params() (sklearn.neighbors.kerneldensity method)": [[857, "sklearn.neighbors.KernelDensity.get_params", false]], "get_params() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.get_params", false]], "get_params() (sklearn.neighbors.kneighborsregressor method)": [[855, "sklearn.neighbors.KNeighborsRegressor.get_params", false]], "get_params() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.get_params", false]], "get_params() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.get_params", false]], "get_params() (sklearn.neighbors.nearestcentroid method)": [[859, "sklearn.neighbors.NearestCentroid.get_params", false]], "get_params() (sklearn.neighbors.nearestneighbors method)": [[860, "sklearn.neighbors.NearestNeighbors.get_params", false]], "get_params() (sklearn.neighbors.neighborhoodcomponentsanalysis method)": [[861, "sklearn.neighbors.NeighborhoodComponentsAnalysis.get_params", false]], "get_params() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.get_params", false]], "get_params() (sklearn.neighbors.radiusneighborsregressor method)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor.get_params", false]], "get_params() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.get_params", false]], "get_params() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.get_params", false]], "get_params() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.get_params", false]], "get_params() (sklearn.neural_network.mlpregressor method)": [[870, "sklearn.neural_network.MLPRegressor.get_params", false]], "get_params() (sklearn.pipeline.featureunion method)": [[871, "sklearn.pipeline.FeatureUnion.get_params", false]], "get_params() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.get_params", false]], "get_params() (sklearn.preprocessing.binarizer method)": [[875, "sklearn.preprocessing.Binarizer.get_params", false]], "get_params() (sklearn.preprocessing.functiontransformer method)": [[876, "sklearn.preprocessing.FunctionTransformer.get_params", false]], "get_params() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.get_params", false]], "get_params() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.get_params", false]], "get_params() (sklearn.preprocessing.labelbinarizer method)": [[879, "sklearn.preprocessing.LabelBinarizer.get_params", false]], "get_params() (sklearn.preprocessing.labelencoder method)": [[880, "sklearn.preprocessing.LabelEncoder.get_params", false]], "get_params() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.get_params", false]], "get_params() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.get_params", false]], "get_params() (sklearn.preprocessing.multilabelbinarizer method)": [[883, "sklearn.preprocessing.MultiLabelBinarizer.get_params", false]], "get_params() (sklearn.preprocessing.normalizer method)": [[884, "sklearn.preprocessing.Normalizer.get_params", false]], "get_params() (sklearn.preprocessing.onehotencoder method)": [[885, "sklearn.preprocessing.OneHotEncoder.get_params", false]], "get_params() (sklearn.preprocessing.ordinalencoder method)": [[886, "sklearn.preprocessing.OrdinalEncoder.get_params", false]], "get_params() (sklearn.preprocessing.polynomialfeatures method)": [[887, "sklearn.preprocessing.PolynomialFeatures.get_params", false]], "get_params() (sklearn.preprocessing.powertransformer method)": [[888, "sklearn.preprocessing.PowerTransformer.get_params", false]], "get_params() (sklearn.preprocessing.quantiletransformer method)": [[889, "sklearn.preprocessing.QuantileTransformer.get_params", false]], "get_params() (sklearn.preprocessing.robustscaler method)": [[890, "sklearn.preprocessing.RobustScaler.get_params", false]], "get_params() (sklearn.preprocessing.splinetransformer method)": [[891, "sklearn.preprocessing.SplineTransformer.get_params", false]], "get_params() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.get_params", false]], "get_params() (sklearn.preprocessing.targetencoder method)": [[893, "sklearn.preprocessing.TargetEncoder.get_params", false]], "get_params() (sklearn.random_projection.gaussianrandomprojection method)": [[904, "sklearn.random_projection.GaussianRandomProjection.get_params", false]], "get_params() (sklearn.random_projection.sparserandomprojection method)": [[905, "sklearn.random_projection.SparseRandomProjection.get_params", false]], "get_params() (sklearn.semi_supervised.labelpropagation method)": [[907, "sklearn.semi_supervised.LabelPropagation.get_params", false]], "get_params() (sklearn.semi_supervised.labelspreading method)": [[908, "sklearn.semi_supervised.LabelSpreading.get_params", false]], "get_params() (sklearn.semi_supervised.selftrainingclassifier method)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier.get_params", false]], "get_params() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.get_params", false]], "get_params() (sklearn.svm.linearsvr method)": [[913, "sklearn.svm.LinearSVR.get_params", false]], "get_params() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.get_params", false]], "get_params() (sklearn.svm.nusvr method)": [[915, "sklearn.svm.NuSVR.get_params", false]], "get_params() (sklearn.svm.oneclasssvm method)": [[916, "sklearn.svm.OneClassSVM.get_params", false]], "get_params() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.get_params", false]], "get_params() (sklearn.svm.svr method)": [[918, "sklearn.svm.SVR.get_params", false]], "get_params() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.get_params", false]], "get_params() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.get_params", false]], "get_params() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.get_params", false]], "get_params() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.get_params", false]], "get_precision() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.get_precision", false]], "get_precision() (sklearn.covariance.empiricalcovariance method)": [[478, "sklearn.covariance.EmpiricalCovariance.get_precision", false]], "get_precision() (sklearn.covariance.graphicallasso method)": [[479, "sklearn.covariance.GraphicalLasso.get_precision", false]], "get_precision() (sklearn.covariance.graphicallassocv method)": [[480, "sklearn.covariance.GraphicalLassoCV.get_precision", false]], "get_precision() (sklearn.covariance.ledoitwolf method)": [[481, "sklearn.covariance.LedoitWolf.get_precision", false]], "get_precision() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.get_precision", false]], "get_precision() (sklearn.covariance.oas method)": [[483, "sklearn.covariance.OAS.get_precision", false]], "get_precision() (sklearn.covariance.shrunkcovariance method)": [[484, "sklearn.covariance.ShrunkCovariance.get_precision", false]], "get_precision() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.get_precision", false]], "get_precision() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.get_precision", false]], "get_precision() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.get_precision", false]], "get_routing_for_object() (in module sklearn.utils.metadata_routing)": [[959, "sklearn.utils.metadata_routing.get_routing_for_object", false]], "get_scorer() (in module sklearn.metrics)": [[740, "sklearn.metrics.get_scorer", false]], "get_scorer_names() (in module sklearn.metrics)": [[741, "sklearn.metrics.get_scorer_names", false]], "get_shape() (sklearn.base.biclustermixin method)": [[431, "sklearn.base.BiclusterMixin.get_shape", false]], "get_shape() (sklearn.cluster.spectralbiclustering method)": [[459, "sklearn.cluster.SpectralBiclustering.get_shape", false]], "get_shape() (sklearn.cluster.spectralcoclustering method)": [[461, "sklearn.cluster.SpectralCoclustering.get_shape", false]], "get_stop_words() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.get_stop_words", false]], "get_stop_words() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.get_stop_words", false]], "get_stop_words() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.get_stop_words", false]], "get_submatrix() (sklearn.base.biclustermixin method)": [[431, "sklearn.base.BiclusterMixin.get_submatrix", false]], "get_submatrix() (sklearn.cluster.spectralbiclustering method)": [[459, "sklearn.cluster.SpectralBiclustering.get_submatrix", false]], "get_submatrix() (sklearn.cluster.spectralcoclustering method)": [[461, "sklearn.cluster.SpectralCoclustering.get_submatrix", false]], "get_support() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.get_support", false]], "get_support() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.get_support", false]], "get_support() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.get_support", false]], "get_support() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.get_support", false]], "get_support() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.get_support", false]], "get_support() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.get_support", false]], "get_support() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.get_support", false]], "get_support() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.get_support", false]], "get_support() (sklearn.feature_selection.selectormixin method)": [[609, "sklearn.feature_selection.SelectorMixin.get_support", false]], "get_support() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.get_support", false]], "get_support() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.get_support", false]], "get_support() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.get_support", false]], "get_tree_stats() (sklearn.neighbors.balltree method)": [[852, "sklearn.neighbors.BallTree.get_tree_stats", false]], "get_tree_stats() (sklearn.neighbors.kdtree method)": [[853, "sklearn.neighbors.KDTree.get_tree_stats", false]], "gibbs() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.gibbs", false]], "gradientboostingclassifier (class in sklearn.ensemble)": [[567, "sklearn.ensemble.GradientBoostingClassifier", false]], "gradientboostingregressor (class in sklearn.ensemble)": [[568, "sklearn.ensemble.GradientBoostingRegressor", false]], "graphical_lasso() (in module sklearn.covariance)": [[486, "sklearn.covariance.graphical_lasso", false]], "graphicallasso (class in sklearn.covariance)": [[479, "sklearn.covariance.GraphicalLasso", false]], "graphicallassocv (class in sklearn.covariance)": [[480, "sklearn.covariance.GraphicalLassoCV", false]], "grid_to_graph() (in module sklearn.feature_extraction.image)": [[593, "sklearn.feature_extraction.image.grid_to_graph", false]], "gridsearchcv (class in sklearn.model_selection)": [[808, "sklearn.model_selection.GridSearchCV", false]], "groupkfold (class in sklearn.model_selection)": [[809, "sklearn.model_selection.GroupKFold", false]], "groups": [[400, "term-groups", true]], "groupshufflesplit (class in sklearn.model_selection)": [[810, "sklearn.model_selection.GroupShuffleSplit", false]], "halvinggridsearchcv (class in sklearn.model_selection)": [[811, "sklearn.model_selection.HalvingGridSearchCV", false]], "halvingrandomsearchcv (class in sklearn.model_selection)": [[812, "sklearn.model_selection.HalvingRandomSearchCV", false]], "hamming_loss() (in module sklearn.metrics)": [[742, "sklearn.metrics.hamming_loss", false]], "has_fit_parameter() (in module sklearn.utils.validation)": [[988, "sklearn.utils.validation.has_fit_parameter", false]], "hashingvectorizer (class in sklearn.feature_extraction.text)": [[597, "sklearn.feature_extraction.text.HashingVectorizer", false]], "haversine_distances() (in module sklearn.metrics.pairwise)": [[772, "sklearn.metrics.pairwise.haversine_distances", false]], "hdbscan (class in sklearn.cluster)": [[454, "sklearn.cluster.HDBSCAN", false]], "hinge_loss() (in module sklearn.metrics)": [[743, "sklearn.metrics.hinge_loss", false]], "histgradientboostingclassifier (class in sklearn.ensemble)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier", false]], "histgradientboostingregressor (class in sklearn.ensemble)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor", false]], "homogeneity_completeness_v_measure() (in module sklearn.metrics)": [[744, "sklearn.metrics.homogeneity_completeness_v_measure", false]], "homogeneity_score() (in module sklearn.metrics)": [[745, "sklearn.metrics.homogeneity_score", false]], "huberregressor (class in sklearn.linear_model)": [[657, "sklearn.linear_model.HuberRegressor", false]], "hyper-parameter": [[400, "term-hyper-parameter", true]], "hyperparameter": [[400, "term-hyperparameter", true]], "hyperparameter (class in sklearn.gaussian_process.kernels)": [[625, "sklearn.gaussian_process.kernels.Hyperparameter", false]], "hyperparameter_length_scale (sklearn.gaussian_process.kernels.expsinesquared property)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.hyperparameter_length_scale", false]], "hyperparameters (sklearn.gaussian_process.kernels.compoundkernel property)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.constantkernel property)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.dotproduct property)": [[622, "sklearn.gaussian_process.kernels.DotProduct.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.exponentiation property)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.expsinesquared property)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.kernel property)": [[626, "sklearn.gaussian_process.kernels.Kernel.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.matern property)": [[627, "sklearn.gaussian_process.kernels.Matern.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.pairwisekernel property)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.product property)": [[629, "sklearn.gaussian_process.kernels.Product.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.rationalquadratic property)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.rbf property)": [[630, "sklearn.gaussian_process.kernels.RBF.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.sum property)": [[632, "sklearn.gaussian_process.kernels.Sum.hyperparameters", false]], "hyperparameters (sklearn.gaussian_process.kernels.whitekernel property)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.hyperparameters", false]], "idf_ (sklearn.feature_extraction.text.tfidfvectorizer property)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.idf_", false]], "img_to_graph() (in module sklearn.feature_extraction.image)": [[594, "sklearn.feature_extraction.image.img_to_graph", false]], "imputation": [[400, "term-imputation", true]], "impute": [[400, "term-impute", true]], "inconsistentversionwarning": [[584, "sklearn.exceptions.InconsistentVersionWarning", false]], "incr_mean_variance_axis() (in module sklearn.utils.sparsefuncs)": [[975, "sklearn.utils.sparsefuncs.incr_mean_variance_axis", false]], "incrementalpca (class in sklearn.decomposition)": [[542, "sklearn.decomposition.IncrementalPCA", false]], "index() (sklearn.gaussian_process.kernels.hyperparameter method)": [[625, "sklearn.gaussian_process.kernels.Hyperparameter.index", false]], "indexable": [[400, "term-indexable", true]], "indexable() (in module sklearn.utils)": [[955, "sklearn.utils.indexable", false]], "induction": [[400, "term-induction", true]], "inductive": [[400, "term-inductive", true]], "infrequent_categories_ (sklearn.preprocessing.onehotencoder property)": [[885, "sklearn.preprocessing.OneHotEncoder.infrequent_categories_", false]], "infrequent_categories_ (sklearn.preprocessing.ordinalencoder property)": [[886, "sklearn.preprocessing.OrdinalEncoder.infrequent_categories_", false]], "infrequent_categories_ (sklearn.preprocessing.targetencoder property)": [[893, "sklearn.preprocessing.TargetEncoder.infrequent_categories_", false]], "inplace_column_scale() (in module sklearn.utils.sparsefuncs)": [[976, "sklearn.utils.sparsefuncs.inplace_column_scale", false]], "inplace_csr_column_scale() (in module sklearn.utils.sparsefuncs)": [[977, "sklearn.utils.sparsefuncs.inplace_csr_column_scale", false]], "inplace_csr_row_normalize_l1() (in module sklearn.utils.sparsefuncs_fast)": [[982, "sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l1", false]], "inplace_csr_row_normalize_l2() (in module sklearn.utils.sparsefuncs_fast)": [[983, "sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l2", false]], "inplace_row_scale() (in module sklearn.utils.sparsefuncs)": [[978, "sklearn.utils.sparsefuncs.inplace_row_scale", false]], "inplace_swap_column() (in module sklearn.utils.sparsefuncs)": [[979, "sklearn.utils.sparsefuncs.inplace_swap_column", false]], "inplace_swap_row() (in module sklearn.utils.sparsefuncs)": [[980, "sklearn.utils.sparsefuncs.inplace_swap_row", false]], "inverse_transform() (sklearn.cluster.featureagglomeration method)": [[453, "sklearn.cluster.FeatureAgglomeration.inverse_transform", false]], "inverse_transform() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.inverse_transform", false]], "inverse_transform() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.inverse_transform", false]], "inverse_transform() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.inverse_transform", false]], "inverse_transform() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.inverse_transform", false]], "inverse_transform() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.inverse_transform", false]], "inverse_transform() (sklearn.decomposition.kernelpca method)": [[543, "sklearn.decomposition.KernelPCA.inverse_transform", false]], "inverse_transform() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.inverse_transform", false]], "inverse_transform() (sklearn.decomposition.minibatchsparsepca method)": [[547, "sklearn.decomposition.MiniBatchSparsePCA.inverse_transform", false]], "inverse_transform() (sklearn.decomposition.nmf method)": [[548, "sklearn.decomposition.NMF.inverse_transform", false]], "inverse_transform() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.inverse_transform", false]], "inverse_transform() (sklearn.decomposition.sparsepca method)": [[551, "sklearn.decomposition.SparsePCA.inverse_transform", false]], "inverse_transform() (sklearn.decomposition.truncatedsvd method)": [[552, "sklearn.decomposition.TruncatedSVD.inverse_transform", false]], "inverse_transform() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.inverse_transform", false]], "inverse_transform() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.inverse_transform", false]], "inverse_transform() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.selectormixin method)": [[609, "sklearn.feature_selection.SelectorMixin.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.inverse_transform", false]], "inverse_transform() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.inverse_transform", false]], "inverse_transform() (sklearn.impute.simpleimputer method)": [[638, "sklearn.impute.SimpleImputer.inverse_transform", false]], "inverse_transform() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.inverse_transform", false]], "inverse_transform() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.inverse_transform", false]], "inverse_transform() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.inverse_transform", false]], "inverse_transform() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.inverse_transform", false]], "inverse_transform() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.functiontransformer method)": [[876, "sklearn.preprocessing.FunctionTransformer.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.labelbinarizer method)": [[879, "sklearn.preprocessing.LabelBinarizer.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.labelencoder method)": [[880, "sklearn.preprocessing.LabelEncoder.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.multilabelbinarizer method)": [[883, "sklearn.preprocessing.MultiLabelBinarizer.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.onehotencoder method)": [[885, "sklearn.preprocessing.OneHotEncoder.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.ordinalencoder method)": [[886, "sklearn.preprocessing.OrdinalEncoder.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.powertransformer method)": [[888, "sklearn.preprocessing.PowerTransformer.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.quantiletransformer method)": [[889, "sklearn.preprocessing.QuantileTransformer.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.robustscaler method)": [[890, "sklearn.preprocessing.RobustScaler.inverse_transform", false]], "inverse_transform() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.inverse_transform", false]], "inverse_transform() (sklearn.random_projection.gaussianrandomprojection method)": [[904, "sklearn.random_projection.GaussianRandomProjection.inverse_transform", false]], "inverse_transform() (sklearn.random_projection.sparserandomprojection method)": [[905, "sklearn.random_projection.SparseRandomProjection.inverse_transform", false]], "is_classifier() (in module sklearn.base)": [[442, "sklearn.base.is_classifier", false]], "is_clusterer() (in module sklearn.base)": [[443, "sklearn.base.is_clusterer", false]], "is_multilabel() (in module sklearn.utils.multiclass)": [[962, "sklearn.utils.multiclass.is_multilabel", false]], "is_regressor() (in module sklearn.base)": [[444, "sklearn.base.is_regressor", false]], "is_stationary() (sklearn.gaussian_process.kernels.compoundkernel method)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.constantkernel method)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.dotproduct method)": [[622, "sklearn.gaussian_process.kernels.DotProduct.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.exponentiation method)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.expsinesquared method)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.kernel method)": [[626, "sklearn.gaussian_process.kernels.Kernel.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.matern method)": [[627, "sklearn.gaussian_process.kernels.Matern.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.pairwisekernel method)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.product method)": [[629, "sklearn.gaussian_process.kernels.Product.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.rationalquadratic method)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.rbf method)": [[630, "sklearn.gaussian_process.kernels.RBF.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.sum method)": [[632, "sklearn.gaussian_process.kernels.Sum.is_stationary", false]], "is_stationary() (sklearn.gaussian_process.kernels.whitekernel method)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.is_stationary", false]], "isolationforest (class in sklearn.ensemble)": [[571, "sklearn.ensemble.IsolationForest", false]], "isomap (class in sklearn.manifold)": [[696, "sklearn.manifold.Isomap", false]], "isotonic_regression() (in module sklearn.isotonic)": [[645, "sklearn.isotonic.isotonic_regression", false]], "isotonicregression (class in sklearn.isotonic)": [[643, "sklearn.isotonic.IsotonicRegression", false]], "items() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.items", false]], "iterativeimputer (class in sklearn.impute)": [[635, "sklearn.impute.IterativeImputer", false]], "jaccard_score() (in module sklearn.metrics)": [[746, "sklearn.metrics.jaccard_score", false]], "joblib": [[400, "term-joblib", true]], "johnson_lindenstrauss_min_dim() (in module sklearn.random_projection)": [[906, "sklearn.random_projection.johnson_lindenstrauss_min_dim", false]], "k_means() (in module sklearn.cluster)": [[467, "sklearn.cluster.k_means", false]], "kbinsdiscretizer (class in sklearn.preprocessing)": [[877, "sklearn.preprocessing.KBinsDiscretizer", false]], "kdtree (class in sklearn.neighbors)": [[853, "sklearn.neighbors.KDTree", false]], "kernel": [[400, "term-kernel", true]], "kernel (class in sklearn.gaussian_process.kernels)": [[626, "sklearn.gaussian_process.kernels.Kernel", false]], "kernel_ (sklearn.gaussian_process.gaussianprocessclassifier property)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.kernel_", false]], "kernel_density() (sklearn.neighbors.balltree method)": [[852, "sklearn.neighbors.BallTree.kernel_density", false]], "kernel_density() (sklearn.neighbors.kdtree method)": [[853, "sklearn.neighbors.KDTree.kernel_density", false]], "kernel_metrics() (in module sklearn.metrics.pairwise)": [[773, "sklearn.metrics.pairwise.kernel_metrics", false]], "kernelcenterer (class in sklearn.preprocessing)": [[878, "sklearn.preprocessing.KernelCenterer", false]], "kerneldensity (class in sklearn.neighbors)": [[857, "sklearn.neighbors.KernelDensity", false]], "kernelpca (class in sklearn.decomposition)": [[543, "sklearn.decomposition.KernelPCA", false]], "kernelridge (class in sklearn.kernel_ridge)": [[651, "sklearn.kernel_ridge.KernelRidge", false]], "keys() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.keys", false]], "kfold (class in sklearn.model_selection)": [[813, "sklearn.model_selection.KFold", false]], "kmeans (class in sklearn.cluster)": [[455, "sklearn.cluster.KMeans", false]], "kmeans_plusplus() (in module sklearn.cluster)": [[468, "sklearn.cluster.kmeans_plusplus", false]], "kneighbors() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.kneighbors", false]], "kneighbors() (sklearn.neighbors.kneighborsregressor method)": [[855, "sklearn.neighbors.KNeighborsRegressor.kneighbors", false]], "kneighbors() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.kneighbors", false]], "kneighbors() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.kneighbors", false]], "kneighbors() (sklearn.neighbors.nearestneighbors method)": [[860, "sklearn.neighbors.NearestNeighbors.kneighbors", false]], "kneighbors_graph() (in module sklearn.neighbors)": [[865, "sklearn.neighbors.kneighbors_graph", false]], "kneighbors_graph() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.kneighbors_graph", false]], "kneighbors_graph() (sklearn.neighbors.kneighborsregressor method)": [[855, "sklearn.neighbors.KNeighborsRegressor.kneighbors_graph", false]], "kneighbors_graph() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.kneighbors_graph", false]], "kneighbors_graph() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.kneighbors_graph", false]], "kneighbors_graph() (sklearn.neighbors.nearestneighbors method)": [[860, "sklearn.neighbors.NearestNeighbors.kneighbors_graph", false]], "kneighborsclassifier (class in sklearn.neighbors)": [[854, "sklearn.neighbors.KNeighborsClassifier", false]], "kneighborsregressor (class in sklearn.neighbors)": [[855, "sklearn.neighbors.KNeighborsRegressor", false]], "kneighborstransformer (class in sklearn.neighbors)": [[856, "sklearn.neighbors.KNeighborsTransformer", false]], "knnimputer (class in sklearn.impute)": [[636, "sklearn.impute.KNNImputer", false]], "l1_min_c() (in module sklearn.svm)": [[919, "sklearn.svm.l1_min_c", false]], "label indicator matrix": [[400, "term-label-indicator-matrix", true]], "label_binarize() (in module sklearn.preprocessing)": [[896, "sklearn.preprocessing.label_binarize", false]], "label_ranking_average_precision_score() (in module sklearn.metrics)": [[747, "sklearn.metrics.label_ranking_average_precision_score", false]], "label_ranking_loss() (in module sklearn.metrics)": [[748, "sklearn.metrics.label_ranking_loss", false]], "labelbinarizer (class in sklearn.preprocessing)": [[879, "sklearn.preprocessing.LabelBinarizer", false]], "labelencoder (class in sklearn.preprocessing)": [[880, "sklearn.preprocessing.LabelEncoder", false]], "labelpropagation (class in sklearn.semi_supervised)": [[907, "sklearn.semi_supervised.LabelPropagation", false]], "labels_": [[400, "term-labels_", true]], "labelspreading (class in sklearn.semi_supervised)": [[908, "sklearn.semi_supervised.LabelSpreading", false]], "laplacian_kernel() (in module sklearn.metrics.pairwise)": [[774, "sklearn.metrics.pairwise.laplacian_kernel", false]], "lars (class in sklearn.linear_model)": [[658, "sklearn.linear_model.Lars", false]], "lars_path() (in module sklearn.linear_model)": [[690, "sklearn.linear_model.lars_path", false]], "lars_path_gram() (in module sklearn.linear_model)": [[691, "sklearn.linear_model.lars_path_gram", false]], "larscv (class in sklearn.linear_model)": [[659, "sklearn.linear_model.LarsCV", false]], "lasso (class in sklearn.linear_model)": [[660, "sklearn.linear_model.Lasso", false]], "lasso_path() (in module sklearn.linear_model)": [[692, "sklearn.linear_model.lasso_path", false]], "lassocv (class in sklearn.linear_model)": [[661, "sklearn.linear_model.LassoCV", false]], "lassolars (class in sklearn.linear_model)": [[662, "sklearn.linear_model.LassoLars", false]], "lassolarscv (class in sklearn.linear_model)": [[663, "sklearn.linear_model.LassoLarsCV", false]], "lassolarsic (class in sklearn.linear_model)": [[664, "sklearn.linear_model.LassoLarsIC", false]], "latentdirichletallocation (class in sklearn.decomposition)": [[544, "sklearn.decomposition.LatentDirichletAllocation", false]], "leakage": [[400, "term-leakage", true]], "learning_curve() (in module sklearn.model_selection)": [[836, "sklearn.model_selection.learning_curve", false]], "learningcurvedisplay (class in sklearn.model_selection)": [[814, "sklearn.model_selection.LearningCurveDisplay", false]], "leaveonegroupout (class in sklearn.model_selection)": [[815, "sklearn.model_selection.LeaveOneGroupOut", false]], "leaveoneout (class in sklearn.model_selection)": [[816, "sklearn.model_selection.LeaveOneOut", false]], "leavepgroupsout (class in sklearn.model_selection)": [[817, "sklearn.model_selection.LeavePGroupsOut", false]], "leavepout (class in sklearn.model_selection)": [[818, "sklearn.model_selection.LeavePOut", false]], "ledoit_wolf() (in module sklearn.covariance)": [[487, "sklearn.covariance.ledoit_wolf", false]], "ledoit_wolf_shrinkage() (in module sklearn.covariance)": [[488, "sklearn.covariance.ledoit_wolf_shrinkage", false]], "ledoitwolf (class in sklearn.covariance)": [[481, "sklearn.covariance.LedoitWolf", false]], "linear_kernel() (in module sklearn.metrics.pairwise)": [[775, "sklearn.metrics.pairwise.linear_kernel", false]], "lineardiscriminantanalysis (class in sklearn.discriminant_analysis)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis", false]], "linearregression (class in sklearn.linear_model)": [[665, "sklearn.linear_model.LinearRegression", false]], "linearsvc (class in sklearn.svm)": [[912, "sklearn.svm.LinearSVC", false]], "linearsvr (class in sklearn.svm)": [[913, "sklearn.svm.LinearSVR", false]], "load_breast_cancer() (in module sklearn.datasets)": [[508, "sklearn.datasets.load_breast_cancer", false]], "load_diabetes() (in module sklearn.datasets)": [[509, "sklearn.datasets.load_diabetes", false]], "load_digits() (in module sklearn.datasets)": [[510, "sklearn.datasets.load_digits", false]], "load_files() (in module sklearn.datasets)": [[511, "sklearn.datasets.load_files", false]], "load_iris() (in module sklearn.datasets)": [[512, "sklearn.datasets.load_iris", false]], "load_linnerud() (in module sklearn.datasets)": [[513, "sklearn.datasets.load_linnerud", false]], "load_sample_image() (in module sklearn.datasets)": [[514, "sklearn.datasets.load_sample_image", false]], "load_sample_images() (in module sklearn.datasets)": [[515, "sklearn.datasets.load_sample_images", false]], "load_svmlight_file() (in module sklearn.datasets)": [[516, "sklearn.datasets.load_svmlight_file", false]], "load_svmlight_files() (in module sklearn.datasets)": [[517, "sklearn.datasets.load_svmlight_files", false]], "load_wine() (in module sklearn.datasets)": [[518, "sklearn.datasets.load_wine", false]], "locally_linear_embedding() (in module sklearn.manifold)": [[701, "sklearn.manifold.locally_linear_embedding", false]], "locallylinearembedding (class in sklearn.manifold)": [[697, "sklearn.manifold.LocallyLinearEmbedding", false]], "localoutlierfactor (class in sklearn.neighbors)": [[858, "sklearn.neighbors.LocalOutlierFactor", false]], "log_loss() (in module sklearn.metrics)": [[749, "sklearn.metrics.log_loss", false]], "log_marginal_likelihood() (sklearn.gaussian_process.gaussianprocessclassifier method)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.log_marginal_likelihood", false]], "log_marginal_likelihood() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.log_marginal_likelihood", false]], "logisticregression (class in sklearn.linear_model)": [[666, "sklearn.linear_model.LogisticRegression", false]], "logisticregressioncv (class in sklearn.linear_model)": [[667, "sklearn.linear_model.LogisticRegressionCV", false]], "mahalanobis() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.mahalanobis", false]], "mahalanobis() (sklearn.covariance.empiricalcovariance method)": [[478, "sklearn.covariance.EmpiricalCovariance.mahalanobis", false]], "mahalanobis() (sklearn.covariance.graphicallasso method)": [[479, "sklearn.covariance.GraphicalLasso.mahalanobis", false]], "mahalanobis() (sklearn.covariance.graphicallassocv method)": [[480, "sklearn.covariance.GraphicalLassoCV.mahalanobis", false]], "mahalanobis() (sklearn.covariance.ledoitwolf method)": [[481, "sklearn.covariance.LedoitWolf.mahalanobis", false]], "mahalanobis() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.mahalanobis", false]], "mahalanobis() (sklearn.covariance.oas method)": [[483, "sklearn.covariance.OAS.mahalanobis", false]], "mahalanobis() (sklearn.covariance.shrunkcovariance method)": [[484, "sklearn.covariance.ShrunkCovariance.mahalanobis", false]], "make_biclusters() (in module sklearn.datasets)": [[519, "sklearn.datasets.make_biclusters", false]], "make_blobs() (in module sklearn.datasets)": [[520, "sklearn.datasets.make_blobs", false]], "make_checkerboard() (in module sklearn.datasets)": [[521, "sklearn.datasets.make_checkerboard", false]], "make_circles() (in module sklearn.datasets)": [[522, "sklearn.datasets.make_circles", false]], "make_classification() (in module sklearn.datasets)": [[523, "sklearn.datasets.make_classification", false]], "make_column_selector (class in sklearn.compose)": [[474, "sklearn.compose.make_column_selector", false]], "make_column_transformer() (in module sklearn.compose)": [[475, "sklearn.compose.make_column_transformer", false]], "make_friedman1() (in module sklearn.datasets)": [[524, "sklearn.datasets.make_friedman1", false]], "make_friedman2() (in module sklearn.datasets)": [[525, "sklearn.datasets.make_friedman2", false]], "make_friedman3() (in module sklearn.datasets)": [[526, "sklearn.datasets.make_friedman3", false]], "make_gaussian_quantiles() (in module sklearn.datasets)": [[527, "sklearn.datasets.make_gaussian_quantiles", false]], "make_hastie_10_2() (in module sklearn.datasets)": [[528, "sklearn.datasets.make_hastie_10_2", false]], "make_low_rank_matrix() (in module sklearn.datasets)": [[529, "sklearn.datasets.make_low_rank_matrix", false]], "make_moons() (in module sklearn.datasets)": [[530, "sklearn.datasets.make_moons", false]], "make_multilabel_classification() (in module sklearn.datasets)": [[531, "sklearn.datasets.make_multilabel_classification", false]], "make_pipeline() (in module sklearn.pipeline)": [[873, "sklearn.pipeline.make_pipeline", false]], "make_regression() (in module sklearn.datasets)": [[532, "sklearn.datasets.make_regression", false]], "make_s_curve() (in module sklearn.datasets)": [[533, "sklearn.datasets.make_s_curve", false]], "make_scorer() (in module sklearn.metrics)": [[750, "sklearn.metrics.make_scorer", false]], "make_sparse_coded_signal() (in module sklearn.datasets)": [[534, "sklearn.datasets.make_sparse_coded_signal", false]], "make_sparse_spd_matrix() (in module sklearn.datasets)": [[535, "sklearn.datasets.make_sparse_spd_matrix", false]], "make_sparse_uncorrelated() (in module sklearn.datasets)": [[536, "sklearn.datasets.make_sparse_uncorrelated", false]], "make_spd_matrix() (in module sklearn.datasets)": [[537, "sklearn.datasets.make_spd_matrix", false]], "make_swiss_roll() (in module sklearn.datasets)": [[538, "sklearn.datasets.make_swiss_roll", false]], "make_union() (in module sklearn.pipeline)": [[874, "sklearn.pipeline.make_union", false]], "manhattan_distances() (in module sklearn.metrics.pairwise)": [[776, "sklearn.metrics.pairwise.manhattan_distances", false]], "matern (class in sklearn.gaussian_process.kernels)": [[627, "sklearn.gaussian_process.kernels.Matern", false]], "matthews_corrcoef() (in module sklearn.metrics)": [[751, "sklearn.metrics.matthews_corrcoef", false]], "max_error() (in module sklearn.metrics)": [[752, "sklearn.metrics.max_error", false]], "max_iter": [[400, "term-max_iter", true]], "maxabs_scale() (in module sklearn.preprocessing)": [[897, "sklearn.preprocessing.maxabs_scale", false]], "maxabsscaler (class in sklearn.preprocessing)": [[881, "sklearn.preprocessing.MaxAbsScaler", false]], "mds (class in sklearn.manifold)": [[698, "sklearn.manifold.MDS", false]], "mean_absolute_error() (in module sklearn.metrics)": [[753, "sklearn.metrics.mean_absolute_error", false]], "mean_absolute_percentage_error() (in module sklearn.metrics)": [[754, "sklearn.metrics.mean_absolute_percentage_error", false]], "mean_gamma_deviance() (in module sklearn.metrics)": [[755, "sklearn.metrics.mean_gamma_deviance", false]], "mean_pinball_loss() (in module sklearn.metrics)": [[756, "sklearn.metrics.mean_pinball_loss", false]], "mean_poisson_deviance() (in module sklearn.metrics)": [[757, "sklearn.metrics.mean_poisson_deviance", false]], "mean_shift() (in module sklearn.cluster)": [[469, "sklearn.cluster.mean_shift", false]], "mean_squared_error() (in module sklearn.metrics)": [[758, "sklearn.metrics.mean_squared_error", false]], "mean_squared_log_error() (in module sklearn.metrics)": [[759, "sklearn.metrics.mean_squared_log_error", false]], "mean_tweedie_deviance() (in module sklearn.metrics)": [[760, "sklearn.metrics.mean_tweedie_deviance", false]], "mean_variance_axis() (in module sklearn.utils.sparsefuncs)": [[981, "sklearn.utils.sparsefuncs.mean_variance_axis", false]], "meanshift (class in sklearn.cluster)": [[456, "sklearn.cluster.MeanShift", false]], "median_absolute_error() (in module sklearn.metrics)": [[761, "sklearn.metrics.median_absolute_error", false]], "memmapping": [[400, "term-memmapping", true]], "memory": [[400, "term-memory", true]], "memory map": [[400, "term-memory-map", true]], "memory mapping": [[400, "term-memory-mapping", true]], "meta-estimator": [[400, "term-meta-estimator", true]], "meta-estimators": [[400, "term-meta-estimators", true]], "metadata": [[400, "term-metadata", true]], "metadatarequest (class in sklearn.utils.metadata_routing)": [[956, "sklearn.utils.metadata_routing.MetadataRequest", false]], "metadatarouter (class in sklearn.utils.metadata_routing)": [[957, "sklearn.utils.metadata_routing.MetadataRouter", false]], "metaestimator": [[400, "term-metaestimator", true]], "metaestimatormixin (class in sklearn.base)": [[436, "sklearn.base.MetaEstimatorMixin", false]], "metaestimators": [[400, "term-metaestimators", true]], "methodmapping (class in sklearn.utils.metadata_routing)": [[958, "sklearn.utils.metadata_routing.MethodMapping", false]], "metric": [[400, "term-metric", true]], "min_pos() (in module sklearn.utils.arrayfuncs)": [[929, "sklearn.utils.arrayfuncs.min_pos", false]], "mincovdet (class in sklearn.covariance)": [[482, "sklearn.covariance.MinCovDet", false]], "minibatchdictionarylearning (class in sklearn.decomposition)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning", false]], "minibatchkmeans (class in sklearn.cluster)": [[457, "sklearn.cluster.MiniBatchKMeans", false]], "minibatchnmf (class in sklearn.decomposition)": [[546, "sklearn.decomposition.MiniBatchNMF", false]], "minibatchsparsepca (class in sklearn.decomposition)": [[547, "sklearn.decomposition.MiniBatchSparsePCA", false]], "minmax_scale() (in module sklearn.preprocessing)": [[898, "sklearn.preprocessing.minmax_scale", false]], "minmaxscaler (class in sklearn.preprocessing)": [[882, "sklearn.preprocessing.MinMaxScaler", false]], "missing values": [[400, "term-missing-values", true]], "missingindicator (class in sklearn.impute)": [[637, "sklearn.impute.MissingIndicator", false]], "mlpclassifier (class in sklearn.neural_network)": [[869, "sklearn.neural_network.MLPClassifier", false]], "mlpregressor (class in sklearn.neural_network)": [[870, "sklearn.neural_network.MLPRegressor", false]], "module": [[3, "module-sklearn", false], [4, "module-sklearn.base", false], [5, "module-sklearn.calibration", false], [6, "module-sklearn.cluster", false], [7, "module-sklearn.compose", false], [8, "module-sklearn.covariance", false], [9, "module-sklearn.cross_decomposition", false], [10, "module-sklearn.datasets", false], [11, "module-sklearn.decomposition", false], [12, "module-sklearn.discriminant_analysis", false], [13, "module-sklearn.dummy", false], [14, "module-sklearn.ensemble", false], [15, "module-sklearn.exceptions", false], [16, "module-sklearn.experimental", false], [17, "module-sklearn.feature_extraction", false], [17, "module-sklearn.feature_extraction.image", false], [17, "module-sklearn.feature_extraction.text", false], [18, "module-sklearn.feature_selection", false], [19, "module-sklearn.gaussian_process", false], [19, "module-sklearn.gaussian_process.kernels", false], [20, "module-sklearn.impute", false], [21, "module-sklearn.inspection", false], [22, "module-sklearn.isotonic", false], [23, "module-sklearn.kernel_approximation", false], [24, "module-sklearn.kernel_ridge", false], [25, "module-sklearn.linear_model", false], [26, "module-sklearn.manifold", false], [27, "module-sklearn.metrics", false], [27, "module-sklearn.metrics.cluster", false], [27, "module-sklearn.metrics.pairwise", false], [28, "module-sklearn.mixture", false], [29, "module-sklearn.model_selection", false], [30, "module-sklearn.multiclass", false], [31, "module-sklearn.multioutput", false], [32, "module-sklearn.naive_bayes", false], [33, "module-sklearn.neighbors", false], [34, "module-sklearn.neural_network", false], [35, "module-sklearn.pipeline", false], [36, "module-sklearn.preprocessing", false], [37, "module-sklearn.random_projection", false], [38, "module-sklearn.semi_supervised", false], [39, "module-sklearn.svm", false], [40, "module-sklearn.tree", false], [41, "module-sklearn.utils", false], [41, "module-sklearn.utils.arrayfuncs", false], [41, "module-sklearn.utils.class_weight", false], [41, "module-sklearn.utils.discovery", false], [41, "module-sklearn.utils.estimator_checks", false], [41, "module-sklearn.utils.extmath", false], [41, "module-sklearn.utils.graph", false], [41, "module-sklearn.utils.metadata_routing", false], [41, "module-sklearn.utils.metaestimators", false], [41, "module-sklearn.utils.multiclass", false], [41, "module-sklearn.utils.parallel", false], [41, "module-sklearn.utils.random", false], [41, "module-sklearn.utils.sparsefuncs", false], [41, "module-sklearn.utils.sparsefuncs_fast", false], [41, "module-sklearn.utils.validation", false], [587, "module-sklearn.experimental.enable_halving_search_cv", false], [588, "module-sklearn.experimental.enable_iterative_imputer", false]], "multi-class": [[400, "term-multi-class", true]], "multi-class multi-output": [[400, "term-multi-class-multi-output", true]], "multi-label": [[400, "term-multi-label", true]], "multi-output": [[400, "term-multi-output", true]], "multi-output continuous": [[400, "term-multi-output-continuous", true]], "multi-output multi-class": [[400, "term-multi-output-multi-class", true]], "multiclass": [[400, "term-multiclass", true]], "multiclass multioutput": [[400, "term-multiclass-multioutput", true]], "multilabel": [[400, "term-multilabel", true]], "multilabel indicator matrices": [[400, "term-multilabel-indicator-matrices", true]], "multilabel indicator matrix": [[400, "term-multilabel-indicator-matrix", true]], "multilabel_ (sklearn.multiclass.onevsrestclassifier property)": [[841, "sklearn.multiclass.OneVsRestClassifier.multilabel_", false]], "multilabel_confusion_matrix() (in module sklearn.metrics)": [[762, "sklearn.metrics.multilabel_confusion_matrix", false]], "multilabelbinarizer (class in sklearn.preprocessing)": [[883, "sklearn.preprocessing.MultiLabelBinarizer", false]], "multinomialnb (class in sklearn.naive_bayes)": [[851, "sklearn.naive_bayes.MultinomialNB", false]], "multioutput": [[400, "term-multioutput", true]], "multioutput continuous": [[400, "term-multioutput-continuous", true]], "multioutput multiclass": [[400, "term-multioutput-multiclass", true]], "multioutputclassifier (class in sklearn.multioutput)": [[844, "sklearn.multioutput.MultiOutputClassifier", false]], "multioutputregressor (class in sklearn.multioutput)": [[845, "sklearn.multioutput.MultiOutputRegressor", false]], "multitaskelasticnet (class in sklearn.linear_model)": [[668, "sklearn.linear_model.MultiTaskElasticNet", false]], "multitaskelasticnetcv (class in sklearn.linear_model)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV", false]], "multitasklasso (class in sklearn.linear_model)": [[670, "sklearn.linear_model.MultiTaskLasso", false]], "multitasklassocv (class in sklearn.linear_model)": [[671, "sklearn.linear_model.MultiTaskLassoCV", false]], "murmurhash3_32() (in module sklearn.utils)": [[965, "sklearn.utils.murmurhash3_32", false]], "mutual_info_classif() (in module sklearn.feature_selection)": [[615, "sklearn.feature_selection.mutual_info_classif", false]], "mutual_info_regression() (in module sklearn.feature_selection)": [[616, "sklearn.feature_selection.mutual_info_regression", false]], "mutual_info_score() (in module sklearn.metrics)": [[763, "sklearn.metrics.mutual_info_score", false]], "n_classes_ (sklearn.multiclass.onevsoneclassifier property)": [[840, "sklearn.multiclass.OneVsOneClassifier.n_classes_", false]], "n_classes_ (sklearn.multiclass.onevsrestclassifier property)": [[841, "sklearn.multiclass.OneVsRestClassifier.n_classes_", false]], "n_components": [[400, "term-n_components", true]], "n_components_ (sklearn.decomposition.sparsecoder property)": [[550, "sklearn.decomposition.SparseCoder.n_components_", false]], "n_dims (sklearn.gaussian_process.kernels.compoundkernel property)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.constantkernel property)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.dotproduct property)": [[622, "sklearn.gaussian_process.kernels.DotProduct.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.exponentiation property)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.expsinesquared property)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.kernel property)": [[626, "sklearn.gaussian_process.kernels.Kernel.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.matern property)": [[627, "sklearn.gaussian_process.kernels.Matern.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.pairwisekernel property)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.product property)": [[629, "sklearn.gaussian_process.kernels.Product.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.rationalquadratic property)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.rbf property)": [[630, "sklearn.gaussian_process.kernels.RBF.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.sum property)": [[632, "sklearn.gaussian_process.kernels.Sum.n_dims", false]], "n_dims (sklearn.gaussian_process.kernels.whitekernel property)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.n_dims", false]], "n_elements (sklearn.gaussian_process.kernels.hyperparameter attribute)": [[625, "sklearn.gaussian_process.kernels.Hyperparameter.n_elements", false]], "n_features": [[400, "term-n_features", true]], "n_features_in_ (sklearn.compose.transformedtargetregressor property)": [[473, "sklearn.compose.TransformedTargetRegressor.n_features_in_", false]], "n_features_in_ (sklearn.decomposition.sparsecoder property)": [[550, "sklearn.decomposition.SparseCoder.n_features_in_", false]], "n_features_in_ (sklearn.ensemble.stackingclassifier property)": [[575, "sklearn.ensemble.StackingClassifier.n_features_in_", false]], "n_features_in_ (sklearn.ensemble.stackingregressor property)": [[576, "sklearn.ensemble.StackingRegressor.n_features_in_", false]], "n_features_in_ (sklearn.ensemble.votingclassifier property)": [[577, "sklearn.ensemble.VotingClassifier.n_features_in_", false]], "n_features_in_ (sklearn.ensemble.votingregressor property)": [[578, "sklearn.ensemble.VotingRegressor.n_features_in_", false]], "n_features_in_ (sklearn.feature_selection.selectfrommodel property)": [[605, "sklearn.feature_selection.SelectFromModel.n_features_in_", false]], "n_features_in_ (sklearn.model_selection.gridsearchcv property)": [[808, "sklearn.model_selection.GridSearchCV.n_features_in_", false]], "n_features_in_ (sklearn.model_selection.halvinggridsearchcv property)": [[811, "sklearn.model_selection.HalvingGridSearchCV.n_features_in_", false]], "n_features_in_ (sklearn.model_selection.halvingrandomsearchcv property)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.n_features_in_", false]], "n_features_in_ (sklearn.model_selection.randomizedsearchcv property)": [[822, "sklearn.model_selection.RandomizedSearchCV.n_features_in_", false]], "n_features_in_ (sklearn.pipeline.featureunion property)": [[871, "sklearn.pipeline.FeatureUnion.n_features_in_", false]], "n_features_in_ (sklearn.pipeline.pipeline property)": [[872, "sklearn.pipeline.Pipeline.n_features_in_", false]], "n_iter_": [[400, "term-n_iter_", true]], "n_iter_ (sklearn.ensemble.histgradientboostingclassifier property)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.n_iter_", false]], "n_iter_ (sklearn.ensemble.histgradientboostingregressor property)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.n_iter_", false]], "n_iter_no_change": [[400, "term-n_iter_no_change", true]], "n_jobs": [[400, "term-n_jobs", true]], "n_outputs": [[400, "term-n_outputs", true]], "n_samples": [[400, "term-n_samples", true]], "n_support_ (sklearn.svm.nusvc property)": [[914, "sklearn.svm.NuSVC.n_support_", false]], "n_support_ (sklearn.svm.nusvr property)": [[915, "sklearn.svm.NuSVR.n_support_", false]], "n_support_ (sklearn.svm.oneclasssvm property)": [[916, "sklearn.svm.OneClassSVM.n_support_", false]], "n_support_ (sklearn.svm.svc property)": [[917, "sklearn.svm.SVC.n_support_", false]], "n_support_ (sklearn.svm.svr property)": [[918, "sklearn.svm.SVR.n_support_", false]], "n_targets": [[400, "term-n_targets", true]], "name (sklearn.gaussian_process.kernels.hyperparameter attribute)": [[625, "sklearn.gaussian_process.kernels.Hyperparameter.name", false]], "named_estimators (sklearn.ensemble.stackingclassifier property)": [[575, "sklearn.ensemble.StackingClassifier.named_estimators", false]], "named_estimators (sklearn.ensemble.stackingregressor property)": [[576, "sklearn.ensemble.StackingRegressor.named_estimators", false]], "named_estimators (sklearn.ensemble.votingclassifier property)": [[577, "sklearn.ensemble.VotingClassifier.named_estimators", false]], "named_estimators (sklearn.ensemble.votingregressor property)": [[578, "sklearn.ensemble.VotingRegressor.named_estimators", false]], "named_steps (sklearn.pipeline.pipeline property)": [[872, "sklearn.pipeline.Pipeline.named_steps", false]], "named_transformers_ (sklearn.compose.columntransformer property)": [[472, "sklearn.compose.ColumnTransformer.named_transformers_", false]], "nan_euclidean_distances() (in module sklearn.metrics.pairwise)": [[777, "sklearn.metrics.pairwise.nan_euclidean_distances", false]], "narrative docs": [[400, "term-narrative-docs", true]], "narrative documentation": [[400, "term-narrative-documentation", true]], "ndcg_score() (in module sklearn.metrics)": [[764, "sklearn.metrics.ndcg_score", false]], "nearestcentroid (class in sklearn.neighbors)": [[859, "sklearn.neighbors.NearestCentroid", false]], "nearestneighbors (class in sklearn.neighbors)": [[860, "sklearn.neighbors.NearestNeighbors", false]], "neighborhoodcomponentsanalysis (class in sklearn.neighbors)": [[861, "sklearn.neighbors.NeighborhoodComponentsAnalysis", false]], "nmf (class in sklearn.decomposition)": [[548, "sklearn.decomposition.NMF", false]], "non_negative_factorization() (in module sklearn.decomposition)": [[555, "sklearn.decomposition.non_negative_factorization", false]], "normalize() (in module sklearn.preprocessing)": [[899, "sklearn.preprocessing.normalize", false]], "normalized_mutual_info_score() (in module sklearn.metrics)": [[765, "sklearn.metrics.normalized_mutual_info_score", false]], "normalizer (class in sklearn.preprocessing)": [[884, "sklearn.preprocessing.Normalizer", false]], "notfittederror": [[585, "sklearn.exceptions.NotFittedError", false]], "np": [[400, "term-np", true]], "nusvc (class in sklearn.svm)": [[914, "sklearn.svm.NuSVC", false]], "nusvr (class in sklearn.svm)": [[915, "sklearn.svm.NuSVR", false]], "nystroem (class in sklearn.kernel_approximation)": [[647, "sklearn.kernel_approximation.Nystroem", false]], "oas (class in sklearn.covariance)": [[483, "sklearn.covariance.OAS", false]], "oas() (in module sklearn.covariance)": [[429, "sklearn.covariance.oas", false]], "oneclasssvm (class in sklearn.svm)": [[916, "sklearn.svm.OneClassSVM", false]], "onehotencoder (class in sklearn.preprocessing)": [[885, "sklearn.preprocessing.OneHotEncoder", false]], "onetoonefeaturemixin (class in sklearn.base)": [[437, "sklearn.base.OneToOneFeatureMixin", false]], "onevsoneclassifier (class in sklearn.multiclass)": [[840, "sklearn.multiclass.OneVsOneClassifier", false]], "onevsrestclassifier (class in sklearn.multiclass)": [[841, "sklearn.multiclass.OneVsRestClassifier", false]], "online learning": [[400, "term-online-learning", true]], "optics (class in sklearn.cluster)": [[458, "sklearn.cluster.OPTICS", false]], "ordinalencoder (class in sklearn.preprocessing)": [[886, "sklearn.preprocessing.OrdinalEncoder", false]], "orthogonal_mp() (in module sklearn.linear_model)": [[693, "sklearn.linear_model.orthogonal_mp", false]], "orthogonal_mp_gram() (in module sklearn.linear_model)": [[694, "sklearn.linear_model.orthogonal_mp_gram", false]], "orthogonalmatchingpursuit (class in sklearn.linear_model)": [[672, "sklearn.linear_model.OrthogonalMatchingPursuit", false]], "orthogonalmatchingpursuitcv (class in sklearn.linear_model)": [[673, "sklearn.linear_model.OrthogonalMatchingPursuitCV", false]], "out-of-core": [[400, "term-out-of-core", true]], "outlier detector": [[400, "term-outlier-detector", true]], "outlier detectors": [[400, "term-outlier-detectors", true]], "outliermixin (class in sklearn.base)": [[438, "sklearn.base.OutlierMixin", false]], "outputcodeclassifier (class in sklearn.multiclass)": [[842, "sklearn.multiclass.OutputCodeClassifier", false]], "outputs": [[400, "term-outputs", true]], "pair": [[400, "term-pair", true]], "pair_confusion_matrix() (in module sklearn.metrics.cluster)": [[723, "sklearn.metrics.cluster.pair_confusion_matrix", false]], "paired_cosine_distances() (in module sklearn.metrics.pairwise)": [[778, "sklearn.metrics.pairwise.paired_cosine_distances", false]], "paired_distances() (in module sklearn.metrics.pairwise)": [[779, "sklearn.metrics.pairwise.paired_distances", false]], "paired_euclidean_distances() (in module sklearn.metrics.pairwise)": [[780, "sklearn.metrics.pairwise.paired_euclidean_distances", false]], "paired_manhattan_distances() (in module sklearn.metrics.pairwise)": [[781, "sklearn.metrics.pairwise.paired_manhattan_distances", false]], "pairwise metric": [[400, "term-pairwise-metric", true]], "pairwise metrics": [[400, "term-pairwise-metrics", true]], "pairwise_distances() (in module sklearn.metrics)": [[786, "sklearn.metrics.pairwise_distances", false]], "pairwise_distances_argmin() (in module sklearn.metrics)": [[787, "sklearn.metrics.pairwise_distances_argmin", false]], "pairwise_distances_argmin_min() (in module sklearn.metrics)": [[788, "sklearn.metrics.pairwise_distances_argmin_min", false]], "pairwise_distances_chunked() (in module sklearn.metrics)": [[789, "sklearn.metrics.pairwise_distances_chunked", false]], "pairwise_kernels() (in module sklearn.metrics.pairwise)": [[782, "sklearn.metrics.pairwise.pairwise_kernels", false]], "pairwisekernel (class in sklearn.gaussian_process.kernels)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel", false]], "parallel (class in sklearn.utils.parallel)": [[966, "sklearn.utils.parallel.Parallel", false]], "parallel_backend (class in sklearn.utils)": [[968, "sklearn.utils.parallel_backend", false]], "param": [[400, "term-param", true]], "parameter": [[400, "term-parameter", true]], "parametergrid (class in sklearn.model_selection)": [[819, "sklearn.model_selection.ParameterGrid", false]], "parameters": [[400, "term-parameters", true]], "parametersampler (class in sklearn.model_selection)": [[820, "sklearn.model_selection.ParameterSampler", false]], "parametrize_with_checks() (in module sklearn.utils.estimator_checks)": [[944, "sklearn.utils.estimator_checks.parametrize_with_checks", false]], "params": [[400, "term-params", true]], "partial_dependence() (in module sklearn.inspection)": [[641, "sklearn.inspection.partial_dependence", false]], "partial_fit": [[400, "term-partial_fit", true]], "partial_fit() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.partial_fit", false]], "partial_fit() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.partial_fit", false]], "partial_fit() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.partial_fit", false]], "partial_fit() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.partial_fit", false]], "partial_fit() (sklearn.decomposition.minibatchdictionarylearning method)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning.partial_fit", false]], "partial_fit() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.partial_fit", false]], "partial_fit() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.partial_fit", false]], "partial_fit() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.partial_fit", false]], "partial_fit() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.partial_fit", false]], "partial_fit() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.partial_fit", false]], "partial_fit() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.partial_fit", false]], "partial_fit() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.partial_fit", false]], "partial_fit() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.partial_fit", false]], "partial_fit() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.partial_fit", false]], "partial_fit() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.partial_fit", false]], "partial_fit() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.partial_fit", false]], "partial_fit() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.partial_fit", false]], "partial_fit() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.partial_fit", false]], "partial_fit() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.partial_fit", false]], "partial_fit() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.partial_fit", false]], "partial_fit() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.partial_fit", false]], "partial_fit() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.partial_fit", false]], "partial_fit() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.partial_fit", false]], "partial_fit() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.partial_fit", false]], "partial_fit() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.partial_fit", false]], "partial_fit() (sklearn.neural_network.mlpregressor method)": [[870, "sklearn.neural_network.MLPRegressor.partial_fit", false]], "partial_fit() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.partial_fit", false]], "partial_fit() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.partial_fit", false]], "partial_fit() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.partial_fit", false]], "partialdependencedisplay (class in sklearn.inspection)": [[640, "sklearn.inspection.PartialDependenceDisplay", false]], "passiveaggressiveclassifier (class in sklearn.linear_model)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier", false]], "passiveaggressiveregressor (class in sklearn.linear_model)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor", false]], "patchextractor (class in sklearn.feature_extraction.image)": [[591, "sklearn.feature_extraction.image.PatchExtractor", false]], "path() (sklearn.linear_model.elasticnet static method)": [[654, "sklearn.linear_model.ElasticNet.path", false]], "path() (sklearn.linear_model.elasticnetcv static method)": [[655, "sklearn.linear_model.ElasticNetCV.path", false]], "path() (sklearn.linear_model.lasso static method)": [[660, "sklearn.linear_model.Lasso.path", false]], "path() (sklearn.linear_model.lassocv static method)": [[661, "sklearn.linear_model.LassoCV.path", false]], "path() (sklearn.linear_model.multitaskelasticnet static method)": [[668, "sklearn.linear_model.MultiTaskElasticNet.path", false]], "path() (sklearn.linear_model.multitaskelasticnetcv static method)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV.path", false]], "path() (sklearn.linear_model.multitasklasso static method)": [[670, "sklearn.linear_model.MultiTaskLasso.path", false]], "path() (sklearn.linear_model.multitasklassocv static method)": [[671, "sklearn.linear_model.MultiTaskLassoCV.path", false]], "pca (class in sklearn.decomposition)": [[549, "sklearn.decomposition.PCA", false]], "pd": [[400, "term-pd", true]], "perceptron (class in sklearn.linear_model)": [[676, "sklearn.linear_model.Perceptron", false]], "permutation_importance() (in module sklearn.inspection)": [[642, "sklearn.inspection.permutation_importance", false]], "permutation_test_score() (in module sklearn.model_selection)": [[837, "sklearn.model_selection.permutation_test_score", false]], "perplexity() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.perplexity", false]], "pipeline (class in sklearn.pipeline)": [[872, "sklearn.pipeline.Pipeline", false]], "plot() (sklearn.calibration.calibrationdisplay method)": [[446, "sklearn.calibration.CalibrationDisplay.plot", false]], "plot() (sklearn.inspection.decisionboundarydisplay method)": [[639, "sklearn.inspection.DecisionBoundaryDisplay.plot", false]], "plot() (sklearn.inspection.partialdependencedisplay method)": [[640, "sklearn.inspection.PartialDependenceDisplay.plot", false]], "plot() (sklearn.metrics.confusionmatrixdisplay method)": [[705, "sklearn.metrics.ConfusionMatrixDisplay.plot", false]], "plot() (sklearn.metrics.detcurvedisplay method)": [[706, "sklearn.metrics.DetCurveDisplay.plot", false]], "plot() (sklearn.metrics.precisionrecalldisplay method)": [[708, "sklearn.metrics.PrecisionRecallDisplay.plot", false]], "plot() (sklearn.metrics.predictionerrordisplay method)": [[709, "sklearn.metrics.PredictionErrorDisplay.plot", false]], "plot() (sklearn.metrics.roccurvedisplay method)": [[710, "sklearn.metrics.RocCurveDisplay.plot", false]], "plot() (sklearn.model_selection.learningcurvedisplay method)": [[814, "sklearn.model_selection.LearningCurveDisplay.plot", false]], "plot() (sklearn.model_selection.validationcurvedisplay method)": [[831, "sklearn.model_selection.ValidationCurveDisplay.plot", false]], "plot_tree() (in module sklearn.tree)": [[926, "sklearn.tree.plot_tree", false]], "plscanonical (class in sklearn.cross_decomposition)": [[491, "sklearn.cross_decomposition.PLSCanonical", false]], "plsregression (class in sklearn.cross_decomposition)": [[492, "sklearn.cross_decomposition.PLSRegression", false]], "plssvd (class in sklearn.cross_decomposition)": [[493, "sklearn.cross_decomposition.PLSSVD", false]], "poissonregressor (class in sklearn.linear_model)": [[677, "sklearn.linear_model.PoissonRegressor", false]], "polynomial_kernel() (in module sklearn.metrics.pairwise)": [[783, "sklearn.metrics.pairwise.polynomial_kernel", false]], "polynomialcountsketch (class in sklearn.kernel_approximation)": [[648, "sklearn.kernel_approximation.PolynomialCountSketch", false]], "polynomialfeatures (class in sklearn.preprocessing)": [[887, "sklearn.preprocessing.PolynomialFeatures", false]], "pop() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.pop", false]], "popitem() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.popitem", false]], "pos_label": [[400, "term-pos_label", true]], "power_transform() (in module sklearn.preprocessing)": [[900, "sklearn.preprocessing.power_transform", false]], "powers_ (sklearn.preprocessing.polynomialfeatures property)": [[887, "sklearn.preprocessing.PolynomialFeatures.powers_", false]], "powertransformer (class in sklearn.preprocessing)": [[888, "sklearn.preprocessing.PowerTransformer", false]], "precision_recall_curve() (in module sklearn.metrics)": [[790, "sklearn.metrics.precision_recall_curve", false]], "precision_recall_fscore_support() (in module sklearn.metrics)": [[791, "sklearn.metrics.precision_recall_fscore_support", false]], "precision_score() (in module sklearn.metrics)": [[792, "sklearn.metrics.precision_score", false]], "precisionrecalldisplay (class in sklearn.metrics)": [[708, "sklearn.metrics.PrecisionRecallDisplay", false]], "precomputed": [[400, "term-precomputed", true]], "predefinedsplit (class in sklearn.model_selection)": [[821, "sklearn.model_selection.PredefinedSplit", false]], "predict": [[400, "term-predict", true]], "predict() (sklearn.calibration.calibratedclassifiercv method)": [[445, "sklearn.calibration.CalibratedClassifierCV.predict", false]], "predict() (sklearn.cluster.affinitypropagation method)": [[448, "sklearn.cluster.AffinityPropagation.predict", false]], "predict() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.predict", false]], "predict() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.predict", false]], "predict() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.predict", false]], "predict() (sklearn.cluster.meanshift method)": [[456, "sklearn.cluster.MeanShift.predict", false]], "predict() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.predict", false]], "predict() (sklearn.compose.transformedtargetregressor method)": [[473, "sklearn.compose.TransformedTargetRegressor.predict", false]], "predict() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.predict", false]], "predict() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.predict", false]], "predict() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.predict", false]], "predict() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.predict", false]], "predict() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict", false]], "predict() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict", false]], "predict() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.predict", false]], "predict() (sklearn.dummy.dummyregressor method)": [[560, "sklearn.dummy.DummyRegressor.predict", false]], "predict() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.predict", false]], "predict() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.predict", false]], "predict() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.predict", false]], "predict() (sklearn.ensemble.baggingregressor method)": [[564, "sklearn.ensemble.BaggingRegressor.predict", false]], "predict() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.predict", false]], "predict() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.predict", false]], "predict() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.predict", false]], "predict() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.predict", false]], "predict() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.predict", false]], "predict() (sklearn.ensemble.histgradientboostingregressor method)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.predict", false]], "predict() (sklearn.ensemble.isolationforest method)": [[571, "sklearn.ensemble.IsolationForest.predict", false]], "predict() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.predict", false]], "predict() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.predict", false]], "predict() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.predict", false]], "predict() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.predict", false]], "predict() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.predict", false]], "predict() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.predict", false]], "predict() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.predict", false]], "predict() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.predict", false]], "predict() (sklearn.gaussian_process.gaussianprocessclassifier method)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.predict", false]], "predict() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.predict", false]], "predict() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.predict", false]], "predict() (sklearn.kernel_ridge.kernelridge method)": [[651, "sklearn.kernel_ridge.KernelRidge.predict", false]], "predict() (sklearn.linear_model.ardregression method)": [[652, "sklearn.linear_model.ARDRegression.predict", false]], "predict() (sklearn.linear_model.bayesianridge method)": [[653, "sklearn.linear_model.BayesianRidge.predict", false]], "predict() (sklearn.linear_model.elasticnet method)": [[654, "sklearn.linear_model.ElasticNet.predict", false]], "predict() (sklearn.linear_model.elasticnetcv method)": [[655, "sklearn.linear_model.ElasticNetCV.predict", false]], "predict() (sklearn.linear_model.gammaregressor method)": [[656, "sklearn.linear_model.GammaRegressor.predict", false]], "predict() (sklearn.linear_model.huberregressor method)": [[657, "sklearn.linear_model.HuberRegressor.predict", false]], "predict() (sklearn.linear_model.lars method)": [[658, "sklearn.linear_model.Lars.predict", false]], "predict() (sklearn.linear_model.larscv method)": [[659, "sklearn.linear_model.LarsCV.predict", false]], "predict() (sklearn.linear_model.lasso method)": [[660, "sklearn.linear_model.Lasso.predict", false]], "predict() (sklearn.linear_model.lassocv method)": [[661, "sklearn.linear_model.LassoCV.predict", false]], "predict() (sklearn.linear_model.lassolars method)": [[662, "sklearn.linear_model.LassoLars.predict", false]], "predict() (sklearn.linear_model.lassolarscv method)": [[663, "sklearn.linear_model.LassoLarsCV.predict", false]], "predict() (sklearn.linear_model.lassolarsic method)": [[664, "sklearn.linear_model.LassoLarsIC.predict", false]], "predict() (sklearn.linear_model.linearregression method)": [[665, "sklearn.linear_model.LinearRegression.predict", false]], "predict() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.predict", false]], "predict() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.predict", false]], "predict() (sklearn.linear_model.multitaskelasticnet method)": [[668, "sklearn.linear_model.MultiTaskElasticNet.predict", false]], "predict() (sklearn.linear_model.multitaskelasticnetcv method)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV.predict", false]], "predict() (sklearn.linear_model.multitasklasso method)": [[670, "sklearn.linear_model.MultiTaskLasso.predict", false]], "predict() (sklearn.linear_model.multitasklassocv method)": [[671, "sklearn.linear_model.MultiTaskLassoCV.predict", false]], "predict() (sklearn.linear_model.orthogonalmatchingpursuit method)": [[672, "sklearn.linear_model.OrthogonalMatchingPursuit.predict", false]], "predict() (sklearn.linear_model.orthogonalmatchingpursuitcv method)": [[673, "sklearn.linear_model.OrthogonalMatchingPursuitCV.predict", false]], "predict() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.predict", false]], "predict() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.predict", false]], "predict() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.predict", false]], "predict() (sklearn.linear_model.poissonregressor method)": [[677, "sklearn.linear_model.PoissonRegressor.predict", false]], "predict() (sklearn.linear_model.quantileregressor method)": [[678, "sklearn.linear_model.QuantileRegressor.predict", false]], "predict() (sklearn.linear_model.ransacregressor method)": [[679, "sklearn.linear_model.RANSACRegressor.predict", false]], "predict() (sklearn.linear_model.ridge method)": [[680, "sklearn.linear_model.Ridge.predict", false]], "predict() (sklearn.linear_model.ridgeclassifier method)": [[682, "sklearn.linear_model.RidgeClassifier.predict", false]], "predict() (sklearn.linear_model.ridgeclassifiercv method)": [[683, "sklearn.linear_model.RidgeClassifierCV.predict", false]], "predict() (sklearn.linear_model.ridgecv method)": [[681, "sklearn.linear_model.RidgeCV.predict", false]], "predict() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.predict", false]], "predict() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.predict", false]], "predict() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.predict", false]], "predict() (sklearn.linear_model.theilsenregressor method)": [[687, "sklearn.linear_model.TheilSenRegressor.predict", false]], "predict() (sklearn.linear_model.tweedieregressor method)": [[688, "sklearn.linear_model.TweedieRegressor.predict", false]], "predict() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.predict", false]], "predict() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.predict", false]], "predict() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.predict", false]], "predict() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.predict", false]], "predict() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.predict", false]], "predict() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.predict", false]], "predict() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.predict", false]], "predict() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.predict", false]], "predict() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.predict", false]], "predict() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.predict", false]], "predict() (sklearn.multiclass.outputcodeclassifier method)": [[842, "sklearn.multiclass.OutputCodeClassifier.predict", false]], "predict() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.predict", false]], "predict() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.predict", false]], "predict() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.predict", false]], "predict() (sklearn.multioutput.regressorchain method)": [[846, "sklearn.multioutput.RegressorChain.predict", false]], "predict() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.predict", false]], "predict() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.predict", false]], "predict() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.predict", false]], "predict() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.predict", false]], "predict() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.predict", false]], "predict() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.predict", false]], "predict() (sklearn.neighbors.kneighborsregressor method)": [[855, "sklearn.neighbors.KNeighborsRegressor.predict", false]], "predict() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.predict", false]], "predict() (sklearn.neighbors.nearestcentroid method)": [[859, "sklearn.neighbors.NearestCentroid.predict", false]], "predict() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.predict", false]], "predict() (sklearn.neighbors.radiusneighborsregressor method)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor.predict", false]], "predict() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.predict", false]], "predict() (sklearn.neural_network.mlpregressor method)": [[870, "sklearn.neural_network.MLPRegressor.predict", false]], "predict() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.predict", false]], "predict() (sklearn.semi_supervised.labelpropagation method)": [[907, "sklearn.semi_supervised.LabelPropagation.predict", false]], "predict() (sklearn.semi_supervised.labelspreading method)": [[908, "sklearn.semi_supervised.LabelSpreading.predict", false]], "predict() (sklearn.semi_supervised.selftrainingclassifier method)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier.predict", false]], "predict() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.predict", false]], "predict() (sklearn.svm.linearsvr method)": [[913, "sklearn.svm.LinearSVR.predict", false]], "predict() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.predict", false]], "predict() (sklearn.svm.nusvr method)": [[915, "sklearn.svm.NuSVR.predict", false]], "predict() (sklearn.svm.oneclasssvm method)": [[916, "sklearn.svm.OneClassSVM.predict", false]], "predict() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.predict", false]], "predict() (sklearn.svm.svr method)": [[918, "sklearn.svm.SVR.predict", false]], "predict() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.predict", false]], "predict() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.predict", false]], "predict() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.predict", false]], "predict() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.predict", false]], "predict_joint_log_proba() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.predict_joint_log_proba", false]], "predict_joint_log_proba() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.predict_joint_log_proba", false]], "predict_joint_log_proba() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.predict_joint_log_proba", false]], "predict_joint_log_proba() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.predict_joint_log_proba", false]], "predict_joint_log_proba() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.predict_joint_log_proba", false]], "predict_log_proba": [[400, "term-predict_log_proba", true]], "predict_log_proba() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba", false]], "predict_log_proba() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict_log_proba", false]], "predict_log_proba() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.predict_log_proba", false]], "predict_log_proba() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.predict_log_proba", false]], "predict_log_proba() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.predict_log_proba", false]], "predict_log_proba() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.predict_log_proba", false]], "predict_log_proba() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.predict_log_proba", false]], "predict_log_proba() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.predict_log_proba", false]], "predict_log_proba() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.predict_log_proba", false]], "predict_log_proba() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.predict_log_proba", false]], "predict_log_proba() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.predict_log_proba", false]], "predict_log_proba() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.predict_log_proba", false]], "predict_log_proba() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.predict_log_proba", false]], "predict_log_proba() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.predict_log_proba", false]], "predict_log_proba() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.predict_log_proba", false]], "predict_log_proba() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.predict_log_proba", false]], "predict_log_proba() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.predict_log_proba", false]], "predict_log_proba() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.predict_log_proba", false]], "predict_log_proba() (sklearn.semi_supervised.selftrainingclassifier method)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.predict_log_proba", false]], "predict_log_proba() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.predict_log_proba", false]], "predict_log_proba() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.predict_log_proba", false]], "predict_log_proba() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.predict_log_proba", false]], "predict_proba": [[400, "term-predict_proba", true]], "predict_proba() (sklearn.calibration.calibratedclassifiercv method)": [[445, "sklearn.calibration.CalibratedClassifierCV.predict_proba", false]], "predict_proba() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba", false]], "predict_proba() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict_proba", false]], "predict_proba() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.predict_proba", false]], "predict_proba() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.predict_proba", false]], "predict_proba() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.predict_proba", false]], "predict_proba() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.predict_proba", false]], "predict_proba() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.predict_proba", false]], "predict_proba() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.predict_proba", false]], "predict_proba() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.predict_proba", false]], "predict_proba() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.predict_proba", false]], "predict_proba() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.predict_proba", false]], "predict_proba() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.predict_proba", false]], "predict_proba() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.predict_proba", false]], "predict_proba() (sklearn.gaussian_process.gaussianprocessclassifier method)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.predict_proba", false]], "predict_proba() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.predict_proba", false]], "predict_proba() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.predict_proba", false]], "predict_proba() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.predict_proba", false]], "predict_proba() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.predict_proba", false]], "predict_proba() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.predict_proba", false]], "predict_proba() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.predict_proba", false]], "predict_proba() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.predict_proba", false]], "predict_proba() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.predict_proba", false]], "predict_proba() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.predict_proba", false]], "predict_proba() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.predict_proba", false]], "predict_proba() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.predict_proba", false]], "predict_proba() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.predict_proba", false]], "predict_proba() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.predict_proba", false]], "predict_proba() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.predict_proba", false]], "predict_proba() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.predict_proba", false]], "predict_proba() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.predict_proba", false]], "predict_proba() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.predict_proba", false]], "predict_proba() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.predict_proba", false]], "predict_proba() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.predict_proba", false]], "predict_proba() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.predict_proba", false]], "predict_proba() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.predict_proba", false]], "predict_proba() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.predict_proba", false]], "predict_proba() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.predict_proba", false]], "predict_proba() (sklearn.semi_supervised.labelpropagation method)": [[907, "sklearn.semi_supervised.LabelPropagation.predict_proba", false]], "predict_proba() (sklearn.semi_supervised.labelspreading method)": [[908, "sklearn.semi_supervised.LabelSpreading.predict_proba", false]], "predict_proba() (sklearn.semi_supervised.selftrainingclassifier method)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier.predict_proba", false]], "predict_proba() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.predict_proba", false]], "predict_proba() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.predict_proba", false]], "predict_proba() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.predict_proba", false]], "predict_proba() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.predict_proba", false]], "predictionerrordisplay (class in sklearn.metrics)": [[709, "sklearn.metrics.PredictionErrorDisplay", false]], "predictor": [[400, "term-predictor", true]], "predictors": [[400, "term-predictors", true]], "print_progress() (sklearn.utils.parallel.parallel method)": [[966, "sklearn.utils.parallel.Parallel.print_progress", false]], "proba_ (sklearn.svm.nusvc property)": [[914, "sklearn.svm.NuSVC.probA_", false]], "proba_ (sklearn.svm.svc property)": [[917, "sklearn.svm.SVC.probA_", false]], "probb_ (sklearn.svm.nusvc property)": [[914, "sklearn.svm.NuSVC.probB_", false]], "probb_ (sklearn.svm.svc property)": [[917, "sklearn.svm.SVC.probB_", false]], "process_routing() (in module sklearn.utils.metadata_routing)": [[960, "sklearn.utils.metadata_routing.process_routing", false]], "product (class in sklearn.gaussian_process.kernels)": [[629, "sklearn.gaussian_process.kernels.Product", false]], "quadraticdiscriminantanalysis (class in sklearn.discriminant_analysis)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis", false]], "quantile_transform() (in module sklearn.preprocessing)": [[901, "sklearn.preprocessing.quantile_transform", false]], "quantileregressor (class in sklearn.linear_model)": [[678, "sklearn.linear_model.QuantileRegressor", false]], "quantiletransformer (class in sklearn.preprocessing)": [[889, "sklearn.preprocessing.QuantileTransformer", false]], "query() (sklearn.neighbors.balltree method)": [[852, "sklearn.neighbors.BallTree.query", false]], "query() (sklearn.neighbors.kdtree method)": [[853, "sklearn.neighbors.KDTree.query", false]], "query_radius() (sklearn.neighbors.balltree method)": [[852, "sklearn.neighbors.BallTree.query_radius", false]], "query_radius() (sklearn.neighbors.kdtree method)": [[853, "sklearn.neighbors.KDTree.query_radius", false]], "r2_score() (in module sklearn.metrics)": [[793, "sklearn.metrics.r2_score", false]], "r_regression() (in module sklearn.feature_selection)": [[617, "sklearn.feature_selection.r_regression", false]], "radius_neighbors() (sklearn.neighbors.nearestneighbors method)": [[860, "sklearn.neighbors.NearestNeighbors.radius_neighbors", false]], "radius_neighbors() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.radius_neighbors", false]], "radius_neighbors() (sklearn.neighbors.radiusneighborsregressor method)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor.radius_neighbors", false]], "radius_neighbors() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.radius_neighbors", false]], "radius_neighbors_graph() (in module sklearn.neighbors)": [[866, "sklearn.neighbors.radius_neighbors_graph", false]], "radius_neighbors_graph() (sklearn.neighbors.nearestneighbors method)": [[860, "sklearn.neighbors.NearestNeighbors.radius_neighbors_graph", false]], "radius_neighbors_graph() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.radius_neighbors_graph", false]], "radius_neighbors_graph() (sklearn.neighbors.radiusneighborsregressor method)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor.radius_neighbors_graph", false]], "radius_neighbors_graph() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.radius_neighbors_graph", false]], "radiusneighborsclassifier (class in sklearn.neighbors)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier", false]], "radiusneighborsregressor (class in sklearn.neighbors)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor", false]], "radiusneighborstransformer (class in sklearn.neighbors)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer", false]], "rand_score() (in module sklearn.metrics)": [[794, "sklearn.metrics.rand_score", false]], "random_state": [[400, "term-random_state", true]], "randomforestclassifier (class in sklearn.ensemble)": [[572, "sklearn.ensemble.RandomForestClassifier", false]], "randomforestregressor (class in sklearn.ensemble)": [[573, "sklearn.ensemble.RandomForestRegressor", false]], "randomized_range_finder() (in module sklearn.utils.extmath)": [[948, "sklearn.utils.extmath.randomized_range_finder", false]], "randomized_svd() (in module sklearn.utils.extmath)": [[949, "sklearn.utils.extmath.randomized_svd", false]], "randomizedsearchcv (class in sklearn.model_selection)": [[822, "sklearn.model_selection.RandomizedSearchCV", false]], "randomtreesembedding (class in sklearn.ensemble)": [[574, "sklearn.ensemble.RandomTreesEmbedding", false]], "ransacregressor (class in sklearn.linear_model)": [[679, "sklearn.linear_model.RANSACRegressor", false]], "rationalquadratic (class in sklearn.gaussian_process.kernels)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic", false]], "rbf (class in sklearn.gaussian_process.kernels)": [[630, "sklearn.gaussian_process.kernels.RBF", false]], "rbf_kernel() (in module sklearn.metrics.pairwise)": [[784, "sklearn.metrics.pairwise.rbf_kernel", false]], "rbfsampler (class in sklearn.kernel_approximation)": [[649, "sklearn.kernel_approximation.RBFSampler", false]], "recall_score() (in module sklearn.metrics)": [[795, "sklearn.metrics.recall_score", false]], "reconstruct_from_patches_2d() (in module sklearn.feature_extraction.image)": [[595, "sklearn.feature_extraction.image.reconstruct_from_patches_2d", false]], "reconstruction_error() (sklearn.manifold.isomap method)": [[696, "sklearn.manifold.Isomap.reconstruction_error", false]], "rectangular": [[400, "term-rectangular", true]], "register_parallel_backend() (in module sklearn.utils)": [[970, "sklearn.utils.register_parallel_backend", false]], "regressor": [[400, "term-regressor", true]], "regressorchain (class in sklearn.multioutput)": [[846, "sklearn.multioutput.RegressorChain", false]], "regressormixin (class in sklearn.base)": [[439, "sklearn.base.RegressorMixin", false]], "regressors": [[400, "term-regressors", true]], "repeatedkfold (class in sklearn.model_selection)": [[823, "sklearn.model_selection.RepeatedKFold", false]], "repeatedstratifiedkfold (class in sklearn.model_selection)": [[824, "sklearn.model_selection.RepeatedStratifiedKFold", false]], "requires_vector_input (sklearn.gaussian_process.kernels.compoundkernel property)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.constantkernel property)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.dotproduct property)": [[622, "sklearn.gaussian_process.kernels.DotProduct.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.exponentiation property)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.expsinesquared property)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.kernel property)": [[626, "sklearn.gaussian_process.kernels.Kernel.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.matern property)": [[627, "sklearn.gaussian_process.kernels.Matern.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.pairwisekernel property)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.product property)": [[629, "sklearn.gaussian_process.kernels.Product.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.rationalquadratic property)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.rbf property)": [[630, "sklearn.gaussian_process.kernels.RBF.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.sum property)": [[632, "sklearn.gaussian_process.kernels.Sum.requires_vector_input", false]], "requires_vector_input (sklearn.gaussian_process.kernels.whitekernel property)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.requires_vector_input", false]], "resample() (in module sklearn.utils)": [[971, "sklearn.utils.resample", false]], "reset_n_calls() (sklearn.neighbors.balltree method)": [[852, "sklearn.neighbors.BallTree.reset_n_calls", false]], "reset_n_calls() (sklearn.neighbors.kdtree method)": [[853, "sklearn.neighbors.KDTree.reset_n_calls", false]], "restrict() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.restrict", false]], "reweight_covariance() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.reweight_covariance", false]], "reweight_covariance() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.reweight_covariance", false]], "rfe (class in sklearn.feature_selection)": [[601, "sklearn.feature_selection.RFE", false]], "rfecv (class in sklearn.feature_selection)": [[602, "sklearn.feature_selection.RFECV", false]], "ridge (class in sklearn.linear_model)": [[680, "sklearn.linear_model.Ridge", false]], "ridge_regression() (in module sklearn.linear_model)": [[695, "sklearn.linear_model.ridge_regression", false]], "ridgeclassifier (class in sklearn.linear_model)": [[682, "sklearn.linear_model.RidgeClassifier", false]], "ridgeclassifiercv (class in sklearn.linear_model)": [[683, "sklearn.linear_model.RidgeClassifierCV", false]], "ridgecv (class in sklearn.linear_model)": [[681, "sklearn.linear_model.RidgeCV", false]], "robust_scale() (in module sklearn.preprocessing)": [[902, "sklearn.preprocessing.robust_scale", false]], "robustscaler (class in sklearn.preprocessing)": [[890, "sklearn.preprocessing.RobustScaler", false]], "roc_auc_score() (in module sklearn.metrics)": [[796, "sklearn.metrics.roc_auc_score", false]], "roc_curve() (in module sklearn.metrics)": [[797, "sklearn.metrics.roc_curve", false]], "roccurvedisplay (class in sklearn.metrics)": [[710, "sklearn.metrics.RocCurveDisplay", false]], "root_mean_squared_error() (in module sklearn.metrics)": [[798, "sklearn.metrics.root_mean_squared_error", false]], "root_mean_squared_log_error() (in module sklearn.metrics)": [[799, "sklearn.metrics.root_mean_squared_log_error", false]], "route_params() (sklearn.utils.metadata_routing.metadatarouter method)": [[957, "sklearn.utils.metadata_routing.MetadataRouter.route_params", false]], "router": [[400, "term-router", true]], "safe_mask() (in module sklearn.utils)": [[972, "sklearn.utils.safe_mask", false]], "safe_sparse_dot() (in module sklearn.utils.extmath)": [[950, "sklearn.utils.extmath.safe_sparse_dot", false]], "safe_sqr() (in module sklearn.utils)": [[973, "sklearn.utils.safe_sqr", false]], "sample": [[400, "term-sample", true]], "sample properties": [[400, "term-sample-properties", true]], "sample property": [[400, "term-sample-property", true]], "sample() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.sample", false]], "sample() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.sample", false]], "sample() (sklearn.neighbors.kerneldensity method)": [[857, "sklearn.neighbors.KernelDensity.sample", false]], "sample_weight": [[400, "term-sample_weight", true]], "sample_without_replacement() (in module sklearn.utils.random)": [[969, "sklearn.utils.random.sample_without_replacement", false]], "sample_y() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.sample_y", false]], "samples": [[400, "term-samples", true]], "scale() (in module sklearn.preprocessing)": [[903, "sklearn.preprocessing.scale", false]], "scikit-learn enhancement proposals": [[400, "term-scikit-learn-enhancement-proposals", true]], "scikit-learn-contrib": [[400, "term-scikit-learn-contrib", true]], "score": [[400, "term-score", true]], "score() (sklearn.base.classifiermixin method)": [[433, "sklearn.base.ClassifierMixin.score", false]], "score() (sklearn.base.densitymixin method)": [[435, "sklearn.base.DensityMixin.score", false]], "score() (sklearn.base.regressormixin method)": [[439, "sklearn.base.RegressorMixin.score", false]], "score() (sklearn.calibration.calibratedclassifiercv method)": [[445, "sklearn.calibration.CalibratedClassifierCV.score", false]], "score() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.score", false]], "score() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.score", false]], "score() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.score", false]], "score() (sklearn.compose.transformedtargetregressor method)": [[473, "sklearn.compose.TransformedTargetRegressor.score", false]], "score() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.score", false]], "score() (sklearn.covariance.empiricalcovariance method)": [[478, "sklearn.covariance.EmpiricalCovariance.score", false]], "score() (sklearn.covariance.graphicallasso method)": [[479, "sklearn.covariance.GraphicalLasso.score", false]], "score() (sklearn.covariance.graphicallassocv method)": [[480, "sklearn.covariance.GraphicalLassoCV.score", false]], "score() (sklearn.covariance.ledoitwolf method)": [[481, "sklearn.covariance.LedoitWolf.score", false]], "score() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.score", false]], "score() (sklearn.covariance.oas method)": [[483, "sklearn.covariance.OAS.score", false]], "score() (sklearn.covariance.shrunkcovariance method)": [[484, "sklearn.covariance.ShrunkCovariance.score", false]], "score() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.score", false]], "score() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.score", false]], "score() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.score", false]], "score() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.score", false]], "score() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.score", false]], "score() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.score", false]], "score() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score", false]], "score() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.score", false]], "score() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.score", false]], "score() (sklearn.dummy.dummyregressor method)": [[560, "sklearn.dummy.DummyRegressor.score", false]], "score() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.score", false]], "score() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.score", false]], "score() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.score", false]], "score() (sklearn.ensemble.baggingregressor method)": [[564, "sklearn.ensemble.BaggingRegressor.score", false]], "score() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.score", false]], "score() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.score", false]], "score() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.score", false]], "score() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.score", false]], "score() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.score", false]], "score() (sklearn.ensemble.histgradientboostingregressor method)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.score", false]], "score() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.score", false]], "score() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.score", false]], "score() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.score", false]], "score() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.score", false]], "score() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.score", false]], "score() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.score", false]], "score() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.score", false]], "score() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.score", false]], "score() (sklearn.gaussian_process.gaussianprocessclassifier method)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.score", false]], "score() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.score", false]], "score() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.score", false]], "score() (sklearn.kernel_ridge.kernelridge method)": [[651, "sklearn.kernel_ridge.KernelRidge.score", false]], "score() (sklearn.linear_model.ardregression method)": [[652, "sklearn.linear_model.ARDRegression.score", false]], "score() (sklearn.linear_model.bayesianridge method)": [[653, "sklearn.linear_model.BayesianRidge.score", false]], "score() (sklearn.linear_model.elasticnet method)": [[654, "sklearn.linear_model.ElasticNet.score", false]], "score() (sklearn.linear_model.elasticnetcv method)": [[655, "sklearn.linear_model.ElasticNetCV.score", false]], "score() (sklearn.linear_model.gammaregressor method)": [[656, "sklearn.linear_model.GammaRegressor.score", false]], "score() (sklearn.linear_model.huberregressor method)": [[657, "sklearn.linear_model.HuberRegressor.score", false]], "score() (sklearn.linear_model.lars method)": [[658, "sklearn.linear_model.Lars.score", false]], "score() (sklearn.linear_model.larscv method)": [[659, "sklearn.linear_model.LarsCV.score", false]], "score() (sklearn.linear_model.lasso method)": [[660, "sklearn.linear_model.Lasso.score", false]], "score() (sklearn.linear_model.lassocv method)": [[661, "sklearn.linear_model.LassoCV.score", false]], "score() (sklearn.linear_model.lassolars method)": [[662, "sklearn.linear_model.LassoLars.score", false]], "score() (sklearn.linear_model.lassolarscv method)": [[663, "sklearn.linear_model.LassoLarsCV.score", false]], "score() (sklearn.linear_model.lassolarsic method)": [[664, "sklearn.linear_model.LassoLarsIC.score", false]], "score() (sklearn.linear_model.linearregression method)": [[665, "sklearn.linear_model.LinearRegression.score", false]], "score() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.score", false]], "score() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.score", false]], "score() (sklearn.linear_model.multitaskelasticnet method)": [[668, "sklearn.linear_model.MultiTaskElasticNet.score", false]], "score() (sklearn.linear_model.multitaskelasticnetcv method)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV.score", false]], "score() (sklearn.linear_model.multitasklasso method)": [[670, "sklearn.linear_model.MultiTaskLasso.score", false]], "score() (sklearn.linear_model.multitasklassocv method)": [[671, "sklearn.linear_model.MultiTaskLassoCV.score", false]], "score() (sklearn.linear_model.orthogonalmatchingpursuit method)": [[672, "sklearn.linear_model.OrthogonalMatchingPursuit.score", false]], "score() (sklearn.linear_model.orthogonalmatchingpursuitcv method)": [[673, "sklearn.linear_model.OrthogonalMatchingPursuitCV.score", false]], "score() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.score", false]], "score() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.score", false]], "score() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.score", false]], "score() (sklearn.linear_model.poissonregressor method)": [[677, "sklearn.linear_model.PoissonRegressor.score", false]], "score() (sklearn.linear_model.quantileregressor method)": [[678, "sklearn.linear_model.QuantileRegressor.score", false]], "score() (sklearn.linear_model.ransacregressor method)": [[679, "sklearn.linear_model.RANSACRegressor.score", false]], "score() (sklearn.linear_model.ridge method)": [[680, "sklearn.linear_model.Ridge.score", false]], "score() (sklearn.linear_model.ridgeclassifier method)": [[682, "sklearn.linear_model.RidgeClassifier.score", false]], "score() (sklearn.linear_model.ridgeclassifiercv method)": [[683, "sklearn.linear_model.RidgeClassifierCV.score", false]], "score() (sklearn.linear_model.ridgecv method)": [[681, "sklearn.linear_model.RidgeCV.score", false]], "score() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.score", false]], "score() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.score", false]], "score() (sklearn.linear_model.theilsenregressor method)": [[687, "sklearn.linear_model.TheilSenRegressor.score", false]], "score() (sklearn.linear_model.tweedieregressor method)": [[688, "sklearn.linear_model.TweedieRegressor.score", false]], "score() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.score", false]], "score() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.score", false]], "score() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.score", false]], "score() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.score", false]], "score() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.score", false]], "score() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.score", false]], "score() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.score", false]], "score() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.score", false]], "score() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.score", false]], "score() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.score", false]], "score() (sklearn.multiclass.outputcodeclassifier method)": [[842, "sklearn.multiclass.OutputCodeClassifier.score", false]], "score() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.score", false]], "score() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.score", false]], "score() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.score", false]], "score() (sklearn.multioutput.regressorchain method)": [[846, "sklearn.multioutput.RegressorChain.score", false]], "score() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.score", false]], "score() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.score", false]], "score() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.score", false]], "score() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.score", false]], "score() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.score", false]], "score() (sklearn.neighbors.kerneldensity method)": [[857, "sklearn.neighbors.KernelDensity.score", false]], "score() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.score", false]], "score() (sklearn.neighbors.kneighborsregressor method)": [[855, "sklearn.neighbors.KNeighborsRegressor.score", false]], "score() (sklearn.neighbors.nearestcentroid method)": [[859, "sklearn.neighbors.NearestCentroid.score", false]], "score() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.score", false]], "score() (sklearn.neighbors.radiusneighborsregressor method)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor.score", false]], "score() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.score", false]], "score() (sklearn.neural_network.mlpregressor method)": [[870, "sklearn.neural_network.MLPRegressor.score", false]], "score() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.score", false]], "score() (sklearn.semi_supervised.labelpropagation method)": [[907, "sklearn.semi_supervised.LabelPropagation.score", false]], "score() (sklearn.semi_supervised.labelspreading method)": [[908, "sklearn.semi_supervised.LabelSpreading.score", false]], "score() (sklearn.semi_supervised.selftrainingclassifier method)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier.score", false]], "score() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.score", false]], "score() (sklearn.svm.linearsvr method)": [[913, "sklearn.svm.LinearSVR.score", false]], "score() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.score", false]], "score() (sklearn.svm.nusvr method)": [[915, "sklearn.svm.NuSVR.score", false]], "score() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.score", false]], "score() (sklearn.svm.svr method)": [[918, "sklearn.svm.SVR.score", false]], "score() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.score", false]], "score() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.score", false]], "score() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.score", false]], "score() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.score", false]], "score_samples": [[400, "term-score_samples", true]], "score_samples() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.score_samples", false]], "score_samples() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.score_samples", false]], "score_samples() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.score_samples", false]], "score_samples() (sklearn.ensemble.isolationforest method)": [[571, "sklearn.ensemble.IsolationForest.score_samples", false]], "score_samples() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.score_samples", false]], "score_samples() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.score_samples", false]], "score_samples() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.score_samples", false]], "score_samples() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.score_samples", false]], "score_samples() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.score_samples", false]], "score_samples() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.score_samples", false]], "score_samples() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.score_samples", false]], "score_samples() (sklearn.neighbors.kerneldensity method)": [[857, "sklearn.neighbors.KernelDensity.score_samples", false]], "score_samples() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.score_samples", false]], "score_samples() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.score_samples", false]], "score_samples() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.score_samples", false]], "score_samples() (sklearn.svm.oneclasssvm method)": [[916, "sklearn.svm.OneClassSVM.score_samples", false]], "scorer": [[400, "term-scorer", true]], "scoring": [[400, "term-scoring", true]], "selectfdr (class in sklearn.feature_selection)": [[603, "sklearn.feature_selection.SelectFdr", false]], "selectfpr (class in sklearn.feature_selection)": [[604, "sklearn.feature_selection.SelectFpr", false]], "selectfrommodel (class in sklearn.feature_selection)": [[605, "sklearn.feature_selection.SelectFromModel", false]], "selectfwe (class in sklearn.feature_selection)": [[606, "sklearn.feature_selection.SelectFwe", false]], "selectkbest (class in sklearn.feature_selection)": [[607, "sklearn.feature_selection.SelectKBest", false]], "selectormixin (class in sklearn.feature_selection)": [[609, "sklearn.feature_selection.SelectorMixin", false]], "selectpercentile (class in sklearn.feature_selection)": [[608, "sklearn.feature_selection.SelectPercentile", false]], "selftrainingclassifier (class in sklearn.semi_supervised)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier", false]], "semi-supervised": [[400, "term-semi-supervised", true]], "semi-supervised learning": [[400, "term-semi-supervised-learning", true]], "semisupervised": [[400, "term-semisupervised", true]], "sequentialfeatureselector (class in sklearn.feature_selection)": [[610, "sklearn.feature_selection.SequentialFeatureSelector", false]], "set_config() (in module sklearn)": [[910, "sklearn.set_config", false]], "set_fit_request() (sklearn.calibration.calibratedclassifiercv method)": [[445, "sklearn.calibration.CalibratedClassifierCV.set_fit_request", false]], "set_fit_request() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.set_fit_request", false]], "set_fit_request() (sklearn.cluster.dbscan method)": [[452, "sklearn.cluster.DBSCAN.set_fit_request", false]], "set_fit_request() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.set_fit_request", false]], "set_fit_request() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.set_fit_request", false]], "set_fit_request() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.set_fit_request", false]], "set_fit_request() (sklearn.dummy.dummyregressor method)": [[560, "sklearn.dummy.DummyRegressor.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.baggingregressor method)": [[564, "sklearn.ensemble.BaggingRegressor.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.histgradientboostingregressor method)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.isolationforest method)": [[571, "sklearn.ensemble.IsolationForest.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.set_fit_request", false]], "set_fit_request() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.set_fit_request", false]], "set_fit_request() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.set_fit_request", false]], "set_fit_request() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.set_fit_request", false]], "set_fit_request() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.set_fit_request", false]], "set_fit_request() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.set_fit_request", false]], "set_fit_request() (sklearn.kernel_ridge.kernelridge method)": [[651, "sklearn.kernel_ridge.KernelRidge.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.bayesianridge method)": [[653, "sklearn.linear_model.BayesianRidge.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.elasticnet method)": [[654, "sklearn.linear_model.ElasticNet.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.elasticnetcv method)": [[655, "sklearn.linear_model.ElasticNetCV.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.gammaregressor method)": [[656, "sklearn.linear_model.GammaRegressor.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.huberregressor method)": [[657, "sklearn.linear_model.HuberRegressor.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.lars method)": [[658, "sklearn.linear_model.Lars.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.larscv method)": [[659, "sklearn.linear_model.LarsCV.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.lasso method)": [[660, "sklearn.linear_model.Lasso.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.lassocv method)": [[661, "sklearn.linear_model.LassoCV.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.lassolars method)": [[662, "sklearn.linear_model.LassoLars.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.lassolarscv method)": [[663, "sklearn.linear_model.LassoLarsCV.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.lassolarsic method)": [[664, "sklearn.linear_model.LassoLarsIC.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.linearregression method)": [[665, "sklearn.linear_model.LinearRegression.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.multitaskelasticnet method)": [[668, "sklearn.linear_model.MultiTaskElasticNet.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.multitaskelasticnetcv method)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.multitasklasso method)": [[670, "sklearn.linear_model.MultiTaskLasso.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.multitasklassocv method)": [[671, "sklearn.linear_model.MultiTaskLassoCV.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.poissonregressor method)": [[677, "sklearn.linear_model.PoissonRegressor.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.quantileregressor method)": [[678, "sklearn.linear_model.QuantileRegressor.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.ransacregressor method)": [[679, "sklearn.linear_model.RANSACRegressor.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.ridge method)": [[680, "sklearn.linear_model.Ridge.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.ridgeclassifier method)": [[682, "sklearn.linear_model.RidgeClassifier.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.ridgeclassifiercv method)": [[683, "sklearn.linear_model.RidgeClassifierCV.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.ridgecv method)": [[681, "sklearn.linear_model.RidgeCV.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.set_fit_request", false]], "set_fit_request() (sklearn.linear_model.tweedieregressor method)": [[688, "sklearn.linear_model.TweedieRegressor.set_fit_request", false]], "set_fit_request() (sklearn.manifold.mds method)": [[698, "sklearn.manifold.MDS.set_fit_request", false]], "set_fit_request() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.set_fit_request", false]], "set_fit_request() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.set_fit_request", false]], "set_fit_request() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.set_fit_request", false]], "set_fit_request() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.set_fit_request", false]], "set_fit_request() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.set_fit_request", false]], "set_fit_request() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.set_fit_request", false]], "set_fit_request() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.set_fit_request", false]], "set_fit_request() (sklearn.neighbors.kerneldensity method)": [[857, "sklearn.neighbors.KernelDensity.set_fit_request", false]], "set_fit_request() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.set_fit_request", false]], "set_fit_request() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.set_fit_request", false]], "set_fit_request() (sklearn.preprocessing.splinetransformer method)": [[891, "sklearn.preprocessing.SplineTransformer.set_fit_request", false]], "set_fit_request() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.set_fit_request", false]], "set_fit_request() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.set_fit_request", false]], "set_fit_request() (sklearn.svm.linearsvr method)": [[913, "sklearn.svm.LinearSVR.set_fit_request", false]], "set_fit_request() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.set_fit_request", false]], "set_fit_request() (sklearn.svm.nusvr method)": [[915, "sklearn.svm.NuSVR.set_fit_request", false]], "set_fit_request() (sklearn.svm.oneclasssvm method)": [[916, "sklearn.svm.OneClassSVM.set_fit_request", false]], "set_fit_request() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.set_fit_request", false]], "set_fit_request() (sklearn.svm.svr method)": [[918, "sklearn.svm.SVR.set_fit_request", false]], "set_fit_request() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.set_fit_request", false]], "set_fit_request() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.set_fit_request", false]], "set_fit_request() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.set_fit_request", false]], "set_fit_request() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.set_fit_request", false]], "set_inverse_transform_request() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.set_inverse_transform_request", false]], "set_inverse_transform_request() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.set_inverse_transform_request", false]], "set_inverse_transform_request() (sklearn.preprocessing.labelbinarizer method)": [[879, "sklearn.preprocessing.LabelBinarizer.set_inverse_transform_request", false]], "set_inverse_transform_request() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.set_inverse_transform_request", false]], "set_output() (sklearn.base.transformermixin method)": [[440, "sklearn.base.TransformerMixin.set_output", false]], "set_output() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.set_output", false]], "set_output() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.set_output", false]], "set_output() (sklearn.cluster.featureagglomeration method)": [[453, "sklearn.cluster.FeatureAgglomeration.set_output", false]], "set_output() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.set_output", false]], "set_output() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.set_output", false]], "set_output() (sklearn.compose.columntransformer method)": [[472, "sklearn.compose.ColumnTransformer.set_output", false]], "set_output() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.set_output", false]], "set_output() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.set_output", false]], "set_output() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.set_output", false]], "set_output() (sklearn.cross_decomposition.plssvd method)": [[493, "sklearn.cross_decomposition.PLSSVD.set_output", false]], "set_output() (sklearn.decomposition.dictionarylearning method)": [[539, "sklearn.decomposition.DictionaryLearning.set_output", false]], "set_output() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.set_output", false]], "set_output() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.set_output", false]], "set_output() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.set_output", false]], "set_output() (sklearn.decomposition.kernelpca method)": [[543, "sklearn.decomposition.KernelPCA.set_output", false]], "set_output() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.set_output", false]], "set_output() (sklearn.decomposition.minibatchdictionarylearning method)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning.set_output", false]], "set_output() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.set_output", false]], "set_output() (sklearn.decomposition.minibatchsparsepca method)": [[547, "sklearn.decomposition.MiniBatchSparsePCA.set_output", false]], "set_output() (sklearn.decomposition.nmf method)": [[548, "sklearn.decomposition.NMF.set_output", false]], "set_output() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.set_output", false]], "set_output() (sklearn.decomposition.sparsecoder method)": [[550, "sklearn.decomposition.SparseCoder.set_output", false]], "set_output() (sklearn.decomposition.sparsepca method)": [[551, "sklearn.decomposition.SparsePCA.set_output", false]], "set_output() (sklearn.decomposition.truncatedsvd method)": [[552, "sklearn.decomposition.TruncatedSVD.set_output", false]], "set_output() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_output", false]], "set_output() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.set_output", false]], "set_output() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.set_output", false]], "set_output() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.set_output", false]], "set_output() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.set_output", false]], "set_output() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.set_output", false]], "set_output() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.set_output", false]], "set_output() (sklearn.feature_extraction.featurehasher method)": [[590, "sklearn.feature_extraction.FeatureHasher.set_output", false]], "set_output() (sklearn.feature_extraction.image.patchextractor method)": [[591, "sklearn.feature_extraction.image.PatchExtractor.set_output", false]], "set_output() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.set_output", false]], "set_output() (sklearn.feature_extraction.text.tfidftransformer method)": [[598, "sklearn.feature_extraction.text.TfidfTransformer.set_output", false]], "set_output() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.set_output", false]], "set_output() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.set_output", false]], "set_output() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.set_output", false]], "set_output() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.set_output", false]], "set_output() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.set_output", false]], "set_output() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.set_output", false]], "set_output() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.set_output", false]], "set_output() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.set_output", false]], "set_output() (sklearn.feature_selection.selectormixin method)": [[609, "sklearn.feature_selection.SelectorMixin.set_output", false]], "set_output() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.set_output", false]], "set_output() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.set_output", false]], "set_output() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.set_output", false]], "set_output() (sklearn.impute.iterativeimputer method)": [[635, "sklearn.impute.IterativeImputer.set_output", false]], "set_output() (sklearn.impute.knnimputer method)": [[636, "sklearn.impute.KNNImputer.set_output", false]], "set_output() (sklearn.impute.missingindicator method)": [[637, "sklearn.impute.MissingIndicator.set_output", false]], "set_output() (sklearn.impute.simpleimputer method)": [[638, "sklearn.impute.SimpleImputer.set_output", false]], "set_output() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.set_output", false]], "set_output() (sklearn.kernel_approximation.additivechi2sampler method)": [[646, "sklearn.kernel_approximation.AdditiveChi2Sampler.set_output", false]], "set_output() (sklearn.kernel_approximation.nystroem method)": [[647, "sklearn.kernel_approximation.Nystroem.set_output", false]], "set_output() (sklearn.kernel_approximation.polynomialcountsketch method)": [[648, "sklearn.kernel_approximation.PolynomialCountSketch.set_output", false]], "set_output() (sklearn.kernel_approximation.rbfsampler method)": [[649, "sklearn.kernel_approximation.RBFSampler.set_output", false]], "set_output() (sklearn.kernel_approximation.skewedchi2sampler method)": [[650, "sklearn.kernel_approximation.SkewedChi2Sampler.set_output", false]], "set_output() (sklearn.manifold.isomap method)": [[696, "sklearn.manifold.Isomap.set_output", false]], "set_output() (sklearn.manifold.locallylinearembedding method)": [[697, "sklearn.manifold.LocallyLinearEmbedding.set_output", false]], "set_output() (sklearn.manifold.tsne method)": [[700, "sklearn.manifold.TSNE.set_output", false]], "set_output() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.set_output", false]], "set_output() (sklearn.neighbors.neighborhoodcomponentsanalysis method)": [[861, "sklearn.neighbors.NeighborhoodComponentsAnalysis.set_output", false]], "set_output() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.set_output", false]], "set_output() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.set_output", false]], "set_output() (sklearn.pipeline.featureunion method)": [[871, "sklearn.pipeline.FeatureUnion.set_output", false]], "set_output() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.set_output", false]], "set_output() (sklearn.preprocessing.binarizer method)": [[875, "sklearn.preprocessing.Binarizer.set_output", false]], "set_output() (sklearn.preprocessing.functiontransformer method)": [[876, "sklearn.preprocessing.FunctionTransformer.set_output", false]], "set_output() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.set_output", false]], "set_output() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.set_output", false]], "set_output() (sklearn.preprocessing.labelbinarizer method)": [[879, "sklearn.preprocessing.LabelBinarizer.set_output", false]], "set_output() (sklearn.preprocessing.labelencoder method)": [[880, "sklearn.preprocessing.LabelEncoder.set_output", false]], "set_output() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.set_output", false]], "set_output() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.set_output", false]], "set_output() (sklearn.preprocessing.multilabelbinarizer method)": [[883, "sklearn.preprocessing.MultiLabelBinarizer.set_output", false]], "set_output() (sklearn.preprocessing.normalizer method)": [[884, "sklearn.preprocessing.Normalizer.set_output", false]], "set_output() (sklearn.preprocessing.onehotencoder method)": [[885, "sklearn.preprocessing.OneHotEncoder.set_output", false]], "set_output() (sklearn.preprocessing.ordinalencoder method)": [[886, "sklearn.preprocessing.OrdinalEncoder.set_output", false]], "set_output() (sklearn.preprocessing.polynomialfeatures method)": [[887, "sklearn.preprocessing.PolynomialFeatures.set_output", false]], "set_output() (sklearn.preprocessing.powertransformer method)": [[888, "sklearn.preprocessing.PowerTransformer.set_output", false]], "set_output() (sklearn.preprocessing.quantiletransformer method)": [[889, "sklearn.preprocessing.QuantileTransformer.set_output", false]], "set_output() (sklearn.preprocessing.robustscaler method)": [[890, "sklearn.preprocessing.RobustScaler.set_output", false]], "set_output() (sklearn.preprocessing.splinetransformer method)": [[891, "sklearn.preprocessing.SplineTransformer.set_output", false]], "set_output() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.set_output", false]], "set_output() (sklearn.preprocessing.targetencoder method)": [[893, "sklearn.preprocessing.TargetEncoder.set_output", false]], "set_output() (sklearn.random_projection.gaussianrandomprojection method)": [[904, "sklearn.random_projection.GaussianRandomProjection.set_output", false]], "set_output() (sklearn.random_projection.sparserandomprojection method)": [[905, "sklearn.random_projection.SparseRandomProjection.set_output", false]], "set_params": [[400, "term-set_params", true]], "set_params() (sklearn.base.baseestimator method)": [[430, "sklearn.base.BaseEstimator.set_params", false]], "set_params() (sklearn.calibration.calibratedclassifiercv method)": [[445, "sklearn.calibration.CalibratedClassifierCV.set_params", false]], "set_params() (sklearn.cluster.affinitypropagation method)": [[448, "sklearn.cluster.AffinityPropagation.set_params", false]], "set_params() (sklearn.cluster.agglomerativeclustering method)": [[449, "sklearn.cluster.AgglomerativeClustering.set_params", false]], "set_params() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.set_params", false]], "set_params() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.set_params", false]], "set_params() (sklearn.cluster.dbscan method)": [[452, "sklearn.cluster.DBSCAN.set_params", false]], "set_params() (sklearn.cluster.featureagglomeration method)": [[453, "sklearn.cluster.FeatureAgglomeration.set_params", false]], "set_params() (sklearn.cluster.hdbscan method)": [[454, "sklearn.cluster.HDBSCAN.set_params", false]], "set_params() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.set_params", false]], "set_params() (sklearn.cluster.meanshift method)": [[456, "sklearn.cluster.MeanShift.set_params", false]], "set_params() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.set_params", false]], "set_params() (sklearn.cluster.optics method)": [[458, "sklearn.cluster.OPTICS.set_params", false]], "set_params() (sklearn.cluster.spectralbiclustering method)": [[459, "sklearn.cluster.SpectralBiclustering.set_params", false]], "set_params() (sklearn.cluster.spectralclustering method)": [[460, "sklearn.cluster.SpectralClustering.set_params", false]], "set_params() (sklearn.cluster.spectralcoclustering method)": [[461, "sklearn.cluster.SpectralCoclustering.set_params", false]], "set_params() (sklearn.compose.columntransformer method)": [[472, "sklearn.compose.ColumnTransformer.set_params", false]], "set_params() (sklearn.compose.transformedtargetregressor method)": [[473, "sklearn.compose.TransformedTargetRegressor.set_params", false]], "set_params() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.set_params", false]], "set_params() (sklearn.covariance.empiricalcovariance method)": [[478, "sklearn.covariance.EmpiricalCovariance.set_params", false]], "set_params() (sklearn.covariance.graphicallasso method)": [[479, "sklearn.covariance.GraphicalLasso.set_params", false]], "set_params() (sklearn.covariance.graphicallassocv method)": [[480, "sklearn.covariance.GraphicalLassoCV.set_params", false]], "set_params() (sklearn.covariance.ledoitwolf method)": [[481, "sklearn.covariance.LedoitWolf.set_params", false]], "set_params() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.set_params", false]], "set_params() (sklearn.covariance.oas method)": [[483, "sklearn.covariance.OAS.set_params", false]], "set_params() (sklearn.covariance.shrunkcovariance method)": [[484, "sklearn.covariance.ShrunkCovariance.set_params", false]], "set_params() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.set_params", false]], "set_params() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.set_params", false]], "set_params() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.set_params", false]], "set_params() (sklearn.cross_decomposition.plssvd method)": [[493, "sklearn.cross_decomposition.PLSSVD.set_params", false]], "set_params() (sklearn.decomposition.dictionarylearning method)": [[539, "sklearn.decomposition.DictionaryLearning.set_params", false]], "set_params() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.set_params", false]], "set_params() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.set_params", false]], "set_params() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.set_params", false]], "set_params() (sklearn.decomposition.kernelpca method)": [[543, "sklearn.decomposition.KernelPCA.set_params", false]], "set_params() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.set_params", false]], "set_params() (sklearn.decomposition.minibatchdictionarylearning method)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning.set_params", false]], "set_params() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.set_params", false]], "set_params() (sklearn.decomposition.minibatchsparsepca method)": [[547, "sklearn.decomposition.MiniBatchSparsePCA.set_params", false]], "set_params() (sklearn.decomposition.nmf method)": [[548, "sklearn.decomposition.NMF.set_params", false]], "set_params() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.set_params", false]], "set_params() (sklearn.decomposition.sparsecoder method)": [[550, "sklearn.decomposition.SparseCoder.set_params", false]], "set_params() (sklearn.decomposition.sparsepca method)": [[551, "sklearn.decomposition.SparsePCA.set_params", false]], "set_params() (sklearn.decomposition.truncatedsvd method)": [[552, "sklearn.decomposition.TruncatedSVD.set_params", false]], "set_params() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_params", false]], "set_params() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.set_params", false]], "set_params() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.set_params", false]], "set_params() (sklearn.dummy.dummyregressor method)": [[560, "sklearn.dummy.DummyRegressor.set_params", false]], "set_params() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.set_params", false]], "set_params() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.set_params", false]], "set_params() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.set_params", false]], "set_params() (sklearn.ensemble.baggingregressor method)": [[564, "sklearn.ensemble.BaggingRegressor.set_params", false]], "set_params() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.set_params", false]], "set_params() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.set_params", false]], "set_params() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.set_params", false]], "set_params() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.set_params", false]], "set_params() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.set_params", false]], "set_params() (sklearn.ensemble.histgradientboostingregressor method)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.set_params", false]], "set_params() (sklearn.ensemble.isolationforest method)": [[571, "sklearn.ensemble.IsolationForest.set_params", false]], "set_params() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.set_params", false]], "set_params() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.set_params", false]], "set_params() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.set_params", false]], "set_params() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.set_params", false]], "set_params() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.set_params", false]], "set_params() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.set_params", false]], "set_params() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.set_params", false]], "set_params() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.set_params", false]], "set_params() (sklearn.feature_extraction.featurehasher method)": [[590, "sklearn.feature_extraction.FeatureHasher.set_params", false]], "set_params() (sklearn.feature_extraction.image.patchextractor method)": [[591, "sklearn.feature_extraction.image.PatchExtractor.set_params", false]], "set_params() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.set_params", false]], "set_params() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.set_params", false]], "set_params() (sklearn.feature_extraction.text.tfidftransformer method)": [[598, "sklearn.feature_extraction.text.TfidfTransformer.set_params", false]], "set_params() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.set_params", false]], "set_params() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.set_params", false]], "set_params() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.set_params", false]], "set_params() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.set_params", false]], "set_params() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.set_params", false]], "set_params() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.set_params", false]], "set_params() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.set_params", false]], "set_params() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.set_params", false]], "set_params() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.set_params", false]], "set_params() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.set_params", false]], "set_params() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.set_params", false]], "set_params() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.set_params", false]], "set_params() (sklearn.gaussian_process.gaussianprocessclassifier method)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.set_params", false]], "set_params() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.compoundkernel method)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.constantkernel method)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.dotproduct method)": [[622, "sklearn.gaussian_process.kernels.DotProduct.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.exponentiation method)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.expsinesquared method)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.kernel method)": [[626, "sklearn.gaussian_process.kernels.Kernel.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.matern method)": [[627, "sklearn.gaussian_process.kernels.Matern.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.pairwisekernel method)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.product method)": [[629, "sklearn.gaussian_process.kernels.Product.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.rationalquadratic method)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.rbf method)": [[630, "sklearn.gaussian_process.kernels.RBF.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.sum method)": [[632, "sklearn.gaussian_process.kernels.Sum.set_params", false]], "set_params() (sklearn.gaussian_process.kernels.whitekernel method)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.set_params", false]], "set_params() (sklearn.impute.iterativeimputer method)": [[635, "sklearn.impute.IterativeImputer.set_params", false]], "set_params() (sklearn.impute.knnimputer method)": [[636, "sklearn.impute.KNNImputer.set_params", false]], "set_params() (sklearn.impute.missingindicator method)": [[637, "sklearn.impute.MissingIndicator.set_params", false]], "set_params() (sklearn.impute.simpleimputer method)": [[638, "sklearn.impute.SimpleImputer.set_params", false]], "set_params() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.set_params", false]], "set_params() (sklearn.kernel_approximation.additivechi2sampler method)": [[646, "sklearn.kernel_approximation.AdditiveChi2Sampler.set_params", false]], "set_params() (sklearn.kernel_approximation.nystroem method)": [[647, "sklearn.kernel_approximation.Nystroem.set_params", false]], "set_params() (sklearn.kernel_approximation.polynomialcountsketch method)": [[648, "sklearn.kernel_approximation.PolynomialCountSketch.set_params", false]], "set_params() (sklearn.kernel_approximation.rbfsampler method)": [[649, "sklearn.kernel_approximation.RBFSampler.set_params", false]], "set_params() (sklearn.kernel_approximation.skewedchi2sampler method)": [[650, "sklearn.kernel_approximation.SkewedChi2Sampler.set_params", false]], "set_params() (sklearn.kernel_ridge.kernelridge method)": [[651, "sklearn.kernel_ridge.KernelRidge.set_params", false]], "set_params() (sklearn.linear_model.ardregression method)": [[652, "sklearn.linear_model.ARDRegression.set_params", false]], "set_params() (sklearn.linear_model.bayesianridge method)": [[653, "sklearn.linear_model.BayesianRidge.set_params", false]], "set_params() (sklearn.linear_model.elasticnet method)": [[654, "sklearn.linear_model.ElasticNet.set_params", false]], "set_params() (sklearn.linear_model.elasticnetcv method)": [[655, "sklearn.linear_model.ElasticNetCV.set_params", false]], "set_params() (sklearn.linear_model.gammaregressor method)": [[656, "sklearn.linear_model.GammaRegressor.set_params", false]], "set_params() (sklearn.linear_model.huberregressor method)": [[657, "sklearn.linear_model.HuberRegressor.set_params", false]], "set_params() (sklearn.linear_model.lars method)": [[658, "sklearn.linear_model.Lars.set_params", false]], "set_params() (sklearn.linear_model.larscv method)": [[659, "sklearn.linear_model.LarsCV.set_params", false]], "set_params() (sklearn.linear_model.lasso method)": [[660, "sklearn.linear_model.Lasso.set_params", false]], "set_params() (sklearn.linear_model.lassocv method)": [[661, "sklearn.linear_model.LassoCV.set_params", false]], "set_params() (sklearn.linear_model.lassolars method)": [[662, "sklearn.linear_model.LassoLars.set_params", false]], "set_params() (sklearn.linear_model.lassolarscv method)": [[663, "sklearn.linear_model.LassoLarsCV.set_params", false]], "set_params() (sklearn.linear_model.lassolarsic method)": [[664, "sklearn.linear_model.LassoLarsIC.set_params", false]], "set_params() (sklearn.linear_model.linearregression method)": [[665, "sklearn.linear_model.LinearRegression.set_params", false]], "set_params() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.set_params", false]], "set_params() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.set_params", false]], "set_params() (sklearn.linear_model.multitaskelasticnet method)": [[668, "sklearn.linear_model.MultiTaskElasticNet.set_params", false]], "set_params() (sklearn.linear_model.multitaskelasticnetcv method)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV.set_params", false]], "set_params() (sklearn.linear_model.multitasklasso method)": [[670, "sklearn.linear_model.MultiTaskLasso.set_params", false]], "set_params() (sklearn.linear_model.multitasklassocv method)": [[671, "sklearn.linear_model.MultiTaskLassoCV.set_params", false]], "set_params() (sklearn.linear_model.orthogonalmatchingpursuit method)": [[672, "sklearn.linear_model.OrthogonalMatchingPursuit.set_params", false]], "set_params() (sklearn.linear_model.orthogonalmatchingpursuitcv method)": [[673, "sklearn.linear_model.OrthogonalMatchingPursuitCV.set_params", false]], "set_params() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.set_params", false]], "set_params() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.set_params", false]], "set_params() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.set_params", false]], "set_params() (sklearn.linear_model.poissonregressor method)": [[677, "sklearn.linear_model.PoissonRegressor.set_params", false]], "set_params() (sklearn.linear_model.quantileregressor method)": [[678, "sklearn.linear_model.QuantileRegressor.set_params", false]], "set_params() (sklearn.linear_model.ransacregressor method)": [[679, "sklearn.linear_model.RANSACRegressor.set_params", false]], "set_params() (sklearn.linear_model.ridge method)": [[680, "sklearn.linear_model.Ridge.set_params", false]], "set_params() (sklearn.linear_model.ridgeclassifier method)": [[682, "sklearn.linear_model.RidgeClassifier.set_params", false]], "set_params() (sklearn.linear_model.ridgeclassifiercv method)": [[683, "sklearn.linear_model.RidgeClassifierCV.set_params", false]], "set_params() (sklearn.linear_model.ridgecv method)": [[681, "sklearn.linear_model.RidgeCV.set_params", false]], "set_params() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.set_params", false]], "set_params() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.set_params", false]], "set_params() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.set_params", false]], "set_params() (sklearn.linear_model.theilsenregressor method)": [[687, "sklearn.linear_model.TheilSenRegressor.set_params", false]], "set_params() (sklearn.linear_model.tweedieregressor method)": [[688, "sklearn.linear_model.TweedieRegressor.set_params", false]], "set_params() (sklearn.manifold.isomap method)": [[696, "sklearn.manifold.Isomap.set_params", false]], "set_params() (sklearn.manifold.locallylinearembedding method)": [[697, "sklearn.manifold.LocallyLinearEmbedding.set_params", false]], "set_params() (sklearn.manifold.mds method)": [[698, "sklearn.manifold.MDS.set_params", false]], "set_params() (sklearn.manifold.spectralembedding method)": [[699, "sklearn.manifold.SpectralEmbedding.set_params", false]], "set_params() (sklearn.manifold.tsne method)": [[700, "sklearn.manifold.TSNE.set_params", false]], "set_params() (sklearn.mixture.bayesiangaussianmixture method)": [[805, "sklearn.mixture.BayesianGaussianMixture.set_params", false]], "set_params() (sklearn.mixture.gaussianmixture method)": [[806, "sklearn.mixture.GaussianMixture.set_params", false]], "set_params() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.set_params", false]], "set_params() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.set_params", false]], "set_params() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.set_params", false]], "set_params() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.set_params", false]], "set_params() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.set_params", false]], "set_params() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.set_params", false]], "set_params() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.set_params", false]], "set_params() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.set_params", false]], "set_params() (sklearn.multiclass.outputcodeclassifier method)": [[842, "sklearn.multiclass.OutputCodeClassifier.set_params", false]], "set_params() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.set_params", false]], "set_params() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.set_params", false]], "set_params() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.set_params", false]], "set_params() (sklearn.multioutput.regressorchain method)": [[846, "sklearn.multioutput.RegressorChain.set_params", false]], "set_params() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.set_params", false]], "set_params() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.set_params", false]], "set_params() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.set_params", false]], "set_params() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.set_params", false]], "set_params() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.set_params", false]], "set_params() (sklearn.neighbors.kerneldensity method)": [[857, "sklearn.neighbors.KernelDensity.set_params", false]], "set_params() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.set_params", false]], "set_params() (sklearn.neighbors.kneighborsregressor method)": [[855, "sklearn.neighbors.KNeighborsRegressor.set_params", false]], "set_params() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.set_params", false]], "set_params() (sklearn.neighbors.localoutlierfactor method)": [[858, "sklearn.neighbors.LocalOutlierFactor.set_params", false]], "set_params() (sklearn.neighbors.nearestcentroid method)": [[859, "sklearn.neighbors.NearestCentroid.set_params", false]], "set_params() (sklearn.neighbors.nearestneighbors method)": [[860, "sklearn.neighbors.NearestNeighbors.set_params", false]], "set_params() (sklearn.neighbors.neighborhoodcomponentsanalysis method)": [[861, "sklearn.neighbors.NeighborhoodComponentsAnalysis.set_params", false]], "set_params() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.set_params", false]], "set_params() (sklearn.neighbors.radiusneighborsregressor method)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor.set_params", false]], "set_params() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.set_params", false]], "set_params() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.set_params", false]], "set_params() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.set_params", false]], "set_params() (sklearn.neural_network.mlpregressor method)": [[870, "sklearn.neural_network.MLPRegressor.set_params", false]], "set_params() (sklearn.pipeline.featureunion method)": [[871, "sklearn.pipeline.FeatureUnion.set_params", false]], "set_params() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.set_params", false]], "set_params() (sklearn.preprocessing.binarizer method)": [[875, "sklearn.preprocessing.Binarizer.set_params", false]], "set_params() (sklearn.preprocessing.functiontransformer method)": [[876, "sklearn.preprocessing.FunctionTransformer.set_params", false]], "set_params() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.set_params", false]], "set_params() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.set_params", false]], "set_params() (sklearn.preprocessing.labelbinarizer method)": [[879, "sklearn.preprocessing.LabelBinarizer.set_params", false]], "set_params() (sklearn.preprocessing.labelencoder method)": [[880, "sklearn.preprocessing.LabelEncoder.set_params", false]], "set_params() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.set_params", false]], "set_params() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.set_params", false]], "set_params() (sklearn.preprocessing.multilabelbinarizer method)": [[883, "sklearn.preprocessing.MultiLabelBinarizer.set_params", false]], "set_params() (sklearn.preprocessing.normalizer method)": [[884, "sklearn.preprocessing.Normalizer.set_params", false]], "set_params() (sklearn.preprocessing.onehotencoder method)": [[885, "sklearn.preprocessing.OneHotEncoder.set_params", false]], "set_params() (sklearn.preprocessing.ordinalencoder method)": [[886, "sklearn.preprocessing.OrdinalEncoder.set_params", false]], "set_params() (sklearn.preprocessing.polynomialfeatures method)": [[887, "sklearn.preprocessing.PolynomialFeatures.set_params", false]], "set_params() (sklearn.preprocessing.powertransformer method)": [[888, "sklearn.preprocessing.PowerTransformer.set_params", false]], "set_params() (sklearn.preprocessing.quantiletransformer method)": [[889, "sklearn.preprocessing.QuantileTransformer.set_params", false]], "set_params() (sklearn.preprocessing.robustscaler method)": [[890, "sklearn.preprocessing.RobustScaler.set_params", false]], "set_params() (sklearn.preprocessing.splinetransformer method)": [[891, "sklearn.preprocessing.SplineTransformer.set_params", false]], "set_params() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.set_params", false]], "set_params() (sklearn.preprocessing.targetencoder method)": [[893, "sklearn.preprocessing.TargetEncoder.set_params", false]], "set_params() (sklearn.random_projection.gaussianrandomprojection method)": [[904, "sklearn.random_projection.GaussianRandomProjection.set_params", false]], "set_params() (sklearn.random_projection.sparserandomprojection method)": [[905, "sklearn.random_projection.SparseRandomProjection.set_params", false]], "set_params() (sklearn.semi_supervised.labelpropagation method)": [[907, "sklearn.semi_supervised.LabelPropagation.set_params", false]], "set_params() (sklearn.semi_supervised.labelspreading method)": [[908, "sklearn.semi_supervised.LabelSpreading.set_params", false]], "set_params() (sklearn.semi_supervised.selftrainingclassifier method)": [[909, "sklearn.semi_supervised.SelfTrainingClassifier.set_params", false]], "set_params() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.set_params", false]], "set_params() (sklearn.svm.linearsvr method)": [[913, "sklearn.svm.LinearSVR.set_params", false]], "set_params() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.set_params", false]], "set_params() (sklearn.svm.nusvr method)": [[915, "sklearn.svm.NuSVR.set_params", false]], "set_params() (sklearn.svm.oneclasssvm method)": [[916, "sklearn.svm.OneClassSVM.set_params", false]], "set_params() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.set_params", false]], "set_params() (sklearn.svm.svr method)": [[918, "sklearn.svm.SVR.set_params", false]], "set_params() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.set_params", false]], "set_params() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.set_params", false]], "set_params() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.set_params", false]], "set_params() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.set_params", false]], "set_partial_fit_request() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.multioutput.multioutputclassifier method)": [[844, "sklearn.multioutput.MultiOutputClassifier.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.set_partial_fit_request", false]], "set_partial_fit_request() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.set_partial_fit_request", false]], "set_predict_proba_request() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.set_predict_proba_request", false]], "set_predict_proba_request() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.set_predict_proba_request", false]], "set_predict_request() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.set_predict_request", false]], "set_predict_request() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.set_predict_request", false]], "set_predict_request() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.set_predict_request", false]], "set_predict_request() (sklearn.dummy.dummyregressor method)": [[560, "sklearn.dummy.DummyRegressor.set_predict_request", false]], "set_predict_request() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.set_predict_request", false]], "set_predict_request() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.set_predict_request", false]], "set_predict_request() (sklearn.linear_model.ardregression method)": [[652, "sklearn.linear_model.ARDRegression.set_predict_request", false]], "set_predict_request() (sklearn.linear_model.bayesianridge method)": [[653, "sklearn.linear_model.BayesianRidge.set_predict_request", false]], "set_predict_request() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.set_predict_request", false]], "set_predict_request() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.set_predict_request", false]], "set_predict_request() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.set_predict_request", false]], "set_predict_request() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.set_predict_request", false]], "set_score_request() (sklearn.calibration.calibratedclassifiercv method)": [[445, "sklearn.calibration.CalibratedClassifierCV.set_score_request", false]], "set_score_request() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.set_score_request", false]], "set_score_request() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.set_score_request", false]], "set_score_request() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.set_score_request", false]], "set_score_request() (sklearn.compose.transformedtargetregressor method)": [[473, "sklearn.compose.TransformedTargetRegressor.set_score_request", false]], "set_score_request() (sklearn.covariance.ellipticenvelope method)": [[477, "sklearn.covariance.EllipticEnvelope.set_score_request", false]], "set_score_request() (sklearn.covariance.empiricalcovariance method)": [[478, "sklearn.covariance.EmpiricalCovariance.set_score_request", false]], "set_score_request() (sklearn.covariance.graphicallasso method)": [[479, "sklearn.covariance.GraphicalLasso.set_score_request", false]], "set_score_request() (sklearn.covariance.graphicallassocv method)": [[480, "sklearn.covariance.GraphicalLassoCV.set_score_request", false]], "set_score_request() (sklearn.covariance.ledoitwolf method)": [[481, "sklearn.covariance.LedoitWolf.set_score_request", false]], "set_score_request() (sklearn.covariance.mincovdet method)": [[482, "sklearn.covariance.MinCovDet.set_score_request", false]], "set_score_request() (sklearn.covariance.oas method)": [[483, "sklearn.covariance.OAS.set_score_request", false]], "set_score_request() (sklearn.covariance.shrunkcovariance method)": [[484, "sklearn.covariance.ShrunkCovariance.set_score_request", false]], "set_score_request() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.set_score_request", false]], "set_score_request() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.set_score_request", false]], "set_score_request() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.set_score_request", false]], "set_score_request() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_score_request", false]], "set_score_request() (sklearn.discriminant_analysis.quadraticdiscriminantanalysis method)": [[558, "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.set_score_request", false]], "set_score_request() (sklearn.dummy.dummyclassifier method)": [[559, "sklearn.dummy.DummyClassifier.set_score_request", false]], "set_score_request() (sklearn.dummy.dummyregressor method)": [[560, "sklearn.dummy.DummyRegressor.set_score_request", false]], "set_score_request() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.set_score_request", false]], "set_score_request() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.set_score_request", false]], "set_score_request() (sklearn.ensemble.baggingclassifier method)": [[563, "sklearn.ensemble.BaggingClassifier.set_score_request", false]], "set_score_request() (sklearn.ensemble.baggingregressor method)": [[564, "sklearn.ensemble.BaggingRegressor.set_score_request", false]], "set_score_request() (sklearn.ensemble.extratreesclassifier method)": [[565, "sklearn.ensemble.ExtraTreesClassifier.set_score_request", false]], "set_score_request() (sklearn.ensemble.extratreesregressor method)": [[566, "sklearn.ensemble.ExtraTreesRegressor.set_score_request", false]], "set_score_request() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.set_score_request", false]], "set_score_request() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.set_score_request", false]], "set_score_request() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.set_score_request", false]], "set_score_request() (sklearn.ensemble.histgradientboostingregressor method)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.set_score_request", false]], "set_score_request() (sklearn.ensemble.randomforestclassifier method)": [[572, "sklearn.ensemble.RandomForestClassifier.set_score_request", false]], "set_score_request() (sklearn.ensemble.randomforestregressor method)": [[573, "sklearn.ensemble.RandomForestRegressor.set_score_request", false]], "set_score_request() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.set_score_request", false]], "set_score_request() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.set_score_request", false]], "set_score_request() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.set_score_request", false]], "set_score_request() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.set_score_request", false]], "set_score_request() (sklearn.gaussian_process.gaussianprocessclassifier method)": [[618, "sklearn.gaussian_process.GaussianProcessClassifier.set_score_request", false]], "set_score_request() (sklearn.gaussian_process.gaussianprocessregressor method)": [[619, "sklearn.gaussian_process.GaussianProcessRegressor.set_score_request", false]], "set_score_request() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.set_score_request", false]], "set_score_request() (sklearn.kernel_ridge.kernelridge method)": [[651, "sklearn.kernel_ridge.KernelRidge.set_score_request", false]], "set_score_request() (sklearn.linear_model.ardregression method)": [[652, "sklearn.linear_model.ARDRegression.set_score_request", false]], "set_score_request() (sklearn.linear_model.bayesianridge method)": [[653, "sklearn.linear_model.BayesianRidge.set_score_request", false]], "set_score_request() (sklearn.linear_model.elasticnet method)": [[654, "sklearn.linear_model.ElasticNet.set_score_request", false]], "set_score_request() (sklearn.linear_model.elasticnetcv method)": [[655, "sklearn.linear_model.ElasticNetCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.gammaregressor method)": [[656, "sklearn.linear_model.GammaRegressor.set_score_request", false]], "set_score_request() (sklearn.linear_model.huberregressor method)": [[657, "sklearn.linear_model.HuberRegressor.set_score_request", false]], "set_score_request() (sklearn.linear_model.lars method)": [[658, "sklearn.linear_model.Lars.set_score_request", false]], "set_score_request() (sklearn.linear_model.larscv method)": [[659, "sklearn.linear_model.LarsCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.lasso method)": [[660, "sklearn.linear_model.Lasso.set_score_request", false]], "set_score_request() (sklearn.linear_model.lassocv method)": [[661, "sklearn.linear_model.LassoCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.lassolars method)": [[662, "sklearn.linear_model.LassoLars.set_score_request", false]], "set_score_request() (sklearn.linear_model.lassolarscv method)": [[663, "sklearn.linear_model.LassoLarsCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.lassolarsic method)": [[664, "sklearn.linear_model.LassoLarsIC.set_score_request", false]], "set_score_request() (sklearn.linear_model.linearregression method)": [[665, "sklearn.linear_model.LinearRegression.set_score_request", false]], "set_score_request() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.set_score_request", false]], "set_score_request() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.multitaskelasticnet method)": [[668, "sklearn.linear_model.MultiTaskElasticNet.set_score_request", false]], "set_score_request() (sklearn.linear_model.multitaskelasticnetcv method)": [[669, "sklearn.linear_model.MultiTaskElasticNetCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.multitasklasso method)": [[670, "sklearn.linear_model.MultiTaskLasso.set_score_request", false]], "set_score_request() (sklearn.linear_model.multitasklassocv method)": [[671, "sklearn.linear_model.MultiTaskLassoCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.orthogonalmatchingpursuit method)": [[672, "sklearn.linear_model.OrthogonalMatchingPursuit.set_score_request", false]], "set_score_request() (sklearn.linear_model.orthogonalmatchingpursuitcv method)": [[673, "sklearn.linear_model.OrthogonalMatchingPursuitCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.set_score_request", false]], "set_score_request() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.set_score_request", false]], "set_score_request() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.set_score_request", false]], "set_score_request() (sklearn.linear_model.poissonregressor method)": [[677, "sklearn.linear_model.PoissonRegressor.set_score_request", false]], "set_score_request() (sklearn.linear_model.quantileregressor method)": [[678, "sklearn.linear_model.QuantileRegressor.set_score_request", false]], "set_score_request() (sklearn.linear_model.ridge method)": [[680, "sklearn.linear_model.Ridge.set_score_request", false]], "set_score_request() (sklearn.linear_model.ridgeclassifier method)": [[682, "sklearn.linear_model.RidgeClassifier.set_score_request", false]], "set_score_request() (sklearn.linear_model.ridgeclassifiercv method)": [[683, "sklearn.linear_model.RidgeClassifierCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.ridgecv method)": [[681, "sklearn.linear_model.RidgeCV.set_score_request", false]], "set_score_request() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.set_score_request", false]], "set_score_request() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.set_score_request", false]], "set_score_request() (sklearn.linear_model.theilsenregressor method)": [[687, "sklearn.linear_model.TheilSenRegressor.set_score_request", false]], "set_score_request() (sklearn.linear_model.tweedieregressor method)": [[688, "sklearn.linear_model.TweedieRegressor.set_score_request", false]], "set_score_request() (sklearn.model_selection.fixedthresholdclassifier method)": [[807, "sklearn.model_selection.FixedThresholdClassifier.set_score_request", false]], "set_score_request() (sklearn.model_selection.tunedthresholdclassifiercv method)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV.set_score_request", false]], "set_score_request() (sklearn.multiclass.onevsoneclassifier method)": [[840, "sklearn.multiclass.OneVsOneClassifier.set_score_request", false]], "set_score_request() (sklearn.multiclass.onevsrestclassifier method)": [[841, "sklearn.multiclass.OneVsRestClassifier.set_score_request", false]], "set_score_request() (sklearn.multiclass.outputcodeclassifier method)": [[842, "sklearn.multiclass.OutputCodeClassifier.set_score_request", false]], "set_score_request() (sklearn.multioutput.classifierchain method)": [[843, "sklearn.multioutput.ClassifierChain.set_score_request", false]], "set_score_request() (sklearn.multioutput.multioutputregressor method)": [[845, "sklearn.multioutput.MultiOutputRegressor.set_score_request", false]], "set_score_request() (sklearn.multioutput.regressorchain method)": [[846, "sklearn.multioutput.RegressorChain.set_score_request", false]], "set_score_request() (sklearn.naive_bayes.bernoullinb method)": [[847, "sklearn.naive_bayes.BernoulliNB.set_score_request", false]], "set_score_request() (sklearn.naive_bayes.categoricalnb method)": [[848, "sklearn.naive_bayes.CategoricalNB.set_score_request", false]], "set_score_request() (sklearn.naive_bayes.complementnb method)": [[849, "sklearn.naive_bayes.ComplementNB.set_score_request", false]], "set_score_request() (sklearn.naive_bayes.gaussiannb method)": [[850, "sklearn.naive_bayes.GaussianNB.set_score_request", false]], "set_score_request() (sklearn.naive_bayes.multinomialnb method)": [[851, "sklearn.naive_bayes.MultinomialNB.set_score_request", false]], "set_score_request() (sklearn.neighbors.kneighborsclassifier method)": [[854, "sklearn.neighbors.KNeighborsClassifier.set_score_request", false]], "set_score_request() (sklearn.neighbors.kneighborsregressor method)": [[855, "sklearn.neighbors.KNeighborsRegressor.set_score_request", false]], "set_score_request() (sklearn.neighbors.nearestcentroid method)": [[859, "sklearn.neighbors.NearestCentroid.set_score_request", false]], "set_score_request() (sklearn.neighbors.radiusneighborsclassifier method)": [[862, "sklearn.neighbors.RadiusNeighborsClassifier.set_score_request", false]], "set_score_request() (sklearn.neighbors.radiusneighborsregressor method)": [[863, "sklearn.neighbors.RadiusNeighborsRegressor.set_score_request", false]], "set_score_request() (sklearn.neural_network.mlpclassifier method)": [[869, "sklearn.neural_network.MLPClassifier.set_score_request", false]], "set_score_request() (sklearn.neural_network.mlpregressor method)": [[870, "sklearn.neural_network.MLPRegressor.set_score_request", false]], "set_score_request() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.set_score_request", false]], "set_score_request() (sklearn.semi_supervised.labelpropagation method)": [[907, "sklearn.semi_supervised.LabelPropagation.set_score_request", false]], "set_score_request() (sklearn.semi_supervised.labelspreading method)": [[908, "sklearn.semi_supervised.LabelSpreading.set_score_request", false]], "set_score_request() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.set_score_request", false]], "set_score_request() (sklearn.svm.linearsvr method)": [[913, "sklearn.svm.LinearSVR.set_score_request", false]], "set_score_request() (sklearn.svm.nusvc method)": [[914, "sklearn.svm.NuSVC.set_score_request", false]], "set_score_request() (sklearn.svm.nusvr method)": [[915, "sklearn.svm.NuSVR.set_score_request", false]], "set_score_request() (sklearn.svm.svc method)": [[917, "sklearn.svm.SVC.set_score_request", false]], "set_score_request() (sklearn.svm.svr method)": [[918, "sklearn.svm.SVR.set_score_request", false]], "set_score_request() (sklearn.tree.decisiontreeclassifier method)": [[920, "sklearn.tree.DecisionTreeClassifier.set_score_request", false]], "set_score_request() (sklearn.tree.decisiontreeregressor method)": [[921, "sklearn.tree.DecisionTreeRegressor.set_score_request", false]], "set_score_request() (sklearn.tree.extratreeclassifier method)": [[922, "sklearn.tree.ExtraTreeClassifier.set_score_request", false]], "set_score_request() (sklearn.tree.extratreeregressor method)": [[923, "sklearn.tree.ExtraTreeRegressor.set_score_request", false]], "set_split_request() (sklearn.model_selection.groupkfold method)": [[809, "sklearn.model_selection.GroupKFold.set_split_request", false]], "set_split_request() (sklearn.model_selection.groupshufflesplit method)": [[810, "sklearn.model_selection.GroupShuffleSplit.set_split_request", false]], "set_split_request() (sklearn.model_selection.leaveonegroupout method)": [[815, "sklearn.model_selection.LeaveOneGroupOut.set_split_request", false]], "set_split_request() (sklearn.model_selection.leavepgroupsout method)": [[817, "sklearn.model_selection.LeavePGroupsOut.set_split_request", false]], "set_split_request() (sklearn.model_selection.stratifiedgroupkfold method)": [[826, "sklearn.model_selection.StratifiedGroupKFold.set_split_request", false]], "set_transform_request() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.set_transform_request", false]], "set_transform_request() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.set_transform_request", false]], "set_transform_request() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.set_transform_request", false]], "set_transform_request() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.set_transform_request", false]], "set_transform_request() (sklearn.feature_extraction.featurehasher method)": [[590, "sklearn.feature_extraction.FeatureHasher.set_transform_request", false]], "set_transform_request() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.set_transform_request", false]], "set_transform_request() (sklearn.feature_extraction.text.tfidftransformer method)": [[598, "sklearn.feature_extraction.text.TfidfTransformer.set_transform_request", false]], "set_transform_request() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.set_transform_request", false]], "set_transform_request() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.set_transform_request", false]], "set_transform_request() (sklearn.preprocessing.binarizer method)": [[875, "sklearn.preprocessing.Binarizer.set_transform_request", false]], "set_transform_request() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.set_transform_request", false]], "set_transform_request() (sklearn.preprocessing.normalizer method)": [[884, "sklearn.preprocessing.Normalizer.set_transform_request", false]], "set_transform_request() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.set_transform_request", false]], "setdefault() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.setdefault", false]], "sgdclassifier (class in sklearn.linear_model)": [[684, "sklearn.linear_model.SGDClassifier", false]], "sgdoneclasssvm (class in sklearn.linear_model)": [[685, "sklearn.linear_model.SGDOneClassSVM", false]], "sgdregressor (class in sklearn.linear_model)": [[686, "sklearn.linear_model.SGDRegressor", false]], "show_versions() (in module sklearn)": [[911, "sklearn.show_versions", false]], "shrunk_covariance() (in module sklearn.covariance)": [[489, "sklearn.covariance.shrunk_covariance", false]], "shrunkcovariance (class in sklearn.covariance)": [[484, "sklearn.covariance.ShrunkCovariance", false]], "shuffle() (in module sklearn.utils)": [[974, "sklearn.utils.shuffle", false]], "shufflesplit (class in sklearn.model_selection)": [[825, "sklearn.model_selection.ShuffleSplit", false]], "sigmoid_kernel() (in module sklearn.metrics.pairwise)": [[785, "sklearn.metrics.pairwise.sigmoid_kernel", false]], "silhouette_samples() (in module sklearn.metrics)": [[800, "sklearn.metrics.silhouette_samples", false]], "silhouette_score() (in module sklearn.metrics)": [[801, "sklearn.metrics.silhouette_score", false]], "simpleimputer (class in sklearn.impute)": [[638, "sklearn.impute.SimpleImputer", false]], "single_source_shortest_path_length() (in module sklearn.utils.graph)": [[954, "sklearn.utils.graph.single_source_shortest_path_length", false]], "skewedchi2sampler (class in sklearn.kernel_approximation)": [[650, "sklearn.kernel_approximation.SkewedChi2Sampler", false]], "sklearn": [[3, "module-sklearn", false]], "sklearn.base": [[4, "module-sklearn.base", false]], "sklearn.calibration": [[5, "module-sklearn.calibration", false]], "sklearn.cluster": [[6, "module-sklearn.cluster", false]], "sklearn.compose": [[7, "module-sklearn.compose", false]], "sklearn.covariance": [[8, "module-sklearn.covariance", false]], "sklearn.cross_decomposition": [[9, "module-sklearn.cross_decomposition", false]], "sklearn.datasets": [[10, "module-sklearn.datasets", false]], "sklearn.decomposition": [[11, "module-sklearn.decomposition", false]], "sklearn.discriminant_analysis": [[12, "module-sklearn.discriminant_analysis", false]], "sklearn.dummy": [[13, "module-sklearn.dummy", false]], "sklearn.ensemble": [[14, "module-sklearn.ensemble", false]], "sklearn.exceptions": [[15, "module-sklearn.exceptions", false]], "sklearn.experimental": [[16, "module-sklearn.experimental", false]], "sklearn.experimental.enable_halving_search_cv": [[587, "module-sklearn.experimental.enable_halving_search_cv", false]], "sklearn.experimental.enable_iterative_imputer": [[588, "module-sklearn.experimental.enable_iterative_imputer", false]], "sklearn.feature_extraction": [[17, "module-sklearn.feature_extraction", false]], "sklearn.feature_extraction.image": [[17, "module-sklearn.feature_extraction.image", false]], "sklearn.feature_extraction.text": [[17, "module-sklearn.feature_extraction.text", false]], "sklearn.feature_selection": [[18, "module-sklearn.feature_selection", false]], "sklearn.gaussian_process": [[19, "module-sklearn.gaussian_process", false]], "sklearn.gaussian_process.kernels": [[19, "module-sklearn.gaussian_process.kernels", false]], "sklearn.impute": [[20, "module-sklearn.impute", false]], "sklearn.inspection": [[21, "module-sklearn.inspection", false]], "sklearn.isotonic": [[22, "module-sklearn.isotonic", false]], "sklearn.kernel_approximation": [[23, "module-sklearn.kernel_approximation", false]], "sklearn.kernel_ridge": [[24, "module-sklearn.kernel_ridge", false]], "sklearn.linear_model": [[25, "module-sklearn.linear_model", false]], "sklearn.manifold": [[26, "module-sklearn.manifold", false]], "sklearn.metrics": [[27, "module-sklearn.metrics", false]], "sklearn.metrics.cluster": [[27, "module-sklearn.metrics.cluster", false]], "sklearn.metrics.pairwise": [[27, "module-sklearn.metrics.pairwise", false]], "sklearn.mixture": [[28, "module-sklearn.mixture", false]], "sklearn.model_selection": [[29, "module-sklearn.model_selection", false]], "sklearn.multiclass": [[30, "module-sklearn.multiclass", false]], "sklearn.multioutput": [[31, "module-sklearn.multioutput", false]], "sklearn.naive_bayes": [[32, "module-sklearn.naive_bayes", false]], "sklearn.neighbors": [[33, "module-sklearn.neighbors", false]], "sklearn.neural_network": [[34, "module-sklearn.neural_network", false]], "sklearn.pipeline": [[35, "module-sklearn.pipeline", false]], "sklearn.preprocessing": [[36, "module-sklearn.preprocessing", false]], "sklearn.random_projection": [[37, "module-sklearn.random_projection", false]], "sklearn.semi_supervised": [[38, "module-sklearn.semi_supervised", false]], "sklearn.svm": [[39, "module-sklearn.svm", false]], "sklearn.tree": [[40, "module-sklearn.tree", false]], "sklearn.utils": [[41, "module-sklearn.utils", false]], "sklearn.utils.arrayfuncs": [[41, "module-sklearn.utils.arrayfuncs", false]], "sklearn.utils.class_weight": [[41, "module-sklearn.utils.class_weight", false]], "sklearn.utils.discovery": [[41, "module-sklearn.utils.discovery", false]], "sklearn.utils.estimator_checks": [[41, "module-sklearn.utils.estimator_checks", false]], "sklearn.utils.extmath": [[41, "module-sklearn.utils.extmath", false]], "sklearn.utils.graph": [[41, "module-sklearn.utils.graph", false]], "sklearn.utils.metadata_routing": [[41, "module-sklearn.utils.metadata_routing", false]], "sklearn.utils.metaestimators": [[41, "module-sklearn.utils.metaestimators", false]], "sklearn.utils.multiclass": [[41, "module-sklearn.utils.multiclass", false]], "sklearn.utils.parallel": [[41, "module-sklearn.utils.parallel", false]], "sklearn.utils.random": [[41, "module-sklearn.utils.random", false]], "sklearn.utils.sparsefuncs": [[41, "module-sklearn.utils.sparsefuncs", false]], "sklearn.utils.sparsefuncs_fast": [[41, "module-sklearn.utils.sparsefuncs_fast", false]], "sklearn.utils.validation": [[41, "module-sklearn.utils.validation", false]], "slep": [[400, "term-SLEP", true]], "sleps": [[400, "term-SLEPs", true]], "smacof() (in module sklearn.manifold)": [[702, "sklearn.manifold.smacof", false]], "sort_graph_by_row_values() (in module sklearn.neighbors)": [[867, "sklearn.neighbors.sort_graph_by_row_values", false]], "sparse graph": [[400, "term-sparse-graph", true]], "sparse matrix": [[400, "term-sparse-matrix", true]], "sparse_coef_ (sklearn.linear_model.elasticnet property)": [[654, "sklearn.linear_model.ElasticNet.sparse_coef_", false]], "sparse_coef_ (sklearn.linear_model.lasso property)": [[660, "sklearn.linear_model.Lasso.sparse_coef_", false]], "sparse_coef_ (sklearn.linear_model.multitaskelasticnet property)": [[668, "sklearn.linear_model.MultiTaskElasticNet.sparse_coef_", false]], "sparse_coef_ (sklearn.linear_model.multitasklasso property)": [[670, "sklearn.linear_model.MultiTaskLasso.sparse_coef_", false]], "sparse_encode() (in module sklearn.decomposition)": [[556, "sklearn.decomposition.sparse_encode", false]], "sparsecoder (class in sklearn.decomposition)": [[550, "sklearn.decomposition.SparseCoder", false]], "sparsepca (class in sklearn.decomposition)": [[551, "sklearn.decomposition.SparsePCA", false]], "sparserandomprojection (class in sklearn.random_projection)": [[905, "sklearn.random_projection.SparseRandomProjection", false]], "sparsify() (sklearn.linear_model.logisticregression method)": [[666, "sklearn.linear_model.LogisticRegression.sparsify", false]], "sparsify() (sklearn.linear_model.logisticregressioncv method)": [[667, "sklearn.linear_model.LogisticRegressionCV.sparsify", false]], "sparsify() (sklearn.linear_model.passiveaggressiveclassifier method)": [[674, "sklearn.linear_model.PassiveAggressiveClassifier.sparsify", false]], "sparsify() (sklearn.linear_model.passiveaggressiveregressor method)": [[675, "sklearn.linear_model.PassiveAggressiveRegressor.sparsify", false]], "sparsify() (sklearn.linear_model.perceptron method)": [[676, "sklearn.linear_model.Perceptron.sparsify", false]], "sparsify() (sklearn.linear_model.sgdclassifier method)": [[684, "sklearn.linear_model.SGDClassifier.sparsify", false]], "sparsify() (sklearn.linear_model.sgdoneclasssvm method)": [[685, "sklearn.linear_model.SGDOneClassSVM.sparsify", false]], "sparsify() (sklearn.linear_model.sgdregressor method)": [[686, "sklearn.linear_model.SGDRegressor.sparsify", false]], "sparsify() (sklearn.svm.linearsvc method)": [[912, "sklearn.svm.LinearSVC.sparsify", false]], "spectral_clustering() (in module sklearn.cluster)": [[470, "sklearn.cluster.spectral_clustering", false]], "spectral_embedding() (in module sklearn.manifold)": [[703, "sklearn.manifold.spectral_embedding", false]], "spectralbiclustering (class in sklearn.cluster)": [[459, "sklearn.cluster.SpectralBiclustering", false]], "spectralclustering (class in sklearn.cluster)": [[460, "sklearn.cluster.SpectralClustering", false]], "spectralcoclustering (class in sklearn.cluster)": [[461, "sklearn.cluster.SpectralCoclustering", false]], "spectralembedding (class in sklearn.manifold)": [[699, "sklearn.manifold.SpectralEmbedding", false]], "splinetransformer (class in sklearn.preprocessing)": [[891, "sklearn.preprocessing.SplineTransformer", false]], "split": [[400, "term-split", true]], "split() (sklearn.model_selection.groupkfold method)": [[809, "sklearn.model_selection.GroupKFold.split", false]], "split() (sklearn.model_selection.groupshufflesplit method)": [[810, "sklearn.model_selection.GroupShuffleSplit.split", false]], "split() (sklearn.model_selection.kfold method)": [[813, "sklearn.model_selection.KFold.split", false]], "split() (sklearn.model_selection.leaveonegroupout method)": [[815, "sklearn.model_selection.LeaveOneGroupOut.split", false]], "split() (sklearn.model_selection.leaveoneout method)": [[816, "sklearn.model_selection.LeaveOneOut.split", false]], "split() (sklearn.model_selection.leavepgroupsout method)": [[817, "sklearn.model_selection.LeavePGroupsOut.split", false]], "split() (sklearn.model_selection.leavepout method)": [[818, "sklearn.model_selection.LeavePOut.split", false]], "split() (sklearn.model_selection.predefinedsplit method)": [[821, "sklearn.model_selection.PredefinedSplit.split", false]], "split() (sklearn.model_selection.repeatedkfold method)": [[823, "sklearn.model_selection.RepeatedKFold.split", false]], "split() (sklearn.model_selection.repeatedstratifiedkfold method)": [[824, "sklearn.model_selection.RepeatedStratifiedKFold.split", false]], "split() (sklearn.model_selection.shufflesplit method)": [[825, "sklearn.model_selection.ShuffleSplit.split", false]], "split() (sklearn.model_selection.stratifiedgroupkfold method)": [[826, "sklearn.model_selection.StratifiedGroupKFold.split", false]], "split() (sklearn.model_selection.stratifiedkfold method)": [[827, "sklearn.model_selection.StratifiedKFold.split", false]], "split() (sklearn.model_selection.stratifiedshufflesplit method)": [[828, "sklearn.model_selection.StratifiedShuffleSplit.split", false]], "split() (sklearn.model_selection.timeseriessplit method)": [[829, "sklearn.model_selection.TimeSeriesSplit.split", false]], "stackingclassifier (class in sklearn.ensemble)": [[575, "sklearn.ensemble.StackingClassifier", false]], "stackingregressor (class in sklearn.ensemble)": [[576, "sklearn.ensemble.StackingRegressor", false]], "staged_decision_function() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.staged_decision_function", false]], "staged_decision_function() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.staged_decision_function", false]], "staged_decision_function() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.staged_decision_function", false]], "staged_predict() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.staged_predict", false]], "staged_predict() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.staged_predict", false]], "staged_predict() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.staged_predict", false]], "staged_predict() (sklearn.ensemble.gradientboostingregressor method)": [[568, "sklearn.ensemble.GradientBoostingRegressor.staged_predict", false]], "staged_predict() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.staged_predict", false]], "staged_predict() (sklearn.ensemble.histgradientboostingregressor method)": [[570, "sklearn.ensemble.HistGradientBoostingRegressor.staged_predict", false]], "staged_predict_proba() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.staged_predict_proba", false]], "staged_predict_proba() (sklearn.ensemble.gradientboostingclassifier method)": [[567, "sklearn.ensemble.GradientBoostingClassifier.staged_predict_proba", false]], "staged_predict_proba() (sklearn.ensemble.histgradientboostingclassifier method)": [[569, "sklearn.ensemble.HistGradientBoostingClassifier.staged_predict_proba", false]], "staged_score() (sklearn.ensemble.adaboostclassifier method)": [[561, "sklearn.ensemble.AdaBoostClassifier.staged_score", false]], "staged_score() (sklearn.ensemble.adaboostregressor method)": [[562, "sklearn.ensemble.AdaBoostRegressor.staged_score", false]], "standardscaler (class in sklearn.preprocessing)": [[892, "sklearn.preprocessing.StandardScaler", false]], "stateless": [[400, "term-stateless", true]], "stratifiedgroupkfold (class in sklearn.model_selection)": [[826, "sklearn.model_selection.StratifiedGroupKFold", false]], "stratifiedkfold (class in sklearn.model_selection)": [[827, "sklearn.model_selection.StratifiedKFold", false]], "stratifiedshufflesplit (class in sklearn.model_selection)": [[828, "sklearn.model_selection.StratifiedShuffleSplit", false]], "sum (class in sklearn.gaussian_process.kernels)": [[632, "sklearn.gaussian_process.kernels.Sum", false]], "supervised": [[400, "term-supervised", true]], "supervised learning": [[400, "term-supervised-learning", true]], "svc (class in sklearn.svm)": [[917, "sklearn.svm.SVC", false]], "svr (class in sklearn.svm)": [[918, "sklearn.svm.SVR", false]], "target": [[400, "term-target", true]], "targetencoder (class in sklearn.preprocessing)": [[893, "sklearn.preprocessing.TargetEncoder", false]], "targets": [[400, "term-targets", true]], "tfidftransformer (class in sklearn.feature_extraction.text)": [[598, "sklearn.feature_extraction.text.TfidfTransformer", false]], "tfidfvectorizer (class in sklearn.feature_extraction.text)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer", false]], "theilsenregressor (class in sklearn.linear_model)": [[687, "sklearn.linear_model.TheilSenRegressor", false]], "theta (sklearn.gaussian_process.kernels.compoundkernel property)": [[620, "sklearn.gaussian_process.kernels.CompoundKernel.theta", false]], "theta (sklearn.gaussian_process.kernels.constantkernel property)": [[621, "sklearn.gaussian_process.kernels.ConstantKernel.theta", false]], "theta (sklearn.gaussian_process.kernels.dotproduct property)": [[622, "sklearn.gaussian_process.kernels.DotProduct.theta", false]], "theta (sklearn.gaussian_process.kernels.exponentiation property)": [[624, "sklearn.gaussian_process.kernels.Exponentiation.theta", false]], "theta (sklearn.gaussian_process.kernels.expsinesquared property)": [[623, "sklearn.gaussian_process.kernels.ExpSineSquared.theta", false]], "theta (sklearn.gaussian_process.kernels.kernel property)": [[626, "sklearn.gaussian_process.kernels.Kernel.theta", false]], "theta (sklearn.gaussian_process.kernels.matern property)": [[627, "sklearn.gaussian_process.kernels.Matern.theta", false]], "theta (sklearn.gaussian_process.kernels.pairwisekernel property)": [[628, "sklearn.gaussian_process.kernels.PairwiseKernel.theta", false]], "theta (sklearn.gaussian_process.kernels.product property)": [[629, "sklearn.gaussian_process.kernels.Product.theta", false]], "theta (sklearn.gaussian_process.kernels.rationalquadratic property)": [[631, "sklearn.gaussian_process.kernels.RationalQuadratic.theta", false]], "theta (sklearn.gaussian_process.kernels.rbf property)": [[630, "sklearn.gaussian_process.kernels.RBF.theta", false]], "theta (sklearn.gaussian_process.kernels.sum property)": [[632, "sklearn.gaussian_process.kernels.Sum.theta", false]], "theta (sklearn.gaussian_process.kernels.whitekernel property)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel.theta", false]], "threshold_ (sklearn.feature_selection.selectfrommodel property)": [[605, "sklearn.feature_selection.SelectFromModel.threshold_", false]], "timeseriessplit (class in sklearn.model_selection)": [[829, "sklearn.model_selection.TimeSeriesSplit", false]], "top_k_accuracy_score() (in module sklearn.metrics)": [[802, "sklearn.metrics.top_k_accuracy_score", false]], "train_test_split() (in module sklearn.model_selection)": [[838, "sklearn.model_selection.train_test_split", false]], "transduction": [[400, "term-transduction", true]], "transductive": [[400, "term-transductive", true]], "transform": [[400, "term-transform", true]], "transform() (sklearn.cluster.birch method)": [[450, "sklearn.cluster.Birch.transform", false]], "transform() (sklearn.cluster.bisectingkmeans method)": [[451, "sklearn.cluster.BisectingKMeans.transform", false]], "transform() (sklearn.cluster.featureagglomeration method)": [[453, "sklearn.cluster.FeatureAgglomeration.transform", false]], "transform() (sklearn.cluster.kmeans method)": [[455, "sklearn.cluster.KMeans.transform", false]], "transform() (sklearn.cluster.minibatchkmeans method)": [[457, "sklearn.cluster.MiniBatchKMeans.transform", false]], "transform() (sklearn.compose.columntransformer method)": [[472, "sklearn.compose.ColumnTransformer.transform", false]], "transform() (sklearn.cross_decomposition.cca method)": [[490, "sklearn.cross_decomposition.CCA.transform", false]], "transform() (sklearn.cross_decomposition.plscanonical method)": [[491, "sklearn.cross_decomposition.PLSCanonical.transform", false]], "transform() (sklearn.cross_decomposition.plsregression method)": [[492, "sklearn.cross_decomposition.PLSRegression.transform", false]], "transform() (sklearn.cross_decomposition.plssvd method)": [[493, "sklearn.cross_decomposition.PLSSVD.transform", false]], "transform() (sklearn.decomposition.dictionarylearning method)": [[539, "sklearn.decomposition.DictionaryLearning.transform", false]], "transform() (sklearn.decomposition.factoranalysis method)": [[540, "sklearn.decomposition.FactorAnalysis.transform", false]], "transform() (sklearn.decomposition.fastica method)": [[541, "sklearn.decomposition.FastICA.transform", false]], "transform() (sklearn.decomposition.incrementalpca method)": [[542, "sklearn.decomposition.IncrementalPCA.transform", false]], "transform() (sklearn.decomposition.kernelpca method)": [[543, "sklearn.decomposition.KernelPCA.transform", false]], "transform() (sklearn.decomposition.latentdirichletallocation method)": [[544, "sklearn.decomposition.LatentDirichletAllocation.transform", false]], "transform() (sklearn.decomposition.minibatchdictionarylearning method)": [[545, "sklearn.decomposition.MiniBatchDictionaryLearning.transform", false]], "transform() (sklearn.decomposition.minibatchnmf method)": [[546, "sklearn.decomposition.MiniBatchNMF.transform", false]], "transform() (sklearn.decomposition.minibatchsparsepca method)": [[547, "sklearn.decomposition.MiniBatchSparsePCA.transform", false]], "transform() (sklearn.decomposition.nmf method)": [[548, "sklearn.decomposition.NMF.transform", false]], "transform() (sklearn.decomposition.pca method)": [[549, "sklearn.decomposition.PCA.transform", false]], "transform() (sklearn.decomposition.sparsecoder method)": [[550, "sklearn.decomposition.SparseCoder.transform", false]], "transform() (sklearn.decomposition.sparsepca method)": [[551, "sklearn.decomposition.SparsePCA.transform", false]], "transform() (sklearn.decomposition.truncatedsvd method)": [[552, "sklearn.decomposition.TruncatedSVD.transform", false]], "transform() (sklearn.discriminant_analysis.lineardiscriminantanalysis method)": [[557, "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform", false]], "transform() (sklearn.ensemble.randomtreesembedding method)": [[574, "sklearn.ensemble.RandomTreesEmbedding.transform", false]], "transform() (sklearn.ensemble.stackingclassifier method)": [[575, "sklearn.ensemble.StackingClassifier.transform", false]], "transform() (sklearn.ensemble.stackingregressor method)": [[576, "sklearn.ensemble.StackingRegressor.transform", false]], "transform() (sklearn.ensemble.votingclassifier method)": [[577, "sklearn.ensemble.VotingClassifier.transform", false]], "transform() (sklearn.ensemble.votingregressor method)": [[578, "sklearn.ensemble.VotingRegressor.transform", false]], "transform() (sklearn.feature_extraction.dictvectorizer method)": [[589, "sklearn.feature_extraction.DictVectorizer.transform", false]], "transform() (sklearn.feature_extraction.featurehasher method)": [[590, "sklearn.feature_extraction.FeatureHasher.transform", false]], "transform() (sklearn.feature_extraction.image.patchextractor method)": [[591, "sklearn.feature_extraction.image.PatchExtractor.transform", false]], "transform() (sklearn.feature_extraction.text.countvectorizer method)": [[596, "sklearn.feature_extraction.text.CountVectorizer.transform", false]], "transform() (sklearn.feature_extraction.text.hashingvectorizer method)": [[597, "sklearn.feature_extraction.text.HashingVectorizer.transform", false]], "transform() (sklearn.feature_extraction.text.tfidftransformer method)": [[598, "sklearn.feature_extraction.text.TfidfTransformer.transform", false]], "transform() (sklearn.feature_extraction.text.tfidfvectorizer method)": [[599, "sklearn.feature_extraction.text.TfidfVectorizer.transform", false]], "transform() (sklearn.feature_selection.genericunivariateselect method)": [[600, "sklearn.feature_selection.GenericUnivariateSelect.transform", false]], "transform() (sklearn.feature_selection.rfe method)": [[601, "sklearn.feature_selection.RFE.transform", false]], "transform() (sklearn.feature_selection.rfecv method)": [[602, "sklearn.feature_selection.RFECV.transform", false]], "transform() (sklearn.feature_selection.selectfdr method)": [[603, "sklearn.feature_selection.SelectFdr.transform", false]], "transform() (sklearn.feature_selection.selectfpr method)": [[604, "sklearn.feature_selection.SelectFpr.transform", false]], "transform() (sklearn.feature_selection.selectfrommodel method)": [[605, "sklearn.feature_selection.SelectFromModel.transform", false]], "transform() (sklearn.feature_selection.selectfwe method)": [[606, "sklearn.feature_selection.SelectFwe.transform", false]], "transform() (sklearn.feature_selection.selectkbest method)": [[607, "sklearn.feature_selection.SelectKBest.transform", false]], "transform() (sklearn.feature_selection.selectormixin method)": [[609, "sklearn.feature_selection.SelectorMixin.transform", false]], "transform() (sklearn.feature_selection.selectpercentile method)": [[608, "sklearn.feature_selection.SelectPercentile.transform", false]], "transform() (sklearn.feature_selection.sequentialfeatureselector method)": [[610, "sklearn.feature_selection.SequentialFeatureSelector.transform", false]], "transform() (sklearn.feature_selection.variancethreshold method)": [[611, "sklearn.feature_selection.VarianceThreshold.transform", false]], "transform() (sklearn.impute.iterativeimputer method)": [[635, "sklearn.impute.IterativeImputer.transform", false]], "transform() (sklearn.impute.knnimputer method)": [[636, "sklearn.impute.KNNImputer.transform", false]], "transform() (sklearn.impute.missingindicator method)": [[637, "sklearn.impute.MissingIndicator.transform", false]], "transform() (sklearn.impute.simpleimputer method)": [[638, "sklearn.impute.SimpleImputer.transform", false]], "transform() (sklearn.isotonic.isotonicregression method)": [[643, "sklearn.isotonic.IsotonicRegression.transform", false]], "transform() (sklearn.kernel_approximation.additivechi2sampler method)": [[646, "sklearn.kernel_approximation.AdditiveChi2Sampler.transform", false]], "transform() (sklearn.kernel_approximation.nystroem method)": [[647, "sklearn.kernel_approximation.Nystroem.transform", false]], "transform() (sklearn.kernel_approximation.polynomialcountsketch method)": [[648, "sklearn.kernel_approximation.PolynomialCountSketch.transform", false]], "transform() (sklearn.kernel_approximation.rbfsampler method)": [[649, "sklearn.kernel_approximation.RBFSampler.transform", false]], "transform() (sklearn.kernel_approximation.skewedchi2sampler method)": [[650, "sklearn.kernel_approximation.SkewedChi2Sampler.transform", false]], "transform() (sklearn.manifold.isomap method)": [[696, "sklearn.manifold.Isomap.transform", false]], "transform() (sklearn.manifold.locallylinearembedding method)": [[697, "sklearn.manifold.LocallyLinearEmbedding.transform", false]], "transform() (sklearn.model_selection.gridsearchcv method)": [[808, "sklearn.model_selection.GridSearchCV.transform", false]], "transform() (sklearn.model_selection.halvinggridsearchcv method)": [[811, "sklearn.model_selection.HalvingGridSearchCV.transform", false]], "transform() (sklearn.model_selection.halvingrandomsearchcv method)": [[812, "sklearn.model_selection.HalvingRandomSearchCV.transform", false]], "transform() (sklearn.model_selection.randomizedsearchcv method)": [[822, "sklearn.model_selection.RandomizedSearchCV.transform", false]], "transform() (sklearn.neighbors.kneighborstransformer method)": [[856, "sklearn.neighbors.KNeighborsTransformer.transform", false]], "transform() (sklearn.neighbors.neighborhoodcomponentsanalysis method)": [[861, "sklearn.neighbors.NeighborhoodComponentsAnalysis.transform", false]], "transform() (sklearn.neighbors.radiusneighborstransformer method)": [[864, "sklearn.neighbors.RadiusNeighborsTransformer.transform", false]], "transform() (sklearn.neural_network.bernoullirbm method)": [[868, "sklearn.neural_network.BernoulliRBM.transform", false]], "transform() (sklearn.pipeline.featureunion method)": [[871, "sklearn.pipeline.FeatureUnion.transform", false]], "transform() (sklearn.pipeline.pipeline method)": [[872, "sklearn.pipeline.Pipeline.transform", false]], "transform() (sklearn.preprocessing.binarizer method)": [[875, "sklearn.preprocessing.Binarizer.transform", false]], "transform() (sklearn.preprocessing.functiontransformer method)": [[876, "sklearn.preprocessing.FunctionTransformer.transform", false]], "transform() (sklearn.preprocessing.kbinsdiscretizer method)": [[877, "sklearn.preprocessing.KBinsDiscretizer.transform", false]], "transform() (sklearn.preprocessing.kernelcenterer method)": [[878, "sklearn.preprocessing.KernelCenterer.transform", false]], "transform() (sklearn.preprocessing.labelbinarizer method)": [[879, "sklearn.preprocessing.LabelBinarizer.transform", false]], "transform() (sklearn.preprocessing.labelencoder method)": [[880, "sklearn.preprocessing.LabelEncoder.transform", false]], "transform() (sklearn.preprocessing.maxabsscaler method)": [[881, "sklearn.preprocessing.MaxAbsScaler.transform", false]], "transform() (sklearn.preprocessing.minmaxscaler method)": [[882, "sklearn.preprocessing.MinMaxScaler.transform", false]], "transform() (sklearn.preprocessing.multilabelbinarizer method)": [[883, "sklearn.preprocessing.MultiLabelBinarizer.transform", false]], "transform() (sklearn.preprocessing.normalizer method)": [[884, "sklearn.preprocessing.Normalizer.transform", false]], "transform() (sklearn.preprocessing.onehotencoder method)": [[885, "sklearn.preprocessing.OneHotEncoder.transform", false]], "transform() (sklearn.preprocessing.ordinalencoder method)": [[886, "sklearn.preprocessing.OrdinalEncoder.transform", false]], "transform() (sklearn.preprocessing.polynomialfeatures method)": [[887, "sklearn.preprocessing.PolynomialFeatures.transform", false]], "transform() (sklearn.preprocessing.powertransformer method)": [[888, "sklearn.preprocessing.PowerTransformer.transform", false]], "transform() (sklearn.preprocessing.quantiletransformer method)": [[889, "sklearn.preprocessing.QuantileTransformer.transform", false]], "transform() (sklearn.preprocessing.robustscaler method)": [[890, "sklearn.preprocessing.RobustScaler.transform", false]], "transform() (sklearn.preprocessing.splinetransformer method)": [[891, "sklearn.preprocessing.SplineTransformer.transform", false]], "transform() (sklearn.preprocessing.standardscaler method)": [[892, "sklearn.preprocessing.StandardScaler.transform", false]], "transform() (sklearn.preprocessing.targetencoder method)": [[893, "sklearn.preprocessing.TargetEncoder.transform", false]], "transform() (sklearn.random_projection.gaussianrandomprojection method)": [[904, "sklearn.random_projection.GaussianRandomProjection.transform", false]], "transform() (sklearn.random_projection.sparserandomprojection method)": [[905, "sklearn.random_projection.SparseRandomProjection.transform", false]], "transformedtargetregressor (class in sklearn.compose)": [[473, "sklearn.compose.TransformedTargetRegressor", false]], "transformer": [[400, "term-transformer", true]], "transformermixin (class in sklearn.base)": [[440, "sklearn.base.TransformerMixin", false]], "transformers": [[400, "term-transformers", true]], "truncatedsvd (class in sklearn.decomposition)": [[552, "sklearn.decomposition.TruncatedSVD", false]], "trustworthiness() (in module sklearn.manifold)": [[704, "sklearn.manifold.trustworthiness", false]], "tsne (class in sklearn.manifold)": [[700, "sklearn.manifold.TSNE", false]], "tunedthresholdclassifiercv (class in sklearn.model_selection)": [[830, "sklearn.model_selection.TunedThresholdClassifierCV", false]], "tweedieregressor (class in sklearn.linear_model)": [[688, "sklearn.linear_model.TweedieRegressor", false]], "two_point_correlation() (sklearn.neighbors.balltree method)": [[852, "sklearn.neighbors.BallTree.two_point_correlation", false]], "two_point_correlation() (sklearn.neighbors.kdtree method)": [[853, "sklearn.neighbors.KDTree.two_point_correlation", false]], "type_of_target() (in module sklearn.utils.multiclass)": [[963, "sklearn.utils.multiclass.type_of_target", false]], "undefinedmetricwarning": [[586, "sklearn.exceptions.UndefinedMetricWarning", false]], "unique_labels() (in module sklearn.utils.multiclass)": [[964, "sklearn.utils.multiclass.unique_labels", false]], "unlabeled": [[400, "term-unlabeled", true]], "unlabeled data": [[400, "term-unlabeled-data", true]], "unsupervised": [[400, "term-unsupervised", true]], "unsupervised learning": [[400, "term-unsupervised-learning", true]], "update() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.update", false]], "v_measure_score() (in module sklearn.metrics)": [[803, "sklearn.metrics.v_measure_score", false]], "validate_metadata() (sklearn.utils.metadata_routing.metadatarouter method)": [[957, "sklearn.utils.metadata_routing.MetadataRouter.validate_metadata", false]], "validation_curve() (in module sklearn.model_selection)": [[839, "sklearn.model_selection.validation_curve", false]], "validationcurvedisplay (class in sklearn.model_selection)": [[831, "sklearn.model_selection.ValidationCurveDisplay", false]], "value_type (sklearn.gaussian_process.kernels.hyperparameter attribute)": [[625, "sklearn.gaussian_process.kernels.Hyperparameter.value_type", false]], "values() (sklearn.utils.bunch method)": [[927, "sklearn.utils.Bunch.values", false]], "variancethreshold (class in sklearn.feature_selection)": [[611, "sklearn.feature_selection.VarianceThreshold", false]], "vectorizer": [[400, "term-vectorizer", true]], "vectorizers": [[400, "term-vectorizers", true]], "verbose": [[400, "term-verbose", true]], "votingclassifier (class in sklearn.ensemble)": [[577, "sklearn.ensemble.VotingClassifier", false]], "votingregressor (class in sklearn.ensemble)": [[578, "sklearn.ensemble.VotingRegressor", false]], "ward_tree() (in module sklearn.cluster)": [[471, "sklearn.cluster.ward_tree", false]], "warm_start": [[400, "term-warm_start", true]], "weighted_mode() (in module sklearn.utils.extmath)": [[951, "sklearn.utils.extmath.weighted_mode", false]], "whitekernel (class in sklearn.gaussian_process.kernels)": [[633, "sklearn.gaussian_process.kernels.WhiteKernel", false]], "x": [[400, "term-X", true]], "xt": [[400, "term-Xt", true]], "y": [[400, "term-Y", true], [400, "term-y", true]], "zero_one_loss() (in module sklearn.metrics)": [[804, "sklearn.metrics.zero_one_loss", false]]}, "objects": {"": [[3, 0, 0, "-", "sklearn"]], "sklearn": [[4, 0, 0, "-", "base"], [5, 0, 0, "-", "calibration"], [6, 0, 0, "-", "cluster"], [7, 0, 0, "-", "compose"], [476, 4, 1, "", "config_context"], [8, 0, 0, "-", "covariance"], [9, 0, 0, "-", "cross_decomposition"], [10, 0, 0, "-", "datasets"], [11, 0, 0, "-", "decomposition"], [12, 0, 0, "-", "discriminant_analysis"], [13, 0, 0, "-", "dummy"], [14, 0, 0, "-", "ensemble"], [15, 0, 0, "-", "exceptions"], [16, 0, 0, "-", "experimental"], [17, 0, 0, "-", "feature_extraction"], [18, 0, 0, "-", "feature_selection"], [19, 0, 0, "-", "gaussian_process"], [634, 4, 1, "", "get_config"], [20, 0, 0, "-", "impute"], [21, 0, 0, "-", "inspection"], [22, 0, 0, "-", "isotonic"], [23, 0, 0, "-", "kernel_approximation"], [24, 0, 0, "-", "kernel_ridge"], [25, 0, 0, "-", "linear_model"], [26, 0, 0, "-", "manifold"], [27, 0, 0, "-", "metrics"], [28, 0, 0, "-", "mixture"], [29, 0, 0, "-", "model_selection"], [30, 0, 0, "-", "multiclass"], [31, 0, 0, "-", "multioutput"], [32, 0, 0, "-", "naive_bayes"], [33, 0, 0, "-", "neighbors"], [34, 0, 0, "-", "neural_network"], [35, 0, 0, "-", "pipeline"], [36, 0, 0, "-", "preprocessing"], [37, 0, 0, "-", "random_projection"], [38, 0, 0, "-", "semi_supervised"], [910, 4, 1, "", "set_config"], [911, 4, 1, "", "show_versions"], [39, 0, 0, "-", "svm"], [40, 0, 0, "-", "tree"], [41, 0, 0, "-", "utils"]], "sklearn.base": [[430, 1, 1, "", "BaseEstimator"], [431, 1, 1, "", "BiclusterMixin"], [432, 1, 1, "", "ClassNamePrefixFeaturesOutMixin"], [433, 1, 1, "", "ClassifierMixin"], [434, 1, 1, "", "ClusterMixin"], [435, 1, 1, "", "DensityMixin"], [436, 1, 1, "", "MetaEstimatorMixin"], [437, 1, 1, "", "OneToOneFeatureMixin"], [438, 1, 1, "", "OutlierMixin"], [439, 1, 1, "", "RegressorMixin"], [440, 1, 1, "", "TransformerMixin"], [441, 4, 1, "", "clone"], [442, 4, 1, "", "is_classifier"], [443, 4, 1, "", "is_clusterer"], [444, 4, 1, "", "is_regressor"]], "sklearn.base.BaseEstimator": [[430, 2, 1, "", "get_metadata_routing"], [430, 2, 1, "", "get_params"], [430, 2, 1, "", "set_params"]], "sklearn.base.BiclusterMixin": [[431, 3, 1, "", "biclusters_"], [431, 2, 1, "", "get_indices"], [431, 2, 1, "", "get_shape"], [431, 2, 1, "", "get_submatrix"]], "sklearn.base.ClassNamePrefixFeaturesOutMixin": [[432, 2, 1, "", "get_feature_names_out"]], "sklearn.base.ClassifierMixin": [[433, 2, 1, "", "score"]], "sklearn.base.ClusterMixin": [[434, 2, 1, "", "fit_predict"]], "sklearn.base.DensityMixin": [[435, 2, 1, "", "score"]], "sklearn.base.OneToOneFeatureMixin": [[437, 2, 1, "", "get_feature_names_out"]], "sklearn.base.OutlierMixin": [[438, 2, 1, "", "fit_predict"]], "sklearn.base.RegressorMixin": [[439, 2, 1, "", "score"]], "sklearn.base.TransformerMixin": [[440, 2, 1, "", "fit_transform"], [440, 2, 1, "", "set_output"]], "sklearn.calibration": [[445, 1, 1, "", "CalibratedClassifierCV"], [446, 1, 1, "", "CalibrationDisplay"], [447, 4, 1, "", "calibration_curve"]], "sklearn.calibration.CalibratedClassifierCV": [[445, 2, 1, "", "fit"], [445, 2, 1, "", "get_metadata_routing"], [445, 2, 1, "", "get_params"], [445, 2, 1, "", "predict"], [445, 2, 1, "", "predict_proba"], [445, 2, 1, "", "score"], [445, 2, 1, "", "set_fit_request"], [445, 2, 1, "", "set_params"], [445, 2, 1, "", "set_score_request"]], "sklearn.calibration.CalibrationDisplay": [[446, 2, 1, "", "from_estimator"], [446, 2, 1, "", "from_predictions"], [446, 2, 1, "", "plot"]], "sklearn.cluster": [[448, 1, 1, "", "AffinityPropagation"], [449, 1, 1, "", "AgglomerativeClustering"], [450, 1, 1, "", "Birch"], [451, 1, 1, "", "BisectingKMeans"], [452, 1, 1, "", "DBSCAN"], [453, 1, 1, "", "FeatureAgglomeration"], [454, 1, 1, "", "HDBSCAN"], [455, 1, 1, "", "KMeans"], [456, 1, 1, "", "MeanShift"], [457, 1, 1, "", "MiniBatchKMeans"], [458, 1, 1, "", "OPTICS"], [459, 1, 1, "", "SpectralBiclustering"], [460, 1, 1, "", "SpectralClustering"], [461, 1, 1, "", "SpectralCoclustering"], [462, 4, 1, "", "affinity_propagation"], [463, 4, 1, "", "cluster_optics_dbscan"], [464, 4, 1, "", "cluster_optics_xi"], [465, 4, 1, "", "compute_optics_graph"], [427, 4, 1, "", "dbscan"], [466, 4, 1, "", "estimate_bandwidth"], [467, 4, 1, "", "k_means"], [468, 4, 1, "", "kmeans_plusplus"], [469, 4, 1, "", "mean_shift"], [470, 4, 1, "", "spectral_clustering"], [471, 4, 1, "", "ward_tree"]], "sklearn.cluster.AffinityPropagation": [[448, 2, 1, "", "fit"], [448, 2, 1, "", "fit_predict"], [448, 2, 1, "", "get_metadata_routing"], [448, 2, 1, "", "get_params"], [448, 2, 1, "", "predict"], [448, 2, 1, "", "set_params"]], "sklearn.cluster.AgglomerativeClustering": [[449, 2, 1, "", "fit"], [449, 2, 1, "", "fit_predict"], [449, 2, 1, "", "get_metadata_routing"], [449, 2, 1, "", "get_params"], [449, 2, 1, "", "set_params"]], "sklearn.cluster.Birch": [[450, 2, 1, "", "fit"], [450, 2, 1, "", "fit_predict"], [450, 2, 1, "", "fit_transform"], [450, 2, 1, "", "get_feature_names_out"], [450, 2, 1, "", "get_metadata_routing"], [450, 2, 1, "", "get_params"], [450, 2, 1, "", "partial_fit"], [450, 2, 1, "", "predict"], [450, 2, 1, "", "set_output"], [450, 2, 1, "", "set_params"], [450, 2, 1, "", "transform"]], "sklearn.cluster.BisectingKMeans": [[451, 2, 1, "", "fit"], [451, 2, 1, "", "fit_predict"], [451, 2, 1, "", "fit_transform"], [451, 2, 1, "", "get_feature_names_out"], [451, 2, 1, "", "get_metadata_routing"], [451, 2, 1, "", "get_params"], [451, 2, 1, "", "predict"], [451, 2, 1, "", "score"], [451, 2, 1, "", "set_fit_request"], [451, 2, 1, "", "set_output"], [451, 2, 1, "", "set_params"], [451, 2, 1, "", "set_score_request"], [451, 2, 1, "", "transform"]], "sklearn.cluster.DBSCAN": [[452, 2, 1, "", "fit"], [452, 2, 1, "", "fit_predict"], [452, 2, 1, "", "get_metadata_routing"], [452, 2, 1, "", "get_params"], [452, 2, 1, "", "set_fit_request"], [452, 2, 1, "", "set_params"]], "sklearn.cluster.FeatureAgglomeration": [[453, 2, 1, "", "fit"], [453, 3, 1, "", "fit_predict"], [453, 2, 1, "", "fit_transform"], [453, 2, 1, "", "get_feature_names_out"], [453, 2, 1, "", "get_metadata_routing"], [453, 2, 1, "", "get_params"], [453, 2, 1, "", "inverse_transform"], [453, 2, 1, "", "set_output"], [453, 2, 1, "", "set_params"], [453, 2, 1, "", "transform"]], "sklearn.cluster.HDBSCAN": [[454, 2, 1, "", "dbscan_clustering"], [454, 2, 1, "", "fit"], [454, 2, 1, "", "fit_predict"], [454, 2, 1, "", "get_metadata_routing"], [454, 2, 1, "", "get_params"], [454, 2, 1, "", "set_params"]], "sklearn.cluster.KMeans": [[455, 2, 1, "", "fit"], [455, 2, 1, "", "fit_predict"], [455, 2, 1, "", "fit_transform"], [455, 2, 1, "", "get_feature_names_out"], [455, 2, 1, "", "get_metadata_routing"], [455, 2, 1, "", "get_params"], [455, 2, 1, "", "predict"], [455, 2, 1, "", "score"], [455, 2, 1, "", "set_fit_request"], [455, 2, 1, "", "set_output"], [455, 2, 1, "", "set_params"], [455, 2, 1, "", "set_score_request"], [455, 2, 1, "", "transform"]], "sklearn.cluster.MeanShift": [[456, 2, 1, "", "fit"], [456, 2, 1, "", "fit_predict"], [456, 2, 1, "", "get_metadata_routing"], [456, 2, 1, "", "get_params"], [456, 2, 1, "", "predict"], [456, 2, 1, "", "set_params"]], "sklearn.cluster.MiniBatchKMeans": [[457, 2, 1, "", "fit"], [457, 2, 1, "", "fit_predict"], [457, 2, 1, "", "fit_transform"], [457, 2, 1, "", "get_feature_names_out"], [457, 2, 1, "", "get_metadata_routing"], [457, 2, 1, "", "get_params"], [457, 2, 1, "", "partial_fit"], [457, 2, 1, "", "predict"], [457, 2, 1, "", "score"], [457, 2, 1, "", "set_fit_request"], [457, 2, 1, "", "set_output"], [457, 2, 1, "", "set_params"], [457, 2, 1, "", "set_partial_fit_request"], [457, 2, 1, "", "set_score_request"], [457, 2, 1, "", "transform"]], "sklearn.cluster.OPTICS": [[458, 2, 1, "", "fit"], [458, 2, 1, "", "fit_predict"], [458, 2, 1, "", "get_metadata_routing"], [458, 2, 1, "", "get_params"], [458, 2, 1, "", "set_params"]], "sklearn.cluster.SpectralBiclustering": [[459, 3, 1, "", "biclusters_"], [459, 2, 1, "", "fit"], [459, 2, 1, "", "get_indices"], [459, 2, 1, "", "get_metadata_routing"], [459, 2, 1, "", "get_params"], [459, 2, 1, "", "get_shape"], [459, 2, 1, "", "get_submatrix"], [459, 2, 1, "", "set_params"]], "sklearn.cluster.SpectralClustering": [[460, 2, 1, "", "fit"], [460, 2, 1, "", "fit_predict"], [460, 2, 1, "", "get_metadata_routing"], [460, 2, 1, "", "get_params"], [460, 2, 1, "", "set_params"]], "sklearn.cluster.SpectralCoclustering": [[461, 3, 1, "", "biclusters_"], [461, 2, 1, "", "fit"], [461, 2, 1, "", "get_indices"], [461, 2, 1, "", "get_metadata_routing"], [461, 2, 1, "", "get_params"], [461, 2, 1, "", "get_shape"], [461, 2, 1, "", "get_submatrix"], [461, 2, 1, "", "set_params"]], "sklearn.compose": [[472, 1, 1, "", "ColumnTransformer"], [473, 1, 1, "", "TransformedTargetRegressor"], [474, 1, 1, "", "make_column_selector"], [475, 4, 1, "", "make_column_transformer"]], "sklearn.compose.ColumnTransformer": [[472, 2, 1, "", "fit"], [472, 2, 1, "", "fit_transform"], [472, 2, 1, "", "get_feature_names_out"], [472, 2, 1, "", "get_metadata_routing"], [472, 2, 1, "", "get_params"], [472, 3, 1, "", "named_transformers_"], [472, 2, 1, "", "set_output"], [472, 2, 1, "", "set_params"], [472, 2, 1, "", "transform"]], "sklearn.compose.TransformedTargetRegressor": [[473, 2, 1, "", "fit"], [473, 2, 1, "", "get_metadata_routing"], [473, 2, 1, "", "get_params"], [473, 3, 1, "", "n_features_in_"], [473, 2, 1, "", "predict"], [473, 2, 1, "", "score"], [473, 2, 1, "", "set_params"], [473, 2, 1, "", "set_score_request"]], "sklearn.compose.make_column_selector": [[474, 2, 1, "", "__call__"]], "sklearn.covariance": [[477, 1, 1, "", "EllipticEnvelope"], [478, 1, 1, "", "EmpiricalCovariance"], [479, 1, 1, "", "GraphicalLasso"], [480, 1, 1, "", "GraphicalLassoCV"], [481, 1, 1, "", "LedoitWolf"], [482, 1, 1, "", "MinCovDet"], [483, 1, 1, "", "OAS"], [484, 1, 1, "", "ShrunkCovariance"], [485, 4, 1, "", "empirical_covariance"], [486, 4, 1, "", "graphical_lasso"], [487, 4, 1, "", "ledoit_wolf"], [488, 4, 1, "", "ledoit_wolf_shrinkage"], [429, 4, 1, "", "oas"], [489, 4, 1, "", "shrunk_covariance"]], "sklearn.covariance.EllipticEnvelope": [[477, 2, 1, "", "correct_covariance"], [477, 2, 1, "", "decision_function"], [477, 2, 1, "", "error_norm"], [477, 2, 1, "", "fit"], [477, 2, 1, "", "fit_predict"], [477, 2, 1, "", "get_metadata_routing"], [477, 2, 1, "", "get_params"], [477, 2, 1, "", "get_precision"], [477, 2, 1, "", "mahalanobis"], [477, 2, 1, "", "predict"], [477, 2, 1, "", "reweight_covariance"], [477, 2, 1, "", "score"], [477, 2, 1, "", "score_samples"], [477, 2, 1, "", "set_params"], [477, 2, 1, "", "set_score_request"]], "sklearn.covariance.EmpiricalCovariance": [[478, 2, 1, "", "error_norm"], [478, 2, 1, "", "fit"], [478, 2, 1, "", "get_metadata_routing"], [478, 2, 1, "", "get_params"], [478, 2, 1, "", "get_precision"], [478, 2, 1, "", "mahalanobis"], [478, 2, 1, "", "score"], [478, 2, 1, "", "set_params"], [478, 2, 1, "", "set_score_request"]], "sklearn.covariance.GraphicalLasso": [[479, 2, 1, "", "error_norm"], [479, 2, 1, "", "fit"], [479, 2, 1, "", "get_metadata_routing"], [479, 2, 1, "", "get_params"], [479, 2, 1, "", "get_precision"], [479, 2, 1, "", "mahalanobis"], [479, 2, 1, "", "score"], [479, 2, 1, "", "set_params"], [479, 2, 1, "", "set_score_request"]], "sklearn.covariance.GraphicalLassoCV": [[480, 2, 1, "", "error_norm"], [480, 2, 1, "", "fit"], [480, 2, 1, "", "get_metadata_routing"], [480, 2, 1, "", "get_params"], [480, 2, 1, "", "get_precision"], [480, 2, 1, "", "mahalanobis"], [480, 2, 1, "", "score"], [480, 2, 1, "", "set_params"], [480, 2, 1, "", "set_score_request"]], "sklearn.covariance.LedoitWolf": [[481, 2, 1, "", "error_norm"], [481, 2, 1, "", "fit"], [481, 2, 1, "", "get_metadata_routing"], [481, 2, 1, "", "get_params"], [481, 2, 1, "", "get_precision"], [481, 2, 1, "", "mahalanobis"], [481, 2, 1, "", "score"], [481, 2, 1, "", "set_params"], [481, 2, 1, "", "set_score_request"]], "sklearn.covariance.MinCovDet": [[482, 2, 1, "", "correct_covariance"], [482, 2, 1, "", "error_norm"], [482, 2, 1, "", "fit"], [482, 2, 1, "", "get_metadata_routing"], [482, 2, 1, "", "get_params"], [482, 2, 1, "", "get_precision"], [482, 2, 1, "", "mahalanobis"], [482, 2, 1, "", "reweight_covariance"], [482, 2, 1, "", "score"], [482, 2, 1, "", "set_params"], [482, 2, 1, "", "set_score_request"]], "sklearn.covariance.OAS": [[483, 2, 1, "", "error_norm"], [483, 2, 1, "", "fit"], [483, 2, 1, "", "get_metadata_routing"], [483, 2, 1, "", "get_params"], [483, 2, 1, "", "get_precision"], [483, 2, 1, "", "mahalanobis"], [483, 2, 1, "", "score"], [483, 2, 1, "", "set_params"], [483, 2, 1, "", "set_score_request"]], "sklearn.covariance.ShrunkCovariance": [[484, 2, 1, "", "error_norm"], [484, 2, 1, "", "fit"], [484, 2, 1, "", "get_metadata_routing"], [484, 2, 1, "", "get_params"], [484, 2, 1, "", "get_precision"], [484, 2, 1, "", "mahalanobis"], [484, 2, 1, "", "score"], [484, 2, 1, "", "set_params"], [484, 2, 1, "", "set_score_request"]], "sklearn.cross_decomposition": [[490, 1, 1, "", "CCA"], [491, 1, 1, "", "PLSCanonical"], [492, 1, 1, "", "PLSRegression"], [493, 1, 1, "", "PLSSVD"]], "sklearn.cross_decomposition.CCA": [[490, 2, 1, "", "fit"], [490, 2, 1, "", "fit_transform"], [490, 2, 1, "", "get_feature_names_out"], [490, 2, 1, "", "get_metadata_routing"], [490, 2, 1, "", "get_params"], [490, 2, 1, "", "inverse_transform"], [490, 2, 1, "", "predict"], [490, 2, 1, "", "score"], [490, 2, 1, "", "set_output"], [490, 2, 1, "", "set_params"], [490, 2, 1, "", "set_predict_request"], [490, 2, 1, "", "set_score_request"], [490, 2, 1, "", "set_transform_request"], [490, 2, 1, "", "transform"]], "sklearn.cross_decomposition.PLSCanonical": [[491, 2, 1, "", "fit"], [491, 2, 1, "", "fit_transform"], [491, 2, 1, "", "get_feature_names_out"], [491, 2, 1, "", "get_metadata_routing"], [491, 2, 1, "", "get_params"], [491, 2, 1, "", "inverse_transform"], [491, 2, 1, "", "predict"], [491, 2, 1, "", "score"], [491, 2, 1, "", "set_output"], [491, 2, 1, "", "set_params"], [491, 2, 1, "", "set_predict_request"], [491, 2, 1, "", "set_score_request"], [491, 2, 1, "", "set_transform_request"], [491, 2, 1, "", "transform"]], "sklearn.cross_decomposition.PLSRegression": [[492, 2, 1, "", "fit"], [492, 2, 1, "", "fit_transform"], [492, 2, 1, "", "get_feature_names_out"], [492, 2, 1, "", "get_metadata_routing"], [492, 2, 1, "", "get_params"], [492, 2, 1, "", "inverse_transform"], [492, 2, 1, "", "predict"], [492, 2, 1, "", "score"], [492, 2, 1, "", "set_output"], [492, 2, 1, "", "set_params"], [492, 2, 1, "", "set_predict_request"], [492, 2, 1, "", "set_score_request"], [492, 2, 1, "", "set_transform_request"], [492, 2, 1, "", "transform"]], "sklearn.cross_decomposition.PLSSVD": [[493, 2, 1, "", "fit"], [493, 2, 1, "", "fit_transform"], [493, 2, 1, "", "get_feature_names_out"], [493, 2, 1, "", "get_metadata_routing"], [493, 2, 1, "", "get_params"], [493, 2, 1, "", "set_output"], [493, 2, 1, "", "set_params"], [493, 2, 1, "", "transform"]], "sklearn.datasets": [[494, 4, 1, "", "clear_data_home"], [495, 4, 1, "", "dump_svmlight_file"], [496, 4, 1, "", "fetch_20newsgroups"], [497, 4, 1, "", "fetch_20newsgroups_vectorized"], [498, 4, 1, "", "fetch_california_housing"], [499, 4, 1, "", "fetch_covtype"], [500, 4, 1, "", "fetch_kddcup99"], [501, 4, 1, "", "fetch_lfw_pairs"], [502, 4, 1, "", "fetch_lfw_people"], [503, 4, 1, "", "fetch_olivetti_faces"], [504, 4, 1, "", "fetch_openml"], [505, 4, 1, "", "fetch_rcv1"], [506, 4, 1, "", "fetch_species_distributions"], [507, 4, 1, "", "get_data_home"], [508, 4, 1, "", "load_breast_cancer"], [509, 4, 1, "", "load_diabetes"], [510, 4, 1, "", "load_digits"], [511, 4, 1, "", "load_files"], [512, 4, 1, "", "load_iris"], [513, 4, 1, "", "load_linnerud"], [514, 4, 1, "", "load_sample_image"], [515, 4, 1, "", "load_sample_images"], [516, 4, 1, "", "load_svmlight_file"], [517, 4, 1, "", "load_svmlight_files"], [518, 4, 1, "", "load_wine"], [519, 4, 1, "", "make_biclusters"], [520, 4, 1, "", "make_blobs"], [521, 4, 1, "", "make_checkerboard"], [522, 4, 1, "", "make_circles"], [523, 4, 1, "", "make_classification"], [524, 4, 1, "", "make_friedman1"], [525, 4, 1, "", "make_friedman2"], [526, 4, 1, "", "make_friedman3"], [527, 4, 1, "", "make_gaussian_quantiles"], [528, 4, 1, "", "make_hastie_10_2"], [529, 4, 1, "", "make_low_rank_matrix"], [530, 4, 1, "", "make_moons"], [531, 4, 1, "", "make_multilabel_classification"], [532, 4, 1, "", "make_regression"], [533, 4, 1, "", "make_s_curve"], [534, 4, 1, "", "make_sparse_coded_signal"], [535, 4, 1, "", "make_sparse_spd_matrix"], [536, 4, 1, "", "make_sparse_uncorrelated"], [537, 4, 1, "", "make_spd_matrix"], [538, 4, 1, "", "make_swiss_roll"]], "sklearn.decomposition": [[539, 1, 1, "", "DictionaryLearning"], [540, 1, 1, "", "FactorAnalysis"], [541, 1, 1, "", "FastICA"], [542, 1, 1, "", "IncrementalPCA"], [543, 1, 1, "", "KernelPCA"], [544, 1, 1, "", "LatentDirichletAllocation"], [545, 1, 1, "", "MiniBatchDictionaryLearning"], [546, 1, 1, "", "MiniBatchNMF"], [547, 1, 1, "", "MiniBatchSparsePCA"], [548, 1, 1, "", "NMF"], [549, 1, 1, "", "PCA"], [550, 1, 1, "", "SparseCoder"], [551, 1, 1, "", "SparsePCA"], [552, 1, 1, "", "TruncatedSVD"], [553, 4, 1, "", "dict_learning"], [554, 4, 1, "", "dict_learning_online"], [428, 4, 1, "", "fastica"], [555, 4, 1, "", "non_negative_factorization"], [556, 4, 1, "", "sparse_encode"]], "sklearn.decomposition.DictionaryLearning": [[539, 2, 1, "", "fit"], [539, 2, 1, "", "fit_transform"], [539, 2, 1, "", "get_feature_names_out"], [539, 2, 1, "", "get_metadata_routing"], [539, 2, 1, "", "get_params"], [539, 2, 1, "", "set_output"], [539, 2, 1, "", "set_params"], [539, 2, 1, "", "transform"]], "sklearn.decomposition.FactorAnalysis": [[540, 2, 1, "", "fit"], [540, 2, 1, "", "fit_transform"], [540, 2, 1, "", "get_covariance"], [540, 2, 1, "", "get_feature_names_out"], [540, 2, 1, "", "get_metadata_routing"], [540, 2, 1, "", "get_params"], [540, 2, 1, "", "get_precision"], [540, 2, 1, "", "score"], [540, 2, 1, "", "score_samples"], [540, 2, 1, "", "set_output"], [540, 2, 1, "", "set_params"], [540, 2, 1, "", "transform"]], "sklearn.decomposition.FastICA": [[541, 2, 1, "", "fit"], [541, 2, 1, "", "fit_transform"], [541, 2, 1, "", "get_feature_names_out"], [541, 2, 1, "", "get_metadata_routing"], [541, 2, 1, "", "get_params"], [541, 2, 1, "", "inverse_transform"], [541, 2, 1, "", "set_inverse_transform_request"], [541, 2, 1, "", "set_output"], [541, 2, 1, "", "set_params"], [541, 2, 1, "", "set_transform_request"], [541, 2, 1, "", "transform"]], "sklearn.decomposition.IncrementalPCA": [[542, 2, 1, "", "fit"], [542, 2, 1, "", "fit_transform"], [542, 2, 1, "", "get_covariance"], [542, 2, 1, "", "get_feature_names_out"], [542, 2, 1, "", "get_metadata_routing"], [542, 2, 1, "", "get_params"], [542, 2, 1, "", "get_precision"], [542, 2, 1, "", "inverse_transform"], [542, 2, 1, "", "partial_fit"], [542, 2, 1, "", "set_output"], [542, 2, 1, "", "set_params"], [542, 2, 1, "", "set_partial_fit_request"], [542, 2, 1, "", "transform"]], "sklearn.decomposition.KernelPCA": [[543, 2, 1, "", "fit"], [543, 2, 1, "", "fit_transform"], [543, 2, 1, "", "get_feature_names_out"], [543, 2, 1, "", "get_metadata_routing"], [543, 2, 1, "", "get_params"], [543, 2, 1, "", "inverse_transform"], [543, 2, 1, "", "set_output"], [543, 2, 1, "", "set_params"], [543, 2, 1, "", "transform"]], "sklearn.decomposition.LatentDirichletAllocation": [[544, 2, 1, "", "fit"], [544, 2, 1, "", "fit_transform"], [544, 2, 1, "", "get_feature_names_out"], [544, 2, 1, "", "get_metadata_routing"], [544, 2, 1, "", "get_params"], [544, 2, 1, "", "partial_fit"], [544, 2, 1, "", "perplexity"], [544, 2, 1, "", "score"], [544, 2, 1, "", "set_output"], [544, 2, 1, "", "set_params"], [544, 2, 1, "", "transform"]], "sklearn.decomposition.MiniBatchDictionaryLearning": [[545, 2, 1, "", "fit"], [545, 2, 1, "", "fit_transform"], [545, 2, 1, "", "get_feature_names_out"], [545, 2, 1, "", "get_metadata_routing"], [545, 2, 1, "", "get_params"], [545, 2, 1, "", "partial_fit"], [545, 2, 1, "", "set_output"], [545, 2, 1, "", "set_params"], [545, 2, 1, "", "transform"]], "sklearn.decomposition.MiniBatchNMF": [[546, 2, 1, "", "fit"], [546, 2, 1, "", "fit_transform"], [546, 2, 1, "", "get_feature_names_out"], [546, 2, 1, "", "get_metadata_routing"], [546, 2, 1, "", "get_params"], [546, 2, 1, "", "inverse_transform"], [546, 2, 1, "", "partial_fit"], [546, 2, 1, "", "set_output"], [546, 2, 1, "", "set_params"], [546, 2, 1, "", "transform"]], "sklearn.decomposition.MiniBatchSparsePCA": [[547, 2, 1, "", "fit"], [547, 2, 1, "", "fit_transform"], [547, 2, 1, "", "get_feature_names_out"], [547, 2, 1, "", "get_metadata_routing"], [547, 2, 1, "", "get_params"], [547, 2, 1, "", "inverse_transform"], [547, 2, 1, "", "set_output"], [547, 2, 1, "", "set_params"], [547, 2, 1, "", "transform"]], "sklearn.decomposition.NMF": [[548, 2, 1, "", "fit"], [548, 2, 1, "", "fit_transform"], [548, 2, 1, "", "get_feature_names_out"], [548, 2, 1, "", "get_metadata_routing"], [548, 2, 1, "", "get_params"], [548, 2, 1, "", "inverse_transform"], [548, 2, 1, "", "set_output"], [548, 2, 1, "", "set_params"], [548, 2, 1, "", "transform"]], "sklearn.decomposition.PCA": [[549, 2, 1, "", "fit"], [549, 2, 1, "", "fit_transform"], [549, 2, 1, "", "get_covariance"], [549, 2, 1, "", "get_feature_names_out"], [549, 2, 1, "", "get_metadata_routing"], [549, 2, 1, "", "get_params"], [549, 2, 1, "", "get_precision"], [549, 2, 1, "", "inverse_transform"], [549, 2, 1, "", "score"], [549, 2, 1, "", "score_samples"], [549, 2, 1, "", "set_output"], [549, 2, 1, "", "set_params"], [549, 2, 1, "", "transform"]], "sklearn.decomposition.SparseCoder": [[550, 2, 1, "", "fit"], [550, 2, 1, "", "fit_transform"], [550, 2, 1, "", "get_feature_names_out"], [550, 2, 1, "", "get_metadata_routing"], [550, 2, 1, "", "get_params"], [550, 3, 1, "", "n_components_"], [550, 3, 1, "", "n_features_in_"], [550, 2, 1, "", "set_output"], [550, 2, 1, "", "set_params"], [550, 2, 1, "", "transform"]], "sklearn.decomposition.SparsePCA": [[551, 2, 1, "", "fit"], [551, 2, 1, "", "fit_transform"], [551, 2, 1, "", "get_feature_names_out"], [551, 2, 1, "", "get_metadata_routing"], [551, 2, 1, "", "get_params"], [551, 2, 1, "", "inverse_transform"], [551, 2, 1, "", "set_output"], [551, 2, 1, "", "set_params"], [551, 2, 1, "", "transform"]], "sklearn.decomposition.TruncatedSVD": [[552, 2, 1, "", "fit"], [552, 2, 1, "", "fit_transform"], [552, 2, 1, "", "get_feature_names_out"], [552, 2, 1, "", "get_metadata_routing"], [552, 2, 1, "", "get_params"], [552, 2, 1, "", "inverse_transform"], [552, 2, 1, "", "set_output"], [552, 2, 1, "", "set_params"], [552, 2, 1, "", "transform"]], "sklearn.discriminant_analysis": [[557, 1, 1, "", "LinearDiscriminantAnalysis"], [558, 1, 1, "", "QuadraticDiscriminantAnalysis"]], "sklearn.discriminant_analysis.LinearDiscriminantAnalysis": [[557, 2, 1, "", "decision_function"], [557, 2, 1, "", "fit"], [557, 2, 1, "", "fit_transform"], [557, 2, 1, "", "get_feature_names_out"], [557, 2, 1, "", "get_metadata_routing"], [557, 2, 1, "", "get_params"], [557, 2, 1, "", "predict"], [557, 2, 1, "", "predict_log_proba"], [557, 2, 1, "", "predict_proba"], [557, 2, 1, "", "score"], [557, 2, 1, "", "set_output"], [557, 2, 1, "", "set_params"], [557, 2, 1, "", "set_score_request"], [557, 2, 1, "", "transform"]], "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis": [[558, 2, 1, "", "decision_function"], [558, 2, 1, "", "fit"], [558, 2, 1, "", "get_metadata_routing"], [558, 2, 1, "", "get_params"], [558, 2, 1, "", "predict"], [558, 2, 1, "", "predict_log_proba"], [558, 2, 1, "", "predict_proba"], [558, 2, 1, "", "score"], [558, 2, 1, "", "set_params"], [558, 2, 1, "", "set_score_request"]], "sklearn.dummy": [[559, 1, 1, "", "DummyClassifier"], [560, 1, 1, "", "DummyRegressor"]], "sklearn.dummy.DummyClassifier": [[559, 2, 1, "", "fit"], [559, 2, 1, "", "get_metadata_routing"], [559, 2, 1, "", "get_params"], [559, 2, 1, "", "predict"], [559, 2, 1, "", "predict_log_proba"], [559, 2, 1, "", "predict_proba"], [559, 2, 1, "", "score"], [559, 2, 1, "", "set_fit_request"], [559, 2, 1, "", "set_params"], [559, 2, 1, "", "set_score_request"]], "sklearn.dummy.DummyRegressor": [[560, 2, 1, "", "fit"], [560, 2, 1, "", "get_metadata_routing"], [560, 2, 1, "", "get_params"], [560, 2, 1, "", "predict"], [560, 2, 1, "", "score"], [560, 2, 1, "", "set_fit_request"], [560, 2, 1, "", "set_params"], [560, 2, 1, "", "set_predict_request"], [560, 2, 1, "", "set_score_request"]], "sklearn.ensemble": [[561, 1, 1, "", "AdaBoostClassifier"], [562, 1, 1, "", "AdaBoostRegressor"], [563, 1, 1, "", "BaggingClassifier"], [564, 1, 1, "", "BaggingRegressor"], [565, 1, 1, "", "ExtraTreesClassifier"], [566, 1, 1, "", "ExtraTreesRegressor"], [567, 1, 1, "", "GradientBoostingClassifier"], [568, 1, 1, "", "GradientBoostingRegressor"], [569, 1, 1, "", "HistGradientBoostingClassifier"], [570, 1, 1, "", "HistGradientBoostingRegressor"], [571, 1, 1, "", "IsolationForest"], [572, 1, 1, "", "RandomForestClassifier"], [573, 1, 1, "", "RandomForestRegressor"], [574, 1, 1, "", "RandomTreesEmbedding"], [575, 1, 1, "", "StackingClassifier"], [576, 1, 1, "", "StackingRegressor"], [577, 1, 1, "", "VotingClassifier"], [578, 1, 1, "", "VotingRegressor"]], "sklearn.ensemble.AdaBoostClassifier": [[561, 2, 1, "", "decision_function"], [561, 3, 1, "", "feature_importances_"], [561, 2, 1, "", "fit"], [561, 2, 1, "", "get_metadata_routing"], [561, 2, 1, "", "get_params"], [561, 2, 1, "", "predict"], [561, 2, 1, "", "predict_log_proba"], [561, 2, 1, "", "predict_proba"], [561, 2, 1, "", "score"], [561, 2, 1, "", "set_fit_request"], [561, 2, 1, "", "set_params"], [561, 2, 1, "", "set_score_request"], [561, 2, 1, "", "staged_decision_function"], [561, 2, 1, "", "staged_predict"], [561, 2, 1, "", "staged_predict_proba"], [561, 2, 1, "", "staged_score"]], "sklearn.ensemble.AdaBoostRegressor": [[562, 3, 1, "", "feature_importances_"], [562, 2, 1, "", "fit"], [562, 2, 1, "", "get_metadata_routing"], [562, 2, 1, "", "get_params"], [562, 2, 1, "", "predict"], [562, 2, 1, "", "score"], [562, 2, 1, "", "set_fit_request"], [562, 2, 1, "", "set_params"], [562, 2, 1, "", "set_score_request"], [562, 2, 1, "", "staged_predict"], [562, 2, 1, "", "staged_score"]], "sklearn.ensemble.BaggingClassifier": [[563, 2, 1, "", "decision_function"], [563, 3, 1, "", "estimators_samples_"], [563, 2, 1, "", "fit"], [563, 2, 1, "", "get_metadata_routing"], [563, 2, 1, "", "get_params"], [563, 2, 1, "", "predict"], [563, 2, 1, "", "predict_log_proba"], [563, 2, 1, "", "predict_proba"], [563, 2, 1, "", "score"], [563, 2, 1, "", "set_fit_request"], [563, 2, 1, "", "set_params"], [563, 2, 1, "", "set_score_request"]], "sklearn.ensemble.BaggingRegressor": [[564, 3, 1, "", "estimators_samples_"], [564, 2, 1, "", "fit"], [564, 2, 1, "", "get_metadata_routing"], [564, 2, 1, "", "get_params"], [564, 2, 1, "", "predict"], [564, 2, 1, "", "score"], [564, 2, 1, "", "set_fit_request"], [564, 2, 1, "", "set_params"], [564, 2, 1, "", "set_score_request"]], "sklearn.ensemble.ExtraTreesClassifier": [[565, 2, 1, "", "apply"], [565, 2, 1, "", "decision_path"], [565, 3, 1, "", "estimators_samples_"], [565, 3, 1, "", "feature_importances_"], [565, 2, 1, "", "fit"], [565, 2, 1, "", "get_metadata_routing"], [565, 2, 1, "", "get_params"], [565, 2, 1, "", "predict"], [565, 2, 1, "", "predict_log_proba"], [565, 2, 1, "", "predict_proba"], [565, 2, 1, "", "score"], [565, 2, 1, "", "set_fit_request"], [565, 2, 1, "", "set_params"], [565, 2, 1, "", "set_score_request"]], "sklearn.ensemble.ExtraTreesRegressor": [[566, 2, 1, "", "apply"], [566, 2, 1, "", "decision_path"], [566, 3, 1, "", "estimators_samples_"], [566, 3, 1, "", "feature_importances_"], [566, 2, 1, "", "fit"], [566, 2, 1, "", "get_metadata_routing"], [566, 2, 1, "", "get_params"], [566, 2, 1, "", "predict"], [566, 2, 1, "", "score"], [566, 2, 1, "", "set_fit_request"], [566, 2, 1, "", "set_params"], [566, 2, 1, "", "set_score_request"]], "sklearn.ensemble.GradientBoostingClassifier": [[567, 2, 1, "", "apply"], [567, 2, 1, "", "decision_function"], [567, 3, 1, "", "feature_importances_"], [567, 2, 1, "", "fit"], [567, 2, 1, "", "get_metadata_routing"], [567, 2, 1, "", "get_params"], [567, 2, 1, "", "predict"], [567, 2, 1, "", "predict_log_proba"], [567, 2, 1, "", "predict_proba"], [567, 2, 1, "", "score"], [567, 2, 1, "", "set_fit_request"], [567, 2, 1, "", "set_params"], [567, 2, 1, "", "set_score_request"], [567, 2, 1, "", "staged_decision_function"], [567, 2, 1, "", "staged_predict"], [567, 2, 1, "", "staged_predict_proba"]], "sklearn.ensemble.GradientBoostingRegressor": [[568, 2, 1, "", "apply"], [568, 3, 1, "", "feature_importances_"], [568, 2, 1, "", "fit"], [568, 2, 1, "", "get_metadata_routing"], [568, 2, 1, "", "get_params"], [568, 2, 1, "", "predict"], [568, 2, 1, "", "score"], [568, 2, 1, "", "set_fit_request"], [568, 2, 1, "", "set_params"], [568, 2, 1, "", "set_score_request"], [568, 2, 1, "", "staged_predict"]], "sklearn.ensemble.HistGradientBoostingClassifier": [[569, 2, 1, "", "decision_function"], [569, 2, 1, "", "fit"], [569, 2, 1, "", "get_metadata_routing"], [569, 2, 1, "", "get_params"], [569, 3, 1, "", "n_iter_"], [569, 2, 1, "", "predict"], [569, 2, 1, "", "predict_proba"], [569, 2, 1, "", "score"], [569, 2, 1, "", "set_fit_request"], [569, 2, 1, "", "set_params"], [569, 2, 1, "", "set_score_request"], [569, 2, 1, "", "staged_decision_function"], [569, 2, 1, "", "staged_predict"], [569, 2, 1, "", "staged_predict_proba"]], "sklearn.ensemble.HistGradientBoostingRegressor": [[570, 2, 1, "", "fit"], [570, 2, 1, "", "get_metadata_routing"], [570, 2, 1, "", "get_params"], [570, 3, 1, "", "n_iter_"], [570, 2, 1, "", "predict"], [570, 2, 1, "", "score"], [570, 2, 1, "", "set_fit_request"], [570, 2, 1, "", "set_params"], [570, 2, 1, "", "set_score_request"], [570, 2, 1, "", "staged_predict"]], "sklearn.ensemble.IsolationForest": [[571, 2, 1, "", "decision_function"], [571, 3, 1, "", "estimators_samples_"], [571, 2, 1, "", "fit"], [571, 2, 1, "", "fit_predict"], [571, 2, 1, "", "get_metadata_routing"], [571, 2, 1, "", "get_params"], [571, 2, 1, "", "predict"], [571, 2, 1, "", "score_samples"], [571, 2, 1, "", "set_fit_request"], [571, 2, 1, "", "set_params"]], "sklearn.ensemble.RandomForestClassifier": [[572, 2, 1, "", "apply"], [572, 2, 1, "", "decision_path"], [572, 3, 1, "", "estimators_samples_"], [572, 3, 1, "", "feature_importances_"], [572, 2, 1, "", "fit"], [572, 2, 1, "", "get_metadata_routing"], [572, 2, 1, "", "get_params"], [572, 2, 1, "", "predict"], [572, 2, 1, "", "predict_log_proba"], [572, 2, 1, "", "predict_proba"], [572, 2, 1, "", "score"], [572, 2, 1, "", "set_fit_request"], [572, 2, 1, "", "set_params"], [572, 2, 1, "", "set_score_request"]], "sklearn.ensemble.RandomForestRegressor": [[573, 2, 1, "", "apply"], [573, 2, 1, "", "decision_path"], [573, 3, 1, "", "estimators_samples_"], [573, 3, 1, "", "feature_importances_"], [573, 2, 1, "", "fit"], [573, 2, 1, "", "get_metadata_routing"], [573, 2, 1, "", "get_params"], [573, 2, 1, "", "predict"], [573, 2, 1, "", "score"], [573, 2, 1, "", "set_fit_request"], [573, 2, 1, "", "set_params"], [573, 2, 1, "", "set_score_request"]], "sklearn.ensemble.RandomTreesEmbedding": [[574, 2, 1, "", "apply"], [574, 2, 1, "", "decision_path"], [574, 3, 1, "", "estimators_samples_"], [574, 3, 1, "", "feature_importances_"], [574, 2, 1, "", "fit"], [574, 2, 1, "", "fit_transform"], [574, 2, 1, "", "get_feature_names_out"], [574, 2, 1, "", "get_metadata_routing"], [574, 2, 1, "", "get_params"], [574, 2, 1, "", "set_fit_request"], [574, 2, 1, "", "set_output"], [574, 2, 1, "", "set_params"], [574, 2, 1, "", "transform"]], "sklearn.ensemble.StackingClassifier": [[575, 2, 1, "", "decision_function"], [575, 2, 1, "", "fit"], [575, 2, 1, "", "fit_transform"], [575, 2, 1, "", "get_feature_names_out"], [575, 2, 1, "", "get_metadata_routing"], [575, 2, 1, "", "get_params"], [575, 3, 1, "", "n_features_in_"], [575, 3, 1, "", "named_estimators"], [575, 2, 1, "", "predict"], [575, 2, 1, "", "predict_proba"], [575, 2, 1, "", "score"], [575, 2, 1, "", "set_fit_request"], [575, 2, 1, "", "set_output"], [575, 2, 1, "", "set_params"], [575, 2, 1, "", "set_score_request"], [575, 2, 1, "", "transform"]], "sklearn.ensemble.StackingRegressor": [[576, 2, 1, "", "fit"], [576, 2, 1, "", "fit_transform"], [576, 2, 1, "", "get_feature_names_out"], [576, 2, 1, "", "get_metadata_routing"], [576, 2, 1, "", "get_params"], [576, 3, 1, "", "n_features_in_"], [576, 3, 1, "", "named_estimators"], [576, 2, 1, "", "predict"], [576, 2, 1, "", "score"], [576, 2, 1, "", "set_fit_request"], [576, 2, 1, "", "set_output"], [576, 2, 1, "", "set_params"], [576, 2, 1, "", "set_score_request"], [576, 2, 1, "", "transform"]], "sklearn.ensemble.VotingClassifier": [[577, 2, 1, "", "fit"], [577, 2, 1, "", "fit_transform"], [577, 2, 1, "", "get_feature_names_out"], [577, 2, 1, "", "get_metadata_routing"], [577, 2, 1, "", "get_params"], [577, 3, 1, "", "n_features_in_"], [577, 3, 1, "", "named_estimators"], [577, 2, 1, "", "predict"], [577, 2, 1, "", "predict_proba"], [577, 2, 1, "", "score"], [577, 2, 1, "", "set_fit_request"], [577, 2, 1, "", "set_output"], [577, 2, 1, "", "set_params"], [577, 2, 1, "", "set_score_request"], [577, 2, 1, "", "transform"]], "sklearn.ensemble.VotingRegressor": [[578, 2, 1, "", "fit"], [578, 2, 1, "", "fit_transform"], [578, 2, 1, "", "get_feature_names_out"], [578, 2, 1, "", "get_metadata_routing"], [578, 2, 1, "", "get_params"], [578, 3, 1, "", "n_features_in_"], [578, 3, 1, "", "named_estimators"], [578, 2, 1, "", "predict"], [578, 2, 1, "", "score"], [578, 2, 1, "", "set_fit_request"], [578, 2, 1, "", "set_output"], [578, 2, 1, "", "set_params"], [578, 2, 1, "", "set_score_request"], [578, 2, 1, "", "transform"]], "sklearn.exceptions": [[579, 5, 1, "", "ConvergenceWarning"], [580, 5, 1, "", "DataConversionWarning"], [581, 5, 1, "", "DataDimensionalityWarning"], [582, 5, 1, "", "EfficiencyWarning"], [583, 5, 1, "", "FitFailedWarning"], [584, 5, 1, "", "InconsistentVersionWarning"], [585, 5, 1, "", "NotFittedError"], [586, 5, 1, "", "UndefinedMetricWarning"]], "sklearn.experimental": [[587, 0, 0, "-", "enable_halving_search_cv"], [588, 0, 0, "-", "enable_iterative_imputer"]], "sklearn.feature_extraction": [[589, 1, 1, "", "DictVectorizer"], [590, 1, 1, "", "FeatureHasher"], [17, 0, 0, "-", "image"], [17, 0, 0, "-", "text"]], "sklearn.feature_extraction.DictVectorizer": [[589, 2, 1, "", "fit"], [589, 2, 1, "", "fit_transform"], [589, 2, 1, "", "get_feature_names_out"], [589, 2, 1, "", "get_metadata_routing"], [589, 2, 1, "", "get_params"], [589, 2, 1, "", "inverse_transform"], [589, 2, 1, "", "restrict"], [589, 2, 1, "", "set_inverse_transform_request"], [589, 2, 1, "", "set_output"], [589, 2, 1, "", "set_params"], [589, 2, 1, "", "transform"]], "sklearn.feature_extraction.FeatureHasher": [[590, 2, 1, "", "fit"], [590, 2, 1, "", "fit_transform"], [590, 2, 1, "", "get_metadata_routing"], [590, 2, 1, "", "get_params"], [590, 2, 1, "", "set_output"], [590, 2, 1, "", "set_params"], [590, 2, 1, "", "set_transform_request"], [590, 2, 1, "", "transform"]], "sklearn.feature_extraction.image": [[591, 1, 1, "", "PatchExtractor"], [592, 4, 1, "", "extract_patches_2d"], [593, 4, 1, "", "grid_to_graph"], [594, 4, 1, "", "img_to_graph"], [595, 4, 1, "", "reconstruct_from_patches_2d"]], "sklearn.feature_extraction.image.PatchExtractor": [[591, 2, 1, "", "fit"], [591, 2, 1, "", "fit_transform"], [591, 2, 1, "", "get_metadata_routing"], [591, 2, 1, "", "get_params"], [591, 2, 1, "", "set_output"], [591, 2, 1, "", "set_params"], [591, 2, 1, "", "transform"]], "sklearn.feature_extraction.text": [[596, 1, 1, "", "CountVectorizer"], [597, 1, 1, "", "HashingVectorizer"], [598, 1, 1, "", "TfidfTransformer"], [599, 1, 1, "", "TfidfVectorizer"]], "sklearn.feature_extraction.text.CountVectorizer": [[596, 2, 1, "", "build_analyzer"], [596, 2, 1, "", "build_preprocessor"], [596, 2, 1, "", "build_tokenizer"], [596, 2, 1, "", "decode"], [596, 2, 1, "", "fit"], [596, 2, 1, "", "fit_transform"], [596, 2, 1, "", "get_feature_names_out"], [596, 2, 1, "", "get_metadata_routing"], [596, 2, 1, "", "get_params"], [596, 2, 1, "", "get_stop_words"], [596, 2, 1, "", "inverse_transform"], [596, 2, 1, "", "set_fit_request"], [596, 2, 1, "", "set_params"], [596, 2, 1, "", "set_transform_request"], [596, 2, 1, "", "transform"]], "sklearn.feature_extraction.text.HashingVectorizer": [[597, 2, 1, "", "build_analyzer"], [597, 2, 1, "", "build_preprocessor"], [597, 2, 1, "", "build_tokenizer"], [597, 2, 1, "", "decode"], [597, 2, 1, "", "fit"], [597, 2, 1, "", "fit_transform"], [597, 2, 1, "", "get_metadata_routing"], [597, 2, 1, "", "get_params"], [597, 2, 1, "", "get_stop_words"], [597, 2, 1, "", "partial_fit"], [597, 2, 1, "", "set_output"], [597, 2, 1, "", "set_params"], [597, 2, 1, "", "transform"]], "sklearn.feature_extraction.text.TfidfTransformer": [[598, 2, 1, "", "fit"], [598, 2, 1, "", "fit_transform"], [598, 2, 1, "", "get_feature_names_out"], [598, 2, 1, "", "get_metadata_routing"], [598, 2, 1, "", "get_params"], [598, 2, 1, "", "set_output"], [598, 2, 1, "", "set_params"], [598, 2, 1, "", "set_transform_request"], [598, 2, 1, "", "transform"]], "sklearn.feature_extraction.text.TfidfVectorizer": [[599, 2, 1, "", "build_analyzer"], [599, 2, 1, "", "build_preprocessor"], [599, 2, 1, "", "build_tokenizer"], [599, 2, 1, "", "decode"], [599, 2, 1, "", "fit"], [599, 2, 1, "", "fit_transform"], [599, 2, 1, "", "get_feature_names_out"], [599, 2, 1, "", "get_metadata_routing"], [599, 2, 1, "", "get_params"], [599, 2, 1, "", "get_stop_words"], [599, 3, 1, "", "idf_"], [599, 2, 1, "", "inverse_transform"], [599, 2, 1, "", "set_fit_request"], [599, 2, 1, "", "set_params"], [599, 2, 1, "", "set_transform_request"], [599, 2, 1, "", "transform"]], "sklearn.feature_selection": [[600, 1, 1, "", "GenericUnivariateSelect"], [601, 1, 1, "", "RFE"], [602, 1, 1, "", "RFECV"], [603, 1, 1, "", "SelectFdr"], [604, 1, 1, "", "SelectFpr"], [605, 1, 1, "", "SelectFromModel"], [606, 1, 1, "", "SelectFwe"], [607, 1, 1, "", "SelectKBest"], [608, 1, 1, "", "SelectPercentile"], [609, 1, 1, "", "SelectorMixin"], [610, 1, 1, "", "SequentialFeatureSelector"], [611, 1, 1, "", "VarianceThreshold"], [612, 4, 1, "", "chi2"], [613, 4, 1, "", "f_classif"], [614, 4, 1, "", "f_regression"], [615, 4, 1, "", "mutual_info_classif"], [616, 4, 1, "", "mutual_info_regression"], [617, 4, 1, "", "r_regression"]], "sklearn.feature_selection.GenericUnivariateSelect": [[600, 2, 1, "", "fit"], [600, 2, 1, "", "fit_transform"], [600, 2, 1, "", "get_feature_names_out"], [600, 2, 1, "", "get_metadata_routing"], [600, 2, 1, "", "get_params"], [600, 2, 1, "", "get_support"], [600, 2, 1, "", "inverse_transform"], [600, 2, 1, "", "set_output"], [600, 2, 1, "", "set_params"], [600, 2, 1, "", "transform"]], "sklearn.feature_selection.RFE": [[601, 3, 1, "", "classes_"], [601, 2, 1, "", "decision_function"], [601, 2, 1, "", "fit"], [601, 2, 1, "", "fit_transform"], [601, 2, 1, "", "get_feature_names_out"], [601, 2, 1, "", "get_metadata_routing"], [601, 2, 1, "", "get_params"], [601, 2, 1, "", "get_support"], [601, 2, 1, "", "inverse_transform"], [601, 2, 1, "", "predict"], [601, 2, 1, "", "predict_log_proba"], [601, 2, 1, "", "predict_proba"], [601, 2, 1, "", "score"], [601, 2, 1, "", "set_output"], [601, 2, 1, "", "set_params"], [601, 2, 1, "", "transform"]], "sklearn.feature_selection.RFECV": [[602, 3, 1, "", "classes_"], [602, 2, 1, "", "decision_function"], [602, 2, 1, "", "fit"], [602, 2, 1, "", "fit_transform"], [602, 2, 1, "", "get_feature_names_out"], [602, 2, 1, "", "get_metadata_routing"], [602, 2, 1, "", "get_params"], [602, 2, 1, "", "get_support"], [602, 2, 1, "", "inverse_transform"], [602, 2, 1, "", "predict"], [602, 2, 1, "", "predict_log_proba"], [602, 2, 1, "", "predict_proba"], [602, 2, 1, "", "score"], [602, 2, 1, "", "set_fit_request"], [602, 2, 1, "", "set_output"], [602, 2, 1, "", "set_params"], [602, 2, 1, "", "transform"]], "sklearn.feature_selection.SelectFdr": [[603, 2, 1, "", "fit"], [603, 2, 1, "", "fit_transform"], [603, 2, 1, "", "get_feature_names_out"], [603, 2, 1, "", "get_metadata_routing"], [603, 2, 1, "", "get_params"], [603, 2, 1, "", "get_support"], [603, 2, 1, "", "inverse_transform"], [603, 2, 1, "", "set_output"], [603, 2, 1, "", "set_params"], [603, 2, 1, "", "transform"]], "sklearn.feature_selection.SelectFpr": [[604, 2, 1, "", "fit"], [604, 2, 1, "", "fit_transform"], [604, 2, 1, "", "get_feature_names_out"], [604, 2, 1, "", "get_metadata_routing"], [604, 2, 1, "", "get_params"], [604, 2, 1, "", "get_support"], [604, 2, 1, "", "inverse_transform"], [604, 2, 1, "", "set_output"], [604, 2, 1, "", "set_params"], [604, 2, 1, "", "transform"]], "sklearn.feature_selection.SelectFromModel": [[605, 2, 1, "", "fit"], [605, 2, 1, "", "fit_transform"], [605, 2, 1, "", "get_feature_names_out"], [605, 2, 1, "", "get_metadata_routing"], [605, 2, 1, "", "get_params"], [605, 2, 1, "", "get_support"], [605, 2, 1, "", "inverse_transform"], [605, 3, 1, "", "n_features_in_"], [605, 2, 1, "", "partial_fit"], [605, 2, 1, "", "set_output"], [605, 2, 1, "", "set_params"], [605, 3, 1, "", "threshold_"], [605, 2, 1, "", "transform"]], "sklearn.feature_selection.SelectFwe": [[606, 2, 1, "", "fit"], [606, 2, 1, "", "fit_transform"], [606, 2, 1, "", "get_feature_names_out"], [606, 2, 1, "", "get_metadata_routing"], [606, 2, 1, "", "get_params"], [606, 2, 1, "", "get_support"], [606, 2, 1, "", "inverse_transform"], [606, 2, 1, "", "set_output"], [606, 2, 1, "", "set_params"], [606, 2, 1, "", "transform"]], "sklearn.feature_selection.SelectKBest": [[607, 2, 1, "", "fit"], [607, 2, 1, "", "fit_transform"], [607, 2, 1, "", "get_feature_names_out"], [607, 2, 1, "", "get_metadata_routing"], [607, 2, 1, "", "get_params"], [607, 2, 1, "", "get_support"], [607, 2, 1, "", "inverse_transform"], [607, 2, 1, "", "set_output"], [607, 2, 1, "", "set_params"], [607, 2, 1, "", "transform"]], "sklearn.feature_selection.SelectPercentile": [[608, 2, 1, "", "fit"], [608, 2, 1, "", "fit_transform"], [608, 2, 1, "", "get_feature_names_out"], [608, 2, 1, "", "get_metadata_routing"], [608, 2, 1, "", "get_params"], [608, 2, 1, "", "get_support"], [608, 2, 1, "", "inverse_transform"], [608, 2, 1, "", "set_output"], [608, 2, 1, "", "set_params"], [608, 2, 1, "", "transform"]], "sklearn.feature_selection.SelectorMixin": [[609, 2, 1, "", "fit_transform"], [609, 2, 1, "", "get_feature_names_out"], [609, 2, 1, "", "get_support"], [609, 2, 1, "", "inverse_transform"], [609, 2, 1, "", "set_output"], [609, 2, 1, "", "transform"]], "sklearn.feature_selection.SequentialFeatureSelector": [[610, 2, 1, "", "fit"], [610, 2, 1, "", "fit_transform"], [610, 2, 1, "", "get_feature_names_out"], [610, 2, 1, "", "get_metadata_routing"], [610, 2, 1, "", "get_params"], [610, 2, 1, "", "get_support"], [610, 2, 1, "", "inverse_transform"], [610, 2, 1, "", "set_output"], [610, 2, 1, "", "set_params"], [610, 2, 1, "", "transform"]], "sklearn.feature_selection.VarianceThreshold": [[611, 2, 1, "", "fit"], [611, 2, 1, "", "fit_transform"], [611, 2, 1, "", "get_feature_names_out"], [611, 2, 1, "", "get_metadata_routing"], [611, 2, 1, "", "get_params"], [611, 2, 1, "", "get_support"], [611, 2, 1, "", "inverse_transform"], [611, 2, 1, "", "set_output"], [611, 2, 1, "", "set_params"], [611, 2, 1, "", "transform"]], "sklearn.gaussian_process": [[618, 1, 1, "", "GaussianProcessClassifier"], [619, 1, 1, "", "GaussianProcessRegressor"], [19, 0, 0, "-", "kernels"]], "sklearn.gaussian_process.GaussianProcessClassifier": [[618, 2, 1, "", "fit"], [618, 2, 1, "", "get_metadata_routing"], [618, 2, 1, "", "get_params"], [618, 3, 1, "", "kernel_"], [618, 2, 1, "", "log_marginal_likelihood"], [618, 2, 1, "", "predict"], [618, 2, 1, "", "predict_proba"], [618, 2, 1, "", "score"], [618, 2, 1, "", "set_params"], [618, 2, 1, "", "set_score_request"]], "sklearn.gaussian_process.GaussianProcessRegressor": [[619, 2, 1, "", "fit"], [619, 2, 1, "", "get_metadata_routing"], [619, 2, 1, "", "get_params"], [619, 2, 1, "", "log_marginal_likelihood"], [619, 2, 1, "", "predict"], [619, 2, 1, "", "sample_y"], [619, 2, 1, "", "score"], [619, 2, 1, "", "set_params"], [619, 2, 1, "", "set_predict_request"], [619, 2, 1, "", "set_score_request"]], "sklearn.gaussian_process.kernels": [[620, 1, 1, "", "CompoundKernel"], [621, 1, 1, "", "ConstantKernel"], [622, 1, 1, "", "DotProduct"], [623, 1, 1, "", "ExpSineSquared"], [624, 1, 1, "", "Exponentiation"], [625, 1, 1, "", "Hyperparameter"], [626, 1, 1, "", "Kernel"], [627, 1, 1, "", "Matern"], [628, 1, 1, "", "PairwiseKernel"], [629, 1, 1, "", "Product"], [630, 1, 1, "", "RBF"], [631, 1, 1, "", "RationalQuadratic"], [632, 1, 1, "", "Sum"], [633, 1, 1, "", "WhiteKernel"]], "sklearn.gaussian_process.kernels.CompoundKernel": [[620, 2, 1, "", "__call__"], [620, 3, 1, "", "bounds"], [620, 2, 1, "", "clone_with_theta"], [620, 2, 1, "", "diag"], [620, 2, 1, "", "get_params"], [620, 3, 1, "", "hyperparameters"], [620, 2, 1, "", "is_stationary"], [620, 3, 1, "", "n_dims"], [620, 3, 1, "", "requires_vector_input"], [620, 2, 1, "", "set_params"], [620, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.ConstantKernel": [[621, 2, 1, "", "__call__"], [621, 3, 1, "", "bounds"], [621, 2, 1, "", "clone_with_theta"], [621, 2, 1, "", "diag"], [621, 2, 1, "", "get_params"], [621, 3, 1, "", "hyperparameters"], [621, 2, 1, "", "is_stationary"], [621, 3, 1, "", "n_dims"], [621, 3, 1, "", "requires_vector_input"], [621, 2, 1, "", "set_params"], [621, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.DotProduct": [[622, 2, 1, "", "__call__"], [622, 3, 1, "", "bounds"], [622, 2, 1, "", "clone_with_theta"], [622, 2, 1, "", "diag"], [622, 2, 1, "", "get_params"], [622, 3, 1, "", "hyperparameters"], [622, 2, 1, "", "is_stationary"], [622, 3, 1, "", "n_dims"], [622, 3, 1, "", "requires_vector_input"], [622, 2, 1, "", "set_params"], [622, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.ExpSineSquared": [[623, 2, 1, "", "__call__"], [623, 3, 1, "", "bounds"], [623, 2, 1, "", "clone_with_theta"], [623, 2, 1, "", "diag"], [623, 2, 1, "", "get_params"], [623, 3, 1, "", "hyperparameter_length_scale"], [623, 3, 1, "", "hyperparameters"], [623, 2, 1, "", "is_stationary"], [623, 3, 1, "", "n_dims"], [623, 3, 1, "", "requires_vector_input"], [623, 2, 1, "", "set_params"], [623, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.Exponentiation": [[624, 2, 1, "", "__call__"], [624, 3, 1, "", "bounds"], [624, 2, 1, "", "clone_with_theta"], [624, 2, 1, "", "diag"], [624, 2, 1, "", "get_params"], [624, 3, 1, "", "hyperparameters"], [624, 2, 1, "", "is_stationary"], [624, 3, 1, "", "n_dims"], [624, 3, 1, "", "requires_vector_input"], [624, 2, 1, "", "set_params"], [624, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.Hyperparameter": [[625, 6, 1, "", "bounds"], [625, 2, 1, "", "count"], [625, 6, 1, "", "fixed"], [625, 2, 1, "", "index"], [625, 6, 1, "", "n_elements"], [625, 6, 1, "", "name"], [625, 6, 1, "", "value_type"]], "sklearn.gaussian_process.kernels.Kernel": [[626, 2, 1, "", "__call__"], [626, 3, 1, "", "bounds"], [626, 2, 1, "", "clone_with_theta"], [626, 2, 1, "", "diag"], [626, 2, 1, "", "get_params"], [626, 3, 1, "", "hyperparameters"], [626, 2, 1, "", "is_stationary"], [626, 3, 1, "", "n_dims"], [626, 3, 1, "", "requires_vector_input"], [626, 2, 1, "", "set_params"], [626, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.Matern": [[627, 2, 1, "", "__call__"], [627, 3, 1, "", "bounds"], [627, 2, 1, "", "clone_with_theta"], [627, 2, 1, "", "diag"], [627, 2, 1, "", "get_params"], [627, 3, 1, "", "hyperparameters"], [627, 2, 1, "", "is_stationary"], [627, 3, 1, "", "n_dims"], [627, 3, 1, "", "requires_vector_input"], [627, 2, 1, "", "set_params"], [627, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.PairwiseKernel": [[628, 2, 1, "", "__call__"], [628, 3, 1, "", "bounds"], [628, 2, 1, "", "clone_with_theta"], [628, 2, 1, "", "diag"], [628, 2, 1, "", "get_params"], [628, 3, 1, "", "hyperparameters"], [628, 2, 1, "", "is_stationary"], [628, 3, 1, "", "n_dims"], [628, 3, 1, "", "requires_vector_input"], [628, 2, 1, "", "set_params"], [628, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.Product": [[629, 2, 1, "", "__call__"], [629, 3, 1, "", "bounds"], [629, 2, 1, "", "clone_with_theta"], [629, 2, 1, "", "diag"], [629, 2, 1, "", "get_params"], [629, 3, 1, "", "hyperparameters"], [629, 2, 1, "", "is_stationary"], [629, 3, 1, "", "n_dims"], [629, 3, 1, "", "requires_vector_input"], [629, 2, 1, "", "set_params"], [629, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.RBF": [[630, 2, 1, "", "__call__"], [630, 3, 1, "", "bounds"], [630, 2, 1, "", "clone_with_theta"], [630, 2, 1, "", "diag"], [630, 2, 1, "", "get_params"], [630, 3, 1, "", "hyperparameters"], [630, 2, 1, "", "is_stationary"], [630, 3, 1, "", "n_dims"], [630, 3, 1, "", "requires_vector_input"], [630, 2, 1, "", "set_params"], [630, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.RationalQuadratic": [[631, 2, 1, "", "__call__"], [631, 3, 1, "", "bounds"], [631, 2, 1, "", "clone_with_theta"], [631, 2, 1, "", "diag"], [631, 2, 1, "", "get_params"], [631, 3, 1, "", "hyperparameters"], [631, 2, 1, "", "is_stationary"], [631, 3, 1, "", "n_dims"], [631, 3, 1, "", "requires_vector_input"], [631, 2, 1, "", "set_params"], [631, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.Sum": [[632, 2, 1, "", "__call__"], [632, 3, 1, "", "bounds"], [632, 2, 1, "", "clone_with_theta"], [632, 2, 1, "", "diag"], [632, 2, 1, "", "get_params"], [632, 3, 1, "", "hyperparameters"], [632, 2, 1, "", "is_stationary"], [632, 3, 1, "", "n_dims"], [632, 3, 1, "", "requires_vector_input"], [632, 2, 1, "", "set_params"], [632, 3, 1, "", "theta"]], "sklearn.gaussian_process.kernels.WhiteKernel": [[633, 2, 1, "", "__call__"], [633, 3, 1, "", "bounds"], [633, 2, 1, "", "clone_with_theta"], [633, 2, 1, "", "diag"], [633, 2, 1, "", "get_params"], [633, 3, 1, "", "hyperparameters"], [633, 2, 1, "", "is_stationary"], [633, 3, 1, "", "n_dims"], [633, 3, 1, "", "requires_vector_input"], [633, 2, 1, "", "set_params"], [633, 3, 1, "", "theta"]], "sklearn.impute": [[635, 1, 1, "", "IterativeImputer"], [636, 1, 1, "", "KNNImputer"], [637, 1, 1, "", "MissingIndicator"], [638, 1, 1, "", "SimpleImputer"]], "sklearn.impute.IterativeImputer": [[635, 2, 1, "", "fit"], [635, 2, 1, "", "fit_transform"], [635, 2, 1, "", "get_feature_names_out"], [635, 2, 1, "", "get_metadata_routing"], [635, 2, 1, "", "get_params"], [635, 2, 1, "", "set_output"], [635, 2, 1, "", "set_params"], [635, 2, 1, "", "transform"]], "sklearn.impute.KNNImputer": [[636, 2, 1, "", "fit"], [636, 2, 1, "", "fit_transform"], [636, 2, 1, "", "get_feature_names_out"], [636, 2, 1, "", "get_metadata_routing"], [636, 2, 1, "", "get_params"], [636, 2, 1, "", "set_output"], [636, 2, 1, "", "set_params"], [636, 2, 1, "", "transform"]], "sklearn.impute.MissingIndicator": [[637, 2, 1, "", "fit"], [637, 2, 1, "", "fit_transform"], [637, 2, 1, "", "get_feature_names_out"], [637, 2, 1, "", "get_metadata_routing"], [637, 2, 1, "", "get_params"], [637, 2, 1, "", "set_output"], [637, 2, 1, "", "set_params"], [637, 2, 1, "", "transform"]], "sklearn.impute.SimpleImputer": [[638, 2, 1, "", "fit"], [638, 2, 1, "", "fit_transform"], [638, 2, 1, "", "get_feature_names_out"], [638, 2, 1, "", "get_metadata_routing"], [638, 2, 1, "", "get_params"], [638, 2, 1, "", "inverse_transform"], [638, 2, 1, "", "set_output"], [638, 2, 1, "", "set_params"], [638, 2, 1, "", "transform"]], "sklearn.inspection": [[639, 1, 1, "", "DecisionBoundaryDisplay"], [640, 1, 1, "", "PartialDependenceDisplay"], [641, 4, 1, "", "partial_dependence"], [642, 4, 1, "", "permutation_importance"]], "sklearn.inspection.DecisionBoundaryDisplay": [[639, 2, 1, "", "from_estimator"], [639, 2, 1, "", "plot"]], "sklearn.inspection.PartialDependenceDisplay": [[640, 2, 1, "", "from_estimator"], [640, 2, 1, "", "plot"]], "sklearn.isotonic": [[643, 1, 1, "", "IsotonicRegression"], [644, 4, 1, "", "check_increasing"], [645, 4, 1, "", "isotonic_regression"]], "sklearn.isotonic.IsotonicRegression": [[643, 2, 1, "", "fit"], [643, 2, 1, "", "fit_transform"], [643, 2, 1, "", "get_feature_names_out"], [643, 2, 1, "", "get_metadata_routing"], [643, 2, 1, "", "get_params"], [643, 2, 1, "", "predict"], [643, 2, 1, "", "score"], [643, 2, 1, "", "set_fit_request"], [643, 2, 1, "", "set_output"], [643, 2, 1, "", "set_params"], [643, 2, 1, "", "set_predict_request"], [643, 2, 1, "", "set_score_request"], [643, 2, 1, "", "set_transform_request"], [643, 2, 1, "", "transform"]], "sklearn.kernel_approximation": [[646, 1, 1, "", "AdditiveChi2Sampler"], [647, 1, 1, "", "Nystroem"], [648, 1, 1, "", "PolynomialCountSketch"], [649, 1, 1, "", "RBFSampler"], [650, 1, 1, "", "SkewedChi2Sampler"]], "sklearn.kernel_approximation.AdditiveChi2Sampler": [[646, 2, 1, "", "fit"], [646, 2, 1, "", "fit_transform"], [646, 2, 1, "", "get_feature_names_out"], [646, 2, 1, "", "get_metadata_routing"], [646, 2, 1, "", "get_params"], [646, 2, 1, "", "set_output"], [646, 2, 1, "", "set_params"], [646, 2, 1, "", "transform"]], "sklearn.kernel_approximation.Nystroem": [[647, 2, 1, "", "fit"], [647, 2, 1, "", "fit_transform"], [647, 2, 1, "", "get_feature_names_out"], [647, 2, 1, "", "get_metadata_routing"], [647, 2, 1, "", "get_params"], [647, 2, 1, "", "set_output"], [647, 2, 1, "", "set_params"], [647, 2, 1, "", "transform"]], "sklearn.kernel_approximation.PolynomialCountSketch": [[648, 2, 1, "", "fit"], [648, 2, 1, "", "fit_transform"], [648, 2, 1, "", "get_feature_names_out"], [648, 2, 1, "", "get_metadata_routing"], [648, 2, 1, "", "get_params"], [648, 2, 1, "", "set_output"], [648, 2, 1, "", "set_params"], [648, 2, 1, "", "transform"]], "sklearn.kernel_approximation.RBFSampler": [[649, 2, 1, "", "fit"], [649, 2, 1, "", "fit_transform"], [649, 2, 1, "", "get_feature_names_out"], [649, 2, 1, "", "get_metadata_routing"], [649, 2, 1, "", "get_params"], [649, 2, 1, "", "set_output"], [649, 2, 1, "", "set_params"], [649, 2, 1, "", "transform"]], "sklearn.kernel_approximation.SkewedChi2Sampler": [[650, 2, 1, "", "fit"], [650, 2, 1, "", "fit_transform"], [650, 2, 1, "", "get_feature_names_out"], [650, 2, 1, "", "get_metadata_routing"], [650, 2, 1, "", "get_params"], [650, 2, 1, "", "set_output"], [650, 2, 1, "", "set_params"], [650, 2, 1, "", "transform"]], "sklearn.kernel_ridge": [[651, 1, 1, "", "KernelRidge"]], "sklearn.kernel_ridge.KernelRidge": [[651, 2, 1, "", "fit"], [651, 2, 1, "", "get_metadata_routing"], [651, 2, 1, "", "get_params"], [651, 2, 1, "", "predict"], [651, 2, 1, "", "score"], [651, 2, 1, "", "set_fit_request"], [651, 2, 1, "", "set_params"], [651, 2, 1, "", "set_score_request"]], "sklearn.linear_model": [[652, 1, 1, "", "ARDRegression"], [653, 1, 1, "", "BayesianRidge"], [654, 1, 1, "", "ElasticNet"], [655, 1, 1, "", "ElasticNetCV"], [656, 1, 1, "", "GammaRegressor"], [657, 1, 1, "", "HuberRegressor"], [658, 1, 1, "", "Lars"], [659, 1, 1, "", "LarsCV"], [660, 1, 1, "", "Lasso"], [661, 1, 1, "", "LassoCV"], [662, 1, 1, "", "LassoLars"], [663, 1, 1, "", "LassoLarsCV"], [664, 1, 1, "", "LassoLarsIC"], [665, 1, 1, "", "LinearRegression"], [666, 1, 1, "", "LogisticRegression"], [667, 1, 1, "", "LogisticRegressionCV"], [668, 1, 1, "", "MultiTaskElasticNet"], [669, 1, 1, "", "MultiTaskElasticNetCV"], [670, 1, 1, "", "MultiTaskLasso"], [671, 1, 1, "", "MultiTaskLassoCV"], [672, 1, 1, "", "OrthogonalMatchingPursuit"], [673, 1, 1, "", "OrthogonalMatchingPursuitCV"], [674, 1, 1, "", "PassiveAggressiveClassifier"], [675, 1, 1, "", "PassiveAggressiveRegressor"], [676, 1, 1, "", "Perceptron"], [677, 1, 1, "", "PoissonRegressor"], [678, 1, 1, "", "QuantileRegressor"], [679, 1, 1, "", "RANSACRegressor"], [680, 1, 1, "", "Ridge"], [681, 1, 1, "", "RidgeCV"], [682, 1, 1, "", "RidgeClassifier"], [683, 1, 1, "", "RidgeClassifierCV"], [684, 1, 1, "", "SGDClassifier"], [685, 1, 1, "", "SGDOneClassSVM"], [686, 1, 1, "", "SGDRegressor"], [687, 1, 1, "", "TheilSenRegressor"], [688, 1, 1, "", "TweedieRegressor"], [689, 4, 1, "", "enet_path"], [690, 4, 1, "", "lars_path"], [691, 4, 1, "", "lars_path_gram"], [692, 4, 1, "", "lasso_path"], [693, 4, 1, "", "orthogonal_mp"], [694, 4, 1, "", "orthogonal_mp_gram"], [695, 4, 1, "", "ridge_regression"]], "sklearn.linear_model.ARDRegression": [[652, 2, 1, "", "fit"], [652, 2, 1, "", "get_metadata_routing"], [652, 2, 1, "", "get_params"], [652, 2, 1, "", "predict"], [652, 2, 1, "", "score"], [652, 2, 1, "", "set_params"], [652, 2, 1, "", "set_predict_request"], [652, 2, 1, "", "set_score_request"]], "sklearn.linear_model.BayesianRidge": [[653, 2, 1, "", "fit"], [653, 2, 1, "", "get_metadata_routing"], [653, 2, 1, "", "get_params"], [653, 2, 1, "", "predict"], [653, 2, 1, "", "score"], [653, 2, 1, "", "set_fit_request"], [653, 2, 1, "", "set_params"], [653, 2, 1, "", "set_predict_request"], [653, 2, 1, "", "set_score_request"]], "sklearn.linear_model.ElasticNet": [[654, 2, 1, "", "fit"], [654, 2, 1, "", "get_metadata_routing"], [654, 2, 1, "", "get_params"], [654, 2, 1, "", "path"], [654, 2, 1, "", "predict"], [654, 2, 1, "", "score"], [654, 2, 1, "", "set_fit_request"], [654, 2, 1, "", "set_params"], [654, 2, 1, "", "set_score_request"], [654, 3, 1, "", "sparse_coef_"]], "sklearn.linear_model.ElasticNetCV": [[655, 2, 1, "", "fit"], [655, 2, 1, "", "get_metadata_routing"], [655, 2, 1, "", "get_params"], [655, 2, 1, "", "path"], [655, 2, 1, "", "predict"], [655, 2, 1, "", "score"], [655, 2, 1, "", "set_fit_request"], [655, 2, 1, "", "set_params"], [655, 2, 1, "", "set_score_request"]], "sklearn.linear_model.GammaRegressor": [[656, 2, 1, "", "fit"], [656, 2, 1, "", "get_metadata_routing"], [656, 2, 1, "", "get_params"], [656, 2, 1, "", "predict"], [656, 2, 1, "", "score"], [656, 2, 1, "", "set_fit_request"], [656, 2, 1, "", "set_params"], [656, 2, 1, "", "set_score_request"]], "sklearn.linear_model.HuberRegressor": [[657, 2, 1, "", "fit"], [657, 2, 1, "", "get_metadata_routing"], [657, 2, 1, "", "get_params"], [657, 2, 1, "", "predict"], [657, 2, 1, "", "score"], [657, 2, 1, "", "set_fit_request"], [657, 2, 1, "", "set_params"], [657, 2, 1, "", "set_score_request"]], "sklearn.linear_model.Lars": [[658, 2, 1, "", "fit"], [658, 2, 1, "", "get_metadata_routing"], [658, 2, 1, "", "get_params"], [658, 2, 1, "", "predict"], [658, 2, 1, "", "score"], [658, 2, 1, "", "set_fit_request"], [658, 2, 1, "", "set_params"], [658, 2, 1, "", "set_score_request"]], "sklearn.linear_model.LarsCV": [[659, 2, 1, "", "fit"], [659, 2, 1, "", "get_metadata_routing"], [659, 2, 1, "", "get_params"], [659, 2, 1, "", "predict"], [659, 2, 1, "", "score"], [659, 2, 1, "", "set_fit_request"], [659, 2, 1, "", "set_params"], [659, 2, 1, "", "set_score_request"]], "sklearn.linear_model.Lasso": [[660, 2, 1, "", "fit"], [660, 2, 1, "", "get_metadata_routing"], [660, 2, 1, "", "get_params"], [660, 2, 1, "", "path"], [660, 2, 1, "", "predict"], [660, 2, 1, "", "score"], [660, 2, 1, "", "set_fit_request"], [660, 2, 1, "", "set_params"], [660, 2, 1, "", "set_score_request"], [660, 3, 1, "", "sparse_coef_"]], "sklearn.linear_model.LassoCV": [[661, 2, 1, "", "fit"], [661, 2, 1, "", "get_metadata_routing"], [661, 2, 1, "", "get_params"], [661, 2, 1, "", "path"], [661, 2, 1, "", "predict"], [661, 2, 1, "", "score"], [661, 2, 1, "", "set_fit_request"], [661, 2, 1, "", "set_params"], [661, 2, 1, "", "set_score_request"]], "sklearn.linear_model.LassoLars": [[662, 2, 1, "", "fit"], [662, 2, 1, "", "get_metadata_routing"], [662, 2, 1, "", "get_params"], [662, 2, 1, "", "predict"], [662, 2, 1, "", "score"], [662, 2, 1, "", "set_fit_request"], [662, 2, 1, "", "set_params"], [662, 2, 1, "", "set_score_request"]], "sklearn.linear_model.LassoLarsCV": [[663, 2, 1, "", "fit"], [663, 2, 1, "", "get_metadata_routing"], [663, 2, 1, "", "get_params"], [663, 2, 1, "", "predict"], [663, 2, 1, "", "score"], [663, 2, 1, "", "set_fit_request"], [663, 2, 1, "", "set_params"], [663, 2, 1, "", "set_score_request"]], "sklearn.linear_model.LassoLarsIC": [[664, 2, 1, "", "fit"], [664, 2, 1, "", "get_metadata_routing"], [664, 2, 1, "", "get_params"], [664, 2, 1, "", "predict"], [664, 2, 1, "", "score"], [664, 2, 1, "", "set_fit_request"], [664, 2, 1, "", "set_params"], [664, 2, 1, "", "set_score_request"]], "sklearn.linear_model.LinearRegression": [[665, 2, 1, "", "fit"], [665, 2, 1, "", "get_metadata_routing"], [665, 2, 1, "", "get_params"], [665, 2, 1, "", "predict"], [665, 2, 1, "", "score"], [665, 2, 1, "", "set_fit_request"], [665, 2, 1, "", "set_params"], [665, 2, 1, "", "set_score_request"]], "sklearn.linear_model.LogisticRegression": [[666, 2, 1, "", "decision_function"], [666, 2, 1, "", "densify"], [666, 2, 1, "", "fit"], [666, 2, 1, "", "get_metadata_routing"], [666, 2, 1, "", "get_params"], [666, 2, 1, "", "predict"], [666, 2, 1, "", "predict_log_proba"], [666, 2, 1, "", "predict_proba"], [666, 2, 1, "", "score"], [666, 2, 1, "", "set_fit_request"], [666, 2, 1, "", "set_params"], [666, 2, 1, "", "set_score_request"], [666, 2, 1, "", "sparsify"]], "sklearn.linear_model.LogisticRegressionCV": [[667, 2, 1, "", "decision_function"], [667, 2, 1, "", "densify"], [667, 2, 1, "", "fit"], [667, 2, 1, "", "get_metadata_routing"], [667, 2, 1, "", "get_params"], [667, 2, 1, "", "predict"], [667, 2, 1, "", "predict_log_proba"], [667, 2, 1, "", "predict_proba"], [667, 2, 1, "", "score"], [667, 2, 1, "", "set_fit_request"], [667, 2, 1, "", "set_params"], [667, 2, 1, "", "set_score_request"], [667, 2, 1, "", "sparsify"]], "sklearn.linear_model.MultiTaskElasticNet": [[668, 2, 1, "", "fit"], [668, 2, 1, "", "get_metadata_routing"], [668, 2, 1, "", "get_params"], [668, 2, 1, "", "path"], [668, 2, 1, "", "predict"], [668, 2, 1, "", "score"], [668, 2, 1, "", "set_fit_request"], [668, 2, 1, "", "set_params"], [668, 2, 1, "", "set_score_request"], [668, 3, 1, "", "sparse_coef_"]], "sklearn.linear_model.MultiTaskElasticNetCV": [[669, 2, 1, "", "fit"], [669, 2, 1, "", "get_metadata_routing"], [669, 2, 1, "", "get_params"], [669, 2, 1, "", "path"], [669, 2, 1, "", "predict"], [669, 2, 1, "", "score"], [669, 2, 1, "", "set_fit_request"], [669, 2, 1, "", "set_params"], [669, 2, 1, "", "set_score_request"]], "sklearn.linear_model.MultiTaskLasso": [[670, 2, 1, "", "fit"], [670, 2, 1, "", "get_metadata_routing"], [670, 2, 1, "", "get_params"], [670, 2, 1, "", "path"], [670, 2, 1, "", "predict"], [670, 2, 1, "", "score"], [670, 2, 1, "", "set_fit_request"], [670, 2, 1, "", "set_params"], [670, 2, 1, "", "set_score_request"], [670, 3, 1, "", "sparse_coef_"]], "sklearn.linear_model.MultiTaskLassoCV": [[671, 2, 1, "", "fit"], [671, 2, 1, "", "get_metadata_routing"], [671, 2, 1, "", "get_params"], [671, 2, 1, "", "path"], [671, 2, 1, "", "predict"], [671, 2, 1, "", "score"], [671, 2, 1, "", "set_fit_request"], [671, 2, 1, "", "set_params"], [671, 2, 1, "", "set_score_request"]], "sklearn.linear_model.OrthogonalMatchingPursuit": [[672, 2, 1, "", "fit"], [672, 2, 1, "", "get_metadata_routing"], [672, 2, 1, "", "get_params"], [672, 2, 1, "", "predict"], [672, 2, 1, "", "score"], [672, 2, 1, "", "set_params"], [672, 2, 1, "", "set_score_request"]], "sklearn.linear_model.OrthogonalMatchingPursuitCV": [[673, 2, 1, "", "fit"], [673, 2, 1, "", "get_metadata_routing"], [673, 2, 1, "", "get_params"], [673, 2, 1, "", "predict"], [673, 2, 1, "", "score"], [673, 2, 1, "", "set_params"], [673, 2, 1, "", "set_score_request"]], "sklearn.linear_model.PassiveAggressiveClassifier": [[674, 2, 1, "", "decision_function"], [674, 2, 1, "", "densify"], [674, 2, 1, "", "fit"], [674, 2, 1, "", "get_metadata_routing"], [674, 2, 1, "", "get_params"], [674, 2, 1, "", "partial_fit"], [674, 2, 1, "", "predict"], [674, 2, 1, "", "score"], [674, 2, 1, "", "set_fit_request"], [674, 2, 1, "", "set_params"], [674, 2, 1, "", "set_partial_fit_request"], [674, 2, 1, "", "set_score_request"], [674, 2, 1, "", "sparsify"]], "sklearn.linear_model.PassiveAggressiveRegressor": [[675, 2, 1, "", "densify"], [675, 2, 1, "", "fit"], [675, 2, 1, "", "get_metadata_routing"], [675, 2, 1, "", "get_params"], [675, 2, 1, "", "partial_fit"], [675, 2, 1, "", "predict"], [675, 2, 1, "", "score"], [675, 2, 1, "", "set_fit_request"], [675, 2, 1, "", "set_params"], [675, 2, 1, "", "set_partial_fit_request"], [675, 2, 1, "", "set_score_request"], [675, 2, 1, "", "sparsify"]], "sklearn.linear_model.Perceptron": [[676, 2, 1, "", "decision_function"], [676, 2, 1, "", "densify"], [676, 2, 1, "", "fit"], [676, 2, 1, "", "get_metadata_routing"], [676, 2, 1, "", "get_params"], [676, 2, 1, "", "partial_fit"], [676, 2, 1, "", "predict"], [676, 2, 1, "", "score"], [676, 2, 1, "", "set_fit_request"], [676, 2, 1, "", "set_params"], [676, 2, 1, "", "set_partial_fit_request"], [676, 2, 1, "", "set_score_request"], [676, 2, 1, "", "sparsify"]], "sklearn.linear_model.PoissonRegressor": [[677, 2, 1, "", "fit"], [677, 2, 1, "", "get_metadata_routing"], [677, 2, 1, "", "get_params"], [677, 2, 1, "", "predict"], [677, 2, 1, "", "score"], [677, 2, 1, "", "set_fit_request"], [677, 2, 1, "", "set_params"], [677, 2, 1, "", "set_score_request"]], "sklearn.linear_model.QuantileRegressor": [[678, 2, 1, "", "fit"], [678, 2, 1, "", "get_metadata_routing"], [678, 2, 1, "", "get_params"], [678, 2, 1, "", "predict"], [678, 2, 1, "", "score"], [678, 2, 1, "", "set_fit_request"], [678, 2, 1, "", "set_params"], [678, 2, 1, "", "set_score_request"]], "sklearn.linear_model.RANSACRegressor": [[679, 2, 1, "", "fit"], [679, 2, 1, "", "get_metadata_routing"], [679, 2, 1, "", "get_params"], [679, 2, 1, "", "predict"], [679, 2, 1, "", "score"], [679, 2, 1, "", "set_fit_request"], [679, 2, 1, "", "set_params"]], "sklearn.linear_model.Ridge": [[680, 2, 1, "", "fit"], [680, 2, 1, "", "get_metadata_routing"], [680, 2, 1, "", "get_params"], [680, 2, 1, "", "predict"], [680, 2, 1, "", "score"], [680, 2, 1, "", "set_fit_request"], [680, 2, 1, "", "set_params"], [680, 2, 1, "", "set_score_request"]], "sklearn.linear_model.RidgeCV": [[681, 2, 1, "", "fit"], [681, 2, 1, "", "get_metadata_routing"], [681, 2, 1, "", "get_params"], [681, 2, 1, "", "predict"], [681, 2, 1, "", "score"], [681, 2, 1, "", "set_fit_request"], [681, 2, 1, "", "set_params"], [681, 2, 1, "", "set_score_request"]], "sklearn.linear_model.RidgeClassifier": [[682, 3, 1, "", "classes_"], [682, 2, 1, "", "decision_function"], [682, 2, 1, "", "fit"], [682, 2, 1, "", "get_metadata_routing"], [682, 2, 1, "", "get_params"], [682, 2, 1, "", "predict"], [682, 2, 1, "", "score"], [682, 2, 1, "", "set_fit_request"], [682, 2, 1, "", "set_params"], [682, 2, 1, "", "set_score_request"]], "sklearn.linear_model.RidgeClassifierCV": [[683, 3, 1, "", "classes_"], [683, 2, 1, "", "decision_function"], [683, 2, 1, "", "fit"], [683, 2, 1, "", "get_metadata_routing"], [683, 2, 1, "", "get_params"], [683, 2, 1, "", "predict"], [683, 2, 1, "", "score"], [683, 2, 1, "", "set_fit_request"], [683, 2, 1, "", "set_params"], [683, 2, 1, "", "set_score_request"]], "sklearn.linear_model.SGDClassifier": [[684, 2, 1, "", "decision_function"], [684, 2, 1, "", "densify"], [684, 2, 1, "", "fit"], [684, 2, 1, "", "get_metadata_routing"], [684, 2, 1, "", "get_params"], [684, 2, 1, "", "partial_fit"], [684, 2, 1, "", "predict"], [684, 2, 1, "", "predict_log_proba"], [684, 2, 1, "", "predict_proba"], [684, 2, 1, "", "score"], [684, 2, 1, "", "set_fit_request"], [684, 2, 1, "", "set_params"], [684, 2, 1, "", "set_partial_fit_request"], [684, 2, 1, "", "set_score_request"], [684, 2, 1, "", "sparsify"]], "sklearn.linear_model.SGDOneClassSVM": [[685, 2, 1, "", "decision_function"], [685, 2, 1, "", "densify"], [685, 2, 1, "", "fit"], [685, 2, 1, "", "fit_predict"], [685, 2, 1, "", "get_metadata_routing"], [685, 2, 1, "", "get_params"], [685, 2, 1, "", "partial_fit"], [685, 2, 1, "", "predict"], [685, 2, 1, "", "score_samples"], [685, 2, 1, "", "set_fit_request"], [685, 2, 1, "", "set_params"], [685, 2, 1, "", "set_partial_fit_request"], [685, 2, 1, "", "sparsify"]], "sklearn.linear_model.SGDRegressor": [[686, 2, 1, "", "densify"], [686, 2, 1, "", "fit"], [686, 2, 1, "", "get_metadata_routing"], [686, 2, 1, "", "get_params"], [686, 2, 1, "", "partial_fit"], [686, 2, 1, "", "predict"], [686, 2, 1, "", "score"], [686, 2, 1, "", "set_fit_request"], [686, 2, 1, "", "set_params"], [686, 2, 1, "", "set_partial_fit_request"], [686, 2, 1, "", "set_score_request"], [686, 2, 1, "", "sparsify"]], "sklearn.linear_model.TheilSenRegressor": [[687, 2, 1, "", "fit"], [687, 2, 1, "", "get_metadata_routing"], [687, 2, 1, "", "get_params"], [687, 2, 1, "", "predict"], [687, 2, 1, "", "score"], [687, 2, 1, "", "set_params"], [687, 2, 1, "", "set_score_request"]], "sklearn.linear_model.TweedieRegressor": [[688, 2, 1, "", "fit"], [688, 2, 1, "", "get_metadata_routing"], [688, 2, 1, "", "get_params"], [688, 2, 1, "", "predict"], [688, 2, 1, "", "score"], [688, 2, 1, "", "set_fit_request"], [688, 2, 1, "", "set_params"], [688, 2, 1, "", "set_score_request"]], "sklearn.manifold": [[696, 1, 1, "", "Isomap"], [697, 1, 1, "", "LocallyLinearEmbedding"], [698, 1, 1, "", "MDS"], [699, 1, 1, "", "SpectralEmbedding"], [700, 1, 1, "", "TSNE"], [701, 4, 1, "", "locally_linear_embedding"], [702, 4, 1, "", "smacof"], [703, 4, 1, "", "spectral_embedding"], [704, 4, 1, "", "trustworthiness"]], "sklearn.manifold.Isomap": [[696, 2, 1, "", "fit"], [696, 2, 1, "", "fit_transform"], [696, 2, 1, "", "get_feature_names_out"], [696, 2, 1, "", "get_metadata_routing"], [696, 2, 1, "", "get_params"], [696, 2, 1, "", "reconstruction_error"], [696, 2, 1, "", "set_output"], [696, 2, 1, "", "set_params"], [696, 2, 1, "", "transform"]], "sklearn.manifold.LocallyLinearEmbedding": [[697, 2, 1, "", "fit"], [697, 2, 1, "", "fit_transform"], [697, 2, 1, "", "get_feature_names_out"], [697, 2, 1, "", "get_metadata_routing"], [697, 2, 1, "", "get_params"], [697, 2, 1, "", "set_output"], [697, 2, 1, "", "set_params"], [697, 2, 1, "", "transform"]], "sklearn.manifold.MDS": [[698, 2, 1, "", "fit"], [698, 2, 1, "", "fit_transform"], [698, 2, 1, "", "get_metadata_routing"], [698, 2, 1, "", "get_params"], [698, 2, 1, "", "set_fit_request"], [698, 2, 1, "", "set_params"]], "sklearn.manifold.SpectralEmbedding": [[699, 2, 1, "", "fit"], [699, 2, 1, "", "fit_transform"], [699, 2, 1, "", "get_metadata_routing"], [699, 2, 1, "", "get_params"], [699, 2, 1, "", "set_params"]], "sklearn.manifold.TSNE": [[700, 2, 1, "", "fit"], [700, 2, 1, "", "fit_transform"], [700, 2, 1, "", "get_feature_names_out"], [700, 2, 1, "", "get_metadata_routing"], [700, 2, 1, "", "get_params"], [700, 2, 1, "", "set_output"], [700, 2, 1, "", "set_params"]], "sklearn.metrics": [[705, 1, 1, "", "ConfusionMatrixDisplay"], [706, 1, 1, "", "DetCurveDisplay"], [707, 1, 1, "", "DistanceMetric"], [708, 1, 1, "", "PrecisionRecallDisplay"], [709, 1, 1, "", "PredictionErrorDisplay"], [710, 1, 1, "", "RocCurveDisplay"], [711, 4, 1, "", "accuracy_score"], [712, 4, 1, "", "adjusted_mutual_info_score"], [713, 4, 1, "", "adjusted_rand_score"], [714, 4, 1, "", "auc"], [715, 4, 1, "", "average_precision_score"], [716, 4, 1, "", "balanced_accuracy_score"], [717, 4, 1, "", "brier_score_loss"], [718, 4, 1, "", "calinski_harabasz_score"], [719, 4, 1, "", "check_scoring"], [720, 4, 1, "", "class_likelihood_ratios"], [721, 4, 1, "", "classification_report"], [27, 0, 0, "-", "cluster"], [724, 4, 1, "", "cohen_kappa_score"], [725, 4, 1, "", "completeness_score"], [726, 4, 1, "", "confusion_matrix"], [727, 4, 1, "", "consensus_score"], [728, 4, 1, "", "coverage_error"], [729, 4, 1, "", "d2_absolute_error_score"], [730, 4, 1, "", "d2_log_loss_score"], [731, 4, 1, "", "d2_pinball_score"], [732, 4, 1, "", "d2_tweedie_score"], [733, 4, 1, "", "davies_bouldin_score"], [734, 4, 1, "", "dcg_score"], [735, 4, 1, "", "det_curve"], [736, 4, 1, "", "explained_variance_score"], [737, 4, 1, "", "f1_score"], [738, 4, 1, "", "fbeta_score"], [739, 4, 1, "", "fowlkes_mallows_score"], [740, 4, 1, "", "get_scorer"], [741, 4, 1, "", "get_scorer_names"], [742, 4, 1, "", "hamming_loss"], [743, 4, 1, "", "hinge_loss"], [744, 4, 1, "", "homogeneity_completeness_v_measure"], [745, 4, 1, "", "homogeneity_score"], [746, 4, 1, "", "jaccard_score"], [747, 4, 1, "", "label_ranking_average_precision_score"], [748, 4, 1, "", "label_ranking_loss"], [749, 4, 1, "", "log_loss"], [750, 4, 1, "", "make_scorer"], [751, 4, 1, "", "matthews_corrcoef"], [752, 4, 1, "", "max_error"], [753, 4, 1, "", "mean_absolute_error"], [754, 4, 1, "", "mean_absolute_percentage_error"], [755, 4, 1, "", "mean_gamma_deviance"], [756, 4, 1, "", "mean_pinball_loss"], [757, 4, 1, "", "mean_poisson_deviance"], [758, 4, 1, "", "mean_squared_error"], [759, 4, 1, "", "mean_squared_log_error"], [760, 4, 1, "", "mean_tweedie_deviance"], [761, 4, 1, "", "median_absolute_error"], [762, 4, 1, "", "multilabel_confusion_matrix"], [763, 4, 1, "", "mutual_info_score"], [764, 4, 1, "", "ndcg_score"], [765, 4, 1, "", "normalized_mutual_info_score"], [27, 0, 0, "-", "pairwise"], [786, 4, 1, "", "pairwise_distances"], [787, 4, 1, "", "pairwise_distances_argmin"], [788, 4, 1, "", "pairwise_distances_argmin_min"], [789, 4, 1, "", "pairwise_distances_chunked"], [790, 4, 1, "", "precision_recall_curve"], [791, 4, 1, "", "precision_recall_fscore_support"], [792, 4, 1, "", "precision_score"], [793, 4, 1, "", "r2_score"], [794, 4, 1, "", "rand_score"], [795, 4, 1, "", "recall_score"], [796, 4, 1, "", "roc_auc_score"], [797, 4, 1, "", "roc_curve"], [798, 4, 1, "", "root_mean_squared_error"], [799, 4, 1, "", "root_mean_squared_log_error"], [800, 4, 1, "", "silhouette_samples"], [801, 4, 1, "", "silhouette_score"], [802, 4, 1, "", "top_k_accuracy_score"], [803, 4, 1, "", "v_measure_score"], [804, 4, 1, "", "zero_one_loss"]], "sklearn.metrics.ConfusionMatrixDisplay": [[705, 2, 1, "", "from_estimator"], [705, 2, 1, "", "from_predictions"], [705, 2, 1, "", "plot"]], "sklearn.metrics.DetCurveDisplay": [[706, 2, 1, "", "from_estimator"], [706, 2, 1, "", "from_predictions"], [706, 2, 1, "", "plot"]], "sklearn.metrics.DistanceMetric": [[707, 2, 1, "", "get_metric"]], "sklearn.metrics.PrecisionRecallDisplay": [[708, 2, 1, "", "from_estimator"], [708, 2, 1, "", "from_predictions"], [708, 2, 1, "", "plot"]], "sklearn.metrics.PredictionErrorDisplay": [[709, 2, 1, "", "from_estimator"], [709, 2, 1, "", "from_predictions"], [709, 2, 1, "", "plot"]], "sklearn.metrics.RocCurveDisplay": [[710, 2, 1, "", "from_estimator"], [710, 2, 1, "", "from_predictions"], [710, 2, 1, "", "plot"]], "sklearn.metrics.cluster": [[722, 4, 1, "", "contingency_matrix"], [723, 4, 1, "", "pair_confusion_matrix"]], "sklearn.metrics.pairwise": [[766, 4, 1, "", "additive_chi2_kernel"], [767, 4, 1, "", "chi2_kernel"], [768, 4, 1, "", "cosine_distances"], [769, 4, 1, "", "cosine_similarity"], [770, 4, 1, "", "distance_metrics"], [771, 4, 1, "", "euclidean_distances"], [772, 4, 1, "", "haversine_distances"], [773, 4, 1, "", "kernel_metrics"], [774, 4, 1, "", "laplacian_kernel"], [775, 4, 1, "", "linear_kernel"], [776, 4, 1, "", "manhattan_distances"], [777, 4, 1, "", "nan_euclidean_distances"], [778, 4, 1, "", "paired_cosine_distances"], [779, 4, 1, "", "paired_distances"], [780, 4, 1, "", "paired_euclidean_distances"], [781, 4, 1, "", "paired_manhattan_distances"], [782, 4, 1, "", "pairwise_kernels"], [783, 4, 1, "", "polynomial_kernel"], [784, 4, 1, "", "rbf_kernel"], [785, 4, 1, "", "sigmoid_kernel"]], "sklearn.mixture": [[805, 1, 1, "", "BayesianGaussianMixture"], [806, 1, 1, "", "GaussianMixture"]], "sklearn.mixture.BayesianGaussianMixture": [[805, 2, 1, "", "fit"], [805, 2, 1, "", "fit_predict"], [805, 2, 1, "", "get_metadata_routing"], [805, 2, 1, "", "get_params"], [805, 2, 1, "", "predict"], [805, 2, 1, "", "predict_proba"], [805, 2, 1, "", "sample"], [805, 2, 1, "", "score"], [805, 2, 1, "", "score_samples"], [805, 2, 1, "", "set_params"]], "sklearn.mixture.GaussianMixture": [[806, 2, 1, "", "aic"], [806, 2, 1, "", "bic"], [806, 2, 1, "", "fit"], [806, 2, 1, "", "fit_predict"], [806, 2, 1, "", "get_metadata_routing"], [806, 2, 1, "", "get_params"], [806, 2, 1, "", "predict"], [806, 2, 1, "", "predict_proba"], [806, 2, 1, "", "sample"], [806, 2, 1, "", "score"], [806, 2, 1, "", "score_samples"], [806, 2, 1, "", "set_params"]], "sklearn.model_selection": [[807, 1, 1, "", "FixedThresholdClassifier"], [808, 1, 1, "", "GridSearchCV"], [809, 1, 1, "", "GroupKFold"], [810, 1, 1, "", "GroupShuffleSplit"], [811, 1, 1, "", "HalvingGridSearchCV"], [812, 1, 1, "", "HalvingRandomSearchCV"], [813, 1, 1, "", "KFold"], [814, 1, 1, "", "LearningCurveDisplay"], [815, 1, 1, "", "LeaveOneGroupOut"], [816, 1, 1, "", "LeaveOneOut"], [817, 1, 1, "", "LeavePGroupsOut"], [818, 1, 1, "", "LeavePOut"], [819, 1, 1, "", "ParameterGrid"], [820, 1, 1, "", "ParameterSampler"], [821, 1, 1, "", "PredefinedSplit"], [822, 1, 1, "", "RandomizedSearchCV"], [823, 1, 1, "", "RepeatedKFold"], [824, 1, 1, "", "RepeatedStratifiedKFold"], [825, 1, 1, "", "ShuffleSplit"], [826, 1, 1, "", "StratifiedGroupKFold"], [827, 1, 1, "", "StratifiedKFold"], [828, 1, 1, "", "StratifiedShuffleSplit"], [829, 1, 1, "", "TimeSeriesSplit"], [830, 1, 1, "", "TunedThresholdClassifierCV"], [831, 1, 1, "", "ValidationCurveDisplay"], [832, 4, 1, "", "check_cv"], [833, 4, 1, "", "cross_val_predict"], [834, 4, 1, "", "cross_val_score"], [835, 4, 1, "", "cross_validate"], [836, 4, 1, "", "learning_curve"], [837, 4, 1, "", "permutation_test_score"], [838, 4, 1, "", "train_test_split"], [839, 4, 1, "", "validation_curve"]], "sklearn.model_selection.FixedThresholdClassifier": [[807, 3, 1, "", "classes_"], [807, 2, 1, "", "decision_function"], [807, 2, 1, "", "fit"], [807, 2, 1, "", "get_metadata_routing"], [807, 2, 1, "", "get_params"], [807, 2, 1, "", "predict"], [807, 2, 1, "", "predict_log_proba"], [807, 2, 1, "", "predict_proba"], [807, 2, 1, "", "score"], [807, 2, 1, "", "set_params"], [807, 2, 1, "", "set_score_request"]], "sklearn.model_selection.GridSearchCV": [[808, 3, 1, "", "classes_"], [808, 2, 1, "", "decision_function"], [808, 2, 1, "", "fit"], [808, 2, 1, "", "get_metadata_routing"], [808, 2, 1, "", "get_params"], [808, 2, 1, "", "inverse_transform"], [808, 3, 1, "", "n_features_in_"], [808, 2, 1, "", "predict"], [808, 2, 1, "", "predict_log_proba"], [808, 2, 1, "", "predict_proba"], [808, 2, 1, "", "score"], [808, 2, 1, "", "score_samples"], [808, 2, 1, "", "set_params"], [808, 2, 1, "", "transform"]], "sklearn.model_selection.GroupKFold": [[809, 2, 1, "", "get_metadata_routing"], [809, 2, 1, "", "get_n_splits"], [809, 2, 1, "", "set_split_request"], [809, 2, 1, "", "split"]], "sklearn.model_selection.GroupShuffleSplit": [[810, 2, 1, "", "get_metadata_routing"], [810, 2, 1, "", "get_n_splits"], [810, 2, 1, "", "set_split_request"], [810, 2, 1, "", "split"]], "sklearn.model_selection.HalvingGridSearchCV": [[811, 3, 1, "", "classes_"], [811, 2, 1, "", "decision_function"], [811, 2, 1, "", "fit"], [811, 2, 1, "", "get_metadata_routing"], [811, 2, 1, "", "get_params"], [811, 2, 1, "", "inverse_transform"], [811, 3, 1, "", "n_features_in_"], [811, 2, 1, "", "predict"], [811, 2, 1, "", "predict_log_proba"], [811, 2, 1, "", "predict_proba"], [811, 2, 1, "", "score"], [811, 2, 1, "", "score_samples"], [811, 2, 1, "", "set_params"], [811, 2, 1, "", "transform"]], "sklearn.model_selection.HalvingRandomSearchCV": [[812, 3, 1, "", "classes_"], [812, 2, 1, "", "decision_function"], [812, 2, 1, "", "fit"], [812, 2, 1, "", "get_metadata_routing"], [812, 2, 1, "", "get_params"], [812, 2, 1, "", "inverse_transform"], [812, 3, 1, "", "n_features_in_"], [812, 2, 1, "", "predict"], [812, 2, 1, "", "predict_log_proba"], [812, 2, 1, "", "predict_proba"], [812, 2, 1, "", "score"], [812, 2, 1, "", "score_samples"], [812, 2, 1, "", "set_params"], [812, 2, 1, "", "transform"]], "sklearn.model_selection.KFold": [[813, 2, 1, "", "get_metadata_routing"], [813, 2, 1, "", "get_n_splits"], [813, 2, 1, "", "split"]], "sklearn.model_selection.LearningCurveDisplay": [[814, 2, 1, "", "from_estimator"], [814, 2, 1, "", "plot"]], "sklearn.model_selection.LeaveOneGroupOut": [[815, 2, 1, "", "get_metadata_routing"], [815, 2, 1, "", "get_n_splits"], [815, 2, 1, "", "set_split_request"], [815, 2, 1, "", "split"]], "sklearn.model_selection.LeaveOneOut": [[816, 2, 1, "", "get_metadata_routing"], [816, 2, 1, "", "get_n_splits"], [816, 2, 1, "", "split"]], "sklearn.model_selection.LeavePGroupsOut": [[817, 2, 1, "", "get_metadata_routing"], [817, 2, 1, "", "get_n_splits"], [817, 2, 1, "", "set_split_request"], [817, 2, 1, "", "split"]], "sklearn.model_selection.LeavePOut": [[818, 2, 1, "", "get_metadata_routing"], [818, 2, 1, "", "get_n_splits"], [818, 2, 1, "", "split"]], "sklearn.model_selection.PredefinedSplit": [[821, 2, 1, "", "get_metadata_routing"], [821, 2, 1, "", "get_n_splits"], [821, 2, 1, "", "split"]], "sklearn.model_selection.RandomizedSearchCV": [[822, 3, 1, "", "classes_"], [822, 2, 1, "", "decision_function"], [822, 2, 1, "", "fit"], [822, 2, 1, "", "get_metadata_routing"], [822, 2, 1, "", "get_params"], [822, 2, 1, "", "inverse_transform"], [822, 3, 1, "", "n_features_in_"], [822, 2, 1, "", "predict"], [822, 2, 1, "", "predict_log_proba"], [822, 2, 1, "", "predict_proba"], [822, 2, 1, "", "score"], [822, 2, 1, "", "score_samples"], [822, 2, 1, "", "set_params"], [822, 2, 1, "", "transform"]], "sklearn.model_selection.RepeatedKFold": [[823, 2, 1, "", "get_metadata_routing"], [823, 2, 1, "", "get_n_splits"], [823, 2, 1, "", "split"]], "sklearn.model_selection.RepeatedStratifiedKFold": [[824, 2, 1, "", "get_metadata_routing"], [824, 2, 1, "", "get_n_splits"], [824, 2, 1, "", "split"]], "sklearn.model_selection.ShuffleSplit": [[825, 2, 1, "", "get_metadata_routing"], [825, 2, 1, "", "get_n_splits"], [825, 2, 1, "", "split"]], "sklearn.model_selection.StratifiedGroupKFold": [[826, 2, 1, "", "get_metadata_routing"], [826, 2, 1, "", "get_n_splits"], [826, 2, 1, "", "set_split_request"], [826, 2, 1, "", "split"]], "sklearn.model_selection.StratifiedKFold": [[827, 2, 1, "", "get_metadata_routing"], [827, 2, 1, "", "get_n_splits"], [827, 2, 1, "", "split"]], "sklearn.model_selection.StratifiedShuffleSplit": [[828, 2, 1, "", "get_metadata_routing"], [828, 2, 1, "", "get_n_splits"], [828, 2, 1, "", "split"]], "sklearn.model_selection.TimeSeriesSplit": [[829, 2, 1, "", "get_metadata_routing"], [829, 2, 1, "", "get_n_splits"], [829, 2, 1, "", "split"]], "sklearn.model_selection.TunedThresholdClassifierCV": [[830, 3, 1, "", "classes_"], [830, 2, 1, "", "decision_function"], [830, 2, 1, "", "fit"], [830, 2, 1, "", "get_metadata_routing"], [830, 2, 1, "", "get_params"], [830, 2, 1, "", "predict"], [830, 2, 1, "", "predict_log_proba"], [830, 2, 1, "", "predict_proba"], [830, 2, 1, "", "score"], [830, 2, 1, "", "set_params"], [830, 2, 1, "", "set_score_request"]], "sklearn.model_selection.ValidationCurveDisplay": [[831, 2, 1, "", "from_estimator"], [831, 2, 1, "", "plot"]], "sklearn.multiclass": [[840, 1, 1, "", "OneVsOneClassifier"], [841, 1, 1, "", "OneVsRestClassifier"], [842, 1, 1, "", "OutputCodeClassifier"]], "sklearn.multiclass.OneVsOneClassifier": [[840, 2, 1, "", "decision_function"], [840, 2, 1, "", "fit"], [840, 2, 1, "", "get_metadata_routing"], [840, 2, 1, "", "get_params"], [840, 3, 1, "", "n_classes_"], [840, 2, 1, "", "partial_fit"], [840, 2, 1, "", "predict"], [840, 2, 1, "", "score"], [840, 2, 1, "", "set_params"], [840, 2, 1, "", "set_partial_fit_request"], [840, 2, 1, "", "set_score_request"]], "sklearn.multiclass.OneVsRestClassifier": [[841, 2, 1, "", "decision_function"], [841, 2, 1, "", "fit"], [841, 2, 1, "", "get_metadata_routing"], [841, 2, 1, "", "get_params"], [841, 3, 1, "", "multilabel_"], [841, 3, 1, "", "n_classes_"], [841, 2, 1, "", "partial_fit"], [841, 2, 1, "", "predict"], [841, 2, 1, "", "predict_proba"], [841, 2, 1, "", "score"], [841, 2, 1, "", "set_params"], [841, 2, 1, "", "set_partial_fit_request"], [841, 2, 1, "", "set_score_request"]], "sklearn.multiclass.OutputCodeClassifier": [[842, 2, 1, "", "fit"], [842, 2, 1, "", "get_metadata_routing"], [842, 2, 1, "", "get_params"], [842, 2, 1, "", "predict"], [842, 2, 1, "", "score"], [842, 2, 1, "", "set_params"], [842, 2, 1, "", "set_score_request"]], "sklearn.multioutput": [[843, 1, 1, "", "ClassifierChain"], [844, 1, 1, "", "MultiOutputClassifier"], [845, 1, 1, "", "MultiOutputRegressor"], [846, 1, 1, "", "RegressorChain"]], "sklearn.multioutput.ClassifierChain": [[843, 2, 1, "", "decision_function"], [843, 2, 1, "", "fit"], [843, 2, 1, "", "get_metadata_routing"], [843, 2, 1, "", "get_params"], [843, 2, 1, "", "predict"], [843, 2, 1, "", "predict_log_proba"], [843, 2, 1, "", "predict_proba"], [843, 2, 1, "", "score"], [843, 2, 1, "", "set_params"], [843, 2, 1, "", "set_score_request"]], "sklearn.multioutput.MultiOutputClassifier": [[844, 2, 1, "", "fit"], [844, 2, 1, "", "get_metadata_routing"], [844, 2, 1, "", "get_params"], [844, 2, 1, "", "partial_fit"], [844, 2, 1, "", "predict"], [844, 2, 1, "", "predict_proba"], [844, 2, 1, "", "score"], [844, 2, 1, "", "set_fit_request"], [844, 2, 1, "", "set_params"], [844, 2, 1, "", "set_partial_fit_request"]], "sklearn.multioutput.MultiOutputRegressor": [[845, 2, 1, "", "fit"], [845, 2, 1, "", "get_metadata_routing"], [845, 2, 1, "", "get_params"], [845, 2, 1, "", "partial_fit"], [845, 2, 1, "", "predict"], [845, 2, 1, "", "score"], [845, 2, 1, "", "set_fit_request"], [845, 2, 1, "", "set_params"], [845, 2, 1, "", "set_partial_fit_request"], [845, 2, 1, "", "set_score_request"]], "sklearn.multioutput.RegressorChain": [[846, 2, 1, "", "fit"], [846, 2, 1, "", "get_metadata_routing"], [846, 2, 1, "", "get_params"], [846, 2, 1, "", "predict"], [846, 2, 1, "", "score"], [846, 2, 1, "", "set_params"], [846, 2, 1, "", "set_score_request"]], "sklearn.naive_bayes": [[847, 1, 1, "", "BernoulliNB"], [848, 1, 1, "", "CategoricalNB"], [849, 1, 1, "", "ComplementNB"], [850, 1, 1, "", "GaussianNB"], [851, 1, 1, "", "MultinomialNB"]], "sklearn.naive_bayes.BernoulliNB": [[847, 2, 1, "", "fit"], [847, 2, 1, "", "get_metadata_routing"], [847, 2, 1, "", "get_params"], [847, 2, 1, "", "partial_fit"], [847, 2, 1, "", "predict"], [847, 2, 1, "", "predict_joint_log_proba"], [847, 2, 1, "", "predict_log_proba"], [847, 2, 1, "", "predict_proba"], [847, 2, 1, "", "score"], [847, 2, 1, "", "set_fit_request"], [847, 2, 1, "", "set_params"], [847, 2, 1, "", "set_partial_fit_request"], [847, 2, 1, "", "set_score_request"]], "sklearn.naive_bayes.CategoricalNB": [[848, 2, 1, "", "fit"], [848, 2, 1, "", "get_metadata_routing"], [848, 2, 1, "", "get_params"], [848, 2, 1, "", "partial_fit"], [848, 2, 1, "", "predict"], [848, 2, 1, "", "predict_joint_log_proba"], [848, 2, 1, "", "predict_log_proba"], [848, 2, 1, "", "predict_proba"], [848, 2, 1, "", "score"], [848, 2, 1, "", "set_fit_request"], [848, 2, 1, "", "set_params"], [848, 2, 1, "", "set_partial_fit_request"], [848, 2, 1, "", "set_score_request"]], "sklearn.naive_bayes.ComplementNB": [[849, 2, 1, "", "fit"], [849, 2, 1, "", "get_metadata_routing"], [849, 2, 1, "", "get_params"], [849, 2, 1, "", "partial_fit"], [849, 2, 1, "", "predict"], [849, 2, 1, "", "predict_joint_log_proba"], [849, 2, 1, "", "predict_log_proba"], [849, 2, 1, "", "predict_proba"], [849, 2, 1, "", "score"], [849, 2, 1, "", "set_fit_request"], [849, 2, 1, "", "set_params"], [849, 2, 1, "", "set_partial_fit_request"], [849, 2, 1, "", "set_score_request"]], "sklearn.naive_bayes.GaussianNB": [[850, 2, 1, "", "fit"], [850, 2, 1, "", "get_metadata_routing"], [850, 2, 1, "", "get_params"], [850, 2, 1, "", "partial_fit"], [850, 2, 1, "", "predict"], [850, 2, 1, "", "predict_joint_log_proba"], [850, 2, 1, "", "predict_log_proba"], [850, 2, 1, "", "predict_proba"], [850, 2, 1, "", "score"], [850, 2, 1, "", "set_fit_request"], [850, 2, 1, "", "set_params"], [850, 2, 1, "", "set_partial_fit_request"], [850, 2, 1, "", "set_score_request"]], "sklearn.naive_bayes.MultinomialNB": [[851, 2, 1, "", "fit"], [851, 2, 1, "", "get_metadata_routing"], [851, 2, 1, "", "get_params"], [851, 2, 1, "", "partial_fit"], [851, 2, 1, "", "predict"], [851, 2, 1, "", "predict_joint_log_proba"], [851, 2, 1, "", "predict_log_proba"], [851, 2, 1, "", "predict_proba"], [851, 2, 1, "", "score"], [851, 2, 1, "", "set_fit_request"], [851, 2, 1, "", "set_params"], [851, 2, 1, "", "set_partial_fit_request"], [851, 2, 1, "", "set_score_request"]], "sklearn.neighbors": [[852, 1, 1, "", "BallTree"], [853, 1, 1, "", "KDTree"], [854, 1, 1, "", "KNeighborsClassifier"], [855, 1, 1, "", "KNeighborsRegressor"], [856, 1, 1, "", "KNeighborsTransformer"], [857, 1, 1, "", "KernelDensity"], [858, 1, 1, "", "LocalOutlierFactor"], [859, 1, 1, "", "NearestCentroid"], [860, 1, 1, "", "NearestNeighbors"], [861, 1, 1, "", "NeighborhoodComponentsAnalysis"], [862, 1, 1, "", "RadiusNeighborsClassifier"], [863, 1, 1, "", "RadiusNeighborsRegressor"], [864, 1, 1, "", "RadiusNeighborsTransformer"], [865, 4, 1, "", "kneighbors_graph"], [866, 4, 1, "", "radius_neighbors_graph"], [867, 4, 1, "", "sort_graph_by_row_values"]], "sklearn.neighbors.BallTree": [[852, 2, 1, "", "get_arrays"], [852, 2, 1, "", "get_n_calls"], [852, 2, 1, "", "get_tree_stats"], [852, 2, 1, "", "kernel_density"], [852, 2, 1, "", "query"], [852, 2, 1, "", "query_radius"], [852, 2, 1, "", "reset_n_calls"], [852, 2, 1, "", "two_point_correlation"]], "sklearn.neighbors.KDTree": [[853, 2, 1, "", "get_arrays"], [853, 2, 1, "", "get_n_calls"], [853, 2, 1, "", "get_tree_stats"], [853, 2, 1, "", "kernel_density"], [853, 2, 1, "", "query"], [853, 2, 1, "", "query_radius"], [853, 2, 1, "", "reset_n_calls"], [853, 2, 1, "", "two_point_correlation"]], "sklearn.neighbors.KNeighborsClassifier": [[854, 2, 1, "", "fit"], [854, 2, 1, "", "get_metadata_routing"], [854, 2, 1, "", "get_params"], [854, 2, 1, "", "kneighbors"], [854, 2, 1, "", "kneighbors_graph"], [854, 2, 1, "", "predict"], [854, 2, 1, "", "predict_proba"], [854, 2, 1, "", "score"], [854, 2, 1, "", "set_params"], [854, 2, 1, "", "set_score_request"]], "sklearn.neighbors.KNeighborsRegressor": [[855, 2, 1, "", "fit"], [855, 2, 1, "", "get_metadata_routing"], [855, 2, 1, "", "get_params"], [855, 2, 1, "", "kneighbors"], [855, 2, 1, "", "kneighbors_graph"], [855, 2, 1, "", "predict"], [855, 2, 1, "", "score"], [855, 2, 1, "", "set_params"], [855, 2, 1, "", "set_score_request"]], "sklearn.neighbors.KNeighborsTransformer": [[856, 2, 1, "", "fit"], [856, 2, 1, "", "fit_transform"], [856, 2, 1, "", "get_feature_names_out"], [856, 2, 1, "", "get_metadata_routing"], [856, 2, 1, "", "get_params"], [856, 2, 1, "", "kneighbors"], [856, 2, 1, "", "kneighbors_graph"], [856, 2, 1, "", "set_output"], [856, 2, 1, "", "set_params"], [856, 2, 1, "", "transform"]], "sklearn.neighbors.KernelDensity": [[857, 2, 1, "", "fit"], [857, 2, 1, "", "get_metadata_routing"], [857, 2, 1, "", "get_params"], [857, 2, 1, "", "sample"], [857, 2, 1, "", "score"], [857, 2, 1, "", "score_samples"], [857, 2, 1, "", "set_fit_request"], [857, 2, 1, "", "set_params"]], "sklearn.neighbors.LocalOutlierFactor": [[858, 2, 1, "", "decision_function"], [858, 2, 1, "", "fit"], [858, 2, 1, "", "fit_predict"], [858, 2, 1, "", "get_metadata_routing"], [858, 2, 1, "", "get_params"], [858, 2, 1, "", "kneighbors"], [858, 2, 1, "", "kneighbors_graph"], [858, 2, 1, "", "predict"], [858, 2, 1, "", "score_samples"], [858, 2, 1, "", "set_params"]], "sklearn.neighbors.NearestCentroid": [[859, 2, 1, "", "fit"], [859, 2, 1, "", "get_metadata_routing"], [859, 2, 1, "", "get_params"], [859, 2, 1, "", "predict"], [859, 2, 1, "", "score"], [859, 2, 1, "", "set_params"], [859, 2, 1, "", "set_score_request"]], "sklearn.neighbors.NearestNeighbors": [[860, 2, 1, "", "fit"], [860, 2, 1, "", "get_metadata_routing"], [860, 2, 1, "", "get_params"], [860, 2, 1, "", "kneighbors"], [860, 2, 1, "", "kneighbors_graph"], [860, 2, 1, "", "radius_neighbors"], [860, 2, 1, "", "radius_neighbors_graph"], [860, 2, 1, "", "set_params"]], "sklearn.neighbors.NeighborhoodComponentsAnalysis": [[861, 2, 1, "", "fit"], [861, 2, 1, "", "fit_transform"], [861, 2, 1, "", "get_feature_names_out"], [861, 2, 1, "", "get_metadata_routing"], [861, 2, 1, "", "get_params"], [861, 2, 1, "", "set_output"], [861, 2, 1, "", "set_params"], [861, 2, 1, "", "transform"]], "sklearn.neighbors.RadiusNeighborsClassifier": [[862, 2, 1, "", "fit"], [862, 2, 1, "", "get_metadata_routing"], [862, 2, 1, "", "get_params"], [862, 2, 1, "", "predict"], [862, 2, 1, "", "predict_proba"], [862, 2, 1, "", "radius_neighbors"], [862, 2, 1, "", "radius_neighbors_graph"], [862, 2, 1, "", "score"], [862, 2, 1, "", "set_params"], [862, 2, 1, "", "set_score_request"]], "sklearn.neighbors.RadiusNeighborsRegressor": [[863, 2, 1, "", "fit"], [863, 2, 1, "", "get_metadata_routing"], [863, 2, 1, "", "get_params"], [863, 2, 1, "", "predict"], [863, 2, 1, "", "radius_neighbors"], [863, 2, 1, "", "radius_neighbors_graph"], [863, 2, 1, "", "score"], [863, 2, 1, "", "set_params"], [863, 2, 1, "", "set_score_request"]], "sklearn.neighbors.RadiusNeighborsTransformer": [[864, 2, 1, "", "fit"], [864, 2, 1, "", "fit_transform"], [864, 2, 1, "", "get_feature_names_out"], [864, 2, 1, "", "get_metadata_routing"], [864, 2, 1, "", "get_params"], [864, 2, 1, "", "radius_neighbors"], [864, 2, 1, "", "radius_neighbors_graph"], [864, 2, 1, "", "set_output"], [864, 2, 1, "", "set_params"], [864, 2, 1, "", "transform"]], "sklearn.neural_network": [[868, 1, 1, "", "BernoulliRBM"], [869, 1, 1, "", "MLPClassifier"], [870, 1, 1, "", "MLPRegressor"]], "sklearn.neural_network.BernoulliRBM": [[868, 2, 1, "", "fit"], [868, 2, 1, "", "fit_transform"], [868, 2, 1, "", "get_feature_names_out"], [868, 2, 1, "", "get_metadata_routing"], [868, 2, 1, "", "get_params"], [868, 2, 1, "", "gibbs"], [868, 2, 1, "", "partial_fit"], [868, 2, 1, "", "score_samples"], [868, 2, 1, "", "set_output"], [868, 2, 1, "", "set_params"], [868, 2, 1, "", "transform"]], "sklearn.neural_network.MLPClassifier": [[869, 2, 1, "", "fit"], [869, 2, 1, "", "get_metadata_routing"], [869, 2, 1, "", "get_params"], [869, 2, 1, "", "partial_fit"], [869, 2, 1, "", "predict"], [869, 2, 1, "", "predict_log_proba"], [869, 2, 1, "", "predict_proba"], [869, 2, 1, "", "score"], [869, 2, 1, "", "set_params"], [869, 2, 1, "", "set_partial_fit_request"], [869, 2, 1, "", "set_score_request"]], "sklearn.neural_network.MLPRegressor": [[870, 2, 1, "", "fit"], [870, 2, 1, "", "get_metadata_routing"], [870, 2, 1, "", "get_params"], [870, 2, 1, "", "partial_fit"], [870, 2, 1, "", "predict"], [870, 2, 1, "", "score"], [870, 2, 1, "", "set_params"], [870, 2, 1, "", "set_score_request"]], "sklearn.pipeline": [[871, 1, 1, "", "FeatureUnion"], [872, 1, 1, "", "Pipeline"], [873, 4, 1, "", "make_pipeline"], [874, 4, 1, "", "make_union"]], "sklearn.pipeline.FeatureUnion": [[871, 3, 1, "", "feature_names_in_"], [871, 2, 1, "", "fit"], [871, 2, 1, "", "fit_transform"], [871, 2, 1, "", "get_feature_names_out"], [871, 2, 1, "", "get_metadata_routing"], [871, 2, 1, "", "get_params"], [871, 3, 1, "", "n_features_in_"], [871, 2, 1, "", "set_output"], [871, 2, 1, "", "set_params"], [871, 2, 1, "", "transform"]], "sklearn.pipeline.Pipeline": [[872, 3, 1, "", "classes_"], [872, 2, 1, "", "decision_function"], [872, 3, 1, "", "feature_names_in_"], [872, 2, 1, "", "fit"], [872, 2, 1, "", "fit_predict"], [872, 2, 1, "", "fit_transform"], [872, 2, 1, "", "get_feature_names_out"], [872, 2, 1, "", "get_metadata_routing"], [872, 2, 1, "", "get_params"], [872, 2, 1, "", "inverse_transform"], [872, 3, 1, "", "n_features_in_"], [872, 3, 1, "", "named_steps"], [872, 2, 1, "", "predict"], [872, 2, 1, "", "predict_log_proba"], [872, 2, 1, "", "predict_proba"], [872, 2, 1, "", "score"], [872, 2, 1, "", "score_samples"], [872, 2, 1, "", "set_output"], [872, 2, 1, "", "set_params"], [872, 2, 1, "", "set_score_request"], [872, 2, 1, "", "transform"]], "sklearn.preprocessing": [[875, 1, 1, "", "Binarizer"], [876, 1, 1, "", "FunctionTransformer"], [877, 1, 1, "", "KBinsDiscretizer"], [878, 1, 1, "", "KernelCenterer"], [879, 1, 1, "", "LabelBinarizer"], [880, 1, 1, "", "LabelEncoder"], [881, 1, 1, "", "MaxAbsScaler"], [882, 1, 1, "", "MinMaxScaler"], [883, 1, 1, "", "MultiLabelBinarizer"], [884, 1, 1, "", "Normalizer"], [885, 1, 1, "", "OneHotEncoder"], [886, 1, 1, "", "OrdinalEncoder"], [887, 1, 1, "", "PolynomialFeatures"], [888, 1, 1, "", "PowerTransformer"], [889, 1, 1, "", "QuantileTransformer"], [890, 1, 1, "", "RobustScaler"], [891, 1, 1, "", "SplineTransformer"], [892, 1, 1, "", "StandardScaler"], [893, 1, 1, "", "TargetEncoder"], [894, 4, 1, "", "add_dummy_feature"], [895, 4, 1, "", "binarize"], [896, 4, 1, "", "label_binarize"], [897, 4, 1, "", "maxabs_scale"], [898, 4, 1, "", "minmax_scale"], [899, 4, 1, "", "normalize"], [900, 4, 1, "", "power_transform"], [901, 4, 1, "", "quantile_transform"], [902, 4, 1, "", "robust_scale"], [903, 4, 1, "", "scale"]], "sklearn.preprocessing.Binarizer": [[875, 2, 1, "", "fit"], [875, 2, 1, "", "fit_transform"], [875, 2, 1, "", "get_feature_names_out"], [875, 2, 1, "", "get_metadata_routing"], [875, 2, 1, "", "get_params"], [875, 2, 1, "", "set_output"], [875, 2, 1, "", "set_params"], [875, 2, 1, "", "set_transform_request"], [875, 2, 1, "", "transform"]], "sklearn.preprocessing.FunctionTransformer": [[876, 2, 1, "", "fit"], [876, 2, 1, "", "fit_transform"], [876, 2, 1, "", "get_feature_names_out"], [876, 2, 1, "", "get_metadata_routing"], [876, 2, 1, "", "get_params"], [876, 2, 1, "", "inverse_transform"], [876, 2, 1, "", "set_output"], [876, 2, 1, "", "set_params"], [876, 2, 1, "", "transform"]], "sklearn.preprocessing.KBinsDiscretizer": [[877, 2, 1, "", "fit"], [877, 2, 1, "", "fit_transform"], [877, 2, 1, "", "get_feature_names_out"], [877, 2, 1, "", "get_metadata_routing"], [877, 2, 1, "", "get_params"], [877, 2, 1, "", "inverse_transform"], [877, 2, 1, "", "set_fit_request"], [877, 2, 1, "", "set_output"], [877, 2, 1, "", "set_params"], [877, 2, 1, "", "transform"]], "sklearn.preprocessing.KernelCenterer": [[878, 2, 1, "", "fit"], [878, 2, 1, "", "fit_transform"], [878, 2, 1, "", "get_feature_names_out"], [878, 2, 1, "", "get_metadata_routing"], [878, 2, 1, "", "get_params"], [878, 2, 1, "", "set_fit_request"], [878, 2, 1, "", "set_output"], [878, 2, 1, "", "set_params"], [878, 2, 1, "", "set_transform_request"], [878, 2, 1, "", "transform"]], "sklearn.preprocessing.LabelBinarizer": [[879, 2, 1, "", "fit"], [879, 2, 1, "", "fit_transform"], [879, 2, 1, "", "get_metadata_routing"], [879, 2, 1, "", "get_params"], [879, 2, 1, "", "inverse_transform"], [879, 2, 1, "", "set_inverse_transform_request"], [879, 2, 1, "", "set_output"], [879, 2, 1, "", "set_params"], [879, 2, 1, "", "transform"]], "sklearn.preprocessing.LabelEncoder": [[880, 2, 1, "", "fit"], [880, 2, 1, "", "fit_transform"], [880, 2, 1, "", "get_metadata_routing"], [880, 2, 1, "", "get_params"], [880, 2, 1, "", "inverse_transform"], [880, 2, 1, "", "set_output"], [880, 2, 1, "", "set_params"], [880, 2, 1, "", "transform"]], "sklearn.preprocessing.MaxAbsScaler": [[881, 2, 1, "", "fit"], [881, 2, 1, "", "fit_transform"], [881, 2, 1, "", "get_feature_names_out"], [881, 2, 1, "", "get_metadata_routing"], [881, 2, 1, "", "get_params"], [881, 2, 1, "", "inverse_transform"], [881, 2, 1, "", "partial_fit"], [881, 2, 1, "", "set_output"], [881, 2, 1, "", "set_params"], [881, 2, 1, "", "transform"]], "sklearn.preprocessing.MinMaxScaler": [[882, 2, 1, "", "fit"], [882, 2, 1, "", "fit_transform"], [882, 2, 1, "", "get_feature_names_out"], [882, 2, 1, "", "get_metadata_routing"], [882, 2, 1, "", "get_params"], [882, 2, 1, "", "inverse_transform"], [882, 2, 1, "", "partial_fit"], [882, 2, 1, "", "set_output"], [882, 2, 1, "", "set_params"], [882, 2, 1, "", "transform"]], "sklearn.preprocessing.MultiLabelBinarizer": [[883, 2, 1, "", "fit"], [883, 2, 1, "", "fit_transform"], [883, 2, 1, "", "get_metadata_routing"], [883, 2, 1, "", "get_params"], [883, 2, 1, "", "inverse_transform"], [883, 2, 1, "", "set_output"], [883, 2, 1, "", "set_params"], [883, 2, 1, "", "transform"]], "sklearn.preprocessing.Normalizer": [[884, 2, 1, "", "fit"], [884, 2, 1, "", "fit_transform"], [884, 2, 1, "", "get_feature_names_out"], [884, 2, 1, "", "get_metadata_routing"], [884, 2, 1, "", "get_params"], [884, 2, 1, "", "set_output"], [884, 2, 1, "", "set_params"], [884, 2, 1, "", "set_transform_request"], [884, 2, 1, "", "transform"]], "sklearn.preprocessing.OneHotEncoder": [[885, 2, 1, "", "fit"], [885, 2, 1, "", "fit_transform"], [885, 2, 1, "", "get_feature_names_out"], [885, 2, 1, "", "get_metadata_routing"], [885, 2, 1, "", "get_params"], [885, 3, 1, "", "infrequent_categories_"], [885, 2, 1, "", "inverse_transform"], [885, 2, 1, "", "set_output"], [885, 2, 1, "", "set_params"], [885, 2, 1, "", "transform"]], "sklearn.preprocessing.OrdinalEncoder": [[886, 2, 1, "", "fit"], [886, 2, 1, "", "fit_transform"], [886, 2, 1, "", "get_feature_names_out"], [886, 2, 1, "", "get_metadata_routing"], [886, 2, 1, "", "get_params"], [886, 3, 1, "", "infrequent_categories_"], [886, 2, 1, "", "inverse_transform"], [886, 2, 1, "", "set_output"], [886, 2, 1, "", "set_params"], [886, 2, 1, "", "transform"]], "sklearn.preprocessing.PolynomialFeatures": [[887, 2, 1, "", "fit"], [887, 2, 1, "", "fit_transform"], [887, 2, 1, "", "get_feature_names_out"], [887, 2, 1, "", "get_metadata_routing"], [887, 2, 1, "", "get_params"], [887, 3, 1, "", "powers_"], [887, 2, 1, "", "set_output"], [887, 2, 1, "", "set_params"], [887, 2, 1, "", "transform"]], "sklearn.preprocessing.PowerTransformer": [[888, 2, 1, "", "fit"], [888, 2, 1, "", "fit_transform"], [888, 2, 1, "", "get_feature_names_out"], [888, 2, 1, "", "get_metadata_routing"], [888, 2, 1, "", "get_params"], [888, 2, 1, "", "inverse_transform"], [888, 2, 1, "", "set_output"], [888, 2, 1, "", "set_params"], [888, 2, 1, "", "transform"]], "sklearn.preprocessing.QuantileTransformer": [[889, 2, 1, "", "fit"], [889, 2, 1, "", "fit_transform"], [889, 2, 1, "", "get_feature_names_out"], [889, 2, 1, "", "get_metadata_routing"], [889, 2, 1, "", "get_params"], [889, 2, 1, "", "inverse_transform"], [889, 2, 1, "", "set_output"], [889, 2, 1, "", "set_params"], [889, 2, 1, "", "transform"]], "sklearn.preprocessing.RobustScaler": [[890, 2, 1, "", "fit"], [890, 2, 1, "", "fit_transform"], [890, 2, 1, "", "get_feature_names_out"], [890, 2, 1, "", "get_metadata_routing"], [890, 2, 1, "", "get_params"], [890, 2, 1, "", "inverse_transform"], [890, 2, 1, "", "set_output"], [890, 2, 1, "", "set_params"], [890, 2, 1, "", "transform"]], "sklearn.preprocessing.SplineTransformer": [[891, 2, 1, "", "fit"], [891, 2, 1, "", "fit_transform"], [891, 2, 1, "", "get_feature_names_out"], [891, 2, 1, "", "get_metadata_routing"], [891, 2, 1, "", "get_params"], [891, 2, 1, "", "set_fit_request"], [891, 2, 1, "", "set_output"], [891, 2, 1, "", "set_params"], [891, 2, 1, "", "transform"]], "sklearn.preprocessing.StandardScaler": [[892, 2, 1, "", "fit"], [892, 2, 1, "", "fit_transform"], [892, 2, 1, "", "get_feature_names_out"], [892, 2, 1, "", "get_metadata_routing"], [892, 2, 1, "", "get_params"], [892, 2, 1, "", "inverse_transform"], [892, 2, 1, "", "partial_fit"], [892, 2, 1, "", "set_fit_request"], [892, 2, 1, "", "set_inverse_transform_request"], [892, 2, 1, "", "set_output"], [892, 2, 1, "", "set_params"], [892, 2, 1, "", "set_partial_fit_request"], [892, 2, 1, "", "set_transform_request"], [892, 2, 1, "", "transform"]], "sklearn.preprocessing.TargetEncoder": [[893, 2, 1, "", "fit"], [893, 2, 1, "", "fit_transform"], [893, 2, 1, "", "get_feature_names_out"], [893, 2, 1, "", "get_metadata_routing"], [893, 2, 1, "", "get_params"], [893, 3, 1, "", "infrequent_categories_"], [893, 2, 1, "", "set_output"], [893, 2, 1, "", "set_params"], [893, 2, 1, "", "transform"]], "sklearn.random_projection": [[904, 1, 1, "", "GaussianRandomProjection"], [905, 1, 1, "", "SparseRandomProjection"], [906, 4, 1, "", "johnson_lindenstrauss_min_dim"]], "sklearn.random_projection.GaussianRandomProjection": [[904, 2, 1, "", "fit"], [904, 2, 1, "", "fit_transform"], [904, 2, 1, "", "get_feature_names_out"], [904, 2, 1, "", "get_metadata_routing"], [904, 2, 1, "", "get_params"], [904, 2, 1, "", "inverse_transform"], [904, 2, 1, "", "set_output"], [904, 2, 1, "", "set_params"], [904, 2, 1, "", "transform"]], "sklearn.random_projection.SparseRandomProjection": [[905, 2, 1, "", "fit"], [905, 2, 1, "", "fit_transform"], [905, 2, 1, "", "get_feature_names_out"], [905, 2, 1, "", "get_metadata_routing"], [905, 2, 1, "", "get_params"], [905, 2, 1, "", "inverse_transform"], [905, 2, 1, "", "set_output"], [905, 2, 1, "", "set_params"], [905, 2, 1, "", "transform"]], "sklearn.semi_supervised": [[907, 1, 1, "", "LabelPropagation"], [908, 1, 1, "", "LabelSpreading"], [909, 1, 1, "", "SelfTrainingClassifier"]], "sklearn.semi_supervised.LabelPropagation": [[907, 2, 1, "", "fit"], [907, 2, 1, "", "get_metadata_routing"], [907, 2, 1, "", "get_params"], [907, 2, 1, "", "predict"], [907, 2, 1, "", "predict_proba"], [907, 2, 1, "", "score"], [907, 2, 1, "", "set_params"], [907, 2, 1, "", "set_score_request"]], "sklearn.semi_supervised.LabelSpreading": [[908, 2, 1, "", "fit"], [908, 2, 1, "", "get_metadata_routing"], [908, 2, 1, "", "get_params"], [908, 2, 1, "", "predict"], [908, 2, 1, "", "predict_proba"], [908, 2, 1, "", "score"], [908, 2, 1, "", "set_params"], [908, 2, 1, "", "set_score_request"]], "sklearn.semi_supervised.SelfTrainingClassifier": [[909, 2, 1, "", "decision_function"], [909, 2, 1, "", "fit"], [909, 2, 1, "", "get_metadata_routing"], [909, 2, 1, "", "get_params"], [909, 2, 1, "", "predict"], [909, 2, 1, "", "predict_log_proba"], [909, 2, 1, "", "predict_proba"], [909, 2, 1, "", "score"], [909, 2, 1, "", "set_params"]], "sklearn.svm": [[912, 1, 1, "", "LinearSVC"], [913, 1, 1, "", "LinearSVR"], [914, 1, 1, "", "NuSVC"], [915, 1, 1, "", "NuSVR"], [916, 1, 1, "", "OneClassSVM"], [917, 1, 1, "", "SVC"], [918, 1, 1, "", "SVR"], [919, 4, 1, "", "l1_min_c"]], "sklearn.svm.LinearSVC": [[912, 2, 1, "", "decision_function"], [912, 2, 1, "", "densify"], [912, 2, 1, "", "fit"], [912, 2, 1, "", "get_metadata_routing"], [912, 2, 1, "", "get_params"], [912, 2, 1, "", "predict"], [912, 2, 1, "", "score"], [912, 2, 1, "", "set_fit_request"], [912, 2, 1, "", "set_params"], [912, 2, 1, "", "set_score_request"], [912, 2, 1, "", "sparsify"]], "sklearn.svm.LinearSVR": [[913, 2, 1, "", "fit"], [913, 2, 1, "", "get_metadata_routing"], [913, 2, 1, "", "get_params"], [913, 2, 1, "", "predict"], [913, 2, 1, "", "score"], [913, 2, 1, "", "set_fit_request"], [913, 2, 1, "", "set_params"], [913, 2, 1, "", "set_score_request"]], "sklearn.svm.NuSVC": [[914, 3, 1, "", "coef_"], [914, 2, 1, "", "decision_function"], [914, 2, 1, "", "fit"], [914, 2, 1, "", "get_metadata_routing"], [914, 2, 1, "", "get_params"], [914, 3, 1, "", "n_support_"], [914, 2, 1, "", "predict"], [914, 2, 1, "", "predict_log_proba"], [914, 2, 1, "", "predict_proba"], [914, 3, 1, "", "probA_"], [914, 3, 1, "", "probB_"], [914, 2, 1, "", "score"], [914, 2, 1, "", "set_fit_request"], [914, 2, 1, "", "set_params"], [914, 2, 1, "", "set_score_request"]], "sklearn.svm.NuSVR": [[915, 3, 1, "", "coef_"], [915, 2, 1, "", "fit"], [915, 2, 1, "", "get_metadata_routing"], [915, 2, 1, "", "get_params"], [915, 3, 1, "", "n_support_"], [915, 2, 1, "", "predict"], [915, 2, 1, "", "score"], [915, 2, 1, "", "set_fit_request"], [915, 2, 1, "", "set_params"], [915, 2, 1, "", "set_score_request"]], "sklearn.svm.OneClassSVM": [[916, 3, 1, "", "coef_"], [916, 2, 1, "", "decision_function"], [916, 2, 1, "", "fit"], [916, 2, 1, "", "fit_predict"], [916, 2, 1, "", "get_metadata_routing"], [916, 2, 1, "", "get_params"], [916, 3, 1, "", "n_support_"], [916, 2, 1, "", "predict"], [916, 2, 1, "", "score_samples"], [916, 2, 1, "", "set_fit_request"], [916, 2, 1, "", "set_params"]], "sklearn.svm.SVC": [[917, 3, 1, "", "coef_"], [917, 2, 1, "", "decision_function"], [917, 2, 1, "", "fit"], [917, 2, 1, "", "get_metadata_routing"], [917, 2, 1, "", "get_params"], [917, 3, 1, "", "n_support_"], [917, 2, 1, "", "predict"], [917, 2, 1, "", "predict_log_proba"], [917, 2, 1, "", "predict_proba"], [917, 3, 1, "", "probA_"], [917, 3, 1, "", "probB_"], [917, 2, 1, "", "score"], [917, 2, 1, "", "set_fit_request"], [917, 2, 1, "", "set_params"], [917, 2, 1, "", "set_score_request"]], "sklearn.svm.SVR": [[918, 3, 1, "", "coef_"], [918, 2, 1, "", "fit"], [918, 2, 1, "", "get_metadata_routing"], [918, 2, 1, "", "get_params"], [918, 3, 1, "", "n_support_"], [918, 2, 1, "", "predict"], [918, 2, 1, "", "score"], [918, 2, 1, "", "set_fit_request"], [918, 2, 1, "", "set_params"], [918, 2, 1, "", "set_score_request"]], "sklearn.tree": [[920, 1, 1, "", "DecisionTreeClassifier"], [921, 1, 1, "", "DecisionTreeRegressor"], [922, 1, 1, "", "ExtraTreeClassifier"], [923, 1, 1, "", "ExtraTreeRegressor"], [924, 4, 1, "", "export_graphviz"], [925, 4, 1, "", "export_text"], [926, 4, 1, "", "plot_tree"]], "sklearn.tree.DecisionTreeClassifier": [[920, 2, 1, "", "apply"], [920, 2, 1, "", "cost_complexity_pruning_path"], [920, 2, 1, "", "decision_path"], [920, 3, 1, "", "feature_importances_"], [920, 2, 1, "", "fit"], [920, 2, 1, "", "get_depth"], [920, 2, 1, "", "get_metadata_routing"], [920, 2, 1, "", "get_n_leaves"], [920, 2, 1, "", "get_params"], [920, 2, 1, "", "predict"], [920, 2, 1, "", "predict_log_proba"], [920, 2, 1, "", "predict_proba"], [920, 2, 1, "", "score"], [920, 2, 1, "", "set_fit_request"], [920, 2, 1, "", "set_params"], [920, 2, 1, "", "set_predict_proba_request"], [920, 2, 1, "", "set_predict_request"], [920, 2, 1, "", "set_score_request"]], "sklearn.tree.DecisionTreeRegressor": [[921, 2, 1, "", "apply"], [921, 2, 1, "", "cost_complexity_pruning_path"], [921, 2, 1, "", "decision_path"], [921, 3, 1, "", "feature_importances_"], [921, 2, 1, "", "fit"], [921, 2, 1, "", "get_depth"], [921, 2, 1, "", "get_metadata_routing"], [921, 2, 1, "", "get_n_leaves"], [921, 2, 1, "", "get_params"], [921, 2, 1, "", "predict"], [921, 2, 1, "", "score"], [921, 2, 1, "", "set_fit_request"], [921, 2, 1, "", "set_params"], [921, 2, 1, "", "set_predict_request"], [921, 2, 1, "", "set_score_request"]], "sklearn.tree.ExtraTreeClassifier": [[922, 2, 1, "", "apply"], [922, 2, 1, "", "cost_complexity_pruning_path"], [922, 2, 1, "", "decision_path"], [922, 3, 1, "", "feature_importances_"], [922, 2, 1, "", "fit"], [922, 2, 1, "", "get_depth"], [922, 2, 1, "", "get_metadata_routing"], [922, 2, 1, "", "get_n_leaves"], [922, 2, 1, "", "get_params"], [922, 2, 1, "", "predict"], [922, 2, 1, "", "predict_log_proba"], [922, 2, 1, "", "predict_proba"], [922, 2, 1, "", "score"], [922, 2, 1, "", "set_fit_request"], [922, 2, 1, "", "set_params"], [922, 2, 1, "", "set_predict_proba_request"], [922, 2, 1, "", "set_predict_request"], [922, 2, 1, "", "set_score_request"]], "sklearn.tree.ExtraTreeRegressor": [[923, 2, 1, "", "apply"], [923, 2, 1, "", "cost_complexity_pruning_path"], [923, 2, 1, "", "decision_path"], [923, 3, 1, "", "feature_importances_"], [923, 2, 1, "", "fit"], [923, 2, 1, "", "get_depth"], [923, 2, 1, "", "get_metadata_routing"], [923, 2, 1, "", "get_n_leaves"], [923, 2, 1, "", "get_params"], [923, 2, 1, "", "predict"], [923, 2, 1, "", "score"], [923, 2, 1, "", "set_fit_request"], [923, 2, 1, "", "set_params"], [923, 2, 1, "", "set_predict_request"], [923, 2, 1, "", "set_score_request"]], "sklearn.utils": [[927, 1, 1, "", "Bunch"], [928, 4, 1, "", "_safe_indexing"], [41, 0, 0, "-", "arrayfuncs"], [930, 4, 1, "", "as_float_array"], [931, 4, 1, "", "assert_all_finite"], [932, 4, 1, "", "check_X_y"], [933, 4, 1, "", "check_array"], [934, 4, 1, "", "check_consistent_length"], [935, 4, 1, "", "check_random_state"], [936, 4, 1, "", "check_scalar"], [41, 0, 0, "-", "class_weight"], [939, 1, 1, "", "deprecated"], [41, 0, 0, "-", "discovery"], [41, 0, 0, "-", "estimator_checks"], [945, 4, 1, "", "estimator_html_repr"], [41, 0, 0, "-", "extmath"], [952, 4, 1, "", "gen_batches"], [953, 4, 1, "", "gen_even_slices"], [41, 0, 0, "-", "graph"], [955, 4, 1, "", "indexable"], [41, 0, 0, "-", "metadata_routing"], [41, 0, 0, "-", "metaestimators"], [41, 0, 0, "-", "multiclass"], [965, 4, 1, "", "murmurhash3_32"], [41, 0, 0, "-", "parallel"], [968, 1, 1, "", "parallel_backend"], [41, 0, 0, "-", "random"], [970, 4, 1, "", "register_parallel_backend"], [971, 4, 1, "", "resample"], [972, 4, 1, "", "safe_mask"], [973, 4, 1, "", "safe_sqr"], [974, 4, 1, "", "shuffle"], [41, 0, 0, "-", "sparsefuncs"], [41, 0, 0, "-", "sparsefuncs_fast"], [41, 0, 0, "-", "validation"]], "sklearn.utils.Bunch": [[927, 2, 1, "", "clear"], [927, 2, 1, "", "copy"], [927, 2, 1, "", "fromkeys"], [927, 2, 1, "", "get"], [927, 2, 1, "", "items"], [927, 2, 1, "", "keys"], [927, 2, 1, "", "pop"], [927, 2, 1, "", "popitem"], [927, 2, 1, "", "setdefault"], [927, 2, 1, "", "update"], [927, 2, 1, "", "values"]], "sklearn.utils.arrayfuncs": [[929, 4, 1, "", "min_pos"]], "sklearn.utils.class_weight": [[937, 4, 1, "", "compute_class_weight"], [938, 4, 1, "", "compute_sample_weight"]], "sklearn.utils.deprecated": [[939, 2, 1, "", "__call__"]], "sklearn.utils.discovery": [[940, 4, 1, "", "all_displays"], [941, 4, 1, "", "all_estimators"], [942, 4, 1, "", "all_functions"]], "sklearn.utils.estimator_checks": [[943, 4, 1, "", "check_estimator"], [944, 4, 1, "", "parametrize_with_checks"]], "sklearn.utils.extmath": [[946, 4, 1, "", "density"], [947, 4, 1, "", "fast_logdet"], [948, 4, 1, "", "randomized_range_finder"], [949, 4, 1, "", "randomized_svd"], [950, 4, 1, "", "safe_sparse_dot"], [951, 4, 1, "", "weighted_mode"]], "sklearn.utils.graph": [[954, 4, 1, "", "single_source_shortest_path_length"]], "sklearn.utils.metadata_routing": [[956, 1, 1, "", "MetadataRequest"], [957, 1, 1, "", "MetadataRouter"], [958, 1, 1, "", "MethodMapping"], [959, 4, 1, "", "get_routing_for_object"], [960, 4, 1, "", "process_routing"]], "sklearn.utils.metadata_routing.MetadataRequest": [[956, 2, 1, "", "consumes"]], "sklearn.utils.metadata_routing.MetadataRouter": [[957, 2, 1, "", "add"], [957, 2, 1, "", "add_self_request"], [957, 2, 1, "", "consumes"], [957, 2, 1, "", "route_params"], [957, 2, 1, "", "validate_metadata"]], "sklearn.utils.metadata_routing.MethodMapping": [[958, 2, 1, "", "add"]], "sklearn.utils.metaestimators": [[961, 4, 1, "", "available_if"]], "sklearn.utils.multiclass": [[962, 4, 1, "", "is_multilabel"], [963, 4, 1, "", "type_of_target"], [964, 4, 1, "", "unique_labels"]], "sklearn.utils.parallel": [[966, 1, 1, "", "Parallel"], [967, 4, 1, "", "delayed"]], "sklearn.utils.parallel.Parallel": [[966, 2, 1, "", "__call__"], [966, 2, 1, "", "dispatch_next"], [966, 2, 1, "", "dispatch_one_batch"], [966, 2, 1, "", "format"], [966, 2, 1, "", "print_progress"]], "sklearn.utils.random": [[969, 4, 1, "", "sample_without_replacement"]], "sklearn.utils.sparsefuncs": [[975, 4, 1, "", "incr_mean_variance_axis"], [976, 4, 1, "", "inplace_column_scale"], [977, 4, 1, "", "inplace_csr_column_scale"], [978, 4, 1, "", "inplace_row_scale"], [979, 4, 1, "", "inplace_swap_column"], [980, 4, 1, "", "inplace_swap_row"], [981, 4, 1, "", "mean_variance_axis"]], "sklearn.utils.sparsefuncs_fast": [[982, 4, 1, "", "inplace_csr_row_normalize_l1"], [983, 4, 1, "", "inplace_csr_row_normalize_l2"]], "sklearn.utils.validation": [[984, 4, 1, "", "check_is_fitted"], [985, 4, 1, "", "check_memory"], [986, 4, 1, "", "check_symmetric"], [987, 4, 1, "", "column_or_1d"], [988, 4, 1, "", "has_fit_parameter"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "function", "Python function"], "5": ["py", "exception", "Python exception"], "6": ["py", "attribute", "Python attribute"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:function", "5": "py:exception", "6": "py:attribute"}, "terms": {"": [0, 2, 43, 44, 45, 46, 47, 49, 50, 51, 52, 55, 57, 58, 61, 64, 70, 73, 74, 75, 77, 78, 79, 81, 82, 83, 87, 88, 90, 92, 93, 94, 95, 96, 97, 99, 100, 102, 104, 105, 111, 112, 115, 117, 121, 122, 123, 125, 126, 127, 130, 133, 134, 135, 137, 139, 141, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 161, 167, 169, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 188, 189, 192, 193, 195, 197, 200, 201, 202, 204, 206, 208, 209, 210, 211, 212, 218, 220, 222, 224, 226, 227, 229, 232, 233, 234, 235, 236, 237, 240, 241, 242, 243, 244, 245, 247, 248, 251, 253, 254, 255, 257, 263, 265, 266, 268, 272, 273, 278, 279, 280, 281, 282, 285, 289, 291, 293, 299, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 317, 318, 319, 322, 325, 328, 330, 331, 332, 333, 334, 335, 336, 339, 340, 346, 347, 348, 349, 350, 353, 354, 355, 358, 360, 361, 362, 365, 366, 367, 368, 369, 373, 374, 375, 379, 380, 381, 383, 384, 385, 386, 387, 388, 390, 392, 393, 394, 395, 400, 401, 403, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 424, 426, 428, 430, 437, 441, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 467, 468, 471, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 497, 499, 504, 506, 508, 512, 518, 519, 527, 533, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 580, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 614, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 693, 695, 696, 697, 698, 699, 700, 701, 708, 709, 710, 716, 719, 724, 728, 730, 743, 749, 766, 767, 787, 788, 805, 806, 807, 808, 810, 811, 812, 817, 822, 826, 827, 830, 833, 834, 835, 837, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 927, 930, 932, 933, 936, 949, 951, 957, 958, 960, 984, 988, 989, 991, 992, 994, 996, 997, 998, 1001, 1002, 1003, 1004, 1005, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1021, 1024, 1025, 1029, 1030, 1032, 1033, 1034, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "0": [2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 380, 381, 383, 384, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 404, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 439, 441, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 585, 586, 589, 590, 591, 592, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 928, 929, 930, 932, 933, 937, 938, 940, 941, 942, 943, 944, 946, 948, 949, 951, 952, 953, 954, 961, 962, 963, 965, 966, 969, 970, 971, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 986, 989, 990, 992, 993, 994, 995, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1019, 1020, 1021, 1022, 1025, 1029, 1030, 1031, 1032, 1033, 1034, 1036, 1037, 1038, 1039], "00": [52, 68, 113, 128, 192, 193, 211, 238, 251, 272, 276, 279, 317, 335, 338, 339, 361, 380, 383, 392, 416, 423, 424, 613, 614, 721, 723, 796, 808, 822, 836, 921, 996, 1000, 1010, 1012, 1014, 1021, 1033], "000": [43, 44, 59, 62, 64, 77, 108, 177, 192, 194, 197, 251, 272, 276, 278, 280, 324, 331, 360, 361, 369, 381, 392, 423, 424, 498, 569, 570, 652, 685, 1014, 1021, 1034, 1052], "0000": [43, 333], "000000": [79, 192, 209, 238, 278, 323, 745], "00000000": 179, "000000e": 238, "000024": 373, "000045": 192, "00005": 54, "0000ff": [67, 307, 314], "0001": [49, 174, 228, 276, 388, 428, 451, 455, 467, 479, 480, 486, 541, 546, 548, 555, 557, 558, 567, 568, 654, 655, 656, 657, 660, 661, 666, 667, 668, 669, 670, 671, 676, 677, 680, 682, 684, 686, 688, 695, 697, 701, 869, 870, 912, 913, 989], "000178": 46, "000194": 46, "000198": 192, "000204": 46, "0002652948464431897": 291, "000266": 46, "000279": 46, "000282": 46, "0003": 142, "000310": 46, "0004": [142, 324, 612], "000415": 46, "000616": 360, "000647": 46, "000692": 360, "0008": 394, "000814": 360, "000850": 46, "000852": 360, "000977": 278, "00099547": 179, "000e": 424, "001": [46, 53, 68, 79, 97, 150, 174, 176, 192, 204, 229, 247, 257, 263, 276, 278, 280, 341, 361, 383, 392, 420, 544, 545, 547, 554, 635, 652, 653, 654, 655, 660, 661, 668, 669, 670, 671, 674, 675, 676, 684, 685, 686, 687, 689, 692, 697, 698, 701, 702, 805, 806, 869, 870, 907, 908, 914, 915, 916, 917, 918, 989, 1025, 1034], "00102": 360, "0011": 360, "0012": [43, 702], "0013": 43, "0014": 43, "0015": 43, "001540": 52, "00166409": 669, "00169": 360, "00171412": [766, 767, 998], "001727": 272, "001882": [208, 209], "002": [43, 51, 174, 176, 361, 383], "0024": 360, "002592": [208, 209], "0026": 360, "00274": 220, "0028": 43, "002861": [208, 209], "003": [43, 163, 1021], "0032": 43, "0034189458230957995": 45, "003533": 209, "003586": 544, "00360392": 544, "0036211": 544, "00362644": 544, "00364": 332, "00368320": 52, "00375": 1029, "00393284e": 201, "003935": [208, 209], "003e": 424, "004": [43, 226, 1021], "0044": 919, "004577621581492997": 326, "00462428": 759, "0049896314219659565": 326, "005": [43, 146, 278, 282, 304, 319, 361, 392], "005027": 281, "005187": 276, "005383": [208, 209], "005422": 278, "005670": [208, 209], "0057717": 52, "005840": 281, "005861": 281, "006": [43, 45, 286, 392], "006360": 281, "007": [263, 286, 299, 361], "0072b2": 263, "0075": [481, 549], "00755": 549, "007581": 283, "00768662e": 201, "0077": 1029, "007822": 292, "007833": 283, "008": [174, 361, 383, 392], "008142": [208, 209], "0083899664": 772, "008449": [208, 209], "00860051": 666, "008915": 281, "009": [43, 356, 392, 1021], "009075": 192, "00911944e": 201, "0092": 142, "009362": [208, 209], "009747": 292, "009778": 281, "009788": 292, "0098": 142, "00ff00": 307, "01": [45, 47, 49, 52, 53, 75, 79, 86, 97, 125, 127, 128, 142, 151, 153, 155, 157, 158, 174, 181, 185, 192, 193, 201, 204, 211, 227, 232, 233, 238, 240, 241, 247, 251, 252, 253, 257, 258, 265, 269, 271, 272, 277, 278, 279, 283, 285, 286, 287, 304, 315, 317, 319, 329, 335, 351, 361, 366, 367, 381, 383, 391, 416, 425, 457, 479, 523, 529, 540, 547, 551, 553, 603, 604, 606, 613, 650, 654, 662, 666, 686, 704, 723, 808, 822, 906, 969, 996, 1000, 1004, 1010, 1012, 1014, 1021, 1030, 1034], "010": [52, 361, 392, 837, 1008], "0106": 657, "010877306503748912": 286, "011": [43, 286, 299, 361, 392], "011595": [208, 209], "0116": 612, "011e": 424, "012": [52, 195, 197, 361], "012191": [208, 209], "012521": 209, "012831": 209, "0129126": 380, "013": [43, 52, 93, 171, 204, 286, 361, 1021], "01327": 381, "013519": 192, "014": [43, 286, 392], "0144": 623, "015": [331, 361, 364, 1008, 1021], "0152": 142, "015347e": 238, "015414e": 238, "015579": 292, "015587e": 238, "015596": [208, 209], "0157": 552, "015716e": 238, "016": 361, "01621459": 416, "016445": 278, "017": [83, 392, 479, 480], "017379": 52, "017646": [208, 209], "018": [52, 278, 480], "0182": 905, "018727": 192, "0188ff": 323, "018900": 209, "019": [174, 383, 392, 479], "019023": 278, "019069": 209, "01915283": 135, "019163": [208, 209], "0193": [478, 484], "0195": [429, 483], "0196": 142, "0198e1": 123, "019907": [208, 209], "01e": 206, "02": [43, 51, 52, 66, 79, 85, 87, 93, 97, 99, 115, 117, 125, 128, 141, 148, 174, 178, 183, 191, 192, 201, 238, 247, 255, 257, 272, 273, 279, 285, 304, 314, 317, 319, 321, 343, 345, 361, 365, 380, 383, 391, 415, 420, 449, 453, 605, 613, 666, 684, 808, 822, 891, 907, 921, 996, 1021], "020": [43, 52, 1008], "02069427": 88, "021849": 333, "021872": [208, 209], "022": [361, 1008], "022594": 192, "0226": 657, "022688": [208, 209], "023": [52, 286, 913, 1008], "02306214": 675, "02449161": 135, "02456369": 204, "024991": [208, 209], "025": [67, 222, 257, 275, 698, 702], "025102": 192, "025118864315095794": 1032, "025422": 278, "0255": 142, "0256": 179, "02564103": 368, "025930": [208, 209], "026": [118, 361], "026328": [208, 209], "026711": 89, "027": [52, 174, 361, 383], "027400": 373, "028": [249, 276, 279, 1021], "02818216": 117, "02891072": 1001, "029": 1008, "02d": 209, "03": [51, 52, 87, 113, 125, 155, 174, 181, 192, 201, 238, 251, 263, 269, 272, 279, 286, 339, 383, 424, 756, 808, 996, 1000, 1021], "030": [155, 335, 361, 1021], "030462": 105, "030498": 105, "030585": 292, "0306": 360, "030677e": 238, "030867": 192, "031": [83, 174, 361, 383], "031020": 105, "031025": 192, "031255": 192, "031555": 209, "03162278": 51, "031988": [208, 209], "0321": 843, "032179": 209, "03228": 630, "03228706": 618, "032356": [208, 209], "03237920e": 201, "032405": 192, "03260883": 1001, "033": 1008, "033764e": 238, "033823": 192, "034": [155, 176, 479], "034077": 209, "034194": [208, 209], "034278": 281, "034309": [208, 209], "03433306456": 45, "034821": [208, 209], "03498585": 1001, "035": [93, 206, 257, 1021], "035005": 192, "03531816": [834, 835], "035404": 46, "035445": 292, "0358": 46, "035914": 292, "036": [392, 480], "036038": [208, 209], "036214": 46, "0363": 360, "036385": [208, 209], "036445": 278, "036592": 292, "036656": [208, 209], "0367": 181, "0368": 627, "037": [216, 717, 1021], "0370": 858, "037600e": 238, "038": [479, 480, 869], "038076": [208, 209], "03812219": 1001, "038159": 820, "03823144": 179, "038689": 268, "0387": 612, "039": [93, 106, 276, 759, 789, 1000, 1021], "0393": 360, "039493": [208, 209], "039497": 261, "03f": 276, "04": [52, 66, 75, 77, 89, 102, 117, 127, 134, 174, 181, 192, 201, 219, 238, 255, 263, 269, 272, 278, 279, 291, 312, 336, 355, 361, 383, 423, 425, 479, 480, 654, 655, 660, 668, 669, 670, 689, 796, 808, 822, 996, 1000, 1004, 1014, 1021], "040530e": 238, "041": 52, "041297": 315, "0416": 415, "042": 392, "0427": [238, 477, 482], "042898": 315, "043": 392, "043401": [208, 209], "044": [43, 276, 759, 1000], "044223": [208, 209], "044451": [208, 209], "044642": [208, 209], "0448": 238, "045": [45, 254, 731, 1021], "04520": 165, "0453": 552, "045311": 315, "045390e": 238, "045599": [208, 209], "045934": 315, "046": [238, 242, 1021], "046010e": 238, "046458": 46, "046636": 192, "046641": [208, 209], "047": 392, "0479": 552, "048": 1008, "049": 479, "049530": 315, "049540": 315, "0499": 552, "04995982": 117, "05": [46, 47, 52, 54, 61, 63, 72, 79, 87, 95, 97, 99, 100, 102, 109, 117, 122, 130, 142, 145, 152, 155, 158, 165, 170, 174, 184, 185, 192, 200, 201, 219, 222, 234, 244, 245, 247, 257, 263, 265, 266, 269, 272, 278, 279, 287, 289, 304, 307, 312, 319, 321, 328, 332, 339, 341, 354, 383, 425, 458, 464, 486, 533, 538, 539, 554, 600, 603, 604, 606, 621, 622, 623, 627, 628, 630, 631, 633, 640, 641, 657, 698, 702, 764, 808, 861, 912, 913, 996, 1004, 1010, 1021], "050": [52, 1008], "05063247886572012": 286, "050680": [208, 209], "051": [75, 203, 480, 1021], "0512": 552, "051474": [208, 209], "0517578125e": 46, "052": 545, "05216586": 117, "052506": 333, "0529": 360, "053": [43, 120, 174, 361, 383, 392, 1021], "05306648": 133, "05317": 181, "054": [209, 1021], "054045": 281, "054699": 192, "0547": 916, "055": [174, 383, 1000], "05518": 631, "05532": 628, "05534985": 316, "0556": 916, "056": [52, 763, 1008], "0561": 916, "0566": 631, "05663": 628, "0568": 755, "057": [193, 392, 837], "057122": 209, "05752333": 135, "057711": 209, "058": [174, 276, 383], "05840206": 135, "059": [242, 361], "0595": 481, "05968": 165, "05994843": 51, "05e": 185, "06": [52, 87, 185, 192, 211, 219, 220, 272, 278, 279, 317, 321, 355, 392, 415, 490, 491, 492, 652, 653, 697, 701, 805, 806, 808, 822, 921, 996, 1010, 1012, 1021], "060": [43, 52, 94, 289, 361, 759, 1021], "0602": 46, "060342": 46, "061": 276, "0614": 631, "06165": 628, "061696": [208, 209], "062": 361, "0622": [478, 484], "0626": 843, "063": [276, 278, 445], "0631": 52, "064": [392, 1008], "065": [276, 298, 392, 1021], "06506307": 316, "0652": 630, "06525643": 618, "066": [276, 277, 656, 1021], "06686804": 235, "06694199": 135, "06695631e": 113, "067": 185, "067109": 209, "067528": 209, "068": [43, 52, 278], "068332": [208, 209], "06880943": 117, "06896552": 457, "069": 276, "069196": 276, "0693": 627, "07": [52, 81, 117, 134, 192, 216, 238, 257, 272, 287, 369, 381, 416, 569, 570, 700, 702, 1000, 1014, 1021], "070": [232, 1021], "0707": 631, "07073": 628, "071": [174, 336, 383, 445], "071964": 192, "072": [174, 445, 656], "073": [276, 350, 479, 480, 1021], "074": 276, "074412": [208, 209], "075": 128, "07582983e": 201, "075887": 209, "076": [43, 166, 354, 900, 1021], "077": [215, 299, 357, 1021], "077846": 278, "0779": 46, "078": 43, "07846529": 316, "07880": 165, "079": [174, 245, 368, 383, 1021], "079297": 278, "07963978e": 201, "07993421": 235, "08": [43, 47, 79, 85, 128, 192, 193, 204, 317, 383, 486, 539, 551, 553, 571, 649, 666, 808, 869, 870, 891, 1006, 1021], "080": [54, 1021], "08022103": [834, 835], "080295": 209, "081": 1008, "0813": [477, 482], "082": 43, "0825": 324, "083": [276, 361], "08333333": 368, "08377444": 759, "084": [61, 83, 131, 1021], "085": [366, 1021], "085299": [208, 209], "08533159": 223, "085711": 89, "08604995": 117, "086944": 261, "08699432": 224, "087": [233, 1021], "0872422": 668, "088": [677, 1008], "089": [92, 207, 1021], "089063": [208, 209], "08d": 55, "08t16": 380, "09": [47, 102, 127, 134, 192, 251, 255, 291, 416, 537, 615, 743, 850, 1000, 1010, 1014, 1021], "09000": 220, "090528": 192, "090808": 192, "091053": 192, "091621": 89, "092": [306, 1021], "092204": [208, 209], "093": 479, "094": 480, "09443967": 316, "09517222": 1032, "09541846": 544, "09684337": 235, "096950": 315, "097": [43, 54, 174, 223, 383, 1021], "098": 361, "098332": 62, "0986": [424, 876], "09861229": [620, 1010], "098758": 62, "098776": 278, "098932": 62, "099": [43, 45], "099820": 62, "09999999999999999": [253, 286, 349], "0d": 1042, "0e": [289, 557, 558], "0e4": 227, "0f": [57, 93], "0min": 89, "0rc1": 390, "0x": 935, "0x7f52650409d0": 290, "0x7f5265546d00": 258, "0x7f52655aedf0": 338, "0x7f5265674c10": 276, "0x7f52662ea3d0": 220, "0x7f5266446b40": 285, "0x7f526661b790": 105, "0x7f526661bd30": 105, "0x7f5266b1e850": 160, "0x7f5266b1eca0": 160, "0x7f5266ba6040": 290, "0x7f5266ba6240": 290, "0x7f5266d56f70": 144, "0x7f5266e98b50": 290, "0x7f52671f0550": 268, "0x7f52672e9280": 144, "0x7f529c18f1f0": 106, "0x7f529c198ca0": 105, "1": [0, 1, 2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 214, 216, 218, 219, 220, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 375, 380, 381, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 399, 400, 401, 404, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 437, 438, 439, 440, 441, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 585, 589, 590, 591, 592, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 936, 937, 938, 943, 946, 947, 948, 949, 950, 951, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 969, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 986, 987, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1021, 1023, 1024, 1025, 1026, 1029, 1030, 1031, 1032, 1033, 1037, 1039, 1043], "10": [2, 43, 44, 45, 46, 47, 49, 51, 52, 54, 55, 58, 62, 63, 64, 66, 67, 68, 72, 74, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 105, 106, 108, 111, 112, 113, 114, 115, 117, 118, 123, 127, 128, 129, 130, 134, 135, 139, 141, 142, 144, 145, 146, 148, 149, 150, 152, 153, 155, 157, 158, 161, 163, 167, 171, 174, 177, 178, 180, 182, 183, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 204, 210, 211, 213, 214, 218, 220, 221, 222, 223, 224, 225, 226, 227, 231, 232, 233, 236, 237, 238, 241, 242, 247, 250, 251, 252, 253, 254, 256, 257, 258, 260, 266, 267, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 283, 284, 286, 289, 292, 293, 296, 298, 304, 314, 315, 316, 317, 319, 320, 322, 323, 324, 328, 329, 330, 331, 332, 334, 335, 336, 338, 339, 340, 342, 347, 348, 349, 351, 352, 354, 355, 356, 358, 360, 361, 362, 369, 373, 380, 381, 382, 383, 384, 386, 388, 391, 392, 398, 399, 400, 404, 407, 408, 409, 413, 416, 417, 418, 419, 420, 421, 423, 424, 425, 426, 429, 446, 451, 455, 457, 459, 460, 461, 467, 468, 470, 483, 496, 500, 501, 504, 508, 509, 510, 512, 518, 519, 520, 521, 524, 528, 529, 532, 534, 536, 539, 543, 544, 545, 546, 547, 549, 550, 552, 553, 554, 556, 560, 563, 564, 565, 566, 569, 570, 572, 573, 574, 575, 576, 578, 590, 591, 595, 601, 602, 607, 608, 613, 615, 619, 625, 627, 635, 638, 640, 642, 643, 644, 645, 648, 650, 651, 652, 654, 655, 657, 660, 667, 668, 669, 670, 672, 673, 674, 675, 677, 678, 680, 681, 683, 684, 685, 686, 689, 693, 694, 699, 700, 703, 704, 707, 713, 723, 734, 750, 764, 777, 805, 806, 808, 809, 810, 811, 812, 819, 822, 823, 824, 825, 826, 828, 829, 831, 836, 838, 839, 840, 841, 847, 848, 849, 851, 852, 853, 859, 868, 869, 870, 872, 878, 882, 885, 886, 889, 901, 909, 915, 918, 920, 921, 925, 936, 946, 949, 953, 964, 969, 970, 976, 977, 986, 989, 990, 995, 996, 997, 998, 1000, 1001, 1003, 1004, 1006, 1007, 1010, 1014, 1015, 1025, 1029, 1030, 1032, 1033, 1034, 1038, 1039, 1042, 1043, 1044, 1049, 1051, 1052, 1053, 1055, 1056], "100": [43, 44, 46, 49, 51, 52, 55, 57, 62, 64, 72, 77, 85, 88, 92, 96, 101, 105, 106, 109, 112, 113, 125, 127, 128, 134, 140, 145, 155, 156, 159, 162, 177, 181, 184, 185, 192, 193, 195, 197, 199, 200, 202, 204, 206, 210, 211, 212, 214, 219, 220, 221, 222, 224, 229, 230, 231, 233, 235, 236, 238, 242, 243, 245, 250, 251, 252, 253, 254, 258, 263, 265, 269, 272, 273, 274, 276, 278, 281, 283, 288, 289, 293, 304, 305, 306, 308, 317, 320, 321, 323, 325, 326, 331, 335, 336, 342, 343, 347, 348, 350, 351, 352, 355, 356, 358, 360, 361, 364, 367, 368, 373, 375, 381, 383, 386, 388, 391, 392, 407, 413, 416, 417, 420, 421, 422, 423, 424, 445, 449, 453, 457, 479, 480, 486, 498, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 531, 532, 533, 534, 536, 538, 542, 544, 547, 552, 553, 554, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 613, 615, 618, 639, 640, 641, 647, 648, 649, 650, 654, 655, 656, 657, 660, 661, 666, 667, 668, 669, 670, 671, 673, 675, 677, 679, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 701, 703, 704, 754, 805, 806, 810, 830, 836, 837, 842, 847, 848, 849, 851, 852, 853, 857, 869, 870, 888, 890, 893, 902, 919, 989, 990, 993, 997, 1000, 1001, 1007, 1010, 1012, 1021, 1025, 1029, 1033, 1034, 1049, 1050, 1051, 1054, 1055], "1000": [43, 46, 47, 54, 63, 67, 72, 85, 106, 109, 117, 134, 142, 144, 146, 150, 151, 152, 157, 162, 166, 169, 182, 197, 206, 212, 223, 242, 250, 251, 253, 263, 267, 272, 276, 278, 284, 287, 289, 304, 306, 320, 323, 329, 330, 332, 334, 335, 350, 351, 357, 360, 361, 391, 392, 399, 414, 424, 445, 481, 487, 488, 539, 540, 545, 547, 549, 550, 551, 553, 554, 556, 561, 572, 640, 654, 655, 659, 660, 661, 663, 668, 669, 670, 671, 674, 675, 676, 680, 684, 685, 686, 695, 700, 706, 709, 772, 889, 901, 907, 912, 913, 989, 993, 1015, 1029, 1032, 1048, 1050, 1059], "10000": [43, 50, 52, 66, 78, 98, 106, 107, 153, 165, 206, 213, 220, 228, 236, 251, 253, 291, 330, 346, 348, 369, 375, 423, 424, 569, 570, 652, 687, 889, 918, 1012, 1030, 1034], "100000": [180, 253, 263, 386, 621, 622, 623, 627, 628, 630, 631, 633, 901, 993, 1032, 1034], "1000000": [55, 544], "10005": 1049, "1000x": 1047, "1001": [231, 261], "10027": 1054, "10045": 1049, "1005": 1015, "10058": 1050, "10059": 1049, "10065": 257, "1007": 713, "10070308464041304": 220, "10071": 1049, "10093": 1049, "10095": 1049, "10096": 1054, "100_000": [62, 64, 192], "100k": [251, 1027], "100ksampl": 1027, "100x": [1041, 1044, 1058], "101": [64, 174, 296, 383, 858, 1042], "10101": 1049, "10112": 1049, "1013": 1008, "10142": 1049, "10153": 1049, "10168": 1056, "10181": 1049, "10192": 1049, "10195": 1049, "101alexmartin": [1058, 1059], "102": [360, 392, 1032, 1043], "10210": 1049, "10229": 1049, "1024": [88, 134, 457, 476, 546, 910, 1054], "10280": 1049, "10297": 1049, "103": [155, 298, 299, 381, 423, 505, 563, 564, 1041], "10306": 1049, "10325": 1049, "10336": 1049, "10346": 1049, "10377": 1049, "1038": 416, "10397": 1049, "104": [43, 61], "10403": 238, "10412": 1049, "10428": 1049, "10437": 1049, "10440": 1050, "10441": 1049, "1045": 105, "10452": 1049, "10458": 1049, "1046": [105, 268], "10463": 1020, "10468": 1056, "10469096": 179, "1047": 105, "10471": 1049, "10474": 1049, "10478008": 416, "10482": 1051, "1048576": [590, 597], "10493": 1053, "105": [95, 323, 1021], "10500": 1049, "10521": 1049, "10526": 416, "10536": 1049, "10580": 1050, "10581": 1049, "10584743": 179, "10587": 1049, "10591": 1053, "10593": 1049, "106": [154, 174, 259, 261, 336, 383, 888, 994, 1021, 1042], "10606655": 235, "10610": 1049, "10655": 1049, "10663": 1049, "10677": 1049, "10687": 1049, "107": [155, 333, 361, 416, 907, 1001, 1021, 1043], "10708": 1053, "10711": 1053, "10723": [1048, 1049], "10727": 1050, "1073": [381, 496], "10733": 1020, "10740": 1049, "1076": 342, "10774": 1049, "10795": 1049, "108": [0, 47, 76, 345, 1021, 1042], "1080": [380, 416], "10805": 1055, "10811": 1049, "10815": 1051, "10827": 1049, "10829": 1049, "10834": 238, "10836": 1049, "1084": 268, "10845": 1049, "10869": 1049, "1088": 261, "10881": 1049, "108843": 281, "10887": 1049, "108880": 62, "10898": 1049, "10899": 1049, "109": [61, 88, 1001, 1043], "10908": 1049, "10913": 1049, "10914094": 235, "10928": 1049, "10933": 1049, "10982": 1049, "10992": 1049, "10998": 1049, "10999": 1049, "10_000": [46, 62, 109, 144, 152, 191, 197, 251, 281, 299, 336, 567, 568, 572, 573, 889], "10_fold": [381, 501], "10e": [199, 204], "10k": [329, 455, 1027], "10ksampl": 1027, "10x": 1041, "10x10": 225, "10\u2079": 1049, "11": [43, 57, 108, 114, 127, 174, 179, 192, 193, 204, 220, 221, 222, 225, 242, 251, 257, 272, 275, 283, 284, 290, 302, 303, 305, 323, 330, 333, 334, 348, 352, 356, 380, 383, 384, 392, 399, 416, 419, 420, 423, 458, 465, 490, 491, 492, 493, 504, 509, 525, 526, 620, 658, 664, 678, 723, 729, 731, 732, 786, 787, 788, 809, 812, 826, 829, 837, 864, 921, 950, 964, 992, 996, 998, 1010, 1014, 1015, 1021, 1025, 1032, 1034, 1039, 1043, 1047, 1049, 1050, 1052, 1055, 1056], "110": [121, 199, 217, 227, 250, 325, 335, 445, 994, 995], "1100": 85, "11000": 1050, "11005": 1049, "11006": 1049, "11010": 1049, "11011": 1049, "11021": 155, "11042": 1049, "11047": [1020, 1051], "11064": 1053, "11082": 1049, "110923": 209, "11099": 772, "111": [43, 46, 47, 102, 121, 131, 217, 235, 244, 278, 299, 864, 1033, 1044], "1111": [658, 664], "1111111111111111": 286, "11124": 1049, "1112658": [906, 1012], "11135": 1049, "11136": 1049, "1114": 268, "11144": [1049, 1050], "11144673": 235, "11160": 1049, "11166": 1049, "1117": 627, "11176": 1049, "11179": 1050, "1118": 105, "112": [89, 174, 230, 316, 381, 383, 1021, 1043], "11206": 1049, "11211": 1049, "112141": 392, "11232": 1051, "11235": 1049, "112589990684262": 754, "11272": 1049, "11293": 1049, "11295": 1049, "11296": 1052, "113": [57, 296, 392, 1021, 1044], "11306": 1049, "11308": 1049, "11310": 1049, "11314": 381, "11315": 1049, "11327": 1049, "113516": 281, "11353": 1049, "11354": 1050, "11364": 1050, "11364637": 51, "113781": 333, "11378556": 316, "114": [208, 333, 718, 1021, 1041], "1140": 381, "11413": 43, "11420": 1049, "1145": [197, 416, 684], "11452112": 235, "11458": 1050, "11464": 1049, "11466": 1049, "11467": 1049, "1148": 268, "115": [88, 193, 1008, 1021], "11505": 1049, "11514": 1052, "11520": 1049, "11526": 1050, "11528972": 235, "11542": 1049, "11553": 1049, "11556": 1049, "11557": 1049, "11558": 1049, "11576": 1049, "11585": 1049, "11596": 1049, "116": 1041, "1162": 416, "11635": 1051, "11646": 1050, "11650": 1050, "11679": 1049, "11680": 47, "11682": 1053, "11682692": 235, "11693539": 117, "11699": 1050, "117": 1042, "11705": 1050, "117154": 192, "11724": 1049, "11727": 1050, "11741": 1049, "11754": 1050, "11756": [1049, 1050], "117608": 62, "11774": 1049, "1179": 268, "118": 598, "11805": 1020, "11841": [906, 1012], "1185": 392, "11860": 1056, "1189": 423, "119": [994, 1044], "11901": 1049, "11905": 1049, "11912": 1049, "11915045": 369, "11924": 1049, "11931": 220, "11932": 220, "11933": 220, "11935": 220, "11950": 1052, "11951": 1049, "11958": 181, "11973": 1050, "11977": 1020, "12": [0, 43, 45, 54, 58, 70, 75, 77, 78, 88, 90, 91, 92, 107, 108, 117, 148, 149, 150, 153, 155, 174, 179, 180, 181, 188, 192, 193, 195, 200, 204, 206, 220, 228, 236, 238, 240, 243, 244, 245, 247, 248, 250, 257, 258, 261, 265, 266, 272, 277, 278, 280, 281, 284, 290, 292, 302, 323, 324, 325, 333, 336, 356, 362, 383, 384, 391, 399, 401, 404, 408, 409, 410, 416, 420, 424, 451, 455, 457, 465, 490, 491, 492, 493, 504, 540, 542, 549, 578, 654, 655, 660, 668, 669, 670, 672, 677, 679, 689, 693, 694, 697, 700, 701, 733, 738, 805, 806, 809, 826, 829, 843, 864, 880, 981, 989, 990, 992, 996, 998, 1001, 1010, 1014, 1015, 1021, 1025, 1030, 1039, 1042, 1044, 1048, 1049, 1051, 1052, 1057, 1058], "120": [156, 202, 241, 335, 425, 598, 1021, 1041], "1200": [85, 151, 319, 423], "12000": 528, "12068": 1051, "12069": 1054, "121": [102, 141, 188, 206, 252, 626, 677, 1010], "12105": 1049, "12116": 1050, "1212": 506, "12122": 1049, "121351": 209, "12143": 1050, "12145": 1051, "12147": 1020, "12159": 1049, "12165": 1049, "12165031": 1001, "1217": 220, "12171": 1049, "12174": 1050, "12177": 1050, "12190903": 117, "12196": 220, "12197": 1050, "122": [0, 141, 181, 188, 193, 252, 272, 392, 1001, 1021], "1220": 627, "12211": 1049, "12222": 1050, "12232": 1050, "12234": 1049, "12246": 1049, "12251": 1050, "12258": 1051, "12274212": 1001, "12279": 1050, "12285": 1056, "1229": 525, "123": [143, 162, 369, 423, 524, 525, 526, 563, 564, 845, 1001, 1008], "12300": 1050, "12303": 1051, "12304": 1049, "12317": [181, 1049], "1232": 423, "12326": 43, "12327": 43, "12328": [43, 1050], "12329": 43, "12330": [43, 1049], "12334": 1050, "12338": 1049, "12339": 1049, "1234": [200, 266, 281, 386], "12344": 1050, "12345": 1049, "12350": 1049, "1236": 325, "12360": 1049, "12365": 1049, "12379": 43, "12380": 43, "12381": 43, "12382": 43, "123828": 281, "12383": 43, "12388": 1049, "12393": 1049, "124": [46, 341, 423, 1021, 1043], "124225": 209, "12436": 1050, "12441": 1049, "12451": 1049, "12462": 1049, "12467": 1049, "12471": 1049, "12481": 1049, "125": [43, 88, 113, 123, 128, 147, 193, 331, 361, 542, 989, 1000, 1010, 1021], "12513": 1050, "12514": 1049, "125140": 281, "12517": 1049, "12518": 1049, "12522": 1049, "125247168": 52, "12543": 1050, "12557": 1051, "12568": 1050, "12569": 1051, "12582": 1050, "12583": 1050, "1259": 57, "12599": 1050, "126": 423, "12612": 1049, "12613": 1050, "12625": 1049, "1263": 392, "12638": 1053, "12650": 1051, "126502": 209, "12669": 1050, "1268187": 235, "12685": 1049, "12699": 1049, "127": [151, 1041], "12701": 1049, "12704": 1049, "127128": 152, "12715": 1050, "12732": 1050, "1276": 47, "12789": 1051, "128": [53, 54, 220, 373, 544], "12800": 1020, "12807": 1050, "12821": 1050, "12834": 1050, "12852": [1020, 1051], "12855": 1050, "12860": [238, 1050], "12861": 1050, "12866": 1020, "1288": [45, 381], "12881": 1049, "12883823": 420, "12887": 1051, "129": [222, 1030, 1041], "12908": 1050, "12914884": 1001, "12916": 1050, "12927": 1051, "12946": 1049, "12949": 1049, "12955": 1050, "12972": 1050, "12983": 1050, "12988": 1050, "1299": [878, 1010], "12th": 1012, "13": [43, 45, 49, 50, 52, 79, 108, 130, 134, 148, 151, 153, 187, 192, 197, 206, 229, 240, 245, 271, 272, 279, 282, 284, 317, 319, 323, 336, 349, 381, 383, 386, 392, 399, 420, 428, 504, 518, 521, 540, 541, 559, 560, 590, 614, 643, 647, 742, 767, 826, 856, 871, 878, 904, 905, 996, 1000, 1001, 1006, 1007, 1010, 1015, 1021, 1025, 1039, 1041, 1043, 1044, 1047, 1048, 1049, 1050, 1053], "130": [261, 392, 1021], "1300": 85, "13003": 1053, "13005": 1049, "13007": 1050, "130107": [235, 251, 497], "13013": 1051, "13042": 1056, "13046": 1049, "13077794": 369, "13086": 1050, "131": [43, 53, 91, 392, 1000, 1042], "13124": [1049, 1050], "13134": 1049, "13142": 1050, "13146": [1020, 1051], "13151": 1050, "13157": 1050, "13164": 1050, "13165": 1049, "13170937": 1032, "13174": 1050, "1319": [878, 1010], "131900": 104, "13193": 1050, "132": [43, 47, 53, 91, 423], "13204": 1053, "13213": 1051, "1322": 630, "13221": 1049, "13222543": 618, "13227": 1020, "1323": 220, "13231": 1051, "13233": [381, 501, 502], "13240": 1050, "13241": 1050, "13250": 1050, "13251": 1050, "13253": 1050, "13260": 1050, "13266": 1050, "13276": 1049, "13279": 1050, "13283": 1050, "13286": 990, "13290": 1051, "133": [53, 91], "13312": 1049, "13317": 1050, "13328": 1050, "13333": 1050, "13336": 1050, "13350": 1050, "13363": 1050, "13366": 1050, "13374": 43, "13375": 43, "13376": 43, "13377": 43, "13378": 43, "1338": 273, "13382": 1050, "13389": 1050, "13392": 1051, "13393": 1051, "13397": 1050, "134": [80, 88, 131, 151, 272, 278, 1044], "13422": 1050, "13427": 1050, "13439": 1050, "13447": 1050, "13459": 1050, "13467": 1051, "13485": 1050, "13486": 1050, "13496": 1050, "135": [174, 253, 333, 383], "13511": 1052, "13524": 1050, "1353": 360, "13531": 1050, "13545": 1050, "13549": 1050, "13554": 1050, "13562": 1050, "13575": 1051, "136": [210, 229, 1021], "13601": 1050, "13607": 1050, "13609": 1051, "13618": 1051, "13620": 1050, "13628": 1050, "13636": [996, 1050], "13641": 1050, "13649": 1058, "13651": 1050, "137": [257, 258, 392, 1021, 1042], "13704": 1051, "13707": 1051, "1371": 542, "13726": 1051, "1373": 997, "1374": 542, "13741": 1050, "13769": 1051, "13772": [1049, 1050], "13773": 1051, "13779": 1050, "1378": 238, "13780": 1050, "1379": 238, "138": [54, 392, 423, 1000, 1021], "13806": 1051, "1382": 532, "13822072286080167": 286, "13835": 1050, "1385": 482, "13864": 1050, "13875": 1051, "13877": 1050, "13894": 1050, "13896": 1051, "139": [238, 299, 392, 423, 460, 470, 699, 703, 1001], "13900": 1053, "13902": [1020, 1051], "13903": [1049, 1050], "13910": 1050, "13911": [1020, 1051], "13925": 1051, "13933": 1051, "13938": 1051, "13947": 1050, "1396": 997, "13960": 1051, "1397": 392, "13974": 1050, "13983521": 316, "13987": 1051, "13988486": 235, "13995": 1051, "13th": 64, "14": [43, 50, 52, 73, 84, 90, 95, 97, 98, 101, 108, 114, 130, 169, 192, 193, 204, 209, 211, 238, 242, 247, 252, 257, 272, 277, 283, 284, 293, 298, 299, 317, 322, 323, 333, 355, 358, 374, 381, 383, 384, 399, 404, 408, 409, 416, 420, 504, 506, 518, 561, 562, 643, 651, 700, 822, 826, 878, 993, 996, 1000, 1010, 1015, 1021, 1025, 1039, 1041, 1042, 1044, 1045, 1049, 1054], "140": [88, 335, 423, 518, 524, 525, 526, 563, 564, 1001], "1400": [85, 482], "14012": 1051, "14024": 1050, "14028": 1051, "14035": 1051, "14048": 1052, "14053": 1050, "14067": 1050, "14075": 1052, "14087": 1050, "14092": 1050, "141": [179, 296, 509, 542, 912, 1001, 1021], "14108": 1051, "14114": 1051, "14156": 238, "14170": 1051, "14180": [1020, 1052], "1419": 43, "14194": 1051, "14197": 1050, "142": [43, 86, 423, 1021], "1422": 43, "14228": 374, "14237": [1049, 1050], "14259": 1051, "14264": 1052, "142857": 238, "14286": 1051, "14287": 1051, "14294": 1051, "14296": 1051, "143": [174, 383, 479, 480, 1012, 1041, 1042], "14300": 1052, "14302": 257, "14305": 1051, "14309": 1050, "14336": 1051, "14338": 990, "14356": 1051, "14357": 1051, "14378": 1051, "14381": 1051, "14393": 1050, "144": [278, 392, 1041], "1440": 43, "14406": 1051, "1441": 630, "14410151": 618, "14417": 1051, "144204": 152, "1443": 1006, "14430": 1051, "14446": 1053, "14458": 1051, "14464": 1051, "14475": 1051, "144943": 62, "14496": [392, 1050], "145": [52, 281, 416, 1021], "14510": 1051, "14516": 1052, "14520": 1051, "14538": 1051, "14544": 1051, "14549": 1051, "1456": 238, "14582": 1020, "14591": 1051, "14593": 1051, "14595": 1051, "145957": 152, "146": [45, 423], "1460": [149, 160], "14602": 1051, "14603365": 235, "14623": 1051, "14625": 47, "14629": 1051, "1464": 248, "14646": 1051, "14647": 1051, "14680": 1051, "14682": 1051, "14696": 1052, "147": [267, 1001, 1021], "14702": 1051, "147022": 209, "14704": 1051, "14706": 1051, "1471": 1006, "14710": 1051, "14732": 1051, "14736": 1056, "1474": 392, "14740": 1051, "14764": 1051, "148": [213, 1021, 1044], "14800": 1053, "14810": 325, "14848": 1052, "14849": 1051, "14862": 1056, "14864": 1051, "14865": 1051, "14869": 1051, "14872": 1051, "14884": 1051, "14890": 1051, "14894": 1051, "14898": 1051, "149": [1001, 1041], "14900": 1051, "14902": 1051, "14907": 1051, "14908": 1051, "14933": 1051, "14936": 1051, "14971": 1051, "14975": 1055, "14982": 1053, "1499": 47, "15": [43, 45, 46, 51, 52, 53, 54, 66, 67, 70, 75, 79, 88, 89, 96, 97, 101, 107, 108, 113, 115, 123, 134, 143, 145, 148, 149, 152, 155, 169, 171, 173, 176, 180, 187, 191, 192, 193, 209, 217, 222, 234, 238, 242, 245, 247, 265, 266, 272, 273, 281, 283, 286, 289, 290, 293, 303, 307, 314, 315, 319, 321, 323, 334, 339, 347, 349, 352, 355, 358, 365, 380, 381, 384, 386, 399, 404, 408, 409, 420, 423, 424, 448, 462, 498, 504, 505, 506, 539, 545, 553, 554, 563, 564, 606, 612, 617, 652, 660, 669, 671, 676, 684, 686, 700, 826, 841, 864, 893, 989, 995, 996, 997, 1000, 1003, 1004, 1010, 1015, 1025, 1030, 1037, 1039, 1043, 1053, 1055, 1056], "150": [43, 45, 121, 123, 143, 152, 165, 241, 245, 247, 291, 335, 348, 353, 356, 383, 420, 425, 512, 609, 610, 833, 834, 835, 1000, 1021, 1029, 1030, 1031], "1500": [74, 85, 92, 97, 102, 123, 240, 244, 263], "15000": [680, 695, 869, 870], "15005": [1052, 1054], "15007": 1053, "15010": 1051, "1502": 1034, "15028": 1051, "15038": 1051, "150407": 392, "15044": 1051, "15049": 1051, "150527": 315, "15053": 1051, "15057": 1051, "1506": 394, "15080": 1051, "15082": 1051, "15083": 1051, "15084": 1051, "15086": 1051, "15094": 1051, "15096": 1051, "15099": 1051, "150x4": 121, "151": [333, 392, 423, 509, 1012], "15100": 1051, "1511007": 261, "151101": 261, "15119": 1051, "15120": 1051, "15126": 1053, "15138": 1051, "15160": 1051, "1517": 317, "15179": 1052, "1519": 47, "152": [93, 392], "15257": 1051, "1527": 868, "15274": 1051, "1528": 47, "15297572": 544, "153": 671, "15304": 1051, "15319": 1020, "153244303321897735": 416, "15361": 1053, "15375": 1051, "15380": 1052, "15382": 1051, "15393": 1051, "154": [317, 659, 1001], "1542": 392, "15427": 1053, "15429": 1051, "15436": 1052, "154453": 315, "15463": 1051, "15488": 1051, "15490": 1051, "1550": 47, "15503": 1052, "15521": 165, "15524": 1051, "1553374": 416, "1553511": 416, "1554": 868, "15550": 1020, "15557": 1051, "15558": 1052, "15582": 1052, "1559": 47, "156": [174, 192, 383], "15611": 990, "15622": 1052, "15625": 1051, "156252": 209, "15636": 1053, "15652": 1052, "15655": 1052, "15661": 1051, "15669": 1052, "15699552": 1001, "157": [260, 392, 1021], "15707": 1052, "15709": 1052, "15730": 1052, "157334": 315, "15751": 1051, "15760": 1051, "15762": 1052, "15763": 1053, "15773": 1052, "15782": 1052, "15785": 1052, "15797": 1051, "158": [77, 82, 309, 423, 677, 1021], "15806": 1052, "15810": 1051, "15834": 1052, "15863": 1051, "15864": 1052, "15868": 1051, "15879": 1051, "15888": 1051, "15898": 1051, "159": [88, 282, 317, 381, 1021, 1041], "15918": 1052, "1592": 506, "15926": 1052, "15930": 1051, "15933": 1051, "15936": 1051, "15937": 1051, "159419": 261, "15946": 1052, "15947": 1051, "15948": 1055, "15950": 1052, "15953": 1052, "15959": 1052, "15963": 1052, "1597": 272, "15980": 1052, "15984": 1055, "15996": 1051, "15e": 125, "16": [43, 44, 52, 57, 64, 78, 85, 86, 89, 101, 108, 113, 125, 128, 169, 193, 213, 219, 220, 221, 238, 240, 241, 252, 256, 272, 280, 281, 282, 303, 317, 319, 323, 328, 353, 361, 366, 381, 383, 384, 392, 399, 404, 408, 409, 420, 421, 424, 450, 465, 467, 479, 480, 486, 487, 505, 506, 510, 524, 542, 543, 578, 597, 603, 604, 615, 616, 647, 658, 659, 662, 663, 664, 665, 690, 691, 821, 826, 838, 887, 913, 921, 976, 977, 978, 989, 996, 1000, 1010, 1015, 1021, 1025, 1034, 1037, 1039, 1041, 1042, 1046, 1047, 1049, 1050], "160": [255, 989, 1032], "1600": 85, "160030": 209, "16006": 1052, "1600x1600": 89, "16018": 1055, "16021": 1052, "16052385": 135, "16061": 1055, "16066": 1053, "16069": 1052, "16075": 1052, "16076": 1051, "16084": 1052, "16090": 1052, "16103": 1052, "16111": 1052, "16112": 1052, "16117": 1052, "161245": 89, "16132": 1052, "16144": 392, "16147": 383, "16149": 1052, "16159": [392, 1052], "1616": 481, "16182": 1052, "16183": 1052, "162": [93, 383], "16224": 1052, "1623": 57, "1624": 506, "16245": 1052, "16257": 1052, "1626": 1020, "16261": 1052, "16266": 1052, "16280": 1052, "16289": 1053, "163": [84, 174, 296, 383, 1008, 1021], "163224": 209, "16323": 1052, "16326": [43, 1053], "16327": 43, "16328": 43, "16329": 43, "16330": 43, "16331": 1052, "16335": 1053, "16352": 1053, "16362": 1052, "16379": 43, "1638": 361, "16380": 43, "16381": 43, "16382": 43, "16383": 43, "16392": 1053, "16397": [1051, 1052], "164": 423, "164009": 281, "16401": 1052, "16403": 1052, "16431": 1052, "16437": 1052, "16442": 1052, "16443186": 1001, "16449": 1054, "16451": 1052, "16466": 1052, "16484": 1052, "16493": 1053, "165": [54, 360, 1001, 1021], "16500": 1051, "16505": 1051, "16508": 1052, "16530": 1053, "16531": 155, "16539": 1052, "16585": 1052, "166": [43, 317, 392, 1000, 1041], "16605": 1055, "16619": 1053, "16622": 1052, "16625": 1053, "16632": 1052, "16655": 1052, "16663": 1052, "166667315173": 52, "16692": 1052, "16695": 1056, "167": [392, 1041], "16718": 1052, "16726": 1052, "16728": 1052, "16747": 1056, "16748": 1055, "168": 1041, "1680": 383, "16801": 1052, "16837": 1052, "16841": 1052, "16849": 1052, "1689": 361, "169": [54, 93, 193, 271, 317, 1021], "16906": 1053, "1691": 996, "169106": 278, "1693": 912, "16935": 1053, "16948": 1055, "16950": 1052, "169504": 238, "16979946": 1001, "1698": 657, "16981": 1052, "16985": 1053, "16993": 1052, "17": [49, 52, 57, 74, 87, 108, 113, 128, 155, 177, 192, 219, 244, 245, 251, 272, 281, 314, 323, 381, 384, 391, 404, 408, 409, 416, 420, 452, 469, 495, 505, 506, 508, 531, 539, 544, 548, 555, 557, 558, 563, 567, 568, 577, 578, 605, 636, 657, 665, 666, 667, 674, 677, 680, 682, 695, 700, 737, 738, 748, 769, 774, 792, 795, 797, 826, 850, 861, 876, 881, 882, 890, 892, 898, 914, 917, 920, 921, 922, 923, 950, 989, 990, 1001, 1003, 1010, 1021, 1037, 1039, 1041, 1042, 1043, 1044, 1047, 1050, 1055], "170": [79, 92, 93, 97, 392], "1700": 85, "170087": 315, "17021": 1052, "17032": 1052, "17036": 1054, "17038": 1053, "170388": 1001, "1706": 342, "17061": 1052, "17090": 1053, "17095": 1053, "171": [88, 174, 383, 392, 796, 1000], "17107": 1053, "1714": 996, "17148": 1053, "17159": 1053, "17169": 1054, "17187": 1053, "17192": 1053, "17193": 1053, "172": [250, 392, 501, 502, 657, 996, 1021], "17204": 1052, "17205": 1052, "17210": [52, 1052], "17225": 1053, "17226834": 88, "1723": 46, "17233": 1053, "17235": 1052, "17236387": 223, "17266": 1055, "17289014": 179, "1729": 193, "173": [392, 592], "17309": 1052, "17317": 1053, "17357": 1052, "17360": [47, 1052], "17367": 1053, "17370318": 235, "17374": 43, "17375": 43, "17376": 43, "17377": 43, "17378": 43, "17379": [43, 52, 1053], "1738": 1000, "17386": 1053, "17388": 1057, "17396": 1053, "174": [151, 317, 392, 592], "17406": 1053, "17412": 1053, "17414": 1053, "17427": 1053, "17433": 1052, "17443": 1054, "17448": 1053, "1747": 193, "17474": 238, "17478": 1053, "17491": 1053, "17499": 1053, "175": [99, 328, 392, 1010, 1021], "17526": 1053, "175298": 281, "17546": 1053, "17569": 1053, "17578": 1053, "17598": 1053, "176": [392, 845, 1001, 1008], "17603": 1053, "17604": 1053, "17606": 1053, "17608": 1053, "17609": 1053, "17610": 1053, "17612": 1053, "17614": 1053, "17616": 1053, "17622": 1054, "17633": 1053, "17644": 1053, "17651": 1053, "17661": 1053, "17662": 1053, "17679": 1053, "17694": 1052, "177": [340, 392, 1021], "17702": 1053, "1771": 361, "17742": 1052, "17743": 1054, "17746": 1054, "17750": 1054, "17759": 1053, "17769": 1054, "17772": 1054, "17777": 1053, "17785": 1054, "178": [46, 383, 392, 518, 856], "178000": 321, "17804": 1053, "17812": 1052, "17819": 1055, "17826": 1053, "17833": 1053, "17848": 1052, "17856": 1053, "17864": 1053, "17876": 1053, "17878": 1053, "179": [67, 121, 383, 392, 423, 1021, 1041], "17914": 1052, "17928620": 380, "17932": 1053, "17935": 1053, "17937": 1053, "17959": 1052, "1797": [93, 120, 276, 317, 338, 383, 428, 453, 510, 540, 541, 542, 543, 607, 608, 696, 697, 698, 699, 701, 1003, 1031], "17984": 1053, "17985": 1052, "17985197": 235, "17987": 1053, "17992": 1053, "17995": 1052, "17997": 1053, "17_760": 155, "17t14": 380, "18": [43, 46, 47, 57, 75, 79, 84, 88, 95, 97, 108, 132, 152, 185, 192, 231, 242, 247, 252, 272, 278, 317, 323, 325, 339, 360, 361, 362, 386, 392, 420, 421, 424, 455, 467, 500, 508, 509, 510, 512, 513, 518, 543, 544, 546, 548, 549, 565, 566, 567, 568, 571, 572, 573, 574, 577, 579, 580, 581, 582, 583, 585, 586, 597, 602, 607, 608, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 654, 657, 666, 667, 679, 722, 726, 739, 742, 743, 749, 751, 768, 778, 805, 806, 829, 845, 868, 869, 870, 876, 882, 890, 891, 902, 912, 913, 920, 921, 922, 923, 924, 948, 949, 989, 998, 1000, 1010, 1037, 1039, 1041, 1042, 1045, 1046, 1048, 1049, 1051, 1052], "180": [70, 263, 264, 265, 268, 269, 308, 312, 392, 510], "1800": 85, "18000": [362, 381], "18010": 1054, "18016": 1052, "18020": 1056, "1804243": 380, "18052": 1053, "18094": 1056, "181": [296, 317, 392], "18114": 1053, "18121": 1053, "18124": 1053, "18149": 1053, "18167": 1053, "18170": 1055, "18176": 1053, "18197458": 369, "182": [176, 317, 392, 423], "18222": 1053, "18256": 1053, "18266": 1053, "18269": 1053, "18278": 1053, "18280": 1053, "18293": 1053, "18298": 1056, "183": [243, 339, 351, 392, 1001, 1021, 1041], "18302": 1053, "18310": 1055, "18326": 1053, "18328": 1054, "18334": 1053, "18341": 1053, "18343": 1053, "18368": 1054, "18370": 1053, "18393": 1054, "18394": 1053, "184": [43, 220, 317, 392, 807, 1032], "18405": 1053, "18406": 1053, "18410": 1053, "18429": 1053, "18433": 1054, "18444": 1054, "18447": 1053, "18459": 1054, "1847": 46, "18482": 1055, "18488": 1057, "185": [88, 174, 185, 383, 392, 869, 870], "1850": [45, 381], "18508": 1053, "18510": 1053, "18525": 1053, "18527": 1053, "18528": 1053, "18543": 1054, "18545": 1053, "18555": 1059, "185654": 281, "18565811e": 1033, "185659": 209, "18595": 1053, "186": [220, 310, 317, 392, 796, 1000, 1021], "18607": 1053, "18612": 1053, "18622": 1053, "18639": 1053, "18649": 1054, "1865": 47, "18682": 1053, "18689": 1058, "18691": 1053, "187": [278, 392, 592, 1001, 1032, 1043], "1871": 1015, "18723": 1057, "18736": 1054, "1874": 1015, "18746": 1053, "1875": 981, "18768": 1053, "188": [174, 181, 206, 217, 383, 392, 592, 1021], "1880": 392, "18805": 1056, "18815268": 261, "188153": 261, "18818427": 675, "18832": 1055, "18842": 1054, "18843": 1059, "18846": [381, 496, 497], "1887": 361, "18898": 1054, "189": [220, 392, 909, 1013], "18925": 1054, "189267": 281, "18959": 1054, "189631": 209, "18964": 1054, "18975": 1055, "189830": 333, "18987": 1053, "19": [43, 52, 77, 181, 192, 224, 242, 245, 268, 272, 323, 324, 339, 383, 384, 390, 400, 404, 408, 409, 416, 424, 427, 452, 500, 524, 525, 526, 544, 548, 549, 555, 557, 558, 565, 566, 567, 568, 572, 573, 574, 590, 597, 615, 656, 666, 667, 674, 675, 676, 679, 680, 682, 684, 686, 695, 715, 789, 793, 807, 808, 822, 835, 840, 841, 843, 844, 858, 859, 878, 889, 910, 914, 917, 920, 921, 922, 923, 989, 1000, 1010, 1037, 1039, 1041, 1042, 1043, 1044, 1046, 1049, 1058], "190": [50, 151, 238, 287, 312, 381, 392, 506], "1900": 85, "19002": 1054, "19004": 1054, "19011": 1054, "19024": 1054, "19035": 1054, "1903908407869": 223, "19041": 1054, "19046": 1054, "19047631514961908949361222113": 52, "1905": [174, 383], "19052": 1054, "19055": 1054, "19069": 1054, "19075": 1056, "19085": 1055, "191": [275, 392, 1001, 1021], "19112072e": 201, "19126": 1053, "19145": 362, "19158": 1055, "19159": 1054, "19162": 1054, "19172": 1054, "19174891": 316, "19179": 1053, "19182": 1053, "19198": 1054, "192": [151, 392, 1041], "19210": 1054, "19211": 1053, "19234": 1053, "19244": 1054, "19263": 1054, "19271": 1053, "19278": 1054, "192913": 281, "192938": 52, "19296": 1054, "19297": 1054, "193": [51, 255, 392, 423, 723, 794, 1013, 1021], "19308": 1053, "1931": 113, "19310": 1054, "19317": 181, "19336": 1054, "19346747e": 1033, "193548": 238, "19356": 1054, "1936": 383, "19365": 1054, "19390": 1054, "19391": 1054, "193949": 281, "194": 317, "1940": 238, "19401": 1054, "19407": 1053, "19411": 1054, "19415": 1054, "19417": 1053, "194239": 392, "19426": 1054, "19428": 1054, "19438": 1055, "19459": 1054, "19472": 1054, "19473": 1054, "1948": 57, "19483": 1054, "19490": 1055, "19491": 1054, "19499": 1054, "195": [133, 274, 362, 501, 502, 1021], "1950": [383, 1000], "1951": 238, "195133": 392, "19520": 1054, "19522393": 235, "19527": 1054, "19564": 1054, "19568": 1054, "19571": 1054, "19579": 1053, "1958": [181, 421, 423, 540], "19580": 1053, "196": [360, 909, 1013], "1960": [635, 724], "19616": 1054, "19631": 1054, "1964": [698, 702, 888, 900, 997], "19641": 1054, "19643": 1054, "19646": 1053, "19659": 1053, "19662693": [852, 853], "19664": 1057, "19669": 1054, "196795181": 52, "19680": 1055, "196861": 209, "19689": 1055, "19703": 1053, "1972": 383, "19721": 1053, "19727": 1053, "1973": [383, 414], "19732": 1053, "19733": 1054, "19734": 1054, "1974": [416, 424, 718], "19747": 1055, "1975": 1003, "19752": 1054, "19766": 1054, "197666": 281, "1977": 643, "1978": [238, 996], "19784": 1054, "19788": 1054, "1979": [416, 733, 777], "19790": 1054, "19794": 1055, "19799": 1054, "198": 1041, "1980": 383, "19803308": 117, "1981": [238, 996], "19829832": 235, "1983": [416, 739, 892], "19836": 1054, "1984": [113, 114, 418, 482, 920, 921, 1016], "19847": 1053, "1985": [192, 416, 713, 723, 794], "1986": [990, 1016], "19869": 1054, "1987": [416, 615, 616, 800, 801], "198766": 281, "19879": 1054, "1988": 383, "19883": 1054, "19888": 1053, "1989": [287, 643, 796, 869, 870, 996, 1003], "199": [655, 799, 1015], "1990": 381, "19906": 1054, "19908": 1054, "1990a": 414, "1991": [524, 525, 526], "19916": 1055, "1992": [174, 381, 383, 420, 423, 575, 576, 653, 996], "19922": 1053, "19924": 1053, "1993": [174, 383, 482, 672, 693, 694, 1016], "19934": 1054, "19939": 1053, "1993apr6": 104, "1994": [174, 381, 383, 652], "19948": 1054, "1995": [174, 278, 383, 414, 423, 561, 562, 842, 909, 1001], "1996": [64, 155, 416, 423, 427, 452, 524, 525, 526, 563, 564, 1010], "1997": [140, 381, 421, 423, 543, 562, 698, 702, 996, 997, 1000], "1998": [155, 278, 381, 383, 421, 423, 563, 564, 842, 847, 878, 1001, 1002, 1004, 1010, 1014], "19982": 1053, "1999": [184, 381, 414, 416, 418, 421, 423, 445, 458, 465, 477, 482, 542, 549, 563, 564, 567, 568, 731, 906, 914, 915, 917, 918, 1006, 1012], "19th": 416, "1_": 1010, "1_000": [44, 64, 70, 83, 106, 130, 155, 176, 181, 183, 193, 251, 275, 356, 415, 545, 547, 709, 807, 830, 831, 839], "1d": [2, 140, 142, 189, 193, 221, 251, 300, 303, 312, 336, 355, 366, 386, 393, 395, 399, 400, 417, 422, 472, 475, 625, 638, 641, 661, 665, 668, 671, 692, 711, 720, 721, 727, 737, 738, 742, 746, 750, 791, 792, 795, 804, 854, 855, 856, 857, 858, 860, 862, 863, 864, 877, 928, 932, 933, 963, 987, 1001, 1021, 1025, 1032, 1041, 1046, 1047, 1048, 1050, 1054, 1055, 1059], "1dlabel": 388, "1e": [44, 45, 46, 49, 55, 63, 81, 125, 174, 176, 179, 181, 182, 183, 184, 185, 187, 192, 200, 213, 220, 221, 227, 234, 238, 243, 247, 253, 258, 263, 266, 269, 276, 286, 289, 316, 326, 331, 334, 342, 347, 349, 356, 360, 392, 428, 451, 455, 460, 467, 470, 479, 480, 486, 490, 491, 492, 539, 540, 541, 544, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 567, 568, 569, 570, 600, 605, 614, 616, 617, 619, 621, 622, 623, 627, 628, 630, 631, 633, 635, 646, 648, 649, 650, 652, 653, 654, 655, 656, 657, 660, 661, 666, 667, 668, 669, 670, 671, 674, 675, 676, 677, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 692, 695, 697, 698, 699, 700, 701, 702, 703, 736, 793, 805, 806, 822, 847, 848, 849, 850, 851, 852, 853, 861, 869, 870, 877, 907, 908, 912, 913, 914, 915, 916, 917, 918, 986, 989, 1000, 1004, 1008, 1010, 1014, 1030, 1034, 1049, 1054, 1055, 1056], "1e0": [176, 253, 269, 286, 989], "1e1": [176, 182, 220, 253, 349], "1e15": 185, "1e2": [49, 176, 183, 253, 269, 349, 754], "1e3": [45, 46, 49, 176, 182, 187, 253, 289, 334, 989, 1030], "1e4": [289, 667, 687, 906, 1012], "1e5": [45, 181, 201, 203, 210, 289, 621, 622, 623, 627, 628, 630, 631, 633, 901, 906, 1012, 1030, 1032], "1e6": [47, 49, 213, 251, 336, 360, 362, 373, 544, 906, 1000, 1012], "1e7": 392, "1er": 424, "1f": [52, 58, 85, 88, 128, 200, 220, 251, 263, 265, 285, 328, 335, 361, 362], "1gb": 373, "1kastner": 1048, "1m": 966, "1mb": [374, 1046], "1mo": 181, "1nn": 383, "1or": 424, "1px": 317, "1qlettinn8oi": 360, "1st": [0, 43, 95, 121, 184, 221, 324, 890, 891], "1x4": 424, "1x5": 424, "1x6": 424, "1z": 424, "2": [2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 165, 167, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 214, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 330, 331, 332, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 375, 380, 381, 383, 384, 386, 388, 390, 391, 392, 393, 395, 398, 399, 400, 404, 407, 408, 409, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 437, 438, 439, 440, 445, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 476, 477, 479, 480, 481, 482, 483, 486, 487, 488, 490, 491, 492, 493, 501, 504, 508, 509, 512, 515, 516, 517, 518, 519, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 536, 537, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 585, 589, 590, 592, 593, 596, 597, 598, 599, 601, 602, 603, 604, 605, 606, 609, 611, 612, 613, 614, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 707, 709, 711, 712, 713, 714, 715, 716, 719, 721, 722, 723, 724, 725, 726, 729, 730, 731, 732, 733, 734, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 764, 765, 766, 767, 771, 772, 775, 776, 777, 779, 781, 782, 783, 784, 786, 789, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 890, 891, 892, 893, 895, 896, 897, 898, 899, 900, 902, 903, 905, 906, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 925, 927, 928, 929, 930, 932, 933, 934, 938, 941, 947, 948, 949, 950, 951, 952, 953, 954, 955, 961, 962, 963, 964, 965, 966, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 986, 987, 989, 990, 991, 992, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1021, 1025, 1026, 1029, 1030, 1031, 1032, 1033, 1037, 1038, 1039, 1041, 1042, 1043, 1045, 1046, 1059], "20": [2, 43, 46, 47, 52, 54, 57, 62, 63, 64, 69, 70, 74, 75, 78, 81, 82, 85, 89, 90, 96, 102, 111, 115, 123, 125, 132, 134, 141, 145, 148, 149, 152, 156, 160, 161, 163, 167, 169, 170, 171, 174, 182, 191, 193, 194, 202, 209, 210, 212, 216, 217, 219, 220, 221, 224, 229, 232, 233, 234, 235, 237, 243, 251, 257, 265, 267, 268, 272, 278, 279, 281, 282, 284, 289, 290, 293, 296, 299, 303, 304, 305, 306, 307, 310, 317, 323, 324, 325, 329, 330, 331, 332, 334, 338, 339, 342, 346, 348, 352, 354, 358, 361, 362, 366, 367, 379, 383, 384, 386, 388, 390, 391, 392, 404, 408, 409, 416, 423, 424, 449, 454, 455, 457, 472, 473, 477, 479, 480, 486, 496, 497, 498, 499, 500, 502, 504, 505, 508, 510, 512, 513, 519, 520, 523, 524, 531, 539, 544, 545, 550, 553, 554, 556, 560, 563, 564, 567, 568, 569, 570, 571, 577, 578, 590, 597, 598, 600, 602, 605, 607, 637, 638, 653, 657, 666, 674, 675, 676, 684, 686, 704, 712, 716, 721, 724, 733, 734, 747, 764, 765, 775, 800, 801, 805, 806, 807, 808, 822, 834, 835, 836, 839, 841, 844, 845, 846, 849, 850, 857, 858, 869, 870, 871, 872, 874, 876, 877, 885, 886, 887, 888, 893, 907, 908, 910, 911, 916, 919, 924, 930, 932, 933, 936, 978, 989, 996, 1000, 1003, 1006, 1007, 1010, 1013, 1023, 1024, 1026, 1032, 1036, 1037, 1039, 1041, 1047, 1050, 1053, 1055, 1056], "200": [69, 70, 79, 85, 89, 95, 109, 128, 141, 142, 152, 159, 180, 206, 215, 221, 224, 225, 226, 232, 237, 241, 259, 263, 279, 285, 287, 288, 314, 319, 322, 340, 348, 349, 367, 369, 381, 388, 398, 421, 423, 428, 448, 462, 476, 479, 480, 530, 541, 542, 543, 546, 547, 548, 551, 555, 592, 657, 659, 679, 687, 700, 822, 869, 870, 910, 914, 915, 916, 917, 918, 1015, 1021], "2000": [54, 63, 75, 85, 109, 126, 132, 197, 266, 269, 278, 296, 314, 332, 361, 381, 383, 416, 417, 423, 428, 460, 470, 541, 542, 567, 697, 699, 701, 751, 796, 805, 858, 888, 900, 997, 1000, 1006, 1012, 1025, 1033], "20000": [57, 127], "200000": [238, 877], "20002": 1054, "2001": [2, 64, 181, 194, 272, 277, 413, 416, 423, 445, 459, 460, 461, 470, 519, 567, 568, 572, 573, 636, 642, 647, 653, 699, 704, 743, 796, 893, 905, 937, 990, 992, 996, 1000, 1006, 1008, 1010, 1012, 1015], "2002": [98, 414, 416, 423, 445, 456, 601, 602, 734, 764, 859, 907, 992, 1000], "20023": 1054, "2003": [2, 51, 181, 413, 416, 421, 424, 459, 460, 470, 521, 523, 697, 701, 847, 849, 996, 997, 1002, 1012, 1049], "20030": 1054, "20031": 1055, "2004": [44, 174, 278, 296, 381, 383, 416, 418, 421, 481, 543, 615, 616, 697, 701, 713, 751, 791, 908, 994, 996, 997, 1002, 1015, 1032], "2005": [62, 64, 114, 383, 414, 445, 447, 861, 996, 1003, 1013], "20056": 1054, "2006": [2, 50, 312, 381, 423, 426, 470, 506, 565, 566, 573, 574, 618, 619, 622, 627, 630, 657, 674, 675, 749, 796, 797, 805, 847, 905, 922, 923, 996, 1000, 1002, 1005, 1012, 1013], "2007": [0, 73, 208, 381, 416, 425, 448, 460, 462, 468, 470, 574, 664, 699, 725, 742, 745, 766, 767, 803, 992, 996, 998, 1000], "20072": 1054, "2008": [51, 418, 420, 421, 486, 542, 571, 598, 653, 672, 693, 694, 700, 724, 734, 764, 842, 847, 851, 868, 994, 997, 998, 1000, 1001, 1002, 1005, 1006, 1015], "20087": 1054, "2009": [2, 139, 142, 143, 154, 204, 416, 420, 421, 423, 424, 527, 528, 536, 539, 545, 546, 548, 549, 552, 555, 561, 567, 568, 643, 679, 687, 704, 843, 920, 921, 948, 949, 996, 1000, 1001, 1007, 1016], "200_000": [877, 1057], "200j": 167, "200m": 381, "200x": 1041, "201": [45, 151, 174, 383, 592, 1021], "2010": [0, 82, 102, 112, 193, 283, 284, 413, 416, 418, 420, 421, 429, 483, 544, 712, 716, 727, 728, 748, 837, 869, 870, 992, 996, 1000, 1004, 1014, 1018, 1041], "2011": [0, 82, 193, 241, 392, 421, 424, 543, 546, 548, 549, 555, 598, 635, 646, 666, 738, 990, 1004, 1014, 1018, 1041], "20117": 1054, "2012": [0, 114, 414, 423, 563, 564, 571, 647, 751, 989, 993, 1000, 1018, 1041], "2013": [0, 197, 383, 416, 420, 421, 544, 734, 764, 992, 1000, 1018, 1042, 1043], "2014": [0, 87, 380, 410, 421, 423, 426, 538, 615, 616, 630, 631, 666, 700, 869, 870, 948, 949, 997, 1004, 1024, 1044], "20145": 1055, "2015": [0, 193, 380, 716, 729, 731, 732, 869, 870, 1000, 1007, 1024, 1045, 1046], "201520": 209, "20155": 1054, "20159": 1054, "2016": [0, 245, 380, 416, 989, 1046, 1047], "20161": 1054, "20165": 1054, "2017": [0, 278, 380, 414, 416, 427, 452, 1000, 1047, 1048], "2018": [0, 220, 238, 424, 458, 989, 1000, 1024, 1048, 1049], "2019": [0, 193, 384, 416, 460, 470, 700, 997, 1000, 1007, 1010, 1049, 1050, 1051], "2020": [0, 381, 1051, 1052, 1053, 1054], "20200": 1054, "20207": 1054, "20209": 1054, "2021": [0, 384, 386, 679, 1053, 1054], "2022": [0, 374, 423, 713, 1010, 1055, 1056], "2023": [0, 398, 410, 414, 1056, 1057], "20231": 1054, "2024": [1058, 1059], "20240": 1054, "20250": 1054, "20272": 1054, "20297": 1054, "203": 88, "20312": 1054, "203174": 209, "20326": 1054, "20331": 1056, "2034": [360, 381], "20380": 1054, "20385": 1054, "2039": 281, "204": [1008, 1013], "20408": 1055, "20415": 1056, "20416": 1054, "20431": 1054, "20477": 1054, "20512": 1054, "20515": 1054, "20521": 1054, "20524": 1057, "20526": 1054, "20528": 1054, "20531": 1054, "20534": 1054, "20552": 1054, "20554": 1054, "20560": 1054, "20567": 1055, "20583": 1054, "20597": 1054, "20617": 1056, "20619": 1054, "20638": 1054, "20640": [145, 188, 381, 498], "20652": 1054, "20653": 1055, "20657": 1054, "20673": 1054, "20683": 1054, "207": [117, 317, 1021, 1041], "2071716": [852, 853], "20727": 1054, "20729": 1054, "20752": 1054, "2075215": 235, "20753": 1055, "20761": 1054, "207667": 281, "2079": 283, "208": [174, 299, 383], "20802": 1056, "20803": 1055, "20811": 1055, "20842": 1054, "20843": 1054, "20860": 1055, "20880": 1054, "208864": 209, "20899": 1054, "209": [749, 888], "20904": 1054, "20959": 1054, "20960": 1054, "20961": 1054, "20_000": 299, "20new": [381, 1034], "20newgroup": [66, 189, 198, 212, 236, 317, 497, 666, 838, 841, 996, 1021], "20news_hom": 381, "20newsgroup": [235, 379, 1041], "20th": 716, "21": [43, 52, 107, 155, 174, 192, 197, 209, 221, 238, 245, 268, 272, 296, 299, 317, 321, 323, 334, 356, 361, 383, 384, 388, 390, 404, 413, 423, 424, 449, 453, 482, 486, 537, 540, 569, 570, 571, 577, 578, 596, 597, 599, 635, 677, 695, 762, 808, 810, 822, 835, 878, 885, 887, 893, 910, 926, 948, 992, 996, 1001, 1010, 1021, 1037, 1039, 1041, 1042, 1044, 1048, 1049, 1051], "210": [44, 174, 1021], "2100": [85, 331], "2102": 552, "21020": 1056, "21026": 1055, "21032": 1055, "21038": 1055, "2107": 283, "21078": 1055, "21079": 1055, "21080": 1054, "21086": 1055, "21093": 1054, "211": [253, 283, 333, 341, 361, 888, 900], "21109": 1055, "21114": 1055, "211217613": 1049, "21130": 1054, "21145": 1054, "21148": 1055, "2117": 342, "21177": 1055, "21179": 1054, "21194": [81, 1054], "21195": 1054, "21199": 1054, "212": [151, 174, 283, 341, 383, 477, 508, 1006, 1032], "21219": 1055, "212197e": 238, "21243": 81, "21251": 1054, "2126": 257, "21271": 1054, "21278": 1055, "21295": 1054, "21298": 1055, "21301203": 179, "213056e": 238, "21310": 1055, "21316": 1055, "21330": 1055, "21334": 1055, "21336": 1054, "21340": 1054, "21341": 1055, "21351": 1054, "21389": 1054, "2139": [220, 238], "214": [177, 293, 592, 1021], "21408": 1055, "21425": 1055, "21430": 1055, "21432": 1055, "21434": 1055, "21436": 1055, "21443888": 235, "21445": 1055, "21448": 1055, "21469": 1056, "21481": [1054, 1055], "21482": 1055, "21493": 1054, "215": 592, "21517": 1054, "21534": 1055, "21542": 1055, "21544347": 51, "21552": 1054, "21565": 1055, "2156660": 335, "21567": 1055, "21569": 1055, "21573": 1055, "21576": 1055, "21578": [47, 1054], "2159048": [661, 671, 692], "216": 1013, "2160": 47, "21606": 1055, "2161": 47, "21616": 749, "21617": 1055, "21632": 1055, "2164": 47, "2165": 47, "21694": 1054, "217": [543, 549, 807], "21701": 1055, "21705": 1055, "2171": 46, "21713": 1055, "21724": 1055, "2173": [208, 664, 996], "21735": 1055, "21741": 1054, "21762": 1055, "21767": 1055, "2178": 47, "2179": 47, "218": [49, 347, 383, 479, 723, 794, 1021], "2180": 57, "21800": 1055, "21805": 1055, "21807": 1058, "21808": 1055, "21809": 1057, "21814": 1055, "2183": 47, "21832": 1055, "21833": 1054, "21837": 1055, "21845": 1054, "21871": 1054, "21873": 1055, "21880": 1055, "21881": 1055, "21888": 1055, "218997": 209, "219": 277, "21901": 1055, "21915": 1054, "21917": 1054, "2192": [208, 664, 996], "21938": 1056, "21954": 1055, "2198": 47, "21987": 1055, "21988": 1055, "21991": 1054, "21998": 1055, "22": [43, 52, 77, 123, 143, 144, 187, 188, 189, 192, 193, 194, 220, 237, 245, 257, 260, 268, 272, 296, 301, 317, 319, 323, 327, 330, 333, 336, 339, 342, 362, 386, 391, 404, 413, 445, 456, 480, 486, 496, 497, 503, 504, 512, 523, 532, 539, 545, 550, 553, 554, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 577, 578, 602, 617, 635, 636, 640, 642, 653, 655, 659, 661, 663, 666, 667, 669, 671, 673, 677, 696, 700, 710, 712, 721, 765, 777, 786, 791, 792, 796, 808, 809, 813, 822, 827, 829, 832, 833, 834, 835, 836, 837, 838, 839, 856, 858, 860, 862, 863, 864, 869, 870, 871, 873, 876, 892, 903, 912, 914, 915, 916, 917, 918, 920, 921, 922, 923, 943, 944, 992, 1000, 1010, 1021, 1037, 1039, 1041, 1044, 1049, 1052, 1054], "220": [79, 272, 1041], "2200": [85, 381, 501], "22002": 1055, "2201": 47, "22014": 1056, "22015": 1055, "22016": 1055, "2202": 47, "22027": 1055, "2203": 47, "220446049250313e": [479, 480, 486, 658, 659, 662, 663, 664, 690, 691], "2205": 47, "22050": 1054, "22054": 1056, "22058": 1055, "22059": 1055, "2206": 47, "22062": 1055, "22063": 1055, "22064": 1055, "22065": 1055, "221": [117, 158, 272, 346, 1021, 1044], "22106": 1055, "22108": 1055, "2211": 642, "22111": 1055, "22114": 1055, "22118": 1055, "22119": 1055, "22120": 1055, "22137": 1055, "22148": 1055, "22149": 1055, "2215": 47, "22150": 1055, "22154": 1055, "22159": 1055, "2218": 47, "22181": 1055, "22188": 1055, "22191": 1055, "22199": 1055, "222": [117, 158, 342, 1015], "22203": 1055, "22206": 1055, "22212": 1055, "22215": 1055, "22217": 1055, "22218": 1055, "2222": 664, "22223": 1055, "22235": 1055, "22237": 1055, "2224": 1043, "22240": 1055, "22248": 1055, "22249": 1055, "22254": 1055, "22255": 1055, "22268": 1056, "22269": 1056, "22284": 1055, "22288": 1055, "223": [117, 158, 174, 383], "22300": 1055, "22314355": 598, "22318": 1055, "22320": 1055, "22356": 1055, "22361": 383, "22370": 1055, "223745": 220, "2239": 47, "224": [88, 117, 158, 416, 733, 830], "2240": 47, "22409": 1057, "2241": 47, "22410": 1055, "22412": 1055, "2243": 47, "22438": 398, "2244": 47, "2245": 47, "2246": 238, "2247": 47, "22476": 1055, "22486": 1055, "22493": 1055, "22498": 1055, "225": 423, "22504": 416, "22506": 1057, "22508": 1055, "22518": 1056, "22525": 1055, "22526": 1055, "22527": 1056, "22537": 1055, "22548": 1055, "22553": 1055, "22554": 1056, "22562": 1056, "22566": 1055, "2257": 1034, "22578": 1055, "225806": 238, "22595": 1055, "226": [416, 427, 452], "22604": 1055, "22629": 1056, "22635": 1055, "22665": 1056, "22685": 1055, "22687": 1055, "22692": 128, "22694": 1055, "22695": 1055, "22696": 1055, "22697": 1055, "227": [278, 416, 733], "22710": 1056, "22735": 1055, "22747343e": 113, "22775": 1055, "22784907": 835, "22806": 1055, "22808": 1055, "22830": 1055, "2284": 193, "22856": 1055, "2286": 381, "22866": 1055, "22868": 1055, "2287": 381, "2288": 381, "22891": 1055, "22898": 1056, "22899": 1055, "229": 1000, "22908": 1055, "22913": 1055, "22950": 1055, "22953": 1055, "22965": 1056, "22968": 1056, "22982": 1055, "22993": 1056, "22nd": 447, "23": [43, 57, 63, 70, 85, 128, 157, 174, 189, 193, 220, 245, 249, 257, 259, 261, 268, 272, 317, 323, 327, 330, 331, 332, 334, 335, 339, 383, 384, 392, 404, 408, 409, 423, 429, 439, 448, 455, 460, 462, 470, 473, 475, 476, 483, 486, 487, 488, 490, 491, 492, 498, 500, 508, 509, 510, 512, 513, 518, 520, 522, 530, 532, 546, 547, 548, 551, 555, 562, 564, 566, 568, 569, 570, 573, 576, 577, 578, 615, 616, 619, 635, 638, 640, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 668, 669, 670, 671, 672, 673, 675, 677, 678, 680, 681, 683, 686, 687, 688, 689, 725, 738, 786, 838, 844, 845, 846, 855, 863, 870, 873, 885, 892, 900, 901, 910, 913, 915, 918, 921, 923, 930, 932, 933, 943, 944, 949, 1000, 1021, 1037, 1039, 1041, 1042, 1048, 1049, 1050, 1053], "230": 592, "2300": [85, 209], "23023": 1055, "23033": 1055, "23034": 1055, "23036": 1055, "23038": 1056, "23040": 1055, "23046": 1055, "23047": 1055, "23077": 1055, "23079": 1055, "23095": 1055, "23097": 1055, "23098": 1055, "23099": 1057, "231": [50, 312, 381, 416, 427, 452, 506, 592], "23101": 1056, "23113": 1055, "23115": 1055, "23127": 1056, "23139": 1056, "23149": [381, 505, 1055], "23194": 1055, "23197": 1056, "23198": 1055, "232": [272, 1000], "23210": 1056, "23214": 1055, "2323": [697, 701, 997], "23252": 1056, "23256": 1055, "23264": 1055, "23271": 1055, "23273": 1055, "23275": 1056, "23299": 1055, "233": [265, 1021], "2331": 43, "23317": 1058, "2332": 43, "2333": 43, "2334": 43, "2335": 43, "23358": 1055, "2336": 392, "23370": 1055, "23395": 1055, "233mb": [45, 1030], "234": [88, 847, 851, 869, 870, 1002], "2341": 532, "23410": 1055, "234137": 209, "23442": 1056, "23446": 1056, "23461": 1056, "23470": 1056, "23471": 1055, "23480": 1056, "235": [197, 325, 1021], "235430": 281, "23548": 1055, "2357juan": [1055, 1056, 1057], "23585": 1056, "23595": 1057, "236": [212, 311, 1021], "23604": 1056, "23608": 1055, "23619": 1056, "23636": 1055, "23637": 1056, "23668876": [661, 671, 692], "236720": 209, "23683": 1056, "23689075": [661, 671, 692], "237": [320, 1021, 1032], "23726": 1056, "23731": 1057, "23734": 1056, "237703": 209, "23773583": 113, "23786125": 216, "23798": 1056, "238": [367, 1021], "23819": [1056, 1057], "23833": 1055, "23834": 1056, "23865": 1056, "23874": 1056, "238744": 209, "23877": 1056, "238955": 281, "239": 1041, "23905": 1056, "23935": 1056, "23977": 1056, "23990": 1055, "23993": 1056, "24": [43, 44, 52, 101, 155, 174, 189, 193, 197, 204, 245, 272, 290, 299, 327, 328, 329, 331, 334, 335, 338, 339, 384, 386, 390, 404, 408, 409, 416, 423, 424, 445, 448, 449, 450, 452, 453, 455, 456, 457, 458, 459, 460, 461, 468, 470, 472, 477, 478, 479, 480, 481, 482, 483, 484, 497, 498, 499, 500, 504, 512, 523, 524, 525, 526, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549, 551, 552, 557, 558, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 577, 578, 589, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 621, 635, 636, 637, 638, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 706, 707, 708, 710, 716, 722, 735, 754, 761, 805, 806, 808, 811, 812, 822, 829, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 873, 875, 876, 877, 878, 881, 882, 884, 886, 887, 888, 889, 890, 892, 902, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 943, 944, 948, 975, 981, 989, 1007, 1010, 1021, 1037, 1039, 1041, 1049, 1050, 1051, 1052, 1054], "240": [43, 52, 79, 1008, 1041], "2400": 85, "24000": 528, "24015": 1055, "24017": 1055, "24027": 1057, "24051": 1056, "24058": 1056, "24075": 1056, "24076": 1057, "24083": 1057, "24084": 1056, "24087": 1055, "241": [423, 575, 576], "2410": 552, "24140": 1057, "24141": 1056, "24145": 1057, "24146": 1056, "24160": 333, "242": [219, 251, 892, 1021, 1041], "24218": 1056, "24230": 1057, "24245": 1056, "24258": 1056, "24264": 1056, "24283": 1056, "243": 592, "2431": 483, "24317": 1056, "24338": 1056, "24350": 1056, "24354": 1056, "24365": 1056, "243802": 315, "244": [272, 296, 592], "24404831511191221642141021252626109": 52, "24405": 1056, "2441": 238, "24412": 1056, "24421": 1056, "24433": 1056, "24446": 1055, "244466": 261, "24465": 1056, "2449": 392, "245": [1012, 1043], "24512": 1056, "24523": 1056, "24528": 1056, "24538": 1056, "24539": 1056, "24543": 1056, "24556": 1056, "24568": 1057, "245961": 152, "245mb": 362, "246": [204, 1008, 1041], "24617": 1056, "2463": 996, "24630": 1056, "24631": 1055, "24637": 1056, "24640578": 113, "24645": 1056, "24667": 1056, "24668": 1057, "24677": 1057, "24683": 1056, "24688": 1056, "24699": 1056, "247": 892, "24714": 1056, "24747": 1056, "24750": 1056, "24755": 1056, "24767": 1056, "24769": 1057, "248": [170, 1021], "24838": 1058, "24849": 1056, "24855": 1056, "24856": 1056, "24871": 1057, "24873": 1056, "2487575": 197, "2487591": 197, "24882": 1057, "24889": 1056, "24894": 1056, "249": 272, "24935": 1057, "24951": 1056, "25": [43, 44, 45, 46, 48, 49, 50, 52, 57, 61, 63, 77, 80, 89, 90, 113, 117, 122, 132, 134, 143, 152, 160, 170, 171, 177, 187, 192, 200, 210, 224, 245, 247, 265, 272, 278, 312, 314, 317, 319, 321, 333, 338, 339, 360, 367, 369, 373, 392, 420, 423, 424, 427, 452, 485, 489, 509, 512, 529, 578, 605, 626, 686, 742, 804, 825, 838, 864, 882, 887, 889, 890, 893, 901, 902, 904, 905, 946, 950, 981, 996, 1000, 1001, 1003, 1010, 1021, 1030, 1041, 1043, 1049, 1052], "250": [49, 100, 152, 197, 240, 501, 700, 830, 989, 1012, 1048], "2500": 1000, "25000": 77, "2501": [174, 383], "25044": 1057, "250639": 209, "25067": 1056, "25077": 1056, "25080": 1056, "25089": 1056, "25093": 1057, "25094": 1056, "251": [174, 242, 383], "25102": 1057, "25120": 1057, "25129": 1056, "25147": 1056, "25163598": 394, "25172": 1056, "25174": 1056, "25177": 1057, "25183501383331797": 286, "25186": 1057, "25188": 1056, "25190": 1057, "25193977": 1001, "25196": 1057, "252": [174, 242, 383, 542, 888, 900], "25209": 1057, "25214": 1057, "25220": 1057, "25232": 1057, "25250": 1056, "25251": 1057, "25257": 1057, "25274": 1056, "25275": 1058, "25291": 1057, "25291366": 369, "25294": 1057, "25295": 1056, "25296": 1056, "25297": 1057, "25299": 1057, "253": [151, 542], "25308": 1057, "25312": 1056, "25334": 1057, "25341": 1056, "253445": 152, "25349312e": 201, "2535": [477, 482], "25354": 1056, "2536": 484, "25363": 1056, "25367": 1057, "25370": 1056, "25387": 1057, "25402": 1057, "25417": 1057, "25432": 1057, "25438": 1057, "25443": 1057, "25477": 1056, "2548": 216, "25490": 1057, "25499205": 544, "255": [83, 128, 288, 299, 316, 325, 331, 381, 423, 501, 502, 569, 570, 1021], "25500": 1056, "25506": 1057, "25511": 1056, "25531": 1057, "25563": 1056, "25570": 1056, "25587": 1057, "25589": 1056, "256": [77, 83, 88, 151, 325, 374, 381, 416, 423, 457, 476, 545, 554, 571, 868, 900, 910, 1034, 1055], "25601": 1057, "25619": 1056, "25629": 1057, "25638": 1056, "25659": 1057, "25664": 1056, "25672": 1057, "25677": 1057, "2568": 1050, "25694": 1056, "25697": 1057, "257": [155, 242, 276, 1021], "25704": 1056, "25713": 1057, "25719016": 1001, "25732": 1057, "25733": 1057, "25744": 1056, "25747": 1056, "25752": 1057, "25774": 1056, "25784": 1057, "2579": 700, "258": [169, 242, 1021], "25805": 1057, "25813": 1057, "25814": 1057, "25815": 1057, "259": [50, 242, 312, 381, 423, 506, 575, 576], "259031": 209, "259297": 209, "25931": 1057, "25956": 1057, "25973": 1057, "25987": 1057, "25991": 1059, "25th": [43, 257, 890], "26": [43, 81, 85, 89, 113, 127, 181, 192, 235, 245, 256, 272, 291, 339, 392, 578, 656, 737, 791, 830, 888, 900, 949, 1000, 1010, 1021, 1041, 1044, 1045, 1053, 1059], "260": [277, 1054], "26019": 1057, "26021": 1057, "26033": 1057, "2605": 700, "26082": 1057, "26093": 1057, "261": 54, "26106": 1057, "26108": 1057, "26113448": 171, "26120": 1059, "26121": 1057, "26163": 1058, "26194": 1057, "262": 1041, "26207": 1057, "26242": 1057, "26243": 1058, "26253567e": 113, "26264": 1057, "26267": 1058, "26278": 1058, "26286": 1057, "26286057": 235, "26289": 1057, "26299": 1058, "26315": 1058, "26316": 181, "26318": 1057, "26323": 1057, "263234": 261, "26323428": 261, "26325": 1057, "26333": 1057, "26337": 1057, "26362917": 235, "26366": 1058, "263758": [591, 595], "26376": 1057, "26385": 1057, "26386": 1057, "26386883": 179, "26391": 1058, "264": [184, 1021], "2640": 843, "26400": 1057, "26410": 1058, "26411": 1058, "26416": 1057, "26424": 1057, "26433": 1057, "26454": 1057, "26459": 1058, "26464": 1058, "26466": 1057, "265": [743, 847, 851, 1002], "26503": 1057, "26506": 1058, "26521": 1057, "2652124": 823, "26525": 1058, "26551": 1057, "26566": 1057, "26579": 1057, "26593496": 235, "266": 360, "26600": 1057, "26602": 1057, "26616": 1058, "26634": 1058, "26642044": 674, "26644": 1057, "26648": 1058, "26653": 1057, "26657": 1057, "2666": 1000, "2667": 506, "26674": 1058, "26683": 1058, "267": 1041, "2671": 1010, "26721": 1058, "26734": 1058, "26736": 1058, "26744": 1058, "26748": 1057, "2675": 46, "26754": 1057, "26760": 1057, "26765": 1058, "267703": 89, "26772": 1057, "26786": 1058, "26789": 1058, "268": [251, 264, 292, 1021], "26814": 1057, "268147": 281, "26828": 1058, "26830": 1058, "26831": 1058, "26837": 1059, "26840": 1058, "26855": 1058, "26862": 1058, "26893": 1057, "26896": 1058, "269": 519, "26903": 1057, "26909": 1058, "26913": 1057, "2692": 1010, "26931": 1057, "26934744": 135, "26940": 1057, "26944": 1058, "26957": 1058, "26th": [416, 734, 764, 1000], "27": [43, 45, 52, 57, 67, 82, 89, 128, 228, 272, 338, 339, 357, 383, 416, 424, 525, 532, 613, 721, 796, 797, 893, 913, 1000, 1010, 1021, 1033, 1041, 1043], "270": [204, 264, 339], "27000": 238, "27002": 1057, "27005": 1058, "27006": 1058, "27017": 1058, "27018": 1058, "27044": 1057, "27054655": 235, "27058": 1058, "27098": 1058, "27100": 1058, "27104": 1058, "27110": 1058, "27137": 1058, "27139": 1058, "2714": 257, "271411": 261, "27161": 1058, "27161955": 171, "27166": 1058, "27167": 1057, "27179": 1058, "27185": 1058, "27204": 1058, "27219": 1058, "272214": 592, "27239": 1058, "27240": 1058, "27243": 1057, "27250": 1058, "27252": 1058, "2727": 566, "27274": 1058, "27277": 1058, "27291": 1058, "27292": 1057, "273": [214, 1021], "27301": 1058, "27308": 1058, "27309": 1058, "27311": 1057, "27314": 1058, "27315": 1058, "27328": 1058, "27336": 1058, "2734": 392, "27344": 1059, "27372": 1058, "27381": 1060, "27389": 1058, "274": 519, "27417": 1058, "27431": 1058, "27438": 1058, "27456": 1059, "27468": 1057, "27478": 1058, "27490": 1058, "27491": 1059, "27499706": 51, "275": [43, 339, 1044], "27500": 1058, "27526": 1059, "27538": 1058, "27544": 1058, "27556": 1058, "27558": 1058, "27560": 1059, "27566": 1059, "275706": 89, "27573": 1057, "27576": 1059, "27577": 1058, "27580": 1057, "27583": 1057, "27584": 1059, "275851": 261, "2759": [904, 905], "27597342": 117, "276": [251, 278], "27601": 1058, "27614": 1058, "27624": 1058, "2763": [429, 483], "27636": 1059, "27645": 1058, "27650": 1058, "27651": 1058, "27657": 1059, "27668": 1058, "27670": 1058, "27675": 1058, "27678": 1058, "277": [1008, 1043], "27700": 1059, "27702": 1058, "27710": 1058, "27718": 1058, "27720": 1058, "27721": 1058, "27734": 1058, "27736": 1060, "27757": 1058, "27760": 1058, "27772182": 52, "278": [113, 383, 852, 853, 1021], "2780": 392, "27800": 1059, "27801": 1058, "27817": 1058, "27821": 1058, "27828": 1058, "27834": 1058, "27835": 1058, "27841": 1058, "27844": 1059, "27865": 1058, "27898": 1058, "27899": 1058, "279": [185, 996], "27904": 1059, "27937": 1059, "27979": 1058, "27990": 1059, "28": [43, 101, 152, 174, 192, 236, 257, 272, 287, 316, 325, 338, 339, 383, 392, 416, 420, 458, 465, 1010, 1021, 1030, 1041, 1044, 1047], "280": [96, 339, 1021], "28009951": 835, "2802": 57, "28040": 1059, "28048": 1058, "28051": 1059, "28053": 1059, "28074": 1058, "28085": 1059, "28090": 1058, "28092": 1059, "28095": 1058, "281": 54, "28102": 1059, "28106": 1060, "28111": 1058, "28121": 1058, "28136": 1059, "28160": 1059, "28165": 1058, "28167": 1058, "2818": 478, "28184": 1058, "28187": 1059, "28188": 1058, "28191": 1058, "28195": 1058, "28198": 1058, "282": [1030, 1041], "28205": 1059, "28207552": 235, "28210": 1059, "28222": 1058, "28225276": 88, "2823": 342, "28233": 1058, "28235": 1058, "28240": 1058, "28241": 1058, "28247": 1058, "2825": 0, "28256": 1058, "28261": 1059, "28262": 1058, "28263": 1058, "28295": 1058, "2830": 0, "28306": 1059, "28327": 1058, "2833": 392, "28351": 1059, "28352": 1059, "28360": 1059, "28365": 1058, "28377": 1058, "28385": 1058, "28399": 1059, "284": 657, "28407": 1059, "28425": 1059, "284315": 272, "28432": 1059, "28435": 1059, "28471": 1059, "284806": 272, "284807": 272, "28483": 1059, "28491": 1059, "28498": 1059, "285": [261, 339, 732], "28521": 1059, "28552": 1059, "28557": 1059, "28582": 1059, "286": 423, "28604": 1059, "28612": 1059, "28651": 1059, "28664": 1059, "28670": 1059, "28692": 1059, "287": [193, 231, 1012, 1021], "28701": 1060, "28703": 1059, "28712": 1059, "28718": 1059, "28722": 1059, "28756": 1059, "28763": 1059, "28768": 1059, "28773": 1060, "2879": 1048, "288": [543, 549], "28808734": 224, "28822": 1059, "28823": 1059, "28843": 1059, "28847": 1059, "289": 192, "28915": 1059, "28925": 1059, "28936": 1060, "28951": 1059, "28975": [1054, 1060], "28988": 1059, "28992": 1060, "28x28": 316, "29": [114, 123, 177, 181, 211, 220, 224, 237, 272, 333, 339, 383, 423, 567, 568, 698, 702, 789, 805, 864, 996, 997, 1014], "290": [339, 361, 696, 697, 701, 997], "290075": 209, "29014": 1060, "290584": 315, "29067": 1060, "29078": 1059, "291": [174, 361, 381, 383], "29105": 1060, "29119": 1059, "29128": 1060, "2914": 502, "292": [151, 404, 423, 743, 1021], "2928359": 235, "293": [251, 290, 1021], "29316": 181, "2939931": 335, "294": [122, 1021], "29473397": [852, 853], "295040e": 238, "295505e": 238, "296": 1012, "2961": 659, "296575": 209, "297": [104, 134, 381, 1021], "298": 1008, "298688": 278, "29898468": 235, "299": [140, 688], "2991059": 335, "299546e": 238, "2_": 992, "2_000": 139, "2_2": [654, 655, 660, 661, 662, 663, 664, 668, 669, 670, 671, 680, 689, 690, 691, 692], "2_f": 660, "2_fro": [661, 670, 671, 692], "2_poli": 278, "2_y": 1002, "2c": [651, 660, 680, 681, 682, 683, 695, 992], "2d": [2, 43, 69, 71, 74, 79, 82, 83, 84, 88, 96, 97, 120, 121, 124, 126, 129, 135, 158, 189, 214, 221, 226, 240, 241, 242, 245, 247, 250, 251, 308, 338, 339, 346, 349, 368, 380, 382, 386, 388, 395, 400, 416, 417, 421, 424, 426, 449, 460, 470, 472, 475, 489, 496, 498, 499, 500, 501, 502, 508, 509, 510, 512, 518, 522, 541, 549, 557, 592, 594, 643, 651, 665, 680, 699, 746, 787, 833, 837, 841, 879, 928, 932, 933, 948, 963, 986, 987, 994, 996, 997, 1000, 1007, 1011, 1016, 1021, 1025, 1031, 1041, 1045, 1048, 1049, 1050, 1053, 1055, 1059], "2darrai": 388, "2dlabel": 388, "2e": [206, 293], "2e6": 1000, "2ec5ac": 323, "2f": [44, 47, 50, 52, 57, 67, 74, 77, 79, 81, 85, 87, 97, 99, 102, 117, 123, 128, 134, 152, 155, 159, 160, 169, 192, 193, 197, 200, 209, 211, 216, 220, 235, 236, 237, 238, 247, 251, 257, 272, 277, 281, 282, 284, 286, 287, 288, 292, 307, 308, 314, 321, 324, 332, 336, 349, 360, 361, 369, 417, 420, 423, 704, 836, 839], "2fbf01908075": 713, "2fx": 266, "2g": [242, 245, 705, 1052], "2h": 422, "2k": 187, "2l": [426, 630], "2n": [704, 992, 1004], "2n_": 996, "2nd": [95, 121, 184, 324, 416, 427, 452, 538, 1010, 1056], "2t_p": 285, "2x": 1041, "2x2": [346, 416, 762], "2x_iy_i": 992, "3": [0, 2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 111, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 165, 169, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 192, 193, 194, 197, 198, 199, 200, 201, 202, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 234, 235, 236, 237, 238, 240, 241, 242, 243, 245, 247, 251, 252, 253, 254, 255, 257, 258, 259, 261, 263, 264, 265, 267, 268, 269, 272, 273, 276, 277, 278, 279, 280, 281, 282, 284, 286, 287, 288, 289, 290, 291, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 330, 331, 332, 333, 335, 336, 338, 339, 341, 342, 343, 345, 346, 348, 349, 352, 353, 354, 355, 356, 357, 360, 361, 362, 365, 366, 368, 369, 374, 375, 380, 381, 383, 384, 386, 387, 388, 391, 392, 398, 399, 400, 404, 407, 408, 409, 410, 413, 414, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 437, 438, 439, 440, 441, 445, 447, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 489, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 509, 510, 512, 513, 514, 515, 518, 520, 523, 524, 525, 526, 527, 529, 531, 533, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 585, 589, 590, 591, 592, 595, 596, 598, 599, 601, 602, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 625, 626, 635, 636, 637, 638, 639, 640, 641, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 695, 696, 697, 698, 700, 701, 702, 704, 707, 708, 710, 711, 712, 713, 715, 717, 718, 721, 724, 725, 729, 731, 732, 733, 734, 736, 737, 738, 739, 741, 742, 743, 744, 745, 749, 751, 752, 753, 754, 756, 758, 759, 760, 761, 762, 764, 765, 776, 777, 783, 789, 790, 791, 792, 793, 794, 795, 796, 798, 799, 800, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 883, 884, 885, 886, 887, 888, 890, 891, 892, 893, 900, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 932, 933, 934, 938, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 963, 964, 966, 967, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 989, 990, 993, 994, 995, 996, 997, 998, 1000, 1001, 1002, 1003, 1006, 1007, 1010, 1011, 1013, 1015, 1016, 1018, 1019, 1021, 1025, 1026, 1029, 1030, 1032, 1033, 1037, 1039, 1041, 1042, 1043, 1044, 1046, 1047, 1048, 1051, 1053, 1054, 1056, 1058, 1059], "30": [43, 47, 49, 54, 57, 70, 74, 75, 79, 89, 95, 105, 107, 111, 123, 128, 132, 139, 148, 152, 155, 159, 165, 174, 176, 177, 180, 182, 193, 197, 199, 214, 218, 220, 238, 240, 241, 245, 252, 256, 257, 267, 272, 278, 280, 283, 293, 296, 299, 308, 309, 323, 324, 325, 333, 334, 338, 339, 343, 347, 350, 352, 353, 373, 381, 383, 391, 392, 420, 424, 427, 452, 458, 463, 464, 465, 508, 539, 543, 545, 546, 547, 549, 551, 553, 554, 578, 600, 603, 604, 606, 656, 700, 743, 791, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 893, 908, 921, 978, 989, 994, 1000, 1001, 1003, 1008, 1021, 1030, 1041, 1042, 1048, 1049, 1050], "300": [43, 58, 59, 70, 73, 85, 93, 128, 139, 140, 141, 145, 188, 210, 245, 247, 251, 267, 272, 281, 309, 322, 330, 338, 353, 356, 388, 451, 455, 456, 467, 469, 521, 647, 652, 653, 687, 698, 700, 702, 869, 996, 1051], "3000": [52, 99, 243, 904, 905], "30000": 381, "300343": 209, "30061": 549, "301": [129, 417, 1014, 1021], "3015": 57, "30151134": 474, "302": [278, 635], "30258509": 426, "303": [238, 643], "30349955": 1032, "30357143": 368, "304": [174, 323, 361, 383], "3044": 153, "305": 392, "30506066": 204, "3053": [477, 482], "305438": 152, "306": [73, 635, 1021], "306012": 209, "30750": 416, "308": [80, 643, 1021], "30897646": 235, "309": 361, "30m": 381, "31": [43, 104, 112, 238, 272, 304, 331, 338, 339, 413, 424, 508, 569, 570, 605, 657, 679, 687, 965, 1001, 1041], "310": [200, 1021], "3109306": 179, "311": 361, "312": [155, 334, 1021, 1044], "3121": 716, "313": 1032, "313276e": 238, "315": [147, 299, 383, 1021], "316": [181, 185, 619, 622, 633, 888], "31622776601683794": 165, "3164764": [220, 238], "317": 181, "31760": 996, "318": [361, 458], "318387": 315, "319": [177, 323, 1021, 1034], "31958": 181, "31973683": 235, "31bit": 1052, "31st": [221, 891], "32": [43, 44, 52, 86, 123, 191, 194, 256, 292, 332, 339, 380, 384, 391, 400, 413, 423, 424, 453, 572, 573, 590, 597, 642, 684, 891, 893, 932, 933, 965, 1008, 1010, 1033, 1041, 1044, 1047, 1049, 1050, 1053, 1054, 1055, 1058], "320": [361, 381, 989, 1014, 1041], "3204": 1047, "321": 122, "321301": 62, "322": [45, 122, 479, 480], "3221": [700, 997], "323": [122, 248, 251, 1021], "323200": 62, "324": [122, 381], "324084": 209, "3245": [700, 997], "325": [122, 206, 1021], "325198e": 238, "3252": 605, "326": 122, "32634568": 224, "3264": 46, "327": [63, 82, 738, 1021, 1032], "3272984419327777": 364, "3273": 754, "327407": 261, "327605": 261, "32767": 1052, "32782448": 179, "3279": 46, "328": 738, "3288": 552, "329": [263, 458, 1021], "329616": 209, "32987858": 573, "32bit": [2, 373, 965], "32x32": 383, "33": [43, 113, 220, 279, 333, 339, 381, 383, 390, 391, 392, 416, 424, 469, 540, 645, 656, 720, 721, 737, 738, 746, 751, 791, 792, 795, 814, 836, 838, 840, 899, 923, 982, 996, 1000, 1010, 1030, 1041, 1049], "330": 339, "33035714": 368, "331": [162, 1021], "331263": 209, "3315057": [834, 835], "3317": 220, "332": [59, 205, 361, 900, 1021], "333": 854, "3333": 506, "333333": 238, "33333333": [862, 1010], "334": 179, "334795": 281, "335": 43, "335919": 315, "336": [61, 155, 392, 1010, 1021], "336188": 315, "3367": 1048, "337": 392, "3375": 333, "338": [90, 218, 257, 1021], "3383": 46, "3384": 361, "3387": 361, "3397": [672, 693, 694], "33rd": [909, 1013], "34": [43, 47, 52, 152, 174, 176, 304, 317, 338, 339, 368, 383, 420, 528, 537, 578, 605, 657, 675, 724, 772, 1030, 1041], "340": [253, 338, 361], "34118": 381, "34125758": 235, "3415": [672, 693, 694], "341523": 315, "3419": 281, "341949": 209, "342": [361, 830], "34279478": 235, "343": 45, "3433": 46, "34346583": 88, "3445": 46, "345": [174, 383], "34545455": 996, "3456": 46, "34586917": 235, "346": [423, 509, 563, 564], "3467": 623, "347": [338, 1021], "347717": 152, "348": [139, 1021], "34867495": 1001, "349": [139, 392, 561], "34990341": 117, "35": [43, 45, 46, 47, 48, 50, 90, 105, 141, 162, 174, 192, 193, 199, 208, 247, 272, 292, 296, 324, 338, 339, 552, 656, 657, 664, 710, 714, 715, 735, 749, 764, 790, 797, 845, 989, 996, 1000, 1006, 1007, 1010, 1021, 1030, 1034, 1041, 1043], "350": [69, 77, 192, 361, 1021], "351": [62, 1021], "351390": 278, "352": [278, 361, 392], "352124": 209, "35278655": 235, "353": 1034, "3534": 57, "3539": 104, "354": 361, "354394": 152, "3551": 46, "355440": 278, "355445": 152, "356": [352, 1008, 1021], "356497": 152, "3565178": 965, "357": [174, 383, 508, 913], "3573": 835, "3577618906572577": 329, "35788": 1034, "3582": 46, "358295": 209, "358990": 209, "3591": 1050, "36": [43, 45, 46, 47, 52, 53, 127, 174, 182, 192, 238, 257, 279, 352, 383, 392, 423, 424, 563, 564, 578, 743, 767, 1000, 1021, 1034, 1041], "360": [139, 561], "360000": 315, "36047253": 235, "361": [381, 423, 563, 564], "362": [315, 1021], "362176": 333, "36251281": 335, "363": [52, 158, 1021], "3635": 835, "364": [126, 361, 479, 480, 1021, 1042], "365": [326, 418, 481, 1021], "3659": 1046, "36607143": 368, "367": [361, 423, 1041], "36787944": 998, "3680": [619, 622, 633], "3684": 843, "36851234": 824, "368896": 62, "3690483151908911912247722318110": 52, "3696": 621, "3697": 858, "3697178": 52, "37": [43, 204, 281, 292, 338, 368, 381, 423, 532, 724, 892, 903, 1010, 1041], "370000e": 238, "370039": 209, "370738": 62, "372": [280, 1021], "37257991": 117, "373333": 281, "375": [88, 181, 457, 758, 1000, 1021], "376": 1008, "37647423": 52, "376999": 62, "377": [127, 361, 1021], "37741762": 135, "377eb8": [75, 79, 97, 98, 247], "378": [192, 253, 423, 1021, 1034, 1041], "37815029": 235, "37845099": 369, "37967282": 1001, "379710": 192, "379763": 152, "38": [123, 193, 211, 219, 224, 271, 287, 304, 334, 423, 640, 893, 948, 1000, 1010, 1041, 1042, 1043], "380": 1034, "3800": 209, "3803": 362, "381327": 381, "382005": 152, "382120e": 238, "383": [150, 1021], "38353048": 235, "383973": 281, "384": [325, 704, 913, 1021], "3840": 1049, "384338": 209, "384616559": 395, "385000e": 238, "3854": [672, 673], "3855": 1020, "386": 888, "3862": 876, "38629436": 1010, "38690531511642143152471231333333107": 52, "387": 1041, "387580e": 238, "387599": 52, "387830e": 238, "3889": 483, "3889873516666431": 52, "389": [601, 602, 1034], "3894": 623, "39": [43, 47, 52, 174, 261, 272, 381, 383, 384, 390, 416, 424, 503, 903, 921, 950], "390": [48, 1021], "3908844": 835, "391": 704, "3910350737": 395, "3911": 47, "3928": 478, "393297": 261, "39329747": 261, "394": [104, 177, 185, 1021], "3947": 1012, "395": [43, 132, 361, 1021], "39568399": 544, "396": [104, 174, 383, 1034], "3964": [429, 483], "397": 381, "3972": 663, "398": [66, 655, 1021, 1034], "3986": 238, "3996": 659, "3_": 992, "3_poli": 278, "3bae43c9b14e387f76a61b6d82bf98a4fb5d3ef99ef7e7075ff2ccbcf59f9d30": 47, "3c479a6885bfa0438971388283a1ce32": 380, "3d": [80, 83, 102, 121, 131, 217, 240, 242, 244, 368, 424, 514, 594, 963, 1033, 1048, 1049, 1051], "3f": [43, 45, 47, 50, 52, 54, 55, 59, 61, 63, 73, 75, 82, 83, 84, 93, 105, 107, 109, 118, 139, 146, 147, 155, 170, 174, 176, 177, 178, 180, 185, 191, 193, 194, 200, 204, 206, 212, 220, 222, 226, 235, 236, 238, 241, 251, 253, 276, 278, 279, 281, 284, 286, 289, 299, 314, 336, 342, 360, 361, 362, 830, 837, 1008, 1030], "3k": 704, "3l": 426, "3llobo": 1056, "3m": 51, "3rd": [121, 184, 847, 890, 1002, 1010], "3ssnporch": 149, "3x1": 955, "3x2": [971, 974], "3x3": 986, "4": [43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 57, 58, 62, 63, 64, 67, 68, 69, 70, 73, 74, 75, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 90, 91, 93, 94, 95, 97, 99, 100, 101, 105, 106, 107, 108, 114, 115, 117, 118, 121, 122, 123, 126, 127, 128, 129, 130, 131, 132, 133, 134, 139, 140, 142, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 165, 170, 174, 176, 179, 181, 182, 184, 185, 187, 188, 189, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 208, 209, 210, 211, 212, 213, 217, 218, 219, 220, 221, 224, 226, 227, 228, 230, 233, 234, 238, 240, 247, 251, 252, 253, 254, 255, 256, 257, 259, 261, 263, 264, 265, 266, 268, 269, 272, 273, 274, 275, 276, 278, 279, 280, 281, 283, 285, 286, 287, 289, 290, 292, 293, 298, 299, 301, 303, 304, 305, 306, 309, 314, 316, 317, 319, 320, 322, 323, 325, 327, 328, 329, 330, 331, 333, 334, 336, 338, 339, 340, 341, 342, 346, 348, 352, 353, 354, 356, 357, 358, 360, 361, 368, 369, 374, 380, 381, 383, 384, 386, 391, 392, 395, 398, 399, 400, 404, 407, 408, 409, 414, 415, 416, 417, 418, 420, 421, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 437, 438, 439, 440, 445, 447, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 499, 504, 512, 520, 521, 524, 525, 526, 532, 534, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 557, 558, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 585, 589, 590, 591, 593, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 622, 625, 626, 627, 630, 635, 636, 637, 638, 639, 640, 641, 643, 644, 645, 646, 647, 648, 649, 650, 651, 653, 654, 655, 656, 657, 659, 660, 661, 663, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 677, 678, 679, 680, 682, 684, 685, 687, 688, 692, 693, 694, 695, 696, 697, 698, 700, 701, 702, 706, 707, 710, 714, 715, 723, 724, 733, 734, 735, 740, 742, 750, 751, 752, 754, 755, 756, 757, 758, 759, 760, 764, 776, 777, 789, 790, 796, 797, 798, 799, 802, 804, 805, 806, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 833, 834, 835, 836, 838, 840, 841, 842, 843, 846, 847, 848, 849, 851, 856, 860, 861, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 899, 900, 904, 905, 906, 910, 912, 913, 916, 920, 921, 922, 923, 928, 929, 931, 932, 933, 934, 938, 948, 949, 950, 951, 953, 954, 955, 956, 957, 964, 971, 972, 973, 975, 976, 977, 978, 981, 982, 983, 989, 990, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1010, 1011, 1014, 1015, 1021, 1025, 1029, 1030, 1031, 1032, 1034, 1037, 1039, 1042, 1043, 1044, 1046, 1047, 1048, 1050, 1054, 1055, 1056, 1059], "40": [43, 47, 54, 89, 101, 111, 121, 125, 156, 162, 176, 204, 211, 212, 214, 237, 242, 244, 255, 257, 267, 279, 305, 311, 316, 321, 338, 339, 347, 348, 350, 352, 354, 355, 368, 374, 381, 420, 454, 503, 525, 526, 807, 852, 853, 857, 869, 870, 989, 1001, 1010, 1041, 1042], "400": [44, 63, 85, 125, 154, 159, 176, 188, 226, 245, 290, 315, 361, 381, 421, 503, 1034], "4000": [94, 154, 266], "400000e": 238, "4017": 532, "4018260": 335, "402": [282, 301, 1021], "402344": 392, "4025": 1046, "403": [282, 361], "404": [98, 238, 1021], "40597": 298, "406": [697, 701, 997], "4066": 46, "407": [174, 383], "408": [70, 1021], "40842387": 51, "40887718": 92, "409": 361, "40945": 105, "4096": [125, 381, 421, 503], "40966": 380, "409717": 281, "41": [47, 50, 52, 174, 220, 257, 368, 381, 383, 465, 477, 489, 500, 629, 632, 643, 654, 655, 660, 666, 668, 669, 670, 672, 689, 693, 694, 707, 789, 847, 1002, 1006], "41075698": 422, "41076071": 422, "41082": 44, "411": [192, 342, 418, 428, 481, 541], "4110": 484, "41187": 181, "412": [361, 504, 996], "412021": 152, "41214": [220, 238], "41215": 238, "412304": 209, "413": [176, 1021], "414": [225, 238, 417, 734, 764, 888, 900, 1000, 1021], "41421356": [771, 777, 1003], "4143": 398, "414810": 261, "414912": 155, "415": [68, 1021], "416": [91, 747, 1000, 1021], "416010": 333, "41666667": 758, "41691605": 135, "417": [298, 360], "41726413": 135, "41888636": 670, "419": [54, 361, 624], "4194": 383, "42": [43, 44, 45, 52, 58, 61, 62, 63, 64, 67, 79, 81, 91, 111, 117, 127, 132, 139, 146, 147, 149, 150, 152, 153, 155, 156, 160, 170, 171, 188, 192, 194, 195, 197, 199, 209, 212, 214, 215, 222, 226, 227, 228, 234, 235, 237, 240, 241, 242, 247, 252, 253, 254, 257, 260, 272, 277, 279, 282, 292, 299, 305, 306, 307, 314, 319, 320, 321, 322, 324, 326, 328, 330, 332, 341, 347, 349, 360, 361, 369, 374, 388, 391, 392, 400, 407, 416, 420, 423, 424, 427, 445, 452, 486, 496, 500, 519, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 535, 537, 539, 545, 552, 553, 554, 565, 566, 573, 574, 575, 576, 578, 613, 614, 615, 616, 617, 685, 702, 703, 704, 768, 800, 801, 805, 807, 810, 830, 836, 838, 852, 853, 857, 861, 864, 904, 905, 907, 908, 909, 919, 922, 923, 935, 948, 965, 969, 1003, 1010, 1030, 1034, 1037, 1038, 1041], "42034597": 335, "42074": 325, "421": [734, 764, 1000], "421087": 281, "42165": 149, "422": [601, 602, 734, 764, 1000], "4226193151": 52, "4232": [43, 52], "423641": 209, "424": 238, "4242": [43, 52], "42425183539869404": 329, "425": [241, 361, 623], "4254": [174, 383], "42545546": 335, "4260": [757, 760], "427": [174, 383, 514, 515, 591, 592, 595], "427329": 261, "428": [135, 1021], "4285714285714286": 1000, "429": 296, "4294": 1047, "43": [174, 183, 217, 251, 278, 299, 383, 391, 808, 822, 893], "430": [296, 428, 541, 1021], "43026679e": 1033, "431": 383, "4310090": 777, "432": [278, 418], "4325": 57, "433": [272, 383], "43348936": 235, "4337": 996, "43475": 886, "435": [273, 1021], "436": 251, "4362": 1046, "437": 146, "437362": 209, "438": [111, 188, 192, 1008, 1021], "43847489": 135, "43873": 362, "4387766": 52, "4394": 1049, "44": [43, 52, 181, 192, 193, 204, 296, 303, 487, 789, 893, 913, 916, 983, 1000, 1007, 1041], "440": [102, 192, 1021], "440409": 209, "4406": 481, "4409": [43, 52], "44139186": 316, "4415": 57, "442": [174, 184, 188, 383, 509, 1032], "4425765": [661, 671, 692], "44300751539296973": 52, "44300752": 52, "443238": 281, "44373091": 1001, "44381023": 224, "44412786": 544, "445": [272, 1008], "445978": 209, "446": [361, 364, 734, 764, 1000, 1021], "447": 361, "447268": 89, "4472869": 135, "4474": 392, "4478": 1046, "448": [156, 299, 1021], "4486": 552, "449": [44, 421, 543], "4496": [43, 52], "4497": 1020, "45": [75, 99, 107, 117, 155, 170, 181, 194, 209, 220, 238, 285, 289, 290, 339, 349, 420, 423, 424, 572, 573, 635, 642, 654, 655, 660, 668, 669, 670, 689, 690, 691, 796, 805, 916, 990, 1000, 1008, 1018, 1030, 1037, 1041, 1044], "4500": 235, "45070924": 674, "451": 654, "45192": 165, "451933": 89, "452": [180, 182], "453": [355, 361, 1021], "45333333": 368, "4544": 43, "455": [54, 221, 325, 1021], "4550": 380, "456": [44, 421, 543], "45612256": 668, "45663524": 668, "457": 623, "4576": 843, "458333315172": 52, "459": [416, 450], "459074": 261, "46": [43, 52, 88, 123, 220, 257, 286, 369, 392, 601, 602, 690, 691, 724, 830, 916, 921, 1010, 1037], "46033": 504, "46043": 504, "46081961": 1001, "461": 392, "462": [140, 194, 1021], "462234": 261, "463": [238, 296], "463088": 52, "46428631511221642143151251232633109": 52, "465660": 62, "465730": 209, "466": 1007, "4666": 642, "46779927": 51, "468": 93, "46858513287221654": 334, "46874778": [661, 671, 692], "469": 93, "4690": 1034, "46915237": [661, 671, 692], "4694": 532, "469474": 209, "46958558": 669, "4697": 82, "47": [43, 185, 216, 381, 501, 502, 543, 549], "471": 383, "47140": 416, "47236": [381, 505], "4733": 153, "47330339": 424, "4738": 1046, "474": [353, 1021], "475": [139, 244, 1021], "47668": 362, "477": [63, 185, 1021], "478522": 209, "47885": 362, "479": [85, 204, 1021], "4792": 238, "47922861": 261, "479229": 261, "47928": 362, "4794": 209, "4795": 209, "4796": 209, "4798": 209, "47985": 504, "47987268e": 201, "4799": 209, "48": [43, 52, 80, 117, 131, 155, 181, 261, 325, 383, 392, 416, 518, 605, 707, 754, 836, 847, 989, 1002, 1010, 1037], "480": [204, 361], "4801": 209, "4802": 209, "4803": 209, "4804": 209, "4805": 209, "4806": 209, "4807": 209, "4809": [209, 281], "481": 185, "4810": 209, "4812": 46, "4815": 209, "482": [234, 1021], "48204257": 1001, "4828": 209, "483": 656, "4830": 209, "4831": [209, 663], "4832": 209, "4836": 209, "484": 185, "4841": 209, "484109": 209, "4846": 209, "485": 704, "4852": 209, "4855": 209, "4857596147013469": 95, "486": [182, 222, 1021], "4860": 209, "48632135": 335, "4866": 209, "4867": 209, "4869": 209, "487": [52, 160, 732, 1021], "4872": 209, "48736655": 675, "4874": 209, "4876": 209, "4880": 209, "4881": [209, 1046], "48841": 504, "48842": 504, "4885": 209, "48858": 392, "4888": 209, "4891": 209, "48938813e": 201, "4894": 209, "48979592": 457, "4898431": [381, 500], "49": [43, 77, 128, 174, 224, 257, 380, 381, 383, 391, 416, 458, 465, 721, 734, 764, 772, 801, 805, 808, 893, 1000, 1010, 1044], "490": 272, "491": [107, 704, 1021], "492": [272, 651, 993, 1032], "4923": 657, "4928": 209, "493": [651, 912, 993], "4936": 209, "4939": 1048, "494": [195, 1021], "494021": 500, "4948": 46, "4951": 661, "495761": 392, "496": [105, 1021], "49665188": 224, "4967": 532, "4976": 605, "499": [174, 247, 383, 392, 1021], "4995": 1047, "49999993": 996, "4daf4a": [79, 97], "4dbd33": 123, "4e": 241, "4e9a06": [94, 99], "4eacc5": [94, 99], "4f": [46, 47, 57, 142, 151, 153, 235, 236, 238, 324, 919], "4gb": 1034, "4i": 85, "4th": [174, 184, 383], "4x": [392, 1056], "4x10": 424, "4x1048576": 424, "4x11": 303, "4x4": [383, 421, 424], "4x9": 424, "5": [43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 61, 62, 63, 64, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 99, 100, 101, 102, 104, 105, 107, 108, 109, 112, 113, 114, 115, 117, 118, 123, 125, 126, 127, 128, 129, 131, 132, 134, 137, 141, 142, 143, 144, 145, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 162, 165, 167, 169, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 200, 201, 202, 203, 204, 206, 208, 209, 210, 211, 212, 214, 215, 217, 218, 220, 221, 222, 223, 226, 228, 231, 232, 233, 234, 235, 236, 238, 241, 242, 243, 245, 247, 250, 251, 252, 253, 255, 256, 257, 258, 259, 261, 263, 264, 265, 266, 267, 268, 269, 272, 273, 275, 276, 277, 278, 279, 280, 281, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 308, 309, 311, 312, 314, 315, 316, 317, 319, 321, 322, 323, 324, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 338, 339, 341, 342, 343, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 381, 383, 384, 386, 388, 391, 392, 394, 398, 399, 400, 404, 408, 409, 410, 414, 415, 416, 417, 420, 421, 423, 424, 425, 426, 427, 428, 431, 445, 446, 447, 448, 450, 452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 469, 470, 471, 472, 474, 475, 477, 480, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 512, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 536, 539, 541, 542, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 560, 563, 564, 565, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 590, 600, 601, 602, 605, 610, 612, 613, 614, 615, 616, 618, 621, 622, 623, 624, 627, 628, 630, 631, 633, 635, 636, 637, 638, 639, 640, 642, 644, 645, 646, 649, 651, 654, 655, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 678, 679, 680, 681, 682, 683, 684, 685, 686, 688, 689, 690, 691, 692, 696, 697, 699, 700, 701, 703, 704, 705, 707, 711, 713, 715, 717, 720, 721, 726, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 743, 746, 747, 748, 750, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 764, 777, 778, 786, 789, 790, 792, 793, 795, 796, 797, 798, 799, 802, 804, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 818, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 841, 842, 843, 846, 847, 848, 849, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 866, 869, 870, 871, 872, 877, 878, 879, 881, 882, 884, 885, 886, 887, 888, 889, 891, 892, 893, 895, 897, 898, 899, 900, 901, 902, 906, 912, 913, 914, 915, 916, 917, 918, 920, 922, 928, 929, 932, 933, 937, 938, 947, 948, 949, 950, 951, 953, 954, 955, 963, 964, 969, 971, 972, 975, 976, 977, 978, 979, 980, 981, 989, 990, 992, 995, 996, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1012, 1014, 1015, 1021, 1022, 1025, 1029, 1030, 1032, 1033, 1034, 1036, 1037, 1039, 1042, 1043, 1044, 1046, 1048, 1049, 1051, 1055, 1056, 1057, 1060], "50": [0, 43, 46, 49, 52, 54, 61, 68, 69, 73, 85, 87, 94, 95, 100, 101, 104, 105, 117, 123, 125, 128, 134, 139, 142, 145, 152, 155, 158, 159, 174, 177, 179, 180, 181, 182, 191, 192, 193, 200, 204, 215, 220, 223, 227, 228, 232, 234, 236, 238, 240, 244, 245, 250, 251, 253, 257, 261, 272, 273, 278, 280, 281, 291, 299, 317, 319, 323, 330, 332, 339, 341, 343, 347, 355, 361, 381, 383, 386, 391, 420, 423, 424, 425, 428, 450, 481, 487, 488, 508, 512, 529, 531, 534, 541, 547, 552, 561, 562, 577, 601, 602, 614, 616, 617, 623, 625, 666, 667, 674, 675, 676, 678, 684, 685, 686, 700, 721, 800, 808, 822, 841, 861, 912, 921, 995, 996, 1000, 1001, 1003, 1006, 1010, 1021, 1023, 1027, 1041, 1058], "500": [49, 79, 85, 92, 95, 96, 98, 117, 118, 132, 134, 143, 145, 153, 173, 176, 197, 233, 234, 241, 258, 259, 263, 264, 268, 272, 278, 281, 291, 292, 299, 305, 311, 323, 329, 334, 335, 353, 358, 373, 423, 429, 477, 478, 482, 483, 484, 489, 490, 491, 492, 619, 621, 622, 624, 629, 632, 633, 658, 659, 662, 663, 664, 688, 690, 691, 870, 989, 1015], "5000": [91, 206, 235, 236, 238, 330, 893], "50000": 61, "500000": 315, "5000000": 55, "50000000": 179, "50000013": 996, "5000083": 52, "500526": 155, "500x500": 549, "5012": 1047, "5016": [418, 429, 483], "5025616": 52, "5029": [418, 429, 483], "503452": 315, "5036": 1048, "504185": 315, "50447799": 1001, "505": [83, 101, 837, 1021], "506": [286, 1021], "507": 417, "50755672": 474, "507943": 281, "508": 1032, "5082": 1020, "50941682": 1001, "50_000": [326, 361], "50sampl": 1027, "51": [61, 106, 181, 238, 296, 299, 416, 417, 774, 784, 789, 996, 1021, 1037], "510": [153, 1021, 1032], "51082562": 598, "512": 219, "512281": 268, "512595": 315, "51292546": 620, "513": [115, 145, 861, 1003, 1021], "513034": 315, "5131": [46, 1046], "51341712": 998, "5141": 1047, "51462041": 857, "5149": 46, "515": 43, "515390": 392, "516": 362, "5166": 681, "5166646": 772, "517": [47, 460, 470, 1032], "517272": 268, "5182": 1046, "5186": 1046, "519": [220, 349, 1021], "5193": 46, "51958": 181, "51961675": 1032, "51963999": 113, "52": [43, 181, 220, 539, 641, 805, 948, 1041], "520": [159, 636, 861, 990, 1003, 1021], "52003279": 1001, "5208": 209, "52106591": 135, "5211": 1048, "5212": 209, "522": 913, "5224167": 52, "5229": 1048, "523": 532, "524": 52, "5243": 424, "52433293": 424, "5244": 209, "525": [447, 636, 990], "5251": 1047, "526": [112, 912, 1021], "526599": 209, "527": [358, 1021], "5279": 1048, "5282": 1046, "52875032": 669, "5289": 46, "529": [118, 1021], "5291": 1047, "5295": 1048, "52955942": 857, "5299": 1047, "53": [43, 88, 257, 416, 423, 543, 549, 554, 800, 801], "530": [269, 1021], "53060544": 1032, "5315170": 52, "5316": 360, "53284267": 261, "532843": 261, "533": 192, "5337": 1046, "534": 192, "5355": 1046, "5359": 1048, "536": [181, 299], "5360": 1046, "53777511": 52, "53844117956": 772, "538mb": 360, "5395559": 235, "53959628e": 201, "54": [123, 174, 197, 204, 220, 223, 257, 381, 383, 416, 499, 1042, 1043], "540": [108, 1021], "54035582": 772, "541": [460, 470], "5415": 997, "5417": 238, "542": [58, 89, 174, 193, 383, 1021], "5420": 552, "542052": 209, "54209": 165, "5425": 532, "543": 204, "5431": 1046, "543841": 209, "54434690031882": 107, "54488318": 395, "546": 253, "5460": 1047, "546068": 261, "54606834": 261, "54666667": 368, "5467523": 52, "5469": 383, "547": [333, 1021], "548": [180, 1021], "5488135": 395, "549": 63, "5495": 1046, "54980": 549, "55": [192, 197, 215, 220, 238, 242, 339, 391, 416, 420, 499, 605, 808, 814, 822, 836, 1000, 1041], "5500": [333, 696, 997], "550213": 209, "55102041": 457, "5515": 754, "552": 1000, "55212743": 369, "5523": 1020, "55249": 605, "55390036": 135, "554": [228, 236, 316], "5540": 1047, "55422893": 424, "555": [285, 724, 1021], "5555555555555556": 286, "5557": 281, "5558": 46, "556": [191, 1021], "55800226": 235, "559": 624, "5591": [697, 701, 997], "55968825": 654, "56": [43, 238, 251, 342, 392, 654, 655, 660, 668, 669, 670, 689, 721, 743, 1000, 1010, 1037, 1041], "560": [220, 525, 526], "561": 416, "561464362648773": 95, "564": 220, "56479934": 369, "56485654": 135, "565": 278, "566": 220, "569": [174, 341, 383, 508, 600, 603, 604, 606], "5697": 1048, "56b4e9": 263, "57": [176, 192, 236, 287, 317, 383, 384, 404, 408, 409, 417, 713, 769, 789, 845, 1000, 1010, 1041], "570": [174, 383, 1032], "570655": 209, "571": [50, 1021], "5713": 671, "57142857": 729, "573": [211, 424, 1021], "5732": 1048, "57320793": 424, "573491": 209, "574": [93, 329, 542, 549, 1021], "5748": 502, "5749": [381, 501, 502], "575": [104, 220], "5762": 1047, "576989": 261, "577": [174, 383], "579": 532, "58": [101, 112, 145, 383, 418, 429, 483, 615, 772, 1010, 1021, 1030], "580": [183, 361, 852, 853, 1021], "5804131": 135, "5805": 1047, "5807": 1003, "581": [157, 197, 1021], "581012": [381, 499], "5814": 1048, "58149261": 424, "58195950e": 201, "582": 913, "5828": [381, 501, 502], "583": [302, 416, 1021, 1032], "5833": [746, 1000], "583333315172": 52, "58364548": 998, "585": 1032, "5853": 1020, "5854": 1032, "5855": 1032, "5857": 1046, "5863": 392, "58667835e": 201, "586798": 209, "5871": 687, "5874": 1047, "5882004012129721": 95, "589715": 209, "59": [43, 197, 204, 238, 354, 383, 392, 416, 417, 518, 830, 1000, 1037, 1041], "59122734": 675, "592": [619, 622, 633, 1007], "592373": 333, "5925110": 52, "5929": 1047, "593": 143, "594": [185, 220], "594754": 209, "59489497": 235, "595": 220, "5956": 1049, "596": [362, 724], "5960": 235, "5963": 1051, "597": 220, "598": [93, 132, 177, 549], "5981": 552, "598533": 209, "599": 688, "5991": 1048, "5_000": 197, "5a": 892, "5d": 47, "5e": [44, 125, 205, 603, 604, 606], "5e5": 220, "5f": [165, 332], "5m": 55, "5n_": 114, "5th": [52, 152, 155, 184, 416], "5x": 1058, "6": [43, 45, 47, 48, 49, 50, 51, 52, 57, 63, 64, 67, 68, 75, 79, 81, 84, 85, 87, 91, 92, 95, 96, 97, 98, 99, 100, 102, 107, 108, 109, 111, 112, 113, 115, 117, 121, 125, 127, 134, 140, 148, 152, 153, 155, 157, 159, 165, 169, 174, 176, 179, 181, 183, 184, 187, 188, 192, 193, 195, 197, 199, 200, 201, 204, 209, 213, 218, 220, 221, 222, 224, 234, 235, 238, 240, 241, 242, 244, 247, 250, 251, 255, 258, 259, 263, 264, 265, 266, 268, 269, 271, 272, 273, 277, 278, 279, 280, 281, 283, 287, 288, 289, 290, 291, 294, 298, 301, 304, 312, 314, 316, 317, 319, 321, 323, 324, 326, 328, 331, 332, 333, 334, 335, 336, 338, 339, 341, 342, 343, 349, 350, 352, 354, 356, 358, 361, 362, 367, 369, 380, 381, 383, 384, 386, 391, 392, 399, 404, 408, 409, 414, 416, 417, 420, 421, 423, 424, 425, 431, 443, 449, 453, 454, 456, 457, 458, 459, 460, 461, 463, 464, 465, 466, 469, 470, 471, 490, 491, 492, 493, 498, 504, 513, 525, 532, 535, 538, 545, 546, 547, 548, 549, 553, 554, 555, 561, 569, 570, 571, 575, 576, 577, 578, 601, 602, 612, 613, 614, 616, 619, 622, 623, 633, 635, 636, 638, 644, 645, 652, 653, 674, 678, 684, 685, 687, 697, 701, 707, 719, 729, 736, 746, 750, 753, 754, 758, 759, 761, 777, 793, 796, 798, 805, 806, 807, 809, 810, 815, 817, 818, 820, 825, 826, 829, 833, 834, 835, 836, 838, 847, 848, 849, 851, 852, 853, 860, 862, 863, 864, 879, 880, 882, 885, 887, 890, 891, 895, 896, 927, 928, 932, 933, 948, 949, 950, 952, 954, 955, 963, 975, 978, 986, 989, 990, 994, 996, 997, 1000, 1010, 1011, 1014, 1015, 1016, 1023, 1025, 1029, 1030, 1032, 1037, 1039, 1042, 1043, 1044, 1047, 1049, 1054, 1058, 1059], "60": [43, 45, 52, 94, 107, 115, 220, 232, 238, 240, 241, 261, 266, 286, 291, 339, 352, 360, 380, 416, 420, 458, 465, 721, 808, 1000, 1010, 1030, 1041, 1044], "600": [63, 85, 93, 150, 159, 160, 227, 381, 688, 1021], "6000": [317, 635], "601052": 315, "601707": 209, "60244657": 857, "60276338": 395, "603": [98, 193, 456, 1021], "604": [132, 165, 549, 1021], "605": [339, 1021], "606": [621, 842, 1001], "60648906": 1032, "607275806426107": 176, "607752": 152, "60809415": 670, "60834549": 92, "60836363e": 201, "609": [185, 237, 392, 1021], "61": [114, 193, 238, 380, 383, 392, 417, 466, 549, 568, 654, 655, 660, 668, 669, 670, 689, 721, 830, 950], "610": [87, 1021], "6101": 1048, "611": [276, 278, 549], "6114": 835, "6114326": 220, "6114327": 220, "6114328": 220, "6114329": 220, "6114330": 220, "611676": 209, "612": 798, "6121": 1047, "6126": 1048, "6147": 1046, "615": [83, 279], "615373": 192, "616": [849, 1002, 1010], "61611719": 179, "617": [93, 281, 416, 777], "617050e": 238, "6173": 1047, "617715": 152, "6178": 1047, "618": [93, 276], "6181": 1048, "6182": 1047, "618263": 209, "619": [98, 100, 176, 456, 1021], "619052": 381, "61958": 181, "6196": [281, 1046], "6198": 754, "62": [47, 52, 193, 197, 238, 271, 333, 339, 369, 381, 501, 502, 852, 853, 1037, 1044], "620": 506, "621": [93, 777], "621645": 209, "622": [93, 549], "62241605": 204, "622811": 152, "623": [849, 1002], "6231": 1020, "6237": 238, "624": [193, 362, 1007], "625": [88, 220, 626, 716], "6250": 1048, "6258": 1046, "626": [84, 206], "6261": 1050, "626286": 209, "62717609": 235, "62722912": 52, "62745778": 1001, "628": [53, 361, 1021], "6282": 1047, "6284": 1020, "6288": 1048, "6291456": 88, "63": [45, 47, 52, 235, 272, 383, 423, 565, 566, 573, 574, 654, 655, 660, 668, 669, 670, 689, 707, 734, 808, 822, 830, 922, 923, 1000], "630": 732, "63035731": 424, "630382": 333, "6312": 52, "632": 325, "6323": 1020, "633": [174, 283, 1021], "6331": 43, "6332": 43, "63327171": 204, "6333": 43, "6334": 43, "6335": 43, "6338211367102258": 326, "63394388": 204, "635": [43, 222, 624, 1021], "636": [204, 392], "63667341": 92, "6371000": 772, "6374": 1049, "6375861597263857": 947, "638": [81, 361, 392, 1021], "638768": 89, "638843": 315, "63931533": 1032, "63bit": 1052, "64": [43, 47, 52, 68, 83, 88, 93, 120, 125, 181, 192, 241, 251, 252, 256, 276, 287, 303, 308, 373, 374, 383, 384, 392, 400, 404, 417, 421, 428, 503, 506, 510, 607, 608, 654, 666, 696, 697, 698, 699, 701, 913, 1003, 1031, 1037, 1041, 1043, 1049, 1050, 1053, 1054, 1055, 1058], "640": [193, 414, 498, 514, 515, 591, 592, 595, 989], "640000e": 238, "640770e": 238, "640880e": 238, "64185414": 674, "64236448": 544, "6424": 1020, "6425": 1020, "643": 276, "644": 342, "6440": 235, "64447187": 88, "645": 93, "6451": 1020, "6452": 1049, "646": [184, 187, 1021], "6463": 1050, "647": 93, "6472": 1047, "6476": 532, "647689": 209, "648": [161, 1021], "648026": 152, "6497": 1047, "64bit": 1041, "64x64": [125, 381, 421], "65": [43, 69, 193, 220, 287, 325, 416, 447, 510, 525, 605, 707, 749, 800, 801, 830, 1007, 1030, 1041, 1042, 1043], "650": 414, "6505186632729437": 95, "6507": 1048, "651": 392, "652": 361, "652739": 209, "653": [392, 619, 622, 633], "6545": 1053, "656": 381, "6567": 859, "657": [143, 261, 278, 1021], "6572": 859, "6573": 1048, "65799352e": 201, "658": [118, 278, 1021], "6586": 1047, "659": [52, 185, 1021], "6599": 1020, "65e": 206, "66": [43, 244, 325, 383, 416, 433, 469, 540, 640, 720, 791, 792, 803, 891, 899, 982, 1000, 1012], "660": 261, "660797": 261, "661": [312, 1021], "661086": 281, "6624": 1053, "662409": 209, "663": [906, 1008, 1012], "664": [174, 383], "665": 43, "6650": 52, "6651": 1047, "666": [179, 416, 854, 990], "6660": 1047, "6666": [746, 1000, 1047], "66666667": [737, 790, 862, 1010], "666667315174": 52, "6667": 1047, "66670169e": 201, "667": [728, 748, 1000], "667219": 152, "6689": 1049, "6691": 1047, "6697": 1047, "669930e": 238, "67": [101, 128, 192, 238, 383, 506, 524, 525, 526, 635, 675, 721, 822, 990, 1000, 1014, 1037, 1041], "670": [222, 272], "671": 1012, "6715": 1020, "67251877": 674, "673": [118, 361, 392], "674": [46, 1021], "67443065": 135, "67451144e": 201, "675": 176, "675318": 89, "676": 677, "6764": 1047, "677": [141, 1021], "678": [174, 1021], "678008": 220, "678009": 220, "678010": 220, "678011": 220, "678012": 220, "678013": [220, 238], "678359": 209, "679": [222, 912], "68": [43, 52, 185, 211, 317, 338, 416, 486, 543, 549, 598, 693, 694, 1041], "681": [93, 392], "6817": 1047, "682": [174, 392], "6821": 47, "682880e": 238, "683980e": 238, "684": [105, 113], "6846": 1047, "6848": 1050, "685": [728, 748, 1000], "6852": 278, "6860": 151, "687": 1012, "6875": 724, "688": 113, "689015": 315, "689143": 315, "689751": 315, "69": [45, 211, 272, 324, 339, 416, 479, 480, 615, 616, 764, 1000, 1010, 1032], "690": 222, "6902": 1047, "691": [173, 242, 729, 1021], "6913": 1047, "692": 139, "692270e": 238, "692470": 315, "6929": 1020, "692901": 152, "693": 1000, "6931": 876, "69314718": [426, 620, 1010], "695": 276, "69513": 93, "6954": 1047, "69545": 93, "695740e": 238, "697": 193, "69735": 93, "698": [93, 272], "6984743": 179, "69892343": 224, "699691": 381, "6d": 47, "6f": [55, 129, 283, 745, 803], "6ppm": 181, "6th": 184, "6x3": 424, "7": [1, 2, 43, 45, 47, 51, 52, 53, 54, 57, 63, 66, 68, 69, 70, 74, 77, 79, 81, 88, 89, 90, 91, 95, 99, 100, 102, 105, 106, 108, 113, 115, 128, 139, 142, 152, 155, 156, 160, 161, 174, 185, 191, 192, 193, 195, 197, 201, 202, 219, 220, 221, 222, 238, 240, 247, 252, 253, 259, 261, 263, 264, 267, 268, 272, 273, 278, 282, 284, 285, 289, 291, 296, 298, 299, 301, 304, 305, 307, 316, 317, 319, 323, 328, 331, 332, 333, 335, 338, 339, 341, 342, 346, 353, 356, 357, 360, 361, 362, 369, 381, 383, 384, 390, 391, 392, 404, 408, 409, 414, 420, 421, 423, 424, 425, 427, 428, 431, 447, 452, 453, 456, 458, 459, 460, 461, 463, 464, 465, 466, 469, 470, 471, 472, 475, 479, 480, 490, 491, 492, 493, 499, 504, 506, 540, 541, 542, 543, 544, 546, 548, 552, 569, 570, 596, 599, 608, 613, 614, 635, 636, 638, 645, 654, 655, 657, 660, 666, 667, 668, 669, 670, 681, 683, 689, 690, 691, 700, 707, 715, 717, 729, 731, 732, 734, 736, 752, 753, 754, 758, 759, 761, 790, 793, 798, 799, 802, 805, 807, 808, 809, 810, 811, 812, 815, 818, 822, 825, 826, 829, 835, 838, 842, 852, 853, 861, 870, 871, 872, 877, 884, 885, 907, 908, 948, 949, 952, 953, 955, 964, 969, 989, 990, 995, 996, 998, 1000, 1001, 1003, 1004, 1006, 1010, 1014, 1015, 1025, 1029, 1032, 1037, 1039, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1054, 1059], "70": [43, 45, 50, 101, 105, 107, 139, 193, 257, 263, 278, 339, 381, 383, 420, 501, 502, 690, 691, 721, 734, 764, 808, 822, 899, 989, 1010, 1030], "700": [85, 272, 330], "7000": 238, "701": 93, "702266": 209, "703": [304, 414, 521, 1021], "70359377": 204, "704": [235, 360], "70432034": 117, "7049": 1047, "7049787496083262": 95, "706026": 209, "707": [888, 900], "7071": 1049, "70763101": 88, "708": [268, 546, 548, 555, 758, 1021], "70814003": 369, "7083": 1000, "708333315174": 52, "7089": 1048, "709": 279, "70x": 1058, "71": [43, 123, 174, 224, 238, 383, 518, 738, 744, 774, 784, 1000, 1032, 1037, 1043], "710": 414, "7101": 1047, "714": 330, "71518937": 395, "7152": 1047, "7154": 1047, "715413": 152, "7159": 1047, "716": 521, "7187": 1047, "718747": 209, "7194": 1047, "72": [43, 45, 46, 52, 145, 179, 391, 830, 836], "7200": 657, "721": [546, 548, 555], "722128e": 238, "72295655": 117, "723": [93, 253], "723665": 292, "7239": 1047, "724": [152, 1021], "7242": 1020, "724702": 281, "7248": 1047, "7256": 643, "726": [236, 1008], "7260": 1047, "7261": 1047, "726573": 192, "72667194": 1001, "7271482064048191": 286, "72850319": 1001, "7295": 1047, "7298221281347033": 43, "73": [47, 123, 141, 282, 339, 399, 489, 744, 808, 822, 858, 921, 1010, 1030, 1041, 1043], "7301": 1047, "730119e": 238, "731249e": 238, "7313": 46, "73153": 392, "732": 222, "7321432711315247203224138160467097": 52, "7323": 1047, "7325": 1047, "732913": 292, "733": 299, "7331": 1048, "7332": 916, "7335": 330, "7337046907": 185, "734": [322, 1021], "7350": 1047, "7353": 1047, "7356": 1048, "7365": 1048, "73654189": 52, "73698041": 1032, "737": [253, 532], "7376": 1048, "738": [64, 1021], "7382": 1020, "7387": 484, "7388": 1048, "739865e": 238, "739950": 292, "74": [43, 47, 236, 338, 339, 383, 598, 702, 808, 822, 891, 1037], "741": [276, 1021], "7411": [477, 482, 1047], "7419": 1047, "743": [130, 276, 1021, 1032], "74310541": 179, "7436926291700353": 215, "744": [276, 299], "744029": 292, "744042e": 238, "7441": 1048, "744497e": 238, "74495357": 204, "745": [266, 1021], "7459": 1048, "746": 383, "7464": 1048, "746492": 278, "748": [360, 392], "7490": [1047, 1048], "75": [43, 45, 46, 47, 49, 52, 69, 79, 90, 115, 142, 171, 183, 184, 188, 192, 197, 199, 202, 211, 227, 238, 242, 261, 265, 266, 272, 278, 287, 291, 304, 319, 331, 358, 360, 369, 457, 509, 559, 645, 666, 702, 714, 720, 742, 747, 748, 753, 761, 764, 802, 808, 890, 898, 902, 909, 925, 937, 938, 981, 1000, 1002, 1010, 1016, 1018, 1030, 1043], "750": [84, 90, 147, 278], "75000": 220, "7501": 1048, "750348": 152, "750389": 209, "7506": 1048, "752": [199, 360, 1021], "752470": 292, "752867": 209, "753": [73, 287, 360, 1021], "7532": 497, "7533": [429, 483, 1048], "75474165": 1001, "7548": 1048, "7548291": 335, "755": [185, 1021], "7553": 1047, "7565": 1048, "756687e": 238, "7567": 1048, "756746e": 238, "7569": 478, "757": [174, 276, 299, 383], "7571304089239168": 329, "7573": 1048, "75747153": 224, "7578": [281, 1048], "75788833": 171, "757915": 292, "759": 299, "7593": 1047, "7594": 1047, "75949622": 224, "75th": [257, 890], "76": [43, 197, 220, 339, 360, 369, 383, 392, 785, 789, 872, 1032], "760": [43, 155], "7608": 1020, "76195467e": 201, "762": [303, 360, 1021], "7621951219512195": 261, "7632": 1047, "7638": 996, "764": [47, 729, 1000, 1021], "7646": 1020, "764779": 209, "764mb": 360, "765012": 333, "7655": 1048, "765671": 209, "766": 193, "7660": 1047, "7661": 1048, "7668": 1049, "7674": [532, 1048], "767498": 152, "7676": 1047, "768": 88, "7680": 1047, "76823": 45, "7685": 1048, "769": 299, "76995": 381, "77": [43, 45, 47, 79, 174, 197, 287, 339, 380, 383, 542, 715, 744, 783, 830], "770": [79, 1021], "77000": 220, "7702": 1048, "770926": 292, "772": [342, 360, 731, 1021], "7721": 1048, "7723": 1048, "7724": 1047, "773": [278, 342, 656, 850], "77310": 381, "7732": 1047, "77322639": 117, "7738": 1049, "7739": 1048, "77426368": 51, "775": 57, "7750": 1047, "775047": 684, "775151": 684, "7756": 1047, "77630514": 424, "7768366": 998, "777": 392, "7771": 1048, "77764": 412, "77777215": 117, "7786": 1047, "779": 360, "7794": 1048, "779751": 292, "7798": 916, "7799": 1047, "78": [43, 47, 88, 123, 197, 238, 287, 321, 339, 501, 502, 654, 655, 660, 661, 663, 668, 669, 670, 672, 673, 689, 693, 694, 808, 814, 830, 836, 1000, 1020, 1030], "780": 276, "7812": 1048, "781265": [381, 505], "7814": 1048, "7816": 52, "7819": [416, 1048], "7823": [1048, 1049], "7825": 1048, "7825594": 51, "7826": 383, "782755": 62, "7831": 360, "783149": 105, "7833": 483, "783392": 278, "7838": 1048, "784": [224, 316, 1021], "7840": 89, "7849": 1048, "785063": 105, "78571427112143152472031331383346104": 52, "786": [88, 105], "786015": 105, "7863": 1048, "786432": 88, "78681467": 88, "7872": 1048, "7880": 1048, "7887550": 52, "788808": 333, "789": [170, 423], "7894": [906, 1012], "79": [43, 45, 47, 66, 68, 113, 114, 128, 174, 197, 317, 339, 383, 391, 418, 482, 532, 605, 702, 830, 850, 1041, 1043], "790": [43, 104], "7906": [630, 657], "79064206": 618, "79084103": 369, "791": 185, "7914": 1048, "791667315161908911936472223112": 52, "79269019073225": 303, "7927845601690917": 326, "7929": [361, 1048], "793": 362, "794": [144, 1021], "7943": 1051, "7944": 1048, "7946": 1047, "795": [235, 656, 1021], "7954": 1048, "796": 152, "7970": 1048, "7971": 671, "7972": 562, "79769376": 117, "798": [105, 423], "7983": 1048, "798301": 261, "7986": 1048, "7986499491396727": 176, "798982054": 1000, "799": [185, 361], "7990": 1048, "7998": 1048, "7_qbz5n2kfra8p0": 404, "8": [43, 44, 45, 46, 47, 48, 51, 52, 53, 57, 62, 63, 64, 67, 68, 70, 72, 78, 79, 80, 83, 85, 88, 90, 95, 97, 99, 100, 104, 106, 108, 109, 114, 117, 121, 122, 123, 125, 126, 129, 130, 133, 135, 139, 142, 144, 145, 149, 151, 152, 154, 158, 161, 162, 165, 173, 174, 177, 179, 181, 182, 184, 185, 188, 191, 192, 193, 195, 197, 199, 200, 205, 206, 211, 214, 220, 221, 224, 228, 230, 236, 238, 240, 241, 242, 244, 245, 248, 251, 252, 253, 255, 259, 260, 261, 263, 264, 265, 267, 268, 269, 272, 273, 274, 276, 277, 278, 279, 281, 282, 283, 285, 288, 289, 296, 298, 301, 303, 307, 311, 314, 316, 317, 319, 321, 322, 323, 324, 325, 328, 333, 338, 339, 340, 342, 343, 346, 349, 353, 354, 355, 356, 357, 360, 361, 362, 367, 369, 374, 380, 381, 383, 384, 386, 391, 392, 404, 410, 414, 416, 420, 421, 423, 424, 425, 427, 429, 447, 451, 452, 455, 457, 458, 460, 463, 464, 465, 470, 471, 477, 478, 479, 480, 481, 482, 483, 484, 487, 488, 489, 491, 492, 493, 495, 498, 504, 506, 510, 511, 522, 524, 539, 542, 546, 548, 551, 553, 555, 557, 558, 563, 564, 573, 578, 590, 596, 597, 598, 599, 612, 613, 636, 637, 644, 645, 656, 666, 678, 684, 687, 697, 700, 701, 702, 703, 707, 710, 714, 715, 717, 718, 723, 729, 735, 736, 737, 749, 753, 754, 758, 759, 761, 790, 791, 793, 796, 797, 798, 799, 803, 805, 807, 809, 810, 815, 818, 825, 826, 829, 830, 831, 838, 839, 841, 850, 852, 853, 859, 869, 870, 871, 877, 884, 891, 893, 914, 917, 947, 948, 949, 953, 969, 975, 976, 977, 978, 979, 980, 981, 989, 990, 996, 997, 998, 1000, 1003, 1008, 1010, 1014, 1024, 1025, 1029, 1030, 1031, 1032, 1033, 1037, 1038, 1039, 1042, 1043, 1044, 1048, 1049, 1054, 1055, 1057, 1060], "80": [43, 45, 47, 50, 64, 102, 114, 160, 167, 171, 193, 199, 255, 321, 325, 338, 352, 354, 360, 366, 369, 381, 383, 386, 414, 420, 425, 427, 452, 487, 518, 549, 721, 808, 822, 830, 893, 906, 925, 989, 995, 996, 1000, 1007, 1013, 1016, 1034], "800": [85, 331, 381, 592, 700], "8000": [238, 281, 282], "800000011920929": 368, "8000184677460305": 326, "8002": 1048, "8003": 1049, "8005": 1048, "8006": 1048, "801": 362, "8010": 1048, "801770e": 238, "802": [46, 174, 383], "8022": [46, 400, 481, 1050], "802601": 209, "8028": 1048, "803483": 152, "803882e": 238, "8040": 1047, "804414": [381, 505], "805": 222, "8053": 1048, "8059798": 204, "806": 657, "8061": 1048, "8065": 1048, "8066": 1049, "8068": 1048, "807": [236, 276, 278, 1021], "8075": 1049, "808": [294, 1021], "8086": [627, 1048], "8087": 1048, "8093": 1048, "8094": 1048, "80956739": 1001, "80_000": 144, "81": [43, 85, 128, 261, 338, 339, 416, 707, 769, 796, 808, 822, 839, 1000, 1001, 1003, 1010], "810": [194, 837], "8100": 1020, "8102": 1049, "810596": 381, "8117": 1048, "8120": 1048, "8125": 729, "812526": 209, "8129": 1049, "8133333333333334": 310, "81355169": 424, "8137": 1048, "8139": 1048, "814": [194, 1032], "81458798": 1032, "815476315189119122164721021826110": 52, "8157": 1020, "8159": 1048, "816": [279, 479, 480], "8160": 1048, "8174": 1048, "817724": 209, "8181": 1048, "819": 424, "8190": 1049, "81940995": 424, "8198": 1048, "82": [43, 66, 88, 93, 148, 171, 223, 310, 338, 360, 796, 808, 822, 948, 1000, 1003, 1030, 1041], "820": [43, 52, 252, 852, 853, 1021], "820705": 209, "8216": 1050, "822": 798, "822097": 192, "8224": 1048, "8225220806196525": 215, "823": 299, "8243": 1020, "825": 758, "8251": 1048, "8253": 236, "8259": 1048, "826": 251, "827917": 152, "828": 299, "8282": 1048, "829429": 268, "8295": 1048, "83": [45, 66, 70, 74, 338, 383, 388, 702, 715, 794, 995, 1000, 1030, 1034, 1044], "830": [365, 1021], "830000": 315, "8306": 1048, "8316": 1048, "832": [194, 423, 563, 564], "83236428": 424, "83281226": [852, 853], "8333": 506, "83333": 772, "833333": 192, "8335": 1048, "834": 342, "834310": 209, "8344": 1048, "8345": 605, "8348": 1034, "8353": 46, "8354": [630, 1048], "83548752": 618, "8355": 1047, "8361": 1049, "836224": 62, "8363": 1048, "8370": 1020, "8377": 1048, "83816048": 654, "83822343": 998, "83833": 392, "8387": 843, "839": 688, "84": [43, 45, 104, 171, 211, 238, 321, 338, 369, 383, 423, 424, 796, 822, 1000, 1010, 1030], "840": 392, "84000": 220, "840000": 315, "8407": 104, "84077985": 204, "841": 105, "84127814": 674, "84253": 1001, "844": [423, 563, 564], "8446": 1048, "8449": 1048, "847222222222214": 215, "8473": 424, "8478": 1050, "8480": 1020, "8481": 1048, "8484": 1049, "84845219": 1032, "848743": 62, "849835": 89, "85": [45, 55, 68, 85, 90, 104, 128, 171, 235, 238, 289, 317, 339, 369, 423, 447, 506, 508, 563, 564, 605, 660, 666, 753, 761, 796, 808, 836, 1000, 1001, 1030, 1041], "850000": 315, "850031": 209, "8508": 1050, "851": [74, 278, 362, 1021], "8512": 1048, "8513": 627, "851348": 62, "8515": [424, 1048], "85151335": 424, "851792": 62, "85253229": 92, "852774": 152, "853174": 62, "853846": 209, "854": 276, "85418642": 369, "8549": 1048, "855": 47, "8554": 1049, "855465": 315, "857": [279, 361], "857400": 62, "858486250088675": 326, "85857475": 135, "8586": 1048, "859007": 62, "8591": 1048, "86": [52, 68, 104, 171, 211, 321, 338, 339, 415, 796, 920, 1000, 1030, 1037], "860": [114, 1021], "860000": 315, "861": [128, 174, 383, 796, 797, 1000, 1021], "861053": 62, "861106": 62, "8614": 1020, "861533": 62, "8617": 1049, "861868": 62, "8626621": 335, "8628": 643, "863": [93, 1021], "8640": 193, "865400": 62, "866": 1008, "866161": 62, "866571": 62, "867": 108, "8672": 1048, "8676": [628, 1048], "8678": 631, "868": [152, 170], "868443": 50, "8698": 1048, "87": [45, 68, 104, 185, 272, 276, 339, 605, 675, 785, 796, 808, 830, 888, 900, 1000, 1034], "870": [174, 383], "871": [73, 113, 114, 418, 482], "871277": 62, "871965": 62, "872": [73, 1008], "8720": [564, 1049], "872186": 62, "873": [174, 240, 292, 383, 1021], "873724": 62, "87382323": 670, "874": [107, 796, 797, 1000], "87421f": 123, "874771": 152, "875": [88, 177, 677], "875315171": 52, "875315173": 52, "875941": 62, "87600388": 179, "8768": 1048, "8769": 1050, "877": [47, 276, 330, 1021], "877206": 276, "8773": 1050, "877981": 62, "878": 47, "878051": 209, "878964": 820, "879": [109, 125, 1021], "87mb": 360, "88": [43, 45, 68, 211, 224, 277, 317, 336, 338, 339, 364, 381, 383, 386, 415, 418, 481, 654, 655, 660, 668, 669, 670, 689, 872, 948, 1030, 1041], "880": 43, "880191": 209, "880298": 209, "88089948": 424, "88096009": 135, "882": [278, 319, 1021], "88213": 381, "882561": 278, "883": 84, "883065": 62, "8833": 506, "8835": 1048, "884": 299, "8845": 1048, "885": [47, 174, 324, 342, 383, 1021], "8854": 1048, "8874": 1048, "8878": 843, "8880": 628, "8881": 631, "889": [276, 445], "88978285": 1001, "89": [43, 68, 181, 211, 257, 338, 339, 983, 995, 1000, 1010, 1034, 1041, 1044, 1052], "890": [256, 276, 1021], "891": [47, 206], "8922": 1048, "893055": 209, "8931": 1048, "8936": 1048, "894264": 261, "8947": 922, "8948018": 52, "89483932": 998, "8948621": 1001, "896": 656, "8963": 281, "8965": 423, "897": [284, 1021], "8973": 1048, "898": [148, 1021], "89856": 820, "899": [68, 276], "8992": 1048, "8995": 1048, "8pt": 1010, "8x8": [68, 120, 211, 251, 308, 317, 383, 510, 1031], "9": [43, 46, 48, 51, 52, 53, 61, 63, 64, 67, 68, 70, 77, 79, 85, 90, 93, 97, 99, 108, 115, 117, 122, 148, 149, 151, 152, 158, 160, 165, 166, 167, 174, 179, 183, 188, 191, 192, 193, 201, 202, 211, 220, 227, 233, 234, 237, 238, 240, 243, 251, 252, 253, 261, 263, 264, 265, 266, 271, 272, 276, 281, 285, 287, 298, 301, 303, 304, 307, 308, 309, 314, 315, 316, 317, 319, 321, 322, 323, 325, 326, 333, 334, 336, 338, 339, 341, 342, 343, 349, 353, 358, 360, 362, 369, 383, 384, 392, 399, 404, 408, 409, 414, 415, 417, 418, 420, 423, 424, 447, 451, 458, 465, 471, 490, 491, 492, 493, 498, 504, 506, 524, 526, 528, 535, 542, 546, 547, 548, 555, 568, 575, 578, 591, 599, 612, 613, 615, 616, 635, 638, 642, 645, 647, 654, 655, 660, 666, 668, 669, 670, 689, 690, 691, 695, 700, 707, 717, 731, 734, 749, 756, 777, 786, 787, 788, 805, 807, 809, 811, 812, 826, 829, 830, 836, 838, 841, 849, 850, 854, 855, 860, 863, 869, 870, 878, 884, 887, 948, 949, 953, 973, 989, 995, 996, 1000, 1004, 1010, 1014, 1015, 1025, 1029, 1034, 1037, 1039, 1042, 1043, 1044, 1046, 1055, 1057], "90": [45, 49, 52, 54, 68, 108, 134, 135, 151, 152, 153, 155, 171, 181, 195, 200, 211, 217, 219, 222, 227, 238, 263, 287, 289, 321, 325, 334, 338, 339, 369, 373, 386, 392, 420, 571, 789, 808, 836, 841, 893, 995, 1000, 1030, 1034, 1056, 1057], "900": [47, 85, 108, 109], "9000": 238, "900000e": 238, "9010": 1047, "9012": 1049, "9015": [671, 1049], "9019": 1048, "9022": 1048, "9024": 1048, "9026666666666666": 152, "903": 47, "904": [193, 276, 417], "9041": 1049, "9043": 1049, "9044": [278, 1048], "90453403": 474, "904556e": 238, "904558e": 238, "904747e": 238, "904751e": 238, "905": 276, "905206": 89, "9067": 1048, "9069": 1050, "907": [97, 1021], "9078": 1048, "908": 1000, "90809432": 135, "9085": 1049, "9087": 1055, "90885631": 88, "909": [47, 178, 1021], "909293": 315, "909909": 152, "91": [45, 68, 86, 181, 317, 338, 339, 423, 995, 1030, 1034], "910": 43, "9100": 1048, "9101": [1034, 1049], "9105": 1048, "9108": 1048, "912": 73, "912632": 315, "913": [423, 567], "914370e": 238, "914387e": 238, "9144052": 52, "9145": 1048, "914538e": 238, "914573e": 238, "9147": 1049, "9149": 1047, "915": 47, "9151": 1049, "9157": 1049, "916": 84, "91629073": 598, "916555e": 238, "91666667": 368, "9167": 333, "917": 84, "917281": 152, "9173": 1020, "917618e": 238, "919": [43, 272, 1021], "92": [52, 68, 85, 128, 171, 197, 276, 317, 338, 339, 349, 381, 383, 546, 548, 555, 570, 605, 704, 808, 822, 830, 995, 1034], "920": [149, 1021], "9206": 1048, "9219": 1048, "922": 1029, "9221": 657, "9222": 1049, "92222222": 1029, "9226260871125187": 286, "923": [167, 1021], "923223": 820, "92329566": 135, "9234": 1049, "9239": 1048, "924": 47, "92461872": 133, "925": [1000, 1029], "9250": 1051, "92529176": 1001, "9257": 1049, "9259": 1048, "9266666666666666": 148, "927": 445, "92708922": 1029, "9274": 1051, "9277": 1048, "9278": 1048, "927905734656278": 335, "928": [114, 445], "9284": 1048, "928571": 238, "9288": 1051, "9289": 1048, "93": [45, 68, 174, 220, 261, 276, 339, 360, 383, 654, 655, 660, 668, 669, 670, 689, 785, 796, 808, 830, 836, 920, 995, 1000, 1030, 1034], "930": 1029, "9300": 278, "930000": 315, "9302": 1048, "93036212": 1029, "9304": 1049, "93192644": 1029, "932": [47, 201, 1021], "9326": 1020, "93271427": 179, "933": [47, 108, 420], "933197": 261, "933253": 152, "9333": 420, "933333": [166, 861], "934": 1029, "935": 1048, "9354": 1049, "936": [47, 445, 1000], "936480": 62, "937": [241, 1021], "9372": 1049, "937443": 62, "937532": 62, "937597": 62, "9378": 1049, "938": [47, 216, 793, 1000, 1029], "938613": 62, "939": [676, 1029], "9399": 1049, "93fletcher": 996, "93goldfarb": 996, "93lindenstrauss_lemma": 906, "93shanno_algorithm": 996, "94": [43, 68, 70, 89, 127, 148, 219, 255, 291, 321, 338, 339, 415, 423, 671, 796, 830, 995, 1000, 1001, 1010, 1034, 1041], "940": 43, "9400": 278, "940000": 315, "940184": 152, "940201": 62, "940374": 62, "9403917": 117, "941": 47, "94114649": [852, 853], "9416": 52, "9417": 679, "943": [78, 1021, 1029], "9431": 843, "944": [47, 291, 1021, 1029], "9456": 1049, "94592424": 670, "946": 114, "947": [305, 1021], "94731329": 675, "9473684210526315": 328, "947958": 989, "948": [793, 1000], "9484": 1049, "949": 47, "9490": 383, "9492": 1049, "9497": 1049, "9499": 646, "95": [45, 52, 54, 68, 79, 87, 92, 102, 122, 131, 148, 152, 155, 183, 192, 199, 220, 222, 227, 238, 257, 265, 266, 269, 278, 279, 304, 312, 321, 325, 332, 339, 349, 369, 423, 535, 640, 641, 644, 655, 669, 756, 830, 909, 996, 1000, 1001, 1013, 1034, 1044], "950": 47, "950000047683716": 368, "9502547": 204, "9507": 1048, "9515": 1049, "951751e": 238, "951958": 989, "952": [47, 84], "9521": 1049, "952289": 209, "9524": 1049, "953": [47, 84], "953061": 316, "95373": 381, "954": [888, 900], "95433992": 117, "955": [299, 420, 662], "9558": 1048, "955989": 989, "956": [47, 1029], "956038": 315, "9565": 383, "9569": 1049, "957": [47, 307, 324, 736, 1000, 1021], "9579": 1049, "958": 47, "9583": 415, "9584": [635, 1048], "959": [888, 900], "9593": 1048, "9595": 682, "9597": 1051, "9599": 1049, "95th": [52, 152, 155, 756], "96": [43, 52, 68, 81, 83, 97, 183, 247, 257, 276, 317, 321, 324, 325, 338, 339, 383, 420, 561, 690, 691, 719, 830, 989, 995, 1000, 1010, 1041], "9600": 1048, "9604": 1048, "961": 869, "961009": 989, "961111": 166, "9612": 1049, "961904": 861, "96190476": 1003, "962": 47, "96228895": 135, "9623": 1048, "963": 1029, "9630": 683, "96362897": 1029, "9637883": 1029, "96388889": 1029, "9641": 1048, "9647": 1049, "965": [47, 1000], "9655": 1049, "9656": 1049, "96578289": 1029, "966": 45, "9666": 551, "96681476": 1029, "966981": 209, "967": [108, 1000, 1004], "9677": 1048, "968": [181, 191, 276], "9681": 1049, "9686": 1049, "969": 380, "9693": 1048, "9694149248180188": 334, "9697": 1048, "97": [68, 134, 174, 195, 255, 269, 339, 349, 383, 392, 399, 420, 654, 655, 660, 666, 668, 669, 670, 689, 690, 691, 995, 1001, 1010, 1041], "9701": 1049, "9707": 1049, "971": [72, 1021], "9711": 1048, "9717": 1048, "972": [332, 1021], "9723": 1049, "9726": 1049, "973": [361, 420], "9731": 1049, "9733": [628, 631], "973554": 333, "973770": 209, "974": [172, 1021], "97435897": 368, "974e": 424, "975": [174, 191, 1015], "9750": 1048, "97545464": 261, "975455": 261, "9759": 47, "976": [146, 212, 286, 1021], "976158": 381, "977": [43, 420], "9771": 562, "9772": 1049, "9775": 1049, "977890": 268, "978": [251, 1021], "9781605585161": 416, "978444": 315, "9786": 1049, "9788": 1048, "979": 361, "98": [68, 77, 79, 89, 97, 99, 115, 128, 174, 247, 276, 314, 321, 339, 383, 390, 420, 423, 667, 847, 903, 995, 1000, 1002, 1029, 1034], "980": 174, "980000": 315, "9802": 1048, "981": [174, 383, 1000], "9815": 1048, "9816": 1049, "9821": 858, "983": [228, 321, 736, 1021], "9830": 1048, "9832": 1049, "9833": 506, "98350372e": 201, "983667": 989, "9837": 1049, "984": [343, 1021], "9843": 1054, "9847": 1048, "984ea3": [79, 97], "9850": 220, "9851": 1049, "9858": 1049, "98633022": 135, "986429": 316, "9865": 1048, "9866": [618, 627, 630], "9866666666666667": 148, "9868": [906, 1012], "986989": 281, "987": [286, 361], "9875": 1049, "98809919e": 201, "9884": 687, "9885": 679, "9886": 1049, "989341": 209, "98mb": 360, "99": [45, 52, 62, 68, 79, 86, 97, 125, 238, 247, 251, 257, 263, 265, 276, 279, 319, 339, 374, 379, 383, 390, 420, 423, 424, 500, 655, 669, 679, 690, 691, 796, 830, 859, 969, 995, 1000, 1010, 1014, 1030, 1036, 1043], "990": [677, 1000], "9900": 238, "9907": 1050, "9908": 1049, "991": [286, 1000], "9915849773450223": 176, "991653": 315, "9922": 1048, "9924": 549, "99244": 549, "992766": 315, "993": [286, 361], "9933333333333333": 148, "9935": 843, "993879": 315, "9939": 1049, "993919": 50, "994": 299, "9945": 1048, "995": 212, "9951": 1051, "9966666666666667": 328, "9969977": 52, "997": [46, 75, 174], "9978": 1054, "9979": 43, "9979281": 52, "998": [174, 1004], "9980": [43, 1049], "9981": 43, "998142": 52, "998273": 272, "9987": 647, "99891212e": 201, "999": [238, 272, 278, 390, 423, 725, 869, 870], "9990": 238, "9991": [672, 673, 1049], "99918858": 135, "9993": [43, 661, 663, 1049], "9994": 671, "9995": 43, "9996": 659, "999791942438998": 329, "9998": [50, 312], "9999": [50, 238, 312, 341, 506, 635, 1049], "99999": 341, "999999": [79, 97], "999999999999999e": 165, "9x": 335, "A": [0, 2, 19, 25, 41, 53, 55, 56, 62, 64, 67, 71, 73, 74, 75, 76, 79, 80, 81, 83, 84, 88, 89, 94, 95, 96, 97, 99, 102, 109, 111, 114, 118, 123, 126, 127, 128, 132, 140, 141, 146, 147, 149, 159, 163, 165, 166, 167, 171, 173, 176, 179, 181, 183, 184, 185, 189, 192, 193, 204, 208, 221, 224, 230, 234, 235, 238, 241, 254, 257, 266, 272, 278, 279, 281, 285, 293, 296, 314, 319, 321, 324, 328, 330, 333, 339, 340, 341, 343, 349, 353, 354, 360, 361, 362, 366, 368, 369, 373, 375, 380, 381, 383, 384, 386, 388, 389, 391, 394, 398, 399, 400, 401, 403, 407, 411, 413, 414, 416, 417, 418, 419, 421, 422, 423, 424, 425, 427, 428, 429, 430, 439, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 466, 470, 471, 472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 496, 498, 499, 500, 502, 505, 508, 509, 510, 511, 512, 516, 518, 519, 520, 521, 522, 528, 530, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 615, 616, 618, 619, 625, 628, 635, 636, 637, 638, 640, 641, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 693, 694, 696, 697, 698, 699, 700, 701, 702, 703, 712, 713, 718, 719, 720, 724, 725, 727, 729, 730, 731, 732, 733, 734, 739, 744, 745, 748, 750, 751, 752, 755, 757, 758, 759, 760, 762, 763, 764, 765, 766, 767, 772, 774, 775, 782, 783, 784, 785, 786, 789, 796, 798, 799, 801, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 897, 898, 900, 901, 902, 903, 904, 905, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 947, 948, 949, 956, 957, 959, 960, 985, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1025, 1026, 1032, 1033, 1034, 1036, 1041, 1043, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "AND": 743, "AS": 428, "AT": [2, 381, 503], "And": [52, 189, 239, 240, 245, 254, 278, 360, 394, 410, 416, 420, 424, 538, 596, 597, 599, 700, 701, 996, 1000, 1021, 1048], "As": [0, 30, 43, 46, 58, 62, 66, 75, 78, 88, 90, 92, 93, 101, 115, 118, 130, 139, 140, 146, 149, 150, 151, 153, 155, 159, 169, 172, 176, 181, 188, 192, 194, 195, 197, 199, 202, 204, 209, 211, 220, 224, 228, 238, 245, 254, 266, 272, 273, 275, 276, 278, 279, 281, 291, 298, 304, 320, 331, 336, 341, 349, 353, 361, 362, 364, 366, 367, 369, 373, 374, 381, 385, 386, 388, 390, 391, 398, 399, 400, 410, 414, 416, 417, 418, 419, 420, 421, 423, 424, 425, 426, 454, 501, 562, 570, 574, 627, 640, 663, 664, 680, 682, 695, 743, 766, 772, 854, 855, 856, 858, 860, 891, 989, 994, 996, 997, 999, 1000, 1001, 1003, 1007, 1010, 1014, 1015, 1016, 1019, 1020, 1024, 1025, 1029, 1032, 1034, 1041, 1047, 1052, 1057, 1059], "At": [52, 109, 139, 225, 254, 272, 290, 296, 298, 338, 341, 373, 374, 390, 401, 407, 412, 419, 423, 445, 448, 473, 596, 597, 599, 610, 840, 842, 879, 964, 989, 996, 999, 1001, 1005, 1014, 1024], "Be": [171, 185, 360, 386, 418, 575, 576, 656, 662, 663, 664, 666, 667, 677, 688, 712, 826, 827, 887, 1010, 1038, 1042], "Being": [386, 400, 401, 996, 1003], "But": [43, 48, 88, 191, 221, 222, 278, 299, 319, 386, 398, 416, 419, 422, 423, 470, 754, 920, 921, 989, 1000, 1015, 1020], "By": [57, 80, 125, 155, 156, 157, 199, 224, 254, 272, 287, 296, 319, 328, 334, 335, 353, 360, 374, 386, 388, 392, 393, 400, 407, 415, 416, 417, 419, 420, 421, 422, 423, 425, 446, 449, 453, 454, 458, 472, 475, 476, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 532, 557, 558, 565, 566, 567, 568, 572, 573, 593, 594, 596, 597, 599, 614, 617, 640, 641, 679, 681, 683, 685, 698, 700, 702, 705, 707, 708, 710, 711, 726, 737, 738, 742, 746, 791, 792, 795, 802, 804, 811, 812, 858, 872, 873, 885, 886, 888, 890, 900, 902, 910, 915, 916, 920, 921, 922, 923, 932, 933, 989, 990, 992, 996, 1000, 1007, 1008, 1010, 1012, 1016, 1025, 1029, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1053, 1055, 1058, 1059], "For": [2, 30, 43, 47, 48, 51, 52, 53, 57, 64, 68, 72, 75, 79, 81, 83, 84, 88, 90, 92, 93, 95, 102, 107, 113, 118, 122, 126, 142, 144, 147, 152, 153, 155, 156, 158, 170, 171, 174, 176, 178, 183, 187, 188, 192, 193, 204, 208, 209, 220, 221, 224, 225, 228, 237, 238, 240, 242, 245, 247, 248, 250, 251, 252, 254, 261, 268, 272, 275, 278, 279, 285, 292, 294, 298, 299, 309, 314, 316, 317, 321, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 341, 343, 349, 351, 353, 356, 360, 361, 362, 364, 365, 368, 369, 373, 375, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 407, 412, 413, 414, 415, 416, 417, 420, 421, 423, 424, 425, 426, 427, 432, 439, 445, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 462, 464, 465, 466, 468, 469, 470, 472, 473, 474, 476, 480, 482, 490, 491, 492, 493, 497, 502, 504, 506, 511, 520, 522, 523, 527, 531, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 580, 581, 589, 590, 591, 592, 596, 597, 599, 600, 601, 602, 605, 610, 615, 616, 617, 618, 619, 622, 627, 630, 631, 635, 636, 637, 638, 639, 640, 641, 643, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 692, 695, 696, 697, 698, 700, 701, 703, 709, 712, 714, 715, 737, 738, 746, 749, 750, 771, 777, 786, 791, 792, 795, 796, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 822, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 839, 841, 843, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 897, 898, 899, 900, 901, 902, 903, 904, 905, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 932, 938, 963, 984, 989, 990, 992, 993, 994, 995, 996, 997, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1014, 1015, 1016, 1018, 1023, 1024, 1025, 1032, 1033, 1034, 1041, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "If": [0, 43, 50, 52, 64, 68, 77, 84, 90, 105, 115, 128, 137, 147, 152, 155, 160, 185, 188, 192, 201, 220, 235, 237, 238, 254, 257, 272, 278, 285, 292, 294, 304, 312, 319, 324, 325, 349, 353, 356, 357, 360, 361, 362, 368, 369, 373, 374, 380, 381, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 400, 401, 404, 407, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 423, 424, 425, 426, 427, 428, 429, 430, 437, 440, 441, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 516, 517, 518, 520, 522, 523, 527, 530, 531, 532, 535, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 702, 703, 704, 705, 706, 708, 709, 710, 711, 712, 713, 715, 719, 720, 721, 722, 724, 725, 726, 730, 734, 735, 736, 737, 738, 739, 740, 744, 746, 749, 750, 753, 754, 756, 758, 759, 761, 762, 763, 764, 765, 766, 767, 769, 771, 772, 774, 775, 776, 777, 779, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 795, 796, 797, 800, 801, 802, 803, 804, 805, 806, 807, 808, 810, 811, 812, 814, 820, 822, 825, 828, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 935, 936, 937, 938, 941, 947, 949, 951, 953, 957, 959, 963, 966, 969, 971, 974, 975, 981, 984, 985, 986, 987, 989, 990, 992, 994, 995, 996, 997, 998, 1000, 1003, 1004, 1006, 1007, 1010, 1012, 1014, 1015, 1016, 1017, 1019, 1020, 1023, 1025, 1026, 1032, 1033, 1034, 1041, 1044, 1045, 1046, 1047, 1050, 1051, 1053, 1054, 1055, 1057, 1059], "In": [0, 7, 37, 43, 44, 46, 48, 50, 51, 52, 53, 54, 62, 63, 64, 70, 72, 74, 83, 84, 88, 90, 92, 93, 95, 101, 102, 105, 106, 108, 109, 111, 113, 114, 115, 118, 120, 121, 125, 127, 130, 132, 133, 137, 139, 142, 144, 145, 146, 147, 148, 149, 150, 152, 154, 155, 156, 157, 158, 160, 163, 170, 171, 173, 174, 176, 180, 181, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 204, 208, 209, 211, 215, 220, 221, 222, 223, 224, 225, 228, 237, 238, 247, 248, 249, 250, 252, 253, 254, 255, 257, 258, 259, 260, 261, 266, 268, 271, 272, 275, 276, 278, 279, 280, 281, 283, 284, 287, 288, 290, 292, 293, 294, 296, 299, 302, 305, 306, 308, 317, 319, 320, 321, 324, 325, 326, 328, 329, 330, 332, 333, 335, 336, 340, 342, 349, 353, 356, 360, 361, 362, 364, 368, 369, 373, 374, 375, 379, 380, 381, 382, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 398, 399, 400, 401, 403, 404, 407, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 433, 445, 448, 449, 450, 451, 452, 455, 456, 457, 460, 470, 471, 472, 477, 480, 483, 501, 504, 511, 516, 517, 519, 531, 542, 544, 546, 548, 549, 550, 552, 555, 556, 557, 558, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 599, 610, 614, 617, 618, 619, 638, 640, 641, 642, 644, 651, 652, 653, 655, 656, 657, 659, 661, 663, 666, 667, 669, 671, 673, 674, 676, 677, 682, 683, 684, 687, 688, 692, 693, 694, 704, 707, 711, 720, 726, 728, 734, 736, 737, 742, 743, 746, 748, 750, 762, 764, 765, 789, 791, 793, 796, 802, 804, 805, 806, 807, 808, 811, 812, 814, 822, 829, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 846, 847, 848, 849, 850, 851, 854, 855, 856, 858, 859, 860, 862, 863, 864, 869, 877, 879, 885, 886, 890, 891, 893, 897, 898, 900, 901, 902, 903, 904, 905, 907, 908, 909, 912, 913, 914, 917, 920, 922, 927, 931, 933, 949, 989, 990, 992, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1020, 1024, 1025, 1032, 1033, 1034, 1038, 1041, 1042, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1060], "Ines": 1058, "It": [0, 30, 43, 46, 47, 48, 52, 58, 62, 70, 72, 75, 88, 90, 93, 106, 111, 113, 115, 125, 128, 129, 134, 139, 142, 144, 145, 148, 150, 152, 160, 174, 181, 182, 183, 187, 188, 192, 193, 194, 200, 204, 208, 209, 217, 220, 224, 234, 237, 238, 240, 241, 247, 252, 254, 257, 272, 273, 274, 276, 278, 279, 281, 284, 285, 292, 296, 299, 305, 306, 307, 309, 310, 312, 319, 323, 324, 326, 328, 334, 336, 345, 349, 353, 356, 360, 361, 362, 369, 373, 374, 375, 379, 381, 383, 384, 386, 388, 390, 391, 392, 394, 395, 398, 399, 400, 404, 407, 410, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 441, 445, 446, 449, 450, 451, 452, 453, 455, 456, 457, 460, 467, 470, 475, 476, 477, 482, 486, 493, 495, 504, 516, 523, 532, 541, 543, 544, 546, 548, 549, 557, 558, 561, 562, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 597, 604, 610, 614, 615, 616, 619, 622, 623, 627, 628, 630, 631, 635, 638, 639, 640, 641, 649, 650, 651, 654, 655, 658, 660, 661, 662, 663, 666, 668, 669, 670, 671, 674, 675, 676, 678, 679, 680, 682, 684, 685, 686, 687, 689, 690, 691, 692, 695, 697, 699, 700, 701, 703, 704, 705, 706, 707, 708, 710, 712, 716, 717, 718, 724, 731, 742, 750, 751, 755, 766, 767, 770, 773, 789, 791, 796, 807, 808, 810, 811, 812, 814, 820, 821, 822, 830, 831, 833, 836, 839, 848, 849, 854, 855, 856, 858, 861, 862, 863, 864, 868, 869, 870, 874, 875, 876, 880, 881, 882, 886, 889, 891, 901, 904, 905, 909, 910, 912, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 925, 936, 949, 957, 958, 971, 974, 976, 977, 978, 979, 980, 981, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1011, 1013, 1014, 1015, 1016, 1019, 1024, 1025, 1031, 1032, 1033, 1034, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "Its": [111, 276, 280, 382, 388, 400, 421, 426, 546, 995, 996, 1005, 1008, 1014, 1019, 1024, 1044, 1058], "NOT": [254, 305, 383, 389, 818, 852, 853], "Nearness": 635, "No": [61, 141, 154, 204, 226, 228, 254, 272, 339, 354, 356, 383, 394, 404, 416, 482, 567, 568, 598, 599, 643, 653, 672, 684, 686, 693, 694, 805, 996, 1058], "Not": [90, 165, 193, 373, 398, 416, 434, 435, 438, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 477, 478, 479, 480, 481, 482, 483, 484, 539, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 571, 574, 577, 578, 589, 590, 591, 596, 597, 599, 635, 636, 637, 638, 685, 696, 697, 698, 699, 701, 802, 805, 806, 808, 811, 812, 822, 849, 852, 853, 856, 857, 858, 860, 864, 876, 884, 887, 888, 890, 893, 904, 905, 916, 1000, 1006, 1019, 1050], "OF": 383, "ON": 333, "ONE": [380, 615, 616], "OR": [319, 416, 427, 452, 1052], "Of": [48, 62, 64, 187, 292, 373, 388, 416, 424, 990], "On": [43, 51, 52, 55, 63, 102, 105, 106, 117, 118, 130, 139, 142, 144, 146, 147, 152, 156, 157, 160, 163, 169, 171, 180, 181, 192, 193, 194, 201, 208, 209, 222, 224, 248, 249, 250, 251, 253, 254, 257, 258, 259, 260, 261, 263, 265, 268, 272, 273, 274, 275, 276, 278, 279, 280, 281, 283, 285, 290, 292, 317, 319, 321, 323, 324, 325, 329, 330, 332, 333, 335, 340, 349, 356, 368, 373, 384, 386, 387, 388, 390, 398, 400, 412, 414, 416, 420, 421, 423, 425, 426, 651, 664, 699, 743, 769, 877, 893, 989, 993, 996, 999, 1000, 1002, 1006, 1008, 1013, 1015, 1029, 1032], "One": [2, 43, 48, 51, 61, 66, 84, 90, 122, 130, 132, 147, 149, 152, 155, 156, 189, 192, 195, 198, 224, 229, 235, 247, 258, 268, 272, 278, 285, 288, 296, 298, 305, 308, 320, 335, 344, 346, 357, 361, 373, 383, 386, 399, 400, 410, 415, 416, 419, 421, 422, 423, 424, 425, 427, 452, 457, 480, 482, 486, 520, 574, 639, 647, 666, 674, 676, 681, 683, 684, 685, 796, 815, 816, 840, 841, 842, 873, 874, 885, 916, 963, 990, 992, 996, 997, 998, 999, 1000, 1001, 1003, 1004, 1007, 1008, 1010, 1015, 1021, 1022, 1036, 1045, 1047, 1054, 1056], "Or": [360, 368, 420, 421, 885, 1000, 1006, 1014], "Such": [53, 156, 176, 181, 191, 199, 204, 209, 221, 272, 281, 360, 400, 401, 410, 420, 421, 423, 563, 564, 664, 990, 1000, 1003, 1010, 1016, 1032, 1051, 1056, 1058], "THE": 383, "That": [52, 64, 125, 139, 155, 174, 192, 209, 247, 278, 282, 361, 362, 374, 380, 394, 400, 415, 420, 425, 426, 451, 454, 455, 565, 572, 601, 826, 920, 921, 989, 997, 998, 1006, 1016, 1050, 1051], "The": [2, 16, 25, 27, 30, 31, 33, 37, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 63, 64, 66, 67, 68, 70, 72, 74, 75, 79, 80, 81, 82, 83, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 119, 122, 123, 125, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 163, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 193, 194, 195, 197, 199, 201, 202, 203, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 223, 224, 226, 228, 229, 237, 238, 239, 242, 243, 246, 247, 248, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 265, 266, 268, 269, 271, 275, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 293, 298, 299, 301, 303, 304, 305, 306, 307, 308, 309, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 346, 347, 349, 353, 354, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 378, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 395, 398, 399, 400, 401, 403, 404, 407, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 421, 422, 423, 425, 426, 427, 428, 429, 430, 431, 432, 438, 439, 441, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 715, 716, 717, 718, 719, 720, 721, 723, 724, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 746, 747, 748, 749, 750, 751, 752, 753, 754, 756, 760, 761, 762, 763, 764, 765, 766, 767, 770, 772, 773, 774, 775, 778, 779, 782, 783, 784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 928, 929, 930, 931, 932, 933, 935, 936, 937, 938, 939, 943, 944, 945, 946, 947, 948, 949, 951, 952, 956, 957, 960, 963, 965, 966, 967, 969, 970, 971, 974, 982, 983, 984, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1023, 1024, 1025, 1026, 1027, 1029, 1030, 1031, 1034, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "Their": [192, 381, 383, 401, 416, 652, 1041], "Then": [105, 140, 144, 147, 155, 160, 163, 171, 192, 197, 204, 208, 220, 224, 244, 248, 254, 260, 272, 280, 281, 296, 360, 380, 390, 392, 394, 404, 413, 414, 416, 419, 421, 424, 425, 578, 601, 727, 764, 808, 822, 912, 913, 990, 999, 1000, 1006, 1015, 1034, 1050], "There": [74, 81, 145, 176, 238, 244, 254, 269, 273, 275, 278, 298, 360, 379, 381, 383, 386, 387, 388, 391, 398, 400, 401, 404, 413, 416, 421, 423, 424, 425, 454, 460, 470, 542, 561, 562, 567, 568, 596, 597, 599, 614, 653, 990, 996, 997, 998, 999, 1000, 1003, 1007, 1010, 1014, 1015, 1016, 1018, 1023, 1033, 1041, 1049], "These": [11, 18, 25, 32, 38, 43, 44, 46, 64, 86, 125, 127, 144, 148, 189, 193, 209, 220, 221, 222, 248, 272, 285, 296, 299, 303, 317, 319, 326, 327, 332, 339, 341, 369, 373, 374, 379, 382, 383, 386, 388, 390, 393, 395, 398, 400, 404, 407, 410, 413, 414, 415, 416, 419, 421, 423, 424, 425, 426, 450, 454, 456, 506, 516, 517, 523, 546, 575, 576, 610, 611, 676, 684, 685, 707, 714, 741, 786, 802, 808, 811, 812, 814, 822, 831, 833, 834, 835, 836, 837, 839, 857, 858, 877, 989, 991, 994, 996, 997, 1000, 1001, 1011, 1013, 1015, 1019, 1025, 1029, 1034, 1041, 1047, 1049, 1050, 1051, 1054, 1058], "To": [1, 43, 47, 63, 64, 68, 81, 90, 92, 111, 113, 115, 118, 130, 139, 149, 152, 153, 162, 165, 174, 181, 182, 185, 187, 188, 191, 192, 197, 201, 204, 208, 220, 221, 222, 224, 228, 238, 251, 252, 254, 257, 259, 261, 268, 272, 273, 275, 276, 278, 280, 281, 283, 285, 292, 296, 298, 316, 319, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 358, 361, 364, 369, 373, 374, 379, 380, 384, 386, 387, 388, 390, 391, 392, 394, 398, 400, 401, 404, 410, 412, 413, 416, 417, 418, 419, 420, 421, 423, 424, 454, 456, 457, 458, 469, 472, 475, 500, 504, 510, 511, 515, 516, 517, 539, 545, 546, 547, 549, 551, 552, 553, 554, 565, 566, 567, 568, 572, 573, 577, 605, 619, 635, 640, 654, 655, 660, 661, 664, 666, 667, 668, 669, 670, 671, 692, 708, 720, 736, 771, 793, 801, 811, 812, 834, 841, 872, 883, 888, 902, 903, 912, 913, 917, 920, 921, 922, 923, 939, 949, 987, 989, 990, 992, 995, 996, 997, 998, 1000, 1001, 1002, 1003, 1006, 1007, 1010, 1014, 1015, 1016, 1024, 1025, 1029, 1031, 1032, 1034, 1041, 1044, 1046, 1047, 1048, 1050, 1052], "Will": [386, 505, 542, 635, 652, 653, 654, 660, 664, 665, 668, 669, 670, 671, 672, 673, 681, 683, 715, 722, 796, 877, 881, 891, 892, 1044, 1045, 1047, 1049, 1059], "Willing": [1047, 1048], "With": [61, 70, 79, 102, 109, 121, 130, 155, 157, 170, 189, 193, 220, 222, 246, 248, 253, 255, 261, 278, 303, 373, 381, 384, 386, 388, 400, 407, 416, 417, 420, 423, 425, 445, 447, 509, 549, 590, 640, 641, 666, 870, 873, 875, 886, 892, 893, 919, 921, 993, 996, 997, 1000, 1001, 1003, 1004, 1007, 1014, 1016, 1021, 1025, 1026, 1033, 1038, 1044, 1048, 1049, 1051, 1053, 1055], "_": [43, 44, 46, 47, 48, 50, 51, 52, 54, 58, 62, 63, 64, 66, 68, 69, 75, 78, 85, 88, 90, 93, 98, 102, 104, 115, 121, 123, 125, 130, 132, 134, 142, 143, 144, 155, 169, 176, 181, 182, 183, 191, 192, 193, 195, 197, 199, 203, 204, 205, 207, 208, 209, 212, 217, 218, 220, 222, 224, 233, 234, 237, 241, 244, 248, 253, 257, 261, 272, 273, 278, 280, 281, 282, 284, 285, 287, 292, 296, 302, 307, 310, 317, 321, 324, 325, 326, 329, 332, 333, 334, 336, 339, 340, 348, 353, 356, 360, 362, 365, 388, 392, 400, 421, 423, 424, 428, 454, 486, 540, 541, 542, 543, 544, 546, 547, 548, 551, 553, 554, 555, 574, 605, 654, 655, 660, 661, 668, 669, 670, 671, 689, 690, 691, 692, 696, 697, 698, 699, 701, 703, 704, 706, 708, 718, 772, 808, 814, 822, 831, 856, 864, 885, 886, 893, 990, 996, 997, 1000, 1002, 1003, 1004, 1007, 1008, 1010, 1015, 1016, 1032, 1033, 1048], "_0": [219, 693, 996, 1000, 1015], "_1": [331, 353, 418, 421, 424, 539, 545, 546, 548, 553, 554, 555, 654, 655, 660, 661, 662, 663, 664, 668, 669, 670, 671, 689, 690, 691, 692, 774, 996, 998, 1000, 1015], "_11": 660, "_2": [114, 181, 353, 421, 424, 539, 545, 553, 554, 654, 660, 996, 1004, 1014, 1015], "_21": [654, 655, 660, 661, 668, 669, 670, 671, 689, 692], "__": [107, 279, 400, 417, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 989, 1030, 1049, 1050], "______________________________________________________________________": 339, "________________________________________________________________________________": [50, 89, 360], "__________________________________________________________________________________": 93, "________________________________________________________ward_tre": 89, "_____________________________________________________f_regress": 89, "__add__": [426, 632], "__array__": [1044, 1051], "__array_function__": [1020, 1051], "__c": 388, "__call__": [184, 349, 400, 424, 426, 474, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 939, 966, 1048], "__class__": [187, 220, 222, 254, 257, 280, 321, 360, 361, 362, 393], "__class_weight": 388, "__dataframe__": [569, 570], "__doc__": [78, 109, 181, 266, 400], "__file__": [47, 49, 1054], "__getattr__": 388, "__getitem__": 1059, "__getstate__": [1048, 1056], "__init__": [47, 91, 137, 184, 254, 299, 349, 386, 388, 390, 391, 392, 393, 400, 424, 430, 433, 436, 439, 440, 626, 961, 1042, 1047, 1049, 1054, 1055, 1056, 1057], "__init_subclass__": 388, "__len__": 1050, "__main__": [342, 398], "__metadata_request__fit": 254, "__mul__": 629, "__mul___": 426, "__name__": [46, 62, 96, 187, 220, 222, 254, 257, 261, 273, 280, 321, 342, 360, 361, 362, 393, 398, 885], "__pow__": [426, 624], "__repr__": [388, 1020, 1050], "__sklearn_clone__": [388, 441, 1057], "__sklearn_is_fitted__": [47, 91, 136, 184, 189, 254, 299, 388, 430, 433, 984, 1021, 1054, 1055], "__version__": 390, "_agglom": 89, "_array_api": 412, "_bag": 941, "_base": [264, 388], "_basehmm": 1041, "_bay": 941, "_birch": 1051, "_breast_cancer_dataset": 174, "_build": 386, "_c_step": 1048, "_cfnode": 450, "_check_bounds_param": 1053, "_check_param_grid": 1047, "_check_sample_weight": 1054, "_check_stop_list": 599, "_check_target": 1048, "_check_x": 1051, "_class": 1000, "_class_cov": 1049, "_class_mean": 1049, "_classif": 317, "_classifier_ha": 91, "_column_transform": [105, 160], "_compon": [251, 544], "_coo": [593, 594], "_count_nonzero_coeffici": 46, "_criterion": 1049, "_csr": 885, "_cython_bla": 387, "_devianc": 1000, "_diabetes_dataset": 174, "_distn_infrastructur": 290, "_doc_link_modul": 388, "_doc_link_templ": 388, "_doc_link_url_param_gener": 388, "_dotbla": 392, "_encod": 1049, "_error": 1000, "_estimator_html_repr": 945, "_estimator_typ": [388, 400, 433, 434, 435, 438, 439, 1046], "_estimator_with_converted_arrai": 412, "_f": [184, 996], "_featur": [421, 546, 548, 555], "_fit_and_scor": 1049, "_fit_stag": [567, 568], "_fro": [539, 545, 553, 554, 654, 655, 660, 668, 669, 670, 689], "_g": 184, "_gb": 1051, "_generate_center_coordin": 53, "_get_support_mask": 609, "_get_tag": [388, 1052], "_get_warnings_filters_info_list": 374, "_gpr": 185, "_h": [546, 548, 555], "_hist_gradient_boost": 390, "_i": [414, 423, 991, 996, 1000, 1004, 1015], "_idx": 400, "_init": 200, "_init_t": 1014, "_initialize_nmf": 392, "_is_fit": 137, "_iter": 390, "_j": [414, 991], "_k": [418, 994, 996], "_l": 1000, "_learntselectormixin": 1046, "_level": [426, 633], "_lfw": 1030, "_logist": 386, "_loss": [400, 1000], "_m": 1016, "_mean": 325, "_mean_frequency_by_risk_group": 220, "_method": 960, "_more_tag": 388, "_my": 386, "_n": [424, 1000], "_n_cluster": 386, "_n_compon": 555, "_n_features_out": 432, "_name_estim": 1051, "_neg": 392, "_newton_cg": 1052, "_nls_subproblem": 392, "_nmf": 392, "_not_in_sphinx": [47, 49], "_num_thread": 374, "_obj": 960, "_openmp_help": 387, "_pairwis": [1051, 1053], "_pairwise_cal": 636, "_plain_sgd": 1056, "_plot": 338, "_po": 392, "_posterior_mod": 618, "_preprocess_data": 695, "_pvalu": 1041, "_rand": 369, "_ratio": [546, 548, 555], "_request": [254, 407, 1059], "_required_paramet": [388, 436], "_reset": 47, "_run_search": 1049, "_safe_index": [2, 1054, 1058, 1059], "_safe_split": 388, "_safe_tag": 1052, "_sag": 1050, "_sampl": [251, 421, 546, 548, 555], "_samples_gener": 266, "_score": [400, 808, 822, 835, 1000, 1041, 1054], "_search": 1047, "_serial": 254, "_sgd_fast": 1056, "_skip_test": 388, "_spars": 392, "_sparse_fit": 1051, "_std": 325, "_t": 1014, "_test": [228, 321, 374, 388, 1054], "_test_scor": [278, 480, 602, 1054], "_transform_select": 1047, "_tree": [920, 921, 922, 923, 1042, 1044], "_typedef": 387, "_univariate_select": 89, "_valu": [426, 621], "_w": [546, 548, 555], "_weight": [53, 238], "_weight_boost": 941, "_weighted_percentil": 1054, "_x_is_even": 961, "_xfail_check": 388, "a16": [1051, 1052], "a65628": [79, 97], "a674e682c281": 391, "a_": [126, 413, 416, 546, 548, 555, 996, 1033], "a_column": 727, "a_i": 416, "a_mask": 287, "a_n": 413, "a_row": 727, "a_tru": 287, "aaa": 184, "aaaaff": [304, 307], "aaai": [416, 427, 452, 847, 1002], "aact": 184, "aaffaa": 307, "aagaard": 1045, "aakanksha": 1049, "aapl": 51, "aarch64": 394, "aaron": [502, 996, 1044, 1045, 1046, 1051], "aarshai": [1048, 1049], "aashil": 1048, "ab": [51, 55, 75, 109, 129, 135, 141, 149, 160, 170, 174, 195, 207, 211, 231, 233, 236, 238, 243, 278, 319, 336, 347, 358, 416, 546, 548, 555, 635, 754, 852, 853, 887, 1000], "ab_mask": 287, "abadi": [1047, 1048], "abandon": 386, "abati": [1056, 1058, 1059, 1060], "abbi": [1051, 1052], "abbrevi": 707, "abdela": 1050, "abdulaziz": 1059, "abdulelah": 1054, "abdur": 1051, "abenbihi": 1051, "abhijeet": 1043, "abhinav": [1051, 1054], "abhishek": [1044, 1045, 1051, 1055, 1057, 1058], "abhyudai": 1048, "abi": 390, "abid": 386, "abil": [48, 52, 96, 113, 152, 175, 176, 177, 181, 183, 185, 187, 189, 191, 192, 194, 220, 224, 238, 247, 360, 375, 404, 423, 424, 426, 619, 630, 633, 790, 791, 792, 795, 796, 997, 1000, 1003, 1006, 1016, 1020, 1021, 1041, 1043, 1048, 1050, 1054, 1055], "abirami": 416, "abl": [43, 44, 48, 61, 82, 90, 96, 115, 118, 129, 130, 155, 157, 182, 192, 195, 204, 209, 220, 236, 238, 244, 284, 289, 335, 336, 349, 369, 373, 374, 375, 380, 384, 386, 388, 390, 391, 398, 410, 416, 418, 420, 424, 493, 511, 542, 837, 884, 989, 990, 996, 999, 1000, 1001, 1006, 1010, 1013, 1016, 1017, 1020, 1025, 1033, 1034, 1047, 1048, 1052, 1059], "ablin": 1056, "abnorm": [234, 247, 305, 348, 381, 500, 571, 858, 1006, 1049], "abnormal_termination_in_lnsrch": 185, "abo7atm": 1053, "abort": 700, "about": [3, 46, 50, 65, 79, 88, 92, 97, 104, 118, 120, 148, 171, 185, 189, 191, 195, 224, 237, 247, 254, 272, 275, 276, 278, 280, 285, 298, 304, 324, 328, 330, 331, 332, 333, 334, 339, 360, 362, 368, 369, 373, 374, 379, 381, 385, 386, 390, 391, 392, 394, 399, 400, 401, 410, 415, 420, 421, 424, 426, 446, 500, 502, 503, 504, 505, 508, 509, 510, 512, 513, 518, 523, 569, 570, 601, 602, 615, 616, 622, 648, 684, 686, 751, 808, 814, 822, 831, 841, 891, 933, 990, 996, 997, 999, 1001, 1003, 1006, 1007, 1010, 1011, 1013, 1015, 1016, 1019, 1023, 1024, 1025, 1026, 1032, 1034, 1046, 1047, 1057, 1059], "abov": [43, 62, 63, 64, 72, 79, 101, 104, 141, 144, 145, 152, 155, 163, 173, 174, 192, 193, 206, 220, 222, 226, 231, 251, 254, 255, 272, 278, 284, 296, 304, 321, 324, 325, 329, 331, 335, 353, 361, 362, 368, 369, 373, 374, 375, 380, 381, 383, 384, 385, 386, 388, 390, 392, 398, 400, 401, 414, 416, 417, 418, 420, 421, 422, 423, 424, 426, 449, 453, 472, 475, 497, 503, 504, 505, 531, 598, 642, 712, 763, 808, 812, 820, 822, 833, 875, 876, 889, 895, 901, 909, 963, 989, 990, 992, 994, 996, 997, 1000, 1003, 1005, 1007, 1010, 1014, 1015, 1016, 1020, 1025, 1026, 1032, 1033, 1034, 1047, 1059], "abraham": [1041, 1042, 1047, 1051], "abrahamowicz": 1010, "absenc": [247, 281, 400, 720, 875, 999, 1000], "absent": [400, 424, 737, 762, 833], "absgrad": 1052, "absher": 1043, "absolut": [2, 43, 52, 109, 129, 149, 174, 192, 220, 222, 226, 238, 336, 388, 410, 416, 418, 420, 421, 423, 424, 425, 426, 427, 452, 458, 464, 465, 539, 545, 550, 553, 554, 556, 557, 558, 566, 568, 569, 570, 573, 596, 598, 599, 601, 605, 610, 627, 635, 640, 654, 657, 658, 660, 662, 664, 679, 680, 682, 684, 686, 690, 691, 712, 725, 729, 744, 745, 753, 754, 756, 761, 763, 765, 803, 810, 814, 825, 828, 836, 838, 850, 852, 853, 857, 876, 881, 884, 897, 921, 923, 986, 996, 997, 1010, 1014, 1016, 1032, 1033, 1042, 1047, 1052, 1053, 1054, 1055, 1058], "absolute_error": [52, 423, 566, 568, 570, 573, 679, 921, 923, 1054], "absolute_loss": 1054, "absolutelynowarranti": 1049, "absp": 868, "abstain": 542, "abstract": [400, 421, 426, 626, 777, 1019, 1041], "abstractmethod": 1051, "absurd": 1007, "abund": 381, "ac": [257, 538, 672, 693, 694, 996, 1013, 1034], "acad": [697, 701, 997], "academ": [420, 1024], "academi": [113, 859], "acategorypredict": 1027, "acc": 151, "acc_clf1": 69, "acc_clf2": 69, "acc_clf3": 69, "acc_histori": 47, "acc_knn": 308, "acceler": [252, 333, 373, 398, 412, 416, 476, 700, 910, 997, 1019, 1024, 1050, 1054, 1056, 1058], "accent": [357, 596, 597, 599, 1051], "accept": [174, 176, 254, 272, 275, 328, 336, 349, 360, 362, 369, 373, 374, 380, 386, 388, 395, 398, 399, 400, 401, 407, 412, 416, 424, 445, 449, 452, 453, 456, 469, 472, 475, 516, 517, 563, 564, 569, 570, 577, 578, 589, 590, 601, 602, 605, 636, 643, 647, 651, 654, 655, 660, 661, 687, 735, 750, 786, 805, 806, 807, 811, 812, 830, 854, 855, 862, 863, 872, 876, 930, 932, 933, 936, 996, 998, 1000, 1003, 1008, 1010, 1015, 1019, 1020, 1029, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "accept_large_spars": [932, 933, 1049], "accept_spars": [876, 932, 933, 1048, 1058], "access": [43, 84, 111, 150, 257, 264, 269, 335, 336, 360, 368, 373, 374, 386, 387, 388, 394, 398, 400, 401, 412, 416, 418, 419, 423, 424, 426, 458, 465, 472, 475, 544, 575, 576, 577, 578, 625, 870, 871, 872, 927, 989, 996, 999, 1000, 1006, 1007, 1008, 1014, 1015, 1020, 1024, 1025, 1033, 1034, 1041, 1043, 1047, 1048, 1049, 1050, 1053, 1055, 1056, 1057], "accid": [220, 238], "accident": [1041, 1045, 1050], "accommod": [181, 1049], "accompani": [278, 1049], "accomplish": [254, 388, 414, 554, 997, 1001, 1003, 1024, 1058], "accord": [2, 55, 61, 63, 72, 84, 111, 145, 151, 174, 177, 203, 220, 238, 251, 328, 353, 361, 369, 386, 388, 398, 399, 400, 401, 410, 413, 414, 416, 418, 420, 421, 423, 424, 426, 445, 458, 460, 464, 468, 470, 473, 477, 512, 524, 525, 526, 533, 538, 540, 543, 544, 546, 548, 558, 561, 562, 569, 570, 571, 574, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 649, 650, 652, 653, 657, 666, 667, 678, 688, 699, 703, 743, 787, 788, 808, 809, 810, 811, 812, 815, 816, 817, 822, 833, 847, 848, 849, 850, 851, 856, 858, 859, 860, 861, 862, 863, 864, 865, 866, 875, 882, 890, 902, 904, 905, 912, 913, 914, 915, 917, 918, 994, 996, 1000, 1002, 1003, 1010, 1013, 1014, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "accordingli": [155, 193, 257, 353, 386, 390, 391, 1048, 1049, 1056], "account": [52, 53, 90, 127, 133, 139, 155, 181, 187, 192, 238, 254, 272, 278, 302, 308, 356, 358, 361, 373, 382, 386, 400, 401, 407, 416, 419, 420, 421, 423, 424, 471, 569, 570, 575, 576, 635, 636, 638, 640, 641, 657, 681, 687, 712, 715, 736, 737, 738, 746, 751, 764, 791, 792, 795, 796, 809, 813, 826, 886, 992, 994, 998, 1000, 1001, 1002, 1003, 1010, 1014, 1016, 1046, 1048, 1049, 1050, 1053, 1054, 1056, 1058, 1059], "acctactagaagtt": 398, "acctcctagaag": 398, "accumul": [47, 85, 146, 147, 209, 390, 392, 416, 424, 1000, 1042, 1049], "accur": [43, 48, 52, 59, 62, 63, 113, 125, 154, 176, 183, 192, 193, 224, 235, 238, 272, 278, 285, 289, 296, 332, 360, 361, 369, 385, 400, 414, 416, 418, 421, 423, 424, 425, 445, 451, 455, 459, 461, 467, 539, 546, 548, 550, 551, 553, 554, 555, 615, 616, 642, 811, 812, 852, 853, 948, 949, 992, 997, 1000, 1016, 1055], "accuraci": [2, 30, 37, 43, 45, 46, 47, 62, 66, 67, 68, 69, 104, 105, 106, 107, 139, 145, 146, 150, 151, 158, 170, 171, 173, 177, 195, 197, 220, 224, 228, 235, 236, 265, 276, 277, 278, 279, 280, 282, 284, 292, 294, 296, 301, 307, 308, 309, 317, 321, 324, 334, 338, 339, 341, 349, 352, 353, 356, 369, 373, 388, 399, 400, 415, 416, 420, 423, 424, 425, 433, 445, 457, 477, 479, 480, 486, 540, 542, 549, 557, 558, 559, 561, 563, 565, 566, 567, 569, 572, 573, 575, 577, 618, 642, 666, 667, 674, 676, 679, 682, 683, 684, 700, 705, 711, 716, 719, 721, 726, 740, 741, 742, 746, 751, 762, 771, 795, 802, 804, 807, 830, 836, 839, 840, 841, 842, 843, 844, 847, 848, 849, 850, 851, 854, 859, 861, 862, 869, 907, 908, 912, 914, 917, 920, 922, 948, 949, 989, 994, 995, 996, 997, 1001, 1003, 1004, 1008, 1012, 1014, 1016, 1029, 1034, 1049, 1050, 1059], "accuracy_histori": 47, "accuracy_scor": [2, 66, 139, 177, 282, 324, 341, 360, 369, 399, 407, 412, 433, 565, 572, 716, 719, 737, 738, 742, 746, 791, 792, 795, 802, 804, 942, 989, 1000, 1042, 1043, 1044, 1053, 1058], "acf": 149, "achar": [1048, 1049, 1050, 1051], "achiev": [43, 51, 55, 57, 64, 67, 128, 139, 148, 150, 155, 158, 184, 197, 220, 228, 275, 278, 285, 324, 336, 341, 349, 352, 353, 356, 360, 369, 373, 375, 380, 381, 383, 388, 392, 398, 400, 413, 414, 415, 416, 420, 421, 423, 424, 561, 566, 573, 648, 657, 684, 686, 715, 737, 738, 746, 748, 771, 791, 792, 795, 811, 812, 848, 892, 989, 990, 992, 996, 1000, 1010, 1013, 1015, 1027, 1034, 1054], "achin": 1024, "achliopta": [251, 905, 906, 1012], "acid": [324, 383], "acknowledg": [385, 617, 1058], "acl": [909, 1013, 1014], "acm": [380, 381, 416, 427, 452, 458, 465, 468, 519, 571, 684, 734, 764, 858, 1000, 1003, 1006, 1012], "acoust": 1000, "acq": 47, "acquaint": 386, "acquir": [53, 147, 280, 1053], "acquisit": [413, 727], "acronym": 390, "across": [0, 2, 15, 43, 52, 90, 96, 102, 117, 121, 145, 165, 192, 209, 214, 241, 273, 275, 278, 292, 299, 319, 324, 353, 387, 388, 395, 400, 410, 416, 420, 423, 424, 425, 428, 445, 448, 458, 460, 462, 465, 468, 470, 477, 480, 482, 496, 499, 500, 503, 505, 511, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 559, 561, 562, 563, 564, 565, 567, 568, 569, 570, 571, 572, 575, 576, 596, 599, 602, 610, 615, 616, 618, 619, 640, 641, 642, 647, 648, 649, 650, 654, 655, 658, 660, 661, 662, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 679, 684, 686, 687, 693, 694, 697, 698, 699, 700, 701, 702, 703, 712, 713, 725, 739, 765, 796, 801, 803, 805, 806, 808, 809, 810, 811, 812, 813, 814, 820, 822, 823, 824, 825, 826, 827, 828, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 857, 861, 868, 869, 870, 877, 881, 882, 889, 890, 892, 893, 901, 904, 905, 907, 908, 912, 913, 914, 917, 920, 921, 948, 949, 971, 974, 989, 996, 998, 1000, 1010, 1014, 1016, 1020, 1024, 1034, 1041, 1044, 1047, 1048, 1049, 1050, 1051, 1059], "act": [349, 360, 386, 399, 422, 423, 721, 737, 738, 746, 791, 792, 795, 887, 891, 997, 1000, 1003, 1015, 1049], "action": [331, 360, 385, 389, 390, 404, 415, 1010, 1051], "activ": [0, 68, 189, 228, 263, 269, 279, 337, 338, 362, 380, 381, 384, 386, 387, 392, 394, 398, 400, 401, 404, 407, 417, 504, 510, 534, 640, 643, 645, 658, 659, 661, 662, 663, 671, 672, 673, 690, 691, 692, 693, 694, 721, 726, 805, 868, 869, 870, 908, 966, 996, 997, 998, 999, 1003, 1004, 1005, 1013, 1021, 1023, 1052], "active_": [658, 659, 662, 663], "active_features_": 1049, "actual": [43, 52, 64, 81, 95, 109, 118, 145, 155, 174, 192, 197, 209, 220, 224, 228, 265, 274, 281, 362, 369, 373, 375, 383, 386, 388, 391, 392, 398, 399, 400, 414, 416, 421, 423, 424, 425, 441, 517, 523, 524, 535, 543, 546, 548, 555, 570, 571, 652, 653, 656, 666, 667, 674, 675, 676, 677, 678, 680, 682, 684, 685, 686, 688, 695, 699, 703, 709, 712, 717, 723, 729, 730, 731, 732, 793, 805, 811, 812, 827, 828, 858, 889, 912, 918, 940, 941, 942, 975, 992, 999, 1000, 1003, 1007, 1008, 1023, 1048, 1049, 1055, 1056, 1057], "actual_vs_predict": [43, 109, 160, 192, 274, 333, 709], "actuari": 414, "ad": [43, 53, 58, 109, 132, 134, 139, 145, 155, 170, 176, 182, 183, 199, 204, 222, 224, 244, 253, 254, 278, 279, 280, 319, 329, 330, 331, 332, 333, 334, 335, 336, 342, 353, 361, 385, 386, 388, 390, 392, 398, 400, 401, 421, 423, 424, 425, 426, 427, 428, 434, 438, 440, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 467, 468, 469, 470, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512, 513, 518, 520, 522, 530, 531, 535, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 582, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 696, 697, 698, 699, 700, 702, 703, 704, 705, 706, 708, 709, 710, 712, 716, 719, 721, 722, 726, 729, 730, 731, 732, 733, 735, 736, 737, 738, 739, 742, 747, 748, 749, 750, 751, 754, 761, 762, 765, 769, 774, 775, 777, 783, 785, 786, 790, 791, 792, 793, 795, 797, 798, 799, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 817, 821, 822, 826, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 867, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 898, 901, 902, 904, 905, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 930, 932, 933, 939, 943, 944, 948, 949, 956, 957, 958, 959, 960, 963, 966, 970, 975, 981, 987, 989, 993, 995, 996, 997, 1001, 1003, 1004, 1006, 1020, 1024, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "adaboost": [2, 67, 122, 138, 142, 148, 156, 159, 160, 163, 179, 189, 366, 367, 527, 559, 561, 562, 567, 639, 711, 838, 920, 921, 1021, 1022, 1036, 1043], "adaboost_clf": 139, "adaboostclassifi": [2, 67, 141, 148, 407, 423, 562, 567, 569, 941, 1043, 1044, 1047, 1048, 1050, 1051, 1054, 1056, 1057, 1058], "adaboostregressor": [2, 140, 407, 423, 561, 570, 941, 1043, 1044, 1047, 1050, 1051, 1054, 1056, 1057], "adagrad": 1019, "adam": [298, 315, 869, 870, 1004, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "adamgonzo": 1055, "adamson": 1053, "adanhawth": [1049, 1050], "adapt": [88, 90, 139, 151, 152, 179, 263, 264, 272, 321, 353, 374, 384, 385, 386, 395, 416, 423, 426, 523, 524, 525, 526, 684, 685, 686, 869, 870, 996, 1002, 1004, 1010, 1014, 1019, 1020, 1049, 1050, 1057, 1058], "adarsh": [1058, 1059], "add": [44, 51, 52, 55, 58, 62, 63, 64, 68, 69, 75, 79, 89, 109, 113, 114, 118, 126, 148, 151, 170, 172, 174, 176, 181, 182, 183, 187, 188, 202, 209, 215, 221, 223, 224, 235, 243, 247, 251, 253, 254, 285, 287, 288, 299, 311, 321, 323, 328, 330, 331, 352, 353, 355, 356, 361, 373, 384, 385, 386, 387, 388, 390, 392, 394, 400, 404, 412, 414, 420, 423, 424, 425, 523, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 610, 635, 636, 638, 640, 666, 667, 702, 705, 829, 852, 853, 909, 939, 957, 958, 989, 990, 999, 1006, 1010, 1013, 1014, 1020, 1033, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "add_2d_scatt": 240, "add_artist": [70, 241, 263, 264, 265, 268, 269], "add_ax": [193, 244, 289], "add_categori": 257, "add_collect": [51, 243, 250], "add_dummy_featur": 2, "add_ind": [160, 188, 635, 636, 638, 990, 1050, 1053, 1057], "add_missing_valu": 188, "add_nois": 182, "add_self_request": [254, 957], "add_subplot": [46, 62, 64, 77, 80, 99, 102, 121, 131, 193, 217, 235, 242, 244, 338, 339, 393, 1033], "add_trac": 145, "adddatapointbatch": 299, "addep": 1052, "addison": [598, 738], "addit": [2, 7, 37, 43, 44, 46, 51, 53, 54, 101, 105, 115, 121, 125, 128, 139, 143, 145, 146, 149, 150, 173, 181, 182, 183, 188, 192, 193, 199, 204, 209, 221, 222, 224, 244, 258, 272, 280, 287, 293, 298, 319, 329, 330, 335, 340, 353, 362, 366, 369, 373, 374, 378, 379, 380, 381, 382, 384, 385, 386, 388, 391, 392, 394, 398, 399, 400, 401, 404, 410, 415, 416, 418, 420, 421, 424, 425, 426, 427, 440, 449, 450, 452, 453, 454, 458, 465, 477, 482, 504, 511, 540, 542, 544, 545, 547, 549, 550, 551, 557, 561, 562, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 590, 591, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 619, 620, 627, 636, 638, 639, 643, 646, 647, 648, 649, 650, 651, 652, 653, 678, 695, 696, 700, 706, 707, 710, 750, 766, 767, 796, 800, 805, 806, 814, 831, 841, 843, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 860, 861, 862, 863, 864, 865, 866, 868, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 889, 890, 891, 892, 894, 904, 905, 912, 913, 943, 949, 989, 994, 996, 1000, 1001, 1003, 1004, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1019, 1025, 1036, 1041, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1059, 1060], "addition": [88, 106, 141, 155, 192, 220, 238, 254, 329, 331, 361, 386, 398, 414, 424, 618, 619, 654, 660, 679, 889, 989, 990, 1000, 1008, 1019, 1047, 1058], "additional_nois": 75, "additive_chi2": [628, 646, 773, 782], "additive_chi2_kernel": [2, 646, 767, 773, 992], "additivechi2sampl": [2, 647, 648, 649, 650, 766, 767, 992, 1055, 1057], "address": [43, 83, 224, 254, 360, 381, 386, 415, 416, 424, 455, 665, 996, 997, 1002, 1003, 1004, 1005, 1006, 1010, 1024, 1032, 1049], "adelr": 1049, "adequ": [374, 392, 575, 1025, 1054], "adher": [2, 373, 388, 400, 943, 944, 1041, 1042], "adien": 1057, "adijohar": 1055, "adil": 1056, "adimension": 192, "adithya": 1046, "aditya": [1047, 1049, 1050, 1051, 1055, 1056], "adityadaflapurkar": 1049, "adjac": [416, 421, 460, 470, 593, 594, 643, 699, 703, 954, 997, 1003, 1033], "adjacency_matrix": 416, "adjust": [2, 43, 48, 55, 71, 73, 84, 93, 111, 139, 152, 169, 189, 224, 247, 252, 260, 279, 296, 328, 342, 356, 361, 393, 416, 417, 421, 423, 424, 532, 561, 562, 565, 567, 569, 570, 572, 666, 667, 674, 676, 682, 683, 684, 712, 713, 716, 722, 723, 763, 765, 794, 803, 847, 848, 850, 851, 882, 904, 905, 912, 913, 914, 917, 920, 922, 938, 999, 1000, 1004, 1010, 1021, 1032, 1038, 1041, 1047, 1057], "adjusted_mutual_info_scor": [2, 72, 73, 84, 93, 416, 713, 723, 741, 763, 765, 794, 1000, 1041, 1049, 1053, 1057], "adjusted_rand_index": 713, "adjusted_rand_scor": [2, 72, 73, 84, 93, 361, 416, 712, 723, 741, 765, 794, 1000, 1054], "administr": 404, "admir": [1056, 1057], "admiss": [251, 374], "adopt": [388, 398, 400, 908, 1000, 1014, 1049, 1056, 1058], "adoublet": [1056, 1057], "adpot": 334, "adrian": [1054, 1055, 1056], "adrien": 1041, "adrin": [0, 100, 357, 401, 405, 410, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "adrinjalali": [1044, 1053], "adult": [335, 504, 1010], "advanc": [44, 157, 189, 193, 246, 248, 278, 298, 375, 416, 421, 497, 509, 543, 640, 647, 791, 805, 861, 870, 873, 892, 921, 992, 1000, 1003, 1010, 1021, 1024, 1038, 1043], "advani": 1053, "advantag": [43, 44, 74, 90, 92, 125, 130, 153, 220, 221, 247, 264, 279, 298, 332, 336, 369, 400, 414, 420, 421, 424, 426, 449, 453, 468, 542, 597, 657, 682, 683, 771, 840, 841, 842, 872, 873, 912, 913, 914, 915, 916, 917, 918, 989, 992, 995, 996, 997, 1000, 1001, 1003, 1004, 1008, 1010, 1014, 1015, 1016, 1044], "advic": [394, 426, 630, 631], "advik": [1058, 1059], "advis": [52, 221, 254, 369, 384, 386, 416, 424, 445, 654, 660, 662, 668, 670, 680, 695, 992, 996, 1002, 1004, 1015, 1055], "advoc": 1001, "aeberhard": 383, "aesthet": [319, 1016, 1046], "af": 73, "affan": 1047, "affanv14": 1048, "affect": [46, 62, 113, 155, 183, 191, 192, 224, 244, 257, 258, 281, 288, 324, 334, 369, 373, 374, 375, 382, 400, 403, 414, 416, 419, 420, 422, 424, 427, 429, 452, 458, 465, 481, 483, 487, 557, 558, 577, 707, 720, 796, 808, 811, 812, 813, 822, 826, 827, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 892, 893, 903, 917, 999, 1003, 1015, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1059], "affili": 381, "affin": [2, 27, 71, 72, 79, 84, 98, 99, 189, 319, 340, 378, 388, 400, 421, 448, 449, 460, 462, 470, 520, 543, 699, 703, 712, 713, 725, 745, 801, 803, 908, 994, 997, 1000, 1021, 1035, 1036, 1041, 1042, 1045, 1051, 1052, 1054, 1056], "affinity_matrix": [699, 703], "affinity_matrix_": [448, 460, 699], "affinity_propag": [2, 51, 79], "affinitypropag": [2, 73, 79, 332, 416, 1041, 1044, 1045, 1049, 1052, 1054, 1055, 1056, 1057, 1058], "affirm": 43, "afnlp": 1014, "afor": [904, 905], "aforement": [374, 1001], "afraid": 404, "africa": 1010, "afroj": 1058, "aft": [325, 1044], "aftab": 1050, "after": [43, 55, 58, 59, 63, 81, 88, 90, 104, 105, 109, 114, 127, 139, 150, 155, 158, 160, 163, 170, 174, 181, 183, 185, 187, 192, 197, 213, 220, 257, 258, 261, 266, 278, 287, 298, 299, 307, 309, 319, 320, 323, 324, 360, 361, 375, 381, 383, 385, 386, 388, 390, 392, 393, 394, 398, 400, 410, 412, 413, 414, 416, 417, 420, 421, 424, 425, 428, 450, 455, 458, 459, 460, 461, 464, 470, 523, 540, 544, 561, 562, 567, 568, 569, 570, 605, 635, 638, 666, 667, 674, 675, 676, 681, 683, 684, 685, 686, 700, 720, 734, 764, 802, 805, 806, 811, 812, 861, 868, 872, 885, 891, 912, 917, 918, 989, 990, 994, 996, 1000, 1004, 1005, 1010, 1012, 1014, 1015, 1016, 1020, 1025, 1032, 1034, 1041, 1044, 1048, 1049, 1052, 1053, 1056, 1059], "afterward": [58, 390, 543, 549, 836], "ag": [105, 174, 192, 194, 208, 209, 220, 238, 258, 259, 261, 272, 319, 331, 332, 333, 335, 381, 383, 504, 1024, 1025, 1032], "again": [43, 58, 102, 106, 152, 180, 182, 184, 192, 244, 279, 360, 369, 390, 395, 400, 401, 416, 417, 418, 423, 424, 480, 575, 576, 642, 655, 659, 661, 663, 669, 671, 673, 700, 989, 996, 1000, 1014, 1038, 1041, 1049, 1058], "against": [64, 72, 118, 134, 142, 153, 169, 197, 211, 212, 229, 237, 254, 287, 325, 328, 349, 381, 386, 401, 410, 414, 416, 420, 424, 446, 517, 550, 556, 559, 684, 686, 763, 765, 796, 810, 815, 817, 837, 841, 966, 992, 996, 1000, 1001, 1003, 1015, 1018, 1025], "agamemnon": [1048, 1049, 1050, 1051, 1053, 1054], "agarw": [1048, 1049, 1051], "agath": 1055, "agc": 184, "agct": 184, "agent": 1024, "agg": 181, "aggfunc": 289, "agglo": [86, 453, 1033], "agglom": [2, 51, 58, 71, 72, 77, 79, 82, 95, 97, 101, 102, 120, 189, 241, 243, 338, 339, 416, 449, 453, 510, 699, 786, 865, 1021, 1044], "agglomer": [2, 44, 68, 71, 82, 85, 120, 170, 172, 189, 202, 219, 256, 291, 378, 416, 424, 453, 510, 608, 614, 653, 808, 813, 872, 1021, 1036], "agglomerativeclust": [2, 74, 75, 76, 79, 82, 87, 91, 97, 102, 400, 416, 448, 450, 453, 1033, 1044, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1056, 1058], "aggreg": [95, 143, 238, 281, 287, 292, 332, 334, 416, 423, 425, 542, 563, 564, 602, 729, 731, 736, 753, 754, 756, 758, 759, 761, 793, 798, 799, 1001, 1003, 1010, 1057], "aggress": [2, 47, 227, 674, 675, 811, 812, 1022, 1036, 1042], "aggressive_elimin": [811, 812, 989], "agnost": [999, 1008], "ago": [51, 1020], "agraw": [1044, 1049, 1055, 1056], "agre": [25, 169, 394, 401, 416, 794, 1025], "agreement": [0, 2, 416, 712, 724, 763, 765, 803, 1000], "agricultur": 996, "aguiar": 425, "agundez": 1049, "ahead": 896, "ahmadi": 1052, "ahmadjubair33": 1055, "ahmedbgh": [1056, 1057], "ahn": 1053, "ahuja": [1048, 1055, 1056], "ai": [108, 143, 211, 252, 340, 356, 420], "ai8rahim": 1044, "aic": [2, 165, 189, 198, 204, 206, 208, 214, 228, 268, 509, 659, 661, 662, 663, 664, 806, 873, 892, 989, 1021, 1041, 1048, 1054, 1055], "aic_criterion": 208, "aid": [275, 416, 800, 801, 997, 1024, 1041, 1053], "aidan": 1049, "aidar": 1055, "aig": 51, "aiko": 1056, "aim": [52, 58, 114, 155, 188, 224, 272, 307, 340, 353, 375, 381, 384, 386, 400, 410, 416, 418, 424, 456, 996, 1000, 1003, 1010, 1015, 1019, 1025, 1033, 1055], "air": [181, 772], "airport": 772, "airspe": 386, "aishgrt1": 1049, "aishwarya": 1049, "aishwaryark": 1048, "aistat": 1013, "aivision2020": 1048, "aj": [502, 1055], "ak": [414, 1055, 1056], "aka": [2, 45, 314, 360, 398, 424, 460, 544, 546, 548, 552, 555, 589, 590, 623, 630, 659, 660, 662, 663, 664, 666, 667, 670, 674, 675, 676, 678, 684, 685, 686, 749, 879, 883, 885, 996, 1004, 1014, 1025, 1030, 1043, 1055], "akai": 1054, "akaik": [208, 209, 268, 664, 806, 989, 996], "akash": [1049, 1059], "aki": [1055, 1056, 1057], "akihiro": 1059, "akin": [43, 221, 400], "akinkunl": 1051, "akitti": 1046, "akshai": [1045, 1048, 1053], "akshay0724": 1048, "akshayah3": 1045, "akshita": 1056, "al": [0, 2, 50, 111, 112, 139, 154, 208, 312, 381, 383, 413, 416, 418, 421, 423, 424, 425, 459, 506, 527, 528, 536, 543, 549, 552, 571, 690, 691, 727, 728, 847, 849, 869, 870, 905, 948, 949, 996, 997, 1000, 1006, 1010, 1012, 1015, 1016, 1049, 1054, 1057, 1058], "ala": [1056, 1057], "aladago": 1051, "alam": [1056, 1057], "alan": [1048, 1049, 1052, 1054, 1055, 1059], "alastuei": 1044, "albeit": 62, "albert": [0, 247, 376, 1048, 1049, 1050, 1053, 1054], "alberto": [1050, 1054, 1055], "alcalin": 383, "alcohol": [324, 383], "alcorn": 1049, "aldrian": 1045, "aleator": 52, "alec": 1051, "alejandro": [1042, 1047, 1058], "alek": [1054, 1055], "aleksandr": 1048, "aleksandra": 1052, "alemagnani": 1044, "alert": 1048, "alessandro": [1051, 1053, 1056], "alessia": 1054, "alex": [410, 424, 1015, 1041, 1044, 1049, 1051, 1052, 1053, 1055, 1056, 1057, 1058], "alexand": [0, 406, 416, 421, 543, 878, 1043, 1044, 1045, 1047, 1048, 1049, 1053, 1054, 1055, 1058], "alexandercbooth": 1048, "alexandr": [0, 61, 62, 66, 77, 82, 89, 102, 125, 127, 132, 205, 207, 208, 209, 211, 213, 214, 247, 250, 284, 291, 311, 401, 405, 406, 1024, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058], "alexandracraciun": 1053, "alexandru": 447, "alexanmv": 1055, "alexei": 1046, "alexfield": 1047, "alexgoryainov": 1051, "alexi": [1041, 1044, 1045, 1048, 1058, 1059], "alexl": [1057, 1058], "alexryndin": 1049, "alexshack": [1051, 1052, 1053], "alfalfa": 57, "alfano": 1048, "alfaro": [0, 376, 1052, 1053, 1054, 1055, 1056], "alfr": 0, "algebra": [374, 384, 389, 398, 421, 424, 470, 878, 1010], "algesheim": 416, "algo": [78, 134], "algo_param": [79, 97], "algorithm": [2, 6, 8, 9, 11, 18, 28, 30, 32, 33, 38, 39, 41, 48, 53, 55, 56, 65, 67, 71, 72, 77, 78, 80, 81, 85, 91, 92, 93, 94, 95, 96, 97, 101, 102, 104, 112, 113, 117, 125, 127, 139, 140, 141, 145, 148, 156, 189, 197, 207, 209, 223, 234, 236, 242, 244, 246, 250, 251, 257, 264, 265, 266, 269, 275, 278, 287, 299, 305, 306, 308, 312, 319, 321, 324, 328, 329, 330, 333, 335, 340, 341, 342, 348, 360, 361, 362, 369, 373, 375, 379, 380, 381, 382, 383, 386, 387, 388, 389, 394, 395, 399, 400, 403, 412, 413, 416, 418, 419, 420, 421, 423, 424, 426, 427, 428, 429, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 477, 482, 483, 486, 490, 491, 492, 496, 511, 519, 520, 521, 522, 523, 530, 538, 539, 540, 541, 542, 543, 544, 545, 546, 548, 549, 550, 552, 553, 554, 555, 556, 561, 562, 563, 564, 567, 568, 571, 599, 611, 612, 618, 619, 643, 645, 647, 652, 653, 654, 656, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 679, 680, 682, 684, 685, 686, 687, 688, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 712, 713, 716, 725, 727, 743, 745, 751, 782, 786, 787, 801, 803, 805, 806, 840, 849, 850, 852, 853, 854, 855, 856, 857, 858, 860, 861, 862, 863, 864, 865, 868, 873, 877, 879, 892, 896, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 932, 948, 949, 951, 965, 969, 975, 990, 992, 995, 997, 998, 999, 1000, 1002, 1005, 1006, 1010, 1013, 1014, 1015, 1018, 1019, 1020, 1021, 1022, 1024, 1025, 1028, 1029, 1031, 1033, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "algorithm_nam": 78, "ali": [1046, 1049, 1050, 1053, 1054, 1056, 1057, 1058], "alia": [52, 254, 387, 390, 394, 400, 407, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 598, 599, 602, 618, 619, 625, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 807, 809, 810, 815, 817, 826, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 974, 1006, 1020, 1041, 1055], "alias": [81, 82, 254, 384, 386, 389, 407, 605, 1041, 1045, 1055], "aliased_sample_weight": 254, "align": [70, 153, 155, 188, 240, 263, 289, 362, 400, 697, 701, 992, 1003, 1014, 1035, 1036, 1057, 1058], "alihan": 1054, "alik": [421, 998], "alin": 1054, "alison": 1048, "all": [0, 2, 4, 30, 43, 44, 46, 47, 50, 53, 57, 61, 62, 64, 70, 73, 74, 75, 77, 78, 83, 87, 88, 89, 90, 95, 99, 109, 115, 122, 125, 127, 128, 137, 144, 145, 147, 148, 152, 155, 162, 163, 174, 181, 182, 184, 189, 191, 192, 193, 195, 199, 204, 206, 212, 213, 214, 220, 221, 222, 223, 224, 229, 231, 235, 237, 238, 240, 241, 247, 253, 254, 257, 258, 261, 264, 266, 268, 272, 276, 279, 280, 281, 282, 284, 285, 286, 288, 290, 296, 299, 302, 304, 316, 319, 320, 324, 328, 329, 330, 331, 333, 334, 335, 336, 338, 340, 341, 342, 346, 349, 353, 354, 356, 357, 360, 361, 362, 365, 368, 369, 373, 374, 375, 379, 381, 382, 383, 384, 386, 388, 390, 391, 392, 394, 395, 398, 399, 400, 401, 407, 410, 412, 413, 414, 415, 416, 417, 420, 421, 423, 424, 425, 426, 427, 428, 430, 431, 433, 434, 435, 436, 438, 439, 440, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 511, 516, 517, 523, 535, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 591, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 614, 615, 616, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 696, 697, 698, 699, 700, 701, 702, 705, 706, 707, 708, 709, 710, 713, 717, 721, 722, 723, 724, 725, 726, 728, 729, 731, 734, 736, 737, 738, 740, 741, 743, 744, 745, 746, 750, 753, 754, 756, 758, 759, 761, 764, 769, 777, 782, 786, 789, 790, 791, 792, 793, 794, 795, 796, 798, 799, 801, 802, 803, 805, 806, 808, 809, 810, 811, 812, 814, 815, 817, 818, 820, 822, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 874, 875, 876, 877, 878, 879, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 932, 933, 934, 938, 940, 941, 942, 943, 954, 957, 963, 975, 984, 989, 990, 992, 993, 994, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1005, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1019, 1020, 1021, 1023, 1024, 1025, 1026, 1028, 1029, 1031, 1032, 1033, 1034, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1059, 1060], "all_class": 47, "all_displai": [2, 395, 1056], "all_estim": [2, 395, 1051, 1052, 1056], "all_funct": [2, 395, 1056], "all_label": 909, "all_model": 152, "all_or_ani": [984, 1051], "all_scor": 741, "all_split": [43, 52], "all_uppercas": 424, "allan": [360, 414, 1053], "allclos": [126, 157, 1012, 1033], "allefeld": 1054, "allen": [333, 1044, 1046, 1048, 1051], "allend": [1052, 1054], "allevi": [92, 155, 199, 204, 416, 1002], "allison": 333, "alloc": [2, 42, 45, 62, 96, 189, 290, 330, 382, 386, 387, 416, 424, 451, 455, 467, 496, 544, 546, 548, 592, 596, 599, 654, 660, 668, 670, 811, 812, 814, 831, 836, 839, 989, 1010, 1019, 1021, 1035, 1036, 1045, 1046, 1051, 1052, 1058], "allow": [25, 43, 58, 91, 93, 108, 109, 121, 129, 130, 142, 143, 150, 158, 176, 181, 183, 185, 214, 220, 224, 238, 241, 248, 251, 258, 260, 261, 263, 272, 278, 292, 298, 328, 329, 330, 331, 333, 336, 353, 354, 360, 368, 369, 373, 380, 381, 386, 387, 388, 390, 393, 395, 398, 400, 401, 407, 410, 414, 415, 416, 417, 419, 420, 421, 423, 424, 425, 426, 427, 445, 451, 452, 454, 455, 457, 472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 504, 531, 532, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 601, 602, 605, 611, 618, 619, 623, 635, 636, 638, 642, 643, 646, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 696, 698, 700, 707, 750, 770, 773, 782, 786, 789, 800, 801, 805, 806, 807, 808, 809, 810, 811, 812, 815, 817, 819, 822, 826, 829, 830, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 858, 859, 862, 863, 867, 869, 870, 872, 874, 875, 877, 878, 879, 884, 891, 892, 896, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 930, 932, 933, 943, 944, 964, 989, 990, 992, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1010, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1024, 1025, 1038, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "allow_nan": [388, 931, 933, 1057], "allow_nd": [932, 933], "allow_non": 719, "allow_single_clust": [79, 454], "allow_unlabel": [123, 255, 531], "allowed_extens": 511, "allwein": 296, "almeida": [1042, 1043, 1054], "almeidayoel": 1055, "almer": 1048, "almost": [43, 70, 145, 151, 222, 228, 254, 257, 272, 293, 324, 336, 341, 369, 379, 381, 390, 392, 398, 399, 400, 407, 416, 420, 421, 478, 479, 480, 481, 483, 484, 485, 805, 989, 995, 996, 999, 1000, 1015, 1033, 1034, 1049, 1054], "almubarak": [1054, 1055], "alon": [192, 224, 284, 349, 400, 414, 656, 677, 688, 750, 1048, 1050], "along": [2, 51, 53, 91, 94, 101, 118, 146, 152, 155, 181, 207, 220, 252, 254, 282, 328, 361, 362, 369, 381, 386, 390, 392, 394, 395, 400, 404, 407, 410, 413, 421, 423, 424, 425, 428, 541, 558, 595, 619, 620, 638, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 684, 686, 689, 690, 691, 692, 693, 694, 787, 788, 800, 808, 822, 881, 882, 885, 886, 889, 890, 891, 892, 897, 898, 899, 901, 902, 903, 928, 951, 975, 981, 989, 996, 1003, 1010, 1013, 1024, 1041, 1046, 1047, 1049, 1053, 1054], "alongsid": [83, 386, 392, 400, 404, 425, 833, 834, 835, 836, 1000, 1007, 1019, 1020], "alonso": [1052, 1054], "aloqe": 1059, "alpaydin": 383, "alpha": [2, 43, 44, 46, 47, 49, 51, 52, 53, 55, 61, 63, 67, 70, 72, 75, 77, 80, 87, 91, 95, 100, 109, 115, 118, 125, 127, 128, 130, 131, 133, 134, 139, 141, 142, 148, 152, 155, 156, 157, 159, 160, 161, 174, 176, 179, 181, 182, 183, 184, 185, 187, 188, 192, 199, 200, 201, 202, 204, 205, 206, 208, 209, 214, 215, 217, 218, 220, 221, 222, 224, 225, 229, 232, 233, 238, 240, 241, 244, 252, 253, 260, 263, 278, 279, 280, 281, 282, 285, 286, 288, 290, 291, 298, 299, 302, 304, 307, 309, 314, 316, 319, 320, 321, 322, 324, 326, 329, 331, 332, 335, 340, 342, 346, 347, 350, 351, 353, 354, 356, 357, 358, 360, 373, 381, 388, 392, 398, 418, 419, 421, 423, 425, 426, 428, 454, 479, 480, 486, 535, 539, 541, 543, 544, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 568, 603, 604, 606, 619, 621, 623, 624, 631, 639, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 688, 689, 690, 691, 692, 695, 731, 756, 847, 848, 849, 851, 869, 870, 908, 920, 921, 922, 923, 989, 996, 1000, 1002, 1004, 1008, 1013, 1014, 1015, 1016, 1029, 1032, 1034, 1038, 1041, 1043, 1044, 1045, 1046, 1048, 1049, 1053, 1054, 1055, 1056, 1057, 1059], "alpha_": [43, 115, 165, 192, 200, 208, 209, 480, 619, 652, 653, 655, 659, 661, 663, 664, 669, 671, 681, 683, 996, 1016, 1029, 1041, 1048], "alpha_1": [652, 653, 996], "alpha_2": [652, 653, 996], "alpha_a": 209, "alpha_b": 209, "alpha_bound": [185, 631], "alpha_h": [54, 421, 546, 548, 555, 1054], "alpha_i": [1002, 1015], "alpha_init": [200, 653, 996, 1051], "alpha_max": [654, 655, 660, 661, 668, 669, 670, 671, 689, 692], "alpha_min": [654, 655, 658, 660, 661, 662, 664, 668, 669, 670, 671, 689, 690, 691, 692], "alpha_optim": 291, "alpha_per_target": [681, 1053], "alpha_w": [54, 421, 546, 548, 555, 1054], "alphabet": [106, 400, 730, 749], "alphalpha": 57, "alphanumer": [400, 596, 597, 599], "alphas_": [208, 209, 655, 658, 659, 661, 662, 663, 664, 669, 671, 690, 691, 1041, 1044, 1054], "alphas_enet": 205, "alphas_lasso": 205, "alphas_positive_enet": 205, "alphas_positive_lasso": 205, "alphavantag": 51, "alphonsu": 1051, "alreadi": [43, 45, 49, 90, 93, 121, 130, 139, 155, 160, 174, 192, 248, 255, 257, 260, 272, 279, 285, 299, 331, 334, 386, 387, 391, 398, 400, 414, 415, 418, 420, 422, 423, 428, 445, 507, 531, 541, 575, 576, 642, 654, 657, 672, 673, 674, 675, 676, 682, 684, 685, 686, 693, 694, 776, 786, 847, 867, 875, 881, 882, 884, 889, 909, 912, 913, 935, 959, 989, 992, 1006, 1010, 1011, 1020, 1025, 1030, 1034, 1038, 1042, 1046, 1049, 1053, 1054, 1055, 1056], "alsadi": 1049, "alsaedi": 1054, "alsalhi": [0, 1044, 1045], "alsawadi": 1054, "also": [0, 2, 25, 30, 43, 46, 50, 52, 55, 57, 58, 61, 62, 63, 64, 68, 81, 83, 88, 92, 93, 95, 99, 104, 105, 111, 113, 117, 118, 125, 132, 134, 139, 142, 145, 147, 149, 150, 151, 152, 153, 155, 158, 160, 170, 171, 172, 174, 176, 178, 181, 188, 189, 192, 193, 194, 195, 197, 200, 201, 203, 209, 212, 213, 216, 220, 221, 222, 224, 225, 229, 237, 238, 240, 250, 252, 254, 257, 258, 269, 272, 276, 278, 279, 280, 281, 283, 284, 285, 287, 288, 289, 292, 296, 298, 299, 307, 310, 312, 314, 319, 320, 321, 323, 324, 328, 329, 330, 331, 335, 336, 343, 345, 346, 347, 349, 351, 353, 360, 361, 362, 364, 365, 368, 369, 373, 374, 375, 379, 380, 381, 383, 384, 385, 386, 388, 389, 392, 394, 395, 398, 399, 400, 401, 404, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 428, 445, 446, 447, 449, 450, 453, 454, 455, 456, 458, 460, 470, 471, 473, 475, 490, 492, 500, 504, 506, 511, 516, 540, 541, 543, 544, 549, 554, 557, 559, 561, 562, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 596, 597, 598, 599, 601, 602, 603, 604, 605, 606, 607, 608, 615, 616, 617, 618, 619, 630, 640, 641, 643, 651, 652, 653, 654, 655, 658, 660, 661, 662, 664, 666, 667, 668, 669, 670, 671, 672, 680, 684, 686, 689, 692, 695, 699, 702, 703, 707, 718, 721, 731, 737, 738, 746, 751, 771, 787, 788, 791, 792, 795, 805, 806, 808, 811, 812, 822, 825, 828, 834, 835, 836, 837, 838, 839, 841, 851, 854, 855, 856, 858, 859, 860, 862, 863, 864, 868, 869, 870, 872, 874, 875, 880, 881, 885, 889, 892, 897, 901, 914, 917, 920, 921, 922, 923, 932, 951, 957, 964, 989, 990, 992, 994, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1011, 1013, 1014, 1015, 1016, 1019, 1020, 1024, 1025, 1027, 1030, 1032, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "alt": [57, 279, 342, 360, 361, 362, 381, 394, 496, 1034], "altai": 1051, "alter": [62, 188, 388, 400, 737, 738, 746, 791, 792, 795, 1046, 1050, 1053], "altern": [43, 63, 105, 118, 146, 147, 153, 155, 160, 194, 204, 220, 238, 248, 266, 269, 272, 287, 328, 353, 360, 361, 362, 369, 381, 386, 389, 390, 392, 398, 400, 401, 404, 410, 411, 413, 414, 416, 417, 418, 420, 421, 423, 424, 426, 449, 450, 453, 454, 455, 460, 466, 471, 507, 546, 548, 549, 555, 561, 562, 565, 566, 567, 568, 572, 573, 574, 590, 596, 597, 599, 625, 628, 651, 700, 714, 716, 779, 782, 786, 789, 810, 841, 876, 882, 885, 898, 905, 907, 920, 921, 922, 923, 967, 994, 996, 997, 999, 1000, 1003, 1004, 1008, 1010, 1012, 1013, 1015, 1016, 1020, 1029, 1034, 1036, 1046, 1048, 1054, 1055, 1059], "alternate_sign": [47, 424, 590, 597, 1048], "although": [43, 48, 62, 146, 160, 191, 217, 238, 247, 265, 298, 353, 369, 375, 388, 400, 416, 417, 421, 424, 504, 825, 828, 883, 999, 1001, 1002, 1003, 1006, 1016, 1025, 1032, 1033, 1034, 1041, 1049, 1056], "altman": [636, 990], "altogeth": [149, 392, 1049], "alva": 1051, "alvaro": [1047, 1049], "alvin": 1049, "alwai": [145, 149, 152, 192, 199, 220, 238, 245, 251, 272, 281, 284, 288, 326, 346, 353, 356, 361, 369, 373, 374, 380, 384, 386, 387, 388, 392, 399, 400, 404, 410, 414, 416, 417, 420, 423, 424, 425, 426, 433, 439, 451, 457, 472, 473, 475, 477, 490, 491, 492, 496, 504, 516, 517, 552, 557, 559, 560, 562, 564, 566, 567, 568, 569, 570, 572, 573, 576, 578, 589, 596, 597, 599, 602, 619, 635, 636, 638, 640, 641, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 675, 678, 679, 680, 681, 684, 686, 687, 703, 713, 717, 723, 729, 730, 731, 732, 740, 742, 743, 747, 790, 793, 794, 805, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 845, 846, 855, 856, 863, 864, 870, 877, 885, 890, 892, 895, 897, 898, 899, 900, 901, 902, 903, 905, 913, 914, 915, 917, 918, 920, 921, 923, 950, 959, 960, 989, 990, 992, 994, 996, 999, 1000, 1003, 1006, 1008, 1012, 1013, 1015, 1016, 1024, 1025, 1032, 1041, 1043, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1058, 1059], "always_accept_polici": 272, "always_reject_polici": 272, "alyssa": [1044, 1048], "alyssaq": 1047, "am": [104, 109, 113, 160, 193, 360, 391, 418, 482, 501, 1048], "amai": 1057, "aman": [1047, 1048, 1049, 1055, 1056], "amanda": [1049, 1052, 1053, 1054, 1055], "amar": [1055, 1056, 1057, 1059], "amax": 111, "amazon": 51, "amber": 400, "ambient": 244, "ambigu": [279, 391, 424, 580, 720, 949, 1003, 1050, 1052, 1054], "ambival": 95, "ambrosio": 1048, "ambroz": [1051, 1052], "amelia": 990, "amen": [392, 398, 426, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 989], "america": [50, 51, 113, 312, 381, 859, 1010], "american": [50, 51, 104, 114, 381, 416, 418, 422, 423, 424, 477, 482, 739, 892], "ames_h": 257, "amg": [81, 101, 416, 460, 470, 699, 703, 1051, 1055, 1056], "amherst": 381, "ami": [72, 84, 93, 416, 712], "amicel": [1041, 1044], "amin": 111, "aminaka": 1045, "amit": [1041, 1055, 1056], "amlan": 1047, "amo": 1044, "amol": 1054, "among": [2, 64, 184, 193, 195, 197, 220, 268, 298, 368, 375, 381, 388, 400, 401, 414, 419, 455, 457, 520, 527, 802, 837, 855, 860, 862, 914, 917, 920, 921, 922, 923, 989, 992, 1000, 1001, 1007, 1010, 1015, 1041, 1047, 1048, 1051, 1058], "amongst": [51, 1016], "amor": [0, 72, 92, 145, 155, 199, 204, 257, 279, 281, 324, 360, 361, 362, 397, 1055, 1056, 1057, 1058, 1059], "amormachin": 1044, "amort": 1003, "amount": [37, 38, 47, 51, 80, 88, 101, 111, 114, 125, 129, 140, 142, 182, 192, 204, 224, 238, 252, 272, 330, 336, 338, 341, 343, 349, 356, 362, 373, 374, 375, 398, 416, 418, 421, 423, 424, 425, 451, 462, 477, 546, 547, 549, 551, 571, 604, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 673, 689, 692, 700, 811, 812, 852, 853, 858, 893, 908, 909, 922, 923, 995, 996, 999, 1002, 1004, 1010, 1012, 1013, 1014, 1015, 1032, 1033, 1054, 1058], "amount_fraud": 272, "amount_iter": 341, "amount_label": 341, "amount_test": 272, "amount_train": 272, "amourav": 1050, "amplitud": [152, 181, 183, 214, 996], "amplitude_nois": 75, "amput": 1020, "amrcod": 1055, "amsterdam": [410, 880, 1011], "amuel": [108, 143, 211, 252, 340, 356], "amy12xx": 1053, "amzn": 51, "an": [0, 2, 25, 29, 37, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 59, 62, 63, 64, 69, 70, 71, 72, 74, 75, 76, 78, 79, 81, 83, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 101, 102, 104, 105, 106, 107, 109, 111, 112, 113, 114, 120, 125, 126, 127, 128, 129, 130, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 152, 153, 155, 156, 157, 158, 159, 160, 163, 166, 167, 170, 174, 176, 177, 178, 181, 182, 183, 185, 186, 187, 189, 191, 192, 193, 194, 197, 198, 199, 200, 203, 204, 208, 215, 220, 221, 222, 224, 225, 227, 228, 234, 236, 237, 238, 240, 241, 242, 243, 245, 247, 248, 250, 251, 252, 253, 254, 255, 257, 261, 263, 264, 266, 268, 269, 271, 272, 274, 275, 276, 278, 279, 280, 281, 282, 283, 284, 285, 287, 289, 291, 294, 298, 299, 302, 305, 306, 307, 310, 312, 319, 324, 325, 326, 329, 330, 331, 333, 334, 335, 336, 339, 343, 345, 346, 348, 349, 351, 352, 353, 360, 361, 362, 364, 367, 368, 369, 373, 374, 375, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 399, 400, 401, 403, 404, 407, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 425, 426, 427, 428, 437, 440, 441, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 511, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 583, 584, 588, 589, 590, 591, 592, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 615, 616, 618, 619, 620, 627, 630, 631, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 712, 713, 714, 717, 719, 720, 726, 728, 729, 735, 737, 738, 742, 743, 745, 750, 751, 753, 754, 756, 758, 759, 761, 764, 766, 767, 771, 772, 774, 775, 776, 777, 778, 781, 783, 784, 785, 786, 789, 790, 791, 792, 795, 796, 797, 798, 799, 800, 801, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 819, 820, 822, 823, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 867, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 927, 929, 930, 932, 933, 935, 936, 939, 943, 944, 945, 947, 948, 949, 951, 953, 956, 957, 958, 959, 960, 961, 963, 964, 965, 970, 971, 974, 975, 981, 984, 986, 987, 988, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1023, 1024, 1026, 1028, 1029, 1033, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "ana": [1052, 1054, 1059], "anaconda": [0, 374, 384, 390], "anak": 1053, "analog": [43, 57, 154, 392, 423, 1000, 1001, 1015, 1050], "analogi": [999, 1000], "analys": [240, 368, 421, 811, 812, 997, 1019, 1024], "analysen": 458, "analysi": [2, 12, 27, 44, 46, 48, 49, 58, 62, 65, 71, 92, 98, 100, 111, 112, 113, 114, 115, 121, 123, 124, 126, 127, 129, 130, 131, 133, 134, 149, 166, 188, 189, 192, 209, 241, 262, 264, 268, 269, 272, 275, 278, 279, 283, 289, 300, 301, 302, 310, 311, 319, 324, 356, 361, 378, 381, 383, 386, 388, 401, 413, 416, 418, 423, 424, 428, 447, 455, 456, 481, 483, 484, 490, 491, 493, 510, 512, 520, 523, 539, 540, 541, 542, 543, 545, 547, 548, 549, 550, 551, 552, 553, 554, 557, 558, 563, 564, 639, 646, 696, 698, 699, 700, 701, 718, 727, 733, 734, 764, 796, 797, 800, 801, 805, 808, 834, 838, 854, 861, 872, 873, 878, 888, 892, 900, 948, 949, 990, 996, 997, 999, 1000, 1010, 1018, 1019, 1021, 1022, 1024, 1026, 1035, 1036, 1041, 1042, 1043, 1045, 1050], "analyst": 875, "analyt": [130, 421, 426, 540, 628, 716, 990, 994, 1000, 1018, 1024], "analyz": [43, 46, 55, 204, 280, 287, 333, 360, 362, 391, 392, 416, 424, 511, 596, 597, 599, 796, 997, 1000, 1007, 1008, 1016, 1034, 1041, 1050], "anam": 1058, "anand": [1049, 1053], "ananiad": 1014, "anantharam": 1055, "anavelyz": 1054, "ana\u00ebl": 1051, "anbari": 536, "anchor": 289, "ander": [1045, 1051], "andersen": [751, 1055], "anderson": [50, 312, 381, 506, 1047, 1053, 1059], "andi": [1041, 1048], "ando": 1046, "andr": [1048, 1055], "andrea": [0, 67, 108, 130, 143, 211, 252, 320, 321, 340, 356, 357, 401, 405, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056], "andreh7": 1048, "andrei": [1056, 1058, 1059], "andrew": [81, 416, 470, 699, 703, 725, 745, 803, 887, 1004, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "andrewww": 1049, "andrii": 1055, "andriushchenko": [1047, 1048], "androutsopoulo": [847, 1002], "andrzej": [546, 548, 555], "andr\u00e1": [1054, 1055, 1056, 1057], "andr\u00e9": [1054, 1055, 1057], "ands": 883, "andyscanzio": 1058, "ang": 1048, "angel": [0, 406], "angela": [1051, 1052, 1056], "angelaambroz": 1052, "angermuel": [1045, 1046], "angl": [2, 53, 70, 128, 174, 263, 264, 265, 268, 269, 383, 421, 539, 545, 547, 550, 551, 553, 554, 556, 658, 659, 660, 661, 662, 663, 664, 671, 672, 673, 686, 690, 691, 692, 693, 694, 700, 997, 998, 1022, 1036, 1041], "angmar": 57, "angu": [1048, 1049, 1055], "angular": [422, 700, 772], "anh": [546, 548, 555], "ani": [2, 25, 37, 43, 47, 48, 52, 53, 57, 79, 81, 90, 92, 102, 157, 169, 174, 182, 183, 191, 192, 193, 194, 195, 209, 220, 224, 238, 247, 250, 251, 254, 264, 268, 269, 272, 278, 279, 281, 284, 287, 296, 312, 319, 320, 323, 328, 330, 331, 333, 336, 349, 353, 362, 369, 373, 374, 375, 380, 381, 383, 384, 386, 388, 390, 391, 392, 394, 399, 400, 401, 404, 407, 410, 412, 413, 414, 416, 417, 420, 421, 422, 423, 424, 425, 441, 448, 454, 456, 457, 458, 460, 462, 464, 465, 469, 472, 475, 496, 497, 516, 517, 531, 542, 545, 547, 554, 559, 565, 566, 567, 568, 572, 573, 574, 575, 576, 577, 578, 587, 588, 590, 596, 597, 599, 601, 611, 618, 619, 628, 635, 640, 641, 653, 656, 666, 667, 674, 675, 676, 677, 684, 685, 686, 687, 688, 700, 704, 707, 708, 712, 724, 725, 727, 732, 744, 745, 760, 763, 765, 782, 786, 787, 788, 789, 800, 801, 803, 808, 811, 812, 820, 821, 841, 844, 852, 853, 858, 862, 871, 872, 876, 877, 881, 883, 885, 886, 893, 902, 903, 906, 909, 912, 913, 920, 921, 922, 923, 924, 926, 928, 932, 933, 970, 984, 989, 990, 992, 995, 996, 997, 1000, 1001, 1002, 1003, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1019, 1023, 1025, 1027, 1031, 1032, 1034, 1042, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "aniket": [1056, 1058], "anil": [416, 460, 470], "anim": [360, 424], "anirban": 424, "aniruddha": 1049, "anish": [1046, 1047], "anisha": 1051, "aniso": [79, 97], "anisotrop": [92, 178, 426, 625, 627, 630], "anisotropicli": [79, 97], "anjirbag": 1049, "ankan": 1046, "ankerst": [416, 458, 465], "ankit": [1044, 1051, 1053, 1055], "ankit810": 1052, "ankita": 1049, "ankur": [1046, 1057], "ann": [1041, 1053, 1055], "anna": 1049, "annaayzenshtat": 1049, "annal": [174, 204, 208, 383, 423, 482, 524, 525, 526, 567, 568, 664, 996], "annau": 1054, "annegnx": 1057, "anno": [700, 997], "annoi": 374, "annot": [2, 43, 48, 63, 162, 172, 197, 241, 282, 285, 360, 386, 387, 388, 416, 724, 926, 1000, 1016, 1050], "annotationbbox": 241, "announc": [328, 329, 330, 331, 332, 333, 334, 335, 336, 390], "annual": [383, 416, 734, 764, 909, 1000, 1013], "anomali": [14, 48, 113, 156, 189, 234, 246, 257, 305, 306, 381, 477, 520, 530, 571, 647, 685, 858, 873, 916, 1006, 1019, 1021, 1047, 1048], "anomaly_algorithm": 247, "anomaly_frac": 257, "anoth": [43, 72, 125, 130, 139, 150, 154, 174, 176, 184, 188, 192, 209, 224, 228, 245, 247, 254, 258, 264, 272, 278, 280, 281, 284, 288, 292, 309, 360, 362, 364, 369, 373, 375, 380, 381, 384, 386, 388, 392, 398, 400, 410, 413, 416, 420, 421, 423, 424, 425, 427, 450, 452, 460, 463, 470, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 516, 546, 548, 555, 681, 684, 700, 717, 727, 814, 830, 831, 871, 872, 893, 989, 990, 995, 996, 997, 1000, 1001, 1003, 1006, 1010, 1014, 1015, 1025, 1032, 1033, 1034, 1050, 1051, 1058], "anova": [2, 49, 89, 108, 168, 170, 173, 174, 189, 344, 417, 512, 523, 600, 603, 604, 606, 607, 608, 612, 613, 614, 617, 721, 834, 838, 872, 873, 892, 912, 917, 1015, 1021], "anova__percentil": [89, 352], "anova_filt": 171, "anova_svm": 171, "ansam": 1057, "answer": [165, 191, 278, 386, 398, 410, 415, 734, 764, 1000, 1024], "ant": [726, 762, 1000], "anthoni": [1046, 1048, 1049], "anthony22": [1056, 1057], "anti": [204, 369, 614, 847, 1002], "anti_alias": [81, 82, 1033], "anticip": 52, "antoin": [1041, 1043, 1044, 1045, 1048], "antoni": [1045, 1047, 1053, 1056], "antonin": 1048, "antonio": [1049, 1051], "anubhav": 1049, "anuja": 1051, "anulekh": 1056, "anupam": [906, 1012, 1056], "any_method": 960, "anymor": [155, 194, 220, 280, 328, 329, 349, 369, 390, 417, 678, 1047, 1050, 1053, 1054, 1055, 1057, 1058, 1060], "anyon": [386, 401, 415, 1023, 1024], "anyth": [362, 390, 392, 400, 407, 417, 420, 960, 964, 1055], "anywai": [48, 360, 388, 673, 693, 694], "anywher": 320, "anz": 1042, "aoif": [716, 1000], "ap": [2, 285, 715, 716, 1000], "apart": [192, 331, 349, 398, 400, 407, 417, 419, 425, 733, 1015, 1024, 1049], "api": [0, 47, 51, 85, 91, 136, 144, 184, 189, 246, 248, 254, 258, 259, 275, 280, 287, 288, 299, 335, 336, 361, 362, 375, 379, 380, 386, 387, 389, 390, 395, 396, 398, 399, 401, 404, 410, 415, 421, 423, 424, 426, 430, 433, 434, 435, 438, 440, 446, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 472, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 504, 512, 516, 518, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 571, 572, 574, 575, 576, 577, 578, 587, 588, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 666, 679, 685, 696, 697, 698, 699, 700, 710, 805, 806, 811, 812, 814, 831, 838, 856, 858, 860, 861, 864, 868, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 910, 916, 917, 966, 984, 989, 998, 999, 1000, 1003, 1010, 1014, 1019, 1020, 1021, 1024, 1025, 1029, 1031, 1036, 1038, 1039, 1040, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057], "api_refer": 386, "apk": 404, "apostolo": 1056, "appar": [117, 1002, 1024], "appdata": 404, "appeal": 401, "appear": [0, 47, 81, 83, 142, 192, 195, 273, 275, 276, 305, 306, 314, 316, 320, 339, 353, 360, 361, 362, 381, 384, 386, 391, 400, 418, 421, 496, 497, 563, 575, 576, 587, 618, 635, 636, 638, 705, 708, 710, 720, 724, 726, 790, 797, 809, 826, 847, 848, 849, 850, 851, 914, 917, 951, 996, 1002, 1006, 1041, 1049, 1053, 1054], "append": [46, 47, 48, 51, 52, 55, 62, 69, 72, 75, 79, 85, 96, 105, 132, 142, 143, 145, 150, 152, 155, 188, 195, 213, 224, 225, 227, 228, 235, 238, 252, 253, 278, 281, 287, 288, 291, 314, 315, 325, 341, 349, 352, 360, 361, 362, 364, 368, 392, 400, 417, 424, 666, 667, 912, 913, 919, 939, 1010, 1029], "appendix": [653, 684, 996, 1010], "appl": [51, 373, 384, 398, 1001], "appli": [2, 32, 48, 54, 57, 62, 64, 68, 75, 79, 81, 82, 90, 91, 93, 97, 105, 109, 118, 121, 125, 126, 131, 133, 135, 144, 145, 150, 152, 170, 176, 192, 194, 204, 209, 224, 225, 234, 240, 241, 242, 247, 252, 254, 278, 279, 281, 290, 292, 298, 308, 319, 323, 324, 329, 349, 353, 362, 368, 369, 373, 378, 386, 388, 394, 398, 399, 400, 407, 413, 414, 416, 417, 418, 420, 421, 423, 424, 425, 426, 428, 448, 454, 460, 470, 472, 473, 475, 477, 482, 490, 491, 492, 493, 516, 517, 524, 525, 526, 532, 539, 540, 541, 542, 543, 545, 547, 549, 550, 551, 556, 557, 558, 561, 562, 565, 566, 567, 568, 572, 573, 574, 596, 597, 598, 599, 635, 640, 641, 646, 647, 649, 650, 666, 667, 676, 684, 685, 686, 699, 707, 709, 715, 719, 734, 764, 766, 767, 789, 796, 800, 801, 808, 822, 838, 841, 847, 848, 849, 850, 851, 861, 871, 872, 881, 888, 889, 892, 897, 898, 900, 901, 902, 903, 908, 919, 920, 921, 922, 923, 932, 938, 941, 948, 949, 972, 990, 992, 996, 997, 998, 999, 1000, 1002, 1004, 1006, 1008, 1010, 1014, 1015, 1016, 1017, 1018, 1024, 1042, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1055], "applic": [42, 44, 57, 84, 90, 113, 189, 197, 220, 237, 242, 271, 272, 281, 319, 336, 373, 375, 381, 383, 386, 388, 392, 394, 395, 398, 400, 414, 415, 416, 420, 421, 422, 423, 426, 428, 452, 454, 460, 504, 506, 540, 541, 542, 561, 562, 637, 696, 697, 698, 702, 720, 737, 738, 746, 791, 792, 795, 838, 989, 996, 997, 998, 999, 1000, 1004, 1006, 1012, 1016, 1019, 1020, 1021, 1023, 1024, 1032, 1034, 1041, 1042, 1047, 1049, 1052], "apply_along_axi": 317, "appr": 627, "appreci": [0, 386, 398], "approach": [44, 47, 93, 98, 101, 129, 174, 176, 187, 192, 195, 202, 208, 220, 222, 228, 238, 240, 272, 296, 325, 353, 360, 361, 362, 375, 385, 386, 392, 395, 400, 404, 410, 414, 416, 418, 419, 420, 421, 422, 423, 424, 425, 426, 445, 451, 454, 456, 460, 470, 528, 540, 590, 597, 619, 643, 666, 667, 682, 683, 841, 857, 949, 989, 990, 996, 997, 1000, 1001, 1003, 1004, 1010, 1014, 1015, 1018, 1019, 1024, 1027, 1032, 1033, 1045, 1057], "appropri": [25, 90, 92, 132, 181, 192, 224, 254, 287, 292, 336, 364, 369, 384, 386, 388, 394, 400, 410, 414, 416, 420, 422, 423, 427, 452, 458, 465, 497, 498, 499, 504, 508, 509, 510, 512, 513, 518, 585, 590, 599, 600, 603, 604, 606, 607, 608, 680, 682, 695, 717, 854, 855, 856, 858, 860, 862, 863, 864, 984, 996, 999, 1000, 1010, 1045, 1048, 1054, 1057, 1059], "approv": [386, 401, 423], "approx": [64, 125, 252, 421, 423, 424, 1000, 1007, 1014], "approxim": [0, 2, 23, 43, 44, 64, 69, 81, 88, 113, 129, 130, 134, 143, 151, 152, 174, 177, 192, 200, 216, 220, 221, 234, 238, 242, 245, 246, 247, 250, 253, 269, 278, 283, 293, 300, 301, 308, 319, 321, 322, 324, 328, 331, 360, 362, 366, 367, 369, 378, 383, 395, 398, 400, 413, 414, 417, 419, 420, 421, 423, 426, 428, 429, 430, 440, 457, 477, 478, 481, 482, 483, 484, 490, 491, 492, 499, 504, 510, 529, 532, 541, 542, 543, 544, 546, 547, 548, 549, 551, 552, 553, 554, 555, 567, 568, 590, 597, 618, 619, 627, 646, 647, 648, 649, 650, 653, 665, 666, 667, 680, 682, 684, 685, 687, 695, 700, 766, 767, 772, 805, 809, 826, 833, 837, 838, 852, 853, 856, 860, 862, 863, 864, 868, 872, 873, 878, 882, 884, 885, 889, 901, 912, 917, 918, 948, 949, 974, 993, 994, 995, 996, 997, 999, 1003, 1004, 1005, 1006, 1007, 1008, 1012, 1014, 1015, 1016, 1019, 1020, 1021, 1034, 1036, 1041, 1042, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055], "approximate_nearest_neighbor": [299, 1021], "approximateident": 1042, "april": [381, 672, 693, 694, 1045, 1053, 1058], "apriori": 238, "apt": [384, 394, 404], "aptitud": 192, "aqua": 287, "aquantitypredict": 1027, "ar": [0, 2, 16, 25, 30, 31, 32, 37, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 68, 70, 72, 74, 75, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 99, 101, 104, 105, 106, 108, 109, 111, 112, 113, 114, 115, 117, 118, 121, 123, 125, 127, 130, 132, 135, 137, 139, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162, 170, 171, 173, 174, 176, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 224, 229, 231, 238, 240, 241, 242, 243, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 261, 264, 265, 266, 268, 271, 273, 275, 276, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 292, 293, 294, 296, 298, 299, 301, 304, 305, 309, 312, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 332, 333, 334, 335, 336, 338, 340, 341, 342, 343, 347, 349, 351, 353, 356, 357, 360, 361, 362, 364, 368, 369, 373, 374, 375, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 399, 400, 401, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 432, 437, 440, 441, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 516, 517, 518, 520, 523, 524, 525, 526, 527, 528, 531, 532, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 699, 700, 701, 702, 704, 705, 706, 707, 708, 709, 710, 712, 713, 715, 717, 719, 720, 721, 723, 724, 725, 726, 728, 729, 730, 731, 733, 734, 735, 736, 737, 738, 739, 742, 743, 744, 745, 746, 748, 749, 750, 751, 753, 754, 756, 758, 759, 761, 762, 764, 765, 769, 770, 771, 773, 775, 776, 777, 781, 782, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 817, 820, 822, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 866, 867, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 897, 898, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 932, 933, 936, 937, 938, 941, 943, 948, 949, 950, 953, 954, 956, 957, 960, 963, 964, 966, 971, 974, 975, 979, 980, 981, 984, 986, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1031, 1032, 1033, 1034, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "arab": 635, "arabi": [416, 713, 723, 794], "aradwad": 1052, "arafat": 1047, "arai": 1051, "arang": [43, 50, 52, 53, 75, 93, 95, 100, 107, 112, 113, 132, 135, 148, 149, 151, 153, 154, 158, 162, 170, 176, 178, 183, 184, 187, 188, 195, 204, 220, 223, 225, 229, 243, 250, 252, 273, 278, 281, 286, 289, 298, 299, 312, 314, 321, 331, 338, 339, 341, 343, 349, 355, 360, 362, 366, 367, 368, 369, 398, 413, 420, 424, 473, 552, 838, 887, 891, 995, 996, 1004, 1010, 1014, 1030], "aravindh": 1056, "arbitarili": 360, "arbitrari": [2, 43, 90, 118, 125, 126, 127, 144, 183, 199, 220, 237, 238, 276, 319, 323, 325, 330, 336, 360, 368, 374, 386, 398, 400, 410, 417, 420, 421, 423, 424, 428, 454, 458, 463, 465, 473, 540, 541, 567, 568, 589, 647, 656, 677, 688, 696, 750, 797, 809, 810, 815, 817, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 876, 878, 891, 989, 991, 992, 996, 997, 1000, 1003, 1010, 1020, 1034, 1041, 1042, 1045, 1047, 1048, 1049, 1051, 1055, 1057], "arbitrarili": [177, 264, 269, 360, 400, 426, 439, 473, 490, 491, 492, 560, 562, 564, 566, 568, 570, 573, 576, 578, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 677, 678, 680, 681, 686, 687, 688, 729, 730, 731, 732, 754, 793, 797, 845, 846, 855, 863, 870, 893, 913, 915, 918, 921, 923, 1000, 1003, 1010, 1016], "arc": [383, 423], "archana": [1051, 1053], "archit": 1047, "architectur": [384, 388, 394, 398, 404, 410, 476, 910, 1004, 1024, 1041, 1058], "archiv": [47, 296, 380, 381, 383, 384, 416, 450, 508, 510, 518, 766, 767, 998, 1015, 1034], "archive_filenam": 47, "archive_path": 47, "archive_sha256": 47, "arci": [716, 1000], "arcidiacono": [1055, 1056, 1058, 1059], "arcsin": [707, 772], "arctan": [70, 264, 269, 382, 526], "arctan2": [263, 265, 268], "ard": [2, 199, 652, 653], "ard_poli": 199, "ard_scor": 199, "ardregress": [2, 199, 204, 653, 941, 996, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1057, 1058], "area": [2, 50, 52, 156, 174, 220, 238, 257, 275, 278, 285, 287, 288, 349, 353, 354, 357, 383, 386, 390, 398, 416, 424, 710, 714, 715, 716, 750, 796, 797, 997, 1000, 1003, 1018, 1043], "aren": [16, 254, 360, 381, 390, 404, 734, 764, 1005, 1051, 1053], "arezki": 1041, "arfa": 1047, "arff": [333, 386, 504, 1053, 1056, 1057], "arg": [254, 315, 353, 387, 400, 421, 423, 430, 707, 876, 966, 968, 996, 1002, 1003], "arg1": 1034, "arg2": 1034, "arg3": 1034, "arg_sort_bi": 52, "argentina": 772, "argmax": [63, 132, 277, 291, 388, 423, 577, 840, 920, 1015, 1054], "argmin": [51, 151, 277, 388, 418, 539, 545, 553, 554, 693, 787, 788, 1016], "argpartit": 1048, "argsort": [54, 55, 57, 58, 59, 151, 153, 194, 195, 220, 238, 328, 338, 339, 360, 361, 381, 1008], "argument": [2, 106, 221, 248, 251, 254, 374, 380, 381, 386, 387, 389, 391, 392, 394, 395, 398, 400, 416, 417, 420, 421, 423, 425, 427, 428, 430, 434, 438, 446, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 460, 462, 465, 467, 469, 471, 476, 477, 501, 504, 511, 516, 541, 543, 544, 546, 548, 559, 567, 568, 571, 575, 576, 577, 578, 585, 589, 590, 596, 597, 599, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 639, 647, 651, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 674, 676, 684, 685, 689, 692, 696, 700, 704, 706, 707, 708, 709, 710, 722, 727, 743, 750, 771, 787, 788, 814, 831, 833, 834, 835, 836, 840, 841, 844, 854, 855, 856, 858, 860, 861, 862, 863, 864, 865, 866, 869, 872, 876, 910, 916, 926, 930, 939, 944, 967, 969, 970, 984, 989, 992, 996, 997, 998, 1000, 1003, 1007, 1008, 1015, 1016, 1025, 1029, 1041, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1053, 1055, 1056, 1057, 1058, 1059], "argv": 251, "ari": [72, 93, 361, 416, 713, 1046, 1052], "aria": [1049, 1050, 1056], "aric": 55, "arida": [91, 1050, 1051, 1053, 1055, 1058], "ariel": [45, 381, 1041, 1047], "ariga": 1047, "arik": 1049, "arima": 1019, "aris": [2, 192, 281, 356, 374, 391, 416, 723, 996, 997, 1053], "arisa": [1055, 1056], "arithmet": [253, 392, 394, 416, 559, 656, 677, 688, 712, 725, 744, 745, 765, 803, 859, 1000, 1049], "ari\u00f1o": 1044, "arjona": 1050, "arka204": [1054, 1056], "arm": [384, 386, 394, 989], "arm64": [384, 389], "arm64v8": 394, "armstrong": 1053, "arnaud": [0, 406, 1042, 1043, 1044, 1045, 1046, 1047, 1059], "arnaudov": [1053, 1055], "arnaudstiegl": 1051, "arnold": [1041, 1042], "arnoldi": [696, 697, 701], "aroma": 325, "arora": [1049, 1056], "around": [0, 43, 63, 72, 87, 117, 139, 142, 152, 182, 193, 197, 254, 257, 272, 281, 292, 317, 338, 340, 341, 349, 352, 353, 360, 361, 362, 369, 381, 383, 386, 392, 398, 415, 416, 420, 421, 424, 479, 480, 523, 552, 628, 648, 657, 676, 712, 750, 805, 814, 831, 858, 860, 862, 863, 864, 892, 996, 997, 999, 1000, 1006, 1010, 1014, 1019, 1020, 1023, 1024, 1027, 1032, 1034, 1045, 1046], "arpack": [51, 57, 79, 81, 101, 104, 241, 335, 421, 459, 460, 461, 470, 543, 549, 552, 696, 697, 699, 701, 703, 997, 1047, 1048, 1053, 1057, 1058, 1059], "arpanchowdhri": 1051, "arr": 336, "arrai": [2, 45, 46, 47, 49, 50, 51, 52, 53, 57, 68, 69, 70, 75, 79, 81, 83, 88, 89, 96, 97, 99, 104, 106, 114, 117, 123, 126, 127, 151, 153, 155, 156, 159, 162, 171, 174, 177, 178, 179, 184, 192, 199, 201, 204, 213, 214, 217, 220, 221, 227, 237, 241, 242, 247, 251, 254, 257, 258, 261, 263, 264, 265, 267, 268, 272, 273, 274, 276, 278, 279, 282, 283, 287, 298, 312, 322, 328, 331, 332, 334, 335, 339, 345, 352, 353, 360, 367, 369, 373, 374, 379, 380, 381, 386, 387, 388, 389, 391, 392, 394, 396, 398, 399, 400, 410, 413, 415, 416, 417, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 437, 438, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 496, 498, 499, 500, 501, 502, 504, 505, 506, 508, 509, 510, 511, 512, 514, 516, 517, 518, 519, 520, 521, 523, 527, 531, 532, 535, 537, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 589, 590, 591, 592, 594, 596, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 720, 721, 722, 723, 724, 725, 726, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 928, 929, 930, 931, 932, 933, 934, 937, 938, 947, 948, 949, 950, 951, 953, 954, 955, 962, 963, 964, 969, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 986, 987, 990, 995, 996, 998, 1000, 1001, 1003, 1004, 1006, 1007, 1010, 1011, 1012, 1014, 1015, 1016, 1018, 1024, 1029, 1030, 1031, 1032, 1033, 1034, 1036, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "arrang": [2, 58, 298, 640, 843, 844, 845, 846, 1000], "array_api": 412, "array_api_compat": 412, "array_api_dispatch": [412, 476, 910], "array_api_support": [388, 412], "array_convert": 933, "array_equ": [577, 1048], "array_lik": 947, "array_paramet": 386, "array_split": 1029, "array_sym": 986, "arrayfunc": [2, 395, 929], "arrow": [63, 1027, 1055], "arrow_arg": 48, "arrowprop": [48, 63], "arrowstyl": 48, "arroyo": 1055, "art": [330, 392, 657, 700, 1019, 1024], "artem": [1045, 1048, 1058], "arth": 1055, "arthur": [235, 236, 416, 455, 468, 1046, 1047, 1048, 1049, 1050, 1053, 1055], "arthurmello": 1055, "articl": [0, 55, 104, 360, 381, 385, 386, 394, 420, 429, 483, 713, 996, 1000, 1034, 1054], "artiem": 1049, "artifact": [43, 53, 81, 82, 319, 375, 390, 1036], "artifici": [10, 146, 149, 157, 174, 188, 224, 240, 253, 272, 317, 360, 381, 382, 383, 391, 413, 416, 420, 421, 543, 704, 842, 869, 870, 993, 997, 999, 1001, 1007, 1012, 1016, 1020, 1024, 1041], "artist": [393, 446, 640, 706, 708, 709, 710, 814, 831, 926], "artsiom": 1048, "artsion": 1047, "artstein": 724, "artur": [1056, 1057], "arturo": [0, 72, 92, 145, 155, 199, 204, 257, 279, 281, 324, 360, 361, 362, 397, 1055, 1056, 1057, 1058, 1059], "arturoamor": 1055, "aruku": [1049, 1050], "arunav": 1052, "arunava": 1049, "arxiv": [386, 470], "arya": 1049, "as_float_arrai": [2, 395], "as_fram": [43, 44, 52, 105, 109, 145, 149, 155, 160, 181, 192, 193, 194, 195, 208, 209, 220, 228, 236, 238, 257, 261, 272, 292, 296, 299, 302, 316, 324, 325, 328, 330, 332, 333, 380, 381, 497, 498, 499, 500, 504, 508, 509, 510, 512, 513, 518, 1051, 1052, 1053, 1054, 1057], "asanyarrai": 388, "asarrai": [47, 55, 220, 238, 317, 340, 360, 361, 388, 400, 412, 734, 764, 860, 862, 863, 864, 1010, 1015, 1058], "ascend": [58, 105, 194, 325, 423, 458, 464, 602, 635, 643, 924, 925, 926, 1014, 1051, 1057], "ascent": [181, 426], "ascii": [50, 312, 424, 495, 596, 597, 599], "ascontiguousarrai": 549, "asctim": 125, "aseem": 1048, "asgd": [227, 1014], "ash": [48, 383, 1044, 1047], "ashah002": [1056, 1057, 1058], "ashim": 1051, "ashimb9": 1051, "ashimin": 1054, "ashish": [1054, 1057], "ashra": 652, "ashutosh": [1048, 1049, 1051, 1053], "ashvith": 1054, "ashwin": [1056, 1057], "asia": [278, 1010], "asian": 424, "asid": [150, 228, 410, 567, 568, 569, 570, 674, 675, 676, 684, 686, 869, 870], "asish": [1047, 1048], "ask": [0, 187, 188, 278, 385, 386, 390, 391, 394, 400, 401, 410, 425, 854, 855, 856, 858, 860, 862, 863, 864, 1023, 1057], "asnt": 1047, "aspect": [46, 93, 118, 125, 180, 193, 240, 247, 287, 292, 308, 373, 374, 375, 386, 400, 401, 416, 499, 666, 667, 1016, 1024, 1058], "aspir": [174, 383, 386], "ass": [113, 114, 418, 482], "assembl": [298, 326, 362, 872], "assert": [47, 55, 83, 126, 251, 278, 287, 374, 389, 1020], "assert_all_finit": [2, 373, 395, 476], "assert_allclos": 388, "assert_array_equ": 424, "assert_warn": 1054, "assert_warns_messag": 1054, "assertionerror": 1048, "assess": [44, 52, 72, 95, 139, 150, 152, 192, 220, 238, 257, 274, 275, 277, 281, 414, 423, 709, 751, 999, 1000, 1006, 1020, 1056], "assia": 1050, "assiaben": 1050, "assign": [47, 55, 58, 70, 72, 81, 84, 92, 93, 95, 139, 144, 156, 158, 170, 172, 178, 233, 238, 247, 252, 255, 272, 314, 321, 326, 336, 343, 356, 361, 381, 386, 388, 400, 413, 420, 421, 423, 424, 425, 426, 448, 449, 450, 451, 453, 454, 455, 456, 457, 460, 462, 464, 467, 468, 469, 470, 523, 544, 569, 570, 601, 602, 615, 616, 618, 666, 667, 674, 675, 676, 684, 685, 686, 712, 713, 723, 724, 725, 728, 737, 738, 739, 746, 747, 751, 763, 765, 791, 792, 794, 795, 801, 802, 803, 808, 811, 812, 814, 817, 822, 831, 833, 834, 835, 836, 839, 856, 862, 864, 865, 866, 879, 907, 908, 912, 913, 914, 915, 916, 917, 918, 994, 996, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1010, 1013, 1024, 1025, 1034, 1041, 1046, 1048, 1049, 1058, 1059], "assign_label": [81, 416, 460, 470], "assist": [0, 386, 398, 415, 1010, 1023, 1024], "associ": [0, 50, 61, 62, 113, 139, 176, 191, 192, 224, 266, 272, 325, 338, 340, 360, 394, 416, 418, 420, 421, 423, 424, 434, 454, 457, 477, 478, 479, 480, 481, 482, 483, 484, 501, 502, 503, 532, 565, 569, 572, 613, 614, 638, 653, 666, 667, 674, 676, 682, 683, 684, 697, 703, 707, 739, 747, 830, 835, 855, 863, 877, 889, 901, 909, 918, 920, 922, 938, 999, 1000, 1003, 1010, 1013, 1024, 1033, 1041, 1053, 1057], "assum": [48, 70, 90, 92, 183, 188, 191, 192, 209, 220, 238, 247, 250, 257, 269, 278, 287, 319, 356, 362, 374, 385, 386, 388, 390, 392, 398, 399, 400, 403, 410, 413, 414, 416, 418, 420, 421, 423, 424, 426, 427, 432, 437, 445, 447, 452, 454, 458, 465, 471, 477, 478, 479, 480, 481, 482, 483, 484, 511, 516, 517, 540, 550, 556, 557, 569, 570, 575, 576, 595, 596, 597, 599, 628, 640, 651, 652, 654, 655, 660, 666, 667, 668, 669, 670, 674, 675, 676, 679, 680, 684, 685, 686, 689, 693, 695, 696, 700, 717, 730, 734, 743, 749, 764, 772, 777, 782, 786, 789, 808, 811, 812, 822, 848, 854, 855, 858, 860, 862, 863, 868, 879, 892, 960, 976, 977, 978, 990, 994, 996, 998, 999, 1000, 1002, 1003, 1005, 1006, 1007, 1010, 1014, 1016, 1047, 1053], "assume_cent": [69, 112, 418, 429, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488], "assume_finit": [373, 374, 476, 910], "assumpt": [32, 43, 48, 52, 62, 64, 71, 78, 111, 112, 128, 181, 185, 189, 191, 220, 222, 247, 274, 298, 319, 392, 398, 399, 403, 414, 416, 418, 420, 421, 424, 426, 455, 459, 461, 496, 511, 520, 540, 542, 549, 658, 662, 806, 808, 811, 812, 822, 849, 904, 905, 994, 996, 1000, 1001, 1002, 1003, 1005, 1006, 1007, 1010, 1013, 1016, 1021, 1048, 1054], "assur": [0, 400, 805, 806, 1048, 1049, 1050, 1051, 1052, 1053, 1054], "astel": 1049, "astolfi": 1041, "astrai": 400, "astro": [50, 183, 240, 266], "astroml": 1019, "astronom": 1018, "astronomi": 1019, "astropi": 386, "astyp": [43, 53, 72, 76, 79, 80, 88, 95, 97, 101, 114, 131, 149, 151, 167, 191, 193, 210, 211, 238, 243, 253, 257, 272, 289, 299, 326, 410, 424, 990, 996, 1048], "asv": 386, "asv_benchmark": 386, "aswathavicki": 1059, "asymmetr": [152, 222, 400, 1046], "asymmetri": [222, 360], "asymptot": [111, 112, 209, 373, 418, 482, 544, 738, 996, 999, 1051], "atag": 184, "atariah": 1050, "ateif": 1054, "atharva": 1055, "atheism": [57, 279, 342, 360, 361, 362, 381, 496, 1034], "atheist": 360, "athena": 1024, "ation": 424, "atla": [373, 384], "atleast_2d": [152, 388], "atmospher": 181, "atol": [388, 680, 682, 852, 853, 857], "atom": [128, 134, 421, 539, 545, 547, 550, 551, 553, 554, 661, 671, 692, 996, 1041, 1054], "atomic_benchmark": 49, "atomic_benchmark_estim": 49, "atomic_runtim": 49, "atsushi": [1053, 1054], "attach": [47, 360, 441, 857, 1042, 1052], "attack": [257, 381], "attalla": 1055, "attard": 1054, "attempt": [43, 89, 193, 216, 226, 273, 360, 373, 385, 400, 416, 428, 454, 458, 465, 472, 476, 639, 696, 697, 701, 826, 854, 855, 856, 858, 860, 862, 863, 864, 890, 892, 910, 932, 933, 996, 997, 1003, 1016, 1025, 1048, 1053, 1058], "attenberg": 424, "attend": 0, "attent": [394, 615, 616, 1014], "attenu": 176, "attia": 805, "attr": [47, 91], "attract": [427, 452, 994, 1003, 1019], "attractador": [1048, 1049], "attrgett": [601, 605], "attribut": [2, 47, 62, 68, 84, 105, 133, 137, 139, 146, 147, 150, 170, 174, 220, 228, 254, 268, 276, 277, 282, 290, 308, 312, 331, 353, 362, 368, 375, 379, 380, 381, 383, 386, 389, 393, 398, 410, 413, 414, 416, 417, 418, 419, 421, 423, 424, 425, 426, 431, 432, 433, 434, 435, 438, 439, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 515, 518, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 587, 588, 589, 596, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 625, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 705, 706, 708, 709, 710, 744, 803, 805, 806, 807, 808, 811, 812, 814, 822, 830, 831, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 927, 961, 984, 992, 994, 996, 1001, 1003, 1004, 1006, 1010, 1013, 1014, 1015, 1016, 1024, 1025, 1031, 1034, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "attributeerror": [417, 567, 585, 961, 1033, 1050, 1051, 1053, 1057, 1058], "attrselect": 1041, "atukorala": 1056, "atuo": [1057, 1058], "aubert": 1048, "auc": [2, 50, 62, 174, 220, 238, 257, 275, 278, 282, 285, 287, 288, 335, 414, 710, 716, 796, 1000, 1046, 1049, 1053], "auc_scor": [1041, 1043], "audio": [380, 511], "aufarkari": 1055, "aug": 1015, "augment": [2, 341, 638, 894, 1008, 1024], "augspurg": [1049, 1051], "august": [174, 383, 416, 519, 542, 1015, 1041, 1043, 1044, 1048, 1055], "aura": 1053, "auroc": 1000, "aur\u00e9lien": [1048, 1049, 1050, 1054, 1055], "austin": 1048, "australian": [155, 404], "author": [0, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 61, 62, 63, 64, 66, 68, 72, 74, 75, 77, 81, 82, 83, 87, 88, 89, 91, 92, 96, 100, 101, 102, 104, 105, 106, 108, 109, 115, 125, 127, 129, 130, 132, 135, 137, 140, 141, 142, 143, 144, 145, 151, 153, 154, 155, 159, 160, 174, 176, 177, 179, 180, 181, 182, 183, 185, 188, 197, 199, 200, 202, 204, 205, 207, 208, 209, 211, 212, 213, 214, 221, 222, 224, 225, 227, 228, 235, 236, 237, 240, 241, 242, 243, 245, 247, 250, 252, 253, 255, 257, 263, 265, 266, 272, 277, 279, 281, 282, 284, 291, 298, 299, 301, 304, 311, 312, 314, 317, 319, 320, 322, 323, 324, 338, 339, 340, 341, 343, 356, 360, 361, 362, 380, 386, 390, 394, 398, 400, 401, 420, 459, 542, 879, 992, 1019, 1044], "authorit": 401, "authorship": 390, "auto": [57, 69, 92, 93, 123, 174, 180, 203, 240, 245, 259, 299, 302, 307, 328, 329, 330, 331, 332, 333, 336, 345, 346, 352, 355, 362, 380, 381, 388, 423, 426, 427, 449, 452, 453, 454, 455, 457, 458, 460, 463, 464, 465, 467, 470, 504, 516, 517, 543, 546, 548, 549, 552, 555, 557, 565, 566, 569, 570, 571, 572, 573, 575, 601, 602, 605, 610, 615, 616, 637, 639, 640, 641, 643, 654, 655, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 680, 681, 682, 688, 689, 690, 692, 693, 695, 696, 697, 698, 699, 700, 701, 702, 703, 706, 708, 710, 807, 811, 812, 830, 852, 853, 854, 855, 856, 857, 858, 860, 861, 862, 863, 864, 865, 866, 869, 870, 885, 886, 893, 904, 905, 909, 912, 913, 914, 915, 916, 917, 918, 922, 923, 948, 949, 966, 969, 991, 994, 996, 997, 1003, 1010, 1019, 1043, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "auto_examples_jupyt": 189, "auto_examples_python": 189, "auto_viml": 1053, "auto_wrap_output_kei": 388, "autoclass": 383, "autocorrel": 420, "autolabel": 47, "autom": [279, 390, 404, 700, 989, 996, 997, 1000, 1019, 1024], "automat": [2, 43, 47, 51, 52, 64, 81, 98, 100, 105, 132, 155, 165, 173, 199, 223, 263, 264, 272, 276, 279, 319, 326, 329, 333, 342, 351, 353, 374, 381, 384, 386, 388, 390, 394, 400, 404, 410, 412, 416, 417, 418, 421, 423, 424, 425, 440, 458, 460, 464, 470, 472, 473, 475, 504, 507, 523, 546, 548, 549, 555, 557, 559, 565, 569, 572, 591, 596, 599, 602, 610, 651, 653, 654, 655, 660, 661, 666, 667, 668, 669, 670, 671, 674, 675, 676, 680, 682, 683, 684, 686, 689, 692, 695, 696, 699, 703, 810, 825, 828, 838, 848, 869, 870, 873, 874, 876, 885, 886, 893, 904, 905, 912, 913, 914, 917, 920, 922, 926, 938, 971, 974, 989, 991, 994, 999, 1004, 1010, 1014, 1016, 1019, 1020, 1029, 1041, 1044, 1045, 1046, 1052, 1055, 1056, 1057, 1058, 1059], "automl": [1000, 1019], "automobil": 1024, "autoregress": 381, "autoviml": 1019, "autoviz": 1053, "auxiliari": [188, 336, 384, 1024, 1056], "av": 1049, "avail": [0, 2, 44, 50, 51, 53, 76, 91, 92, 128, 147, 151, 155, 174, 176, 181, 185, 191, 192, 193, 209, 220, 228, 238, 241, 254, 257, 272, 275, 276, 281, 282, 285, 292, 304, 305, 306, 312, 324, 328, 329, 330, 331, 333, 334, 341, 343, 369, 373, 380, 381, 383, 384, 385, 386, 387, 391, 395, 399, 400, 404, 410, 413, 416, 417, 420, 421, 422, 423, 424, 425, 427, 455, 458, 459, 460, 461, 477, 478, 479, 480, 481, 482, 483, 484, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 516, 543, 557, 563, 564, 565, 566, 567, 568, 572, 573, 575, 576, 577, 578, 601, 602, 618, 619, 635, 640, 641, 655, 659, 661, 663, 665, 669, 671, 673, 676, 678, 679, 680, 681, 682, 683, 684, 697, 704, 707, 740, 741, 808, 811, 812, 822, 834, 835, 840, 841, 842, 843, 844, 845, 846, 858, 869, 870, 872, 879, 888, 891, 896, 900, 905, 956, 961, 990, 994, 997, 999, 1000, 1001, 1002, 1003, 1006, 1010, 1013, 1014, 1015, 1018, 1019, 1020, 1023, 1024, 1025, 1029, 1034, 1036, 1041, 1046, 1047, 1048, 1049, 1050, 1051, 1054, 1055, 1057], "available_if": [2, 91, 400, 1054, 1055, 1058], "avebedrm": [319, 381, 498], "aventi": 51, "aveoccup": [319, 330, 381, 498], "averag": [2, 43, 52, 62, 64, 72, 74, 75, 79, 87, 95, 97, 142, 143, 148, 152, 155, 156, 161, 162, 163, 174, 181, 193, 201, 209, 220, 227, 238, 257, 272, 281, 283, 286, 288, 292, 298, 319, 328, 334, 336, 342, 360, 369, 373, 381, 383, 388, 398, 413, 414, 418, 420, 424, 425, 427, 428, 445, 446, 449, 452, 453, 454, 455, 457, 498, 501, 502, 531, 539, 540, 541, 545, 546, 548, 549, 553, 554, 555, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 577, 578, 595, 602, 640, 641, 656, 666, 667, 674, 675, 677, 680, 682, 684, 685, 686, 688, 695, 708, 711, 712, 714, 715, 716, 721, 728, 729, 731, 733, 734, 736, 737, 738, 742, 743, 744, 746, 747, 748, 751, 753, 754, 756, 758, 759, 761, 764, 772, 789, 790, 791, 792, 793, 795, 796, 798, 799, 803, 804, 805, 806, 836, 839, 858, 878, 893, 986, 990, 995, 996, 1001, 1004, 1006, 1007, 1014, 1015, 1016, 1032, 1034, 1041, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1055, 1056, 1057, 1058, 1059], "average_bike_rent": 193, "average_coef_": 1052, "average_feature_effect": 360, "average_intercept_": 1052, "average_linkag": 79, "average_method": [416, 712, 765, 1049], "average_pr": 155, "average_precis": [285, 708, 715, 750, 1000], "average_precision_scor": [2, 285, 708, 714, 716, 790, 796, 1000, 1041, 1044, 1048, 1049, 1055, 1057], "average_week_demand": [43, 155], "averoom": [319, 330, 381, 498], "avg": [45, 68, 104, 171, 276, 317, 338, 339, 577, 712, 721, 830, 1000, 1030, 1034, 1057], "avg_dist": [75, 789], "avgclaim": 238, "avgclaimamount": 238, "avi": [1053, 1054], "avidar": 1057, "avinash": 1053, "avm19": [1055, 1056, 1058], "avoid": [43, 46, 51, 52, 79, 92, 97, 106, 144, 145, 150, 155, 192, 193, 222, 224, 229, 238, 243, 254, 257, 272, 273, 279, 283, 307, 309, 310, 323, 324, 335, 345, 346, 361, 374, 384, 386, 387, 388, 390, 391, 392, 398, 400, 401, 404, 410, 414, 416, 418, 420, 423, 424, 427, 448, 450, 452, 460, 470, 476, 501, 502, 503, 507, 516, 517, 542, 547, 551, 642, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 697, 699, 701, 703, 720, 800, 808, 809, 813, 819, 822, 833, 834, 835, 872, 875, 881, 882, 884, 889, 890, 891, 892, 895, 897, 898, 899, 900, 901, 902, 903, 905, 910, 949, 994, 997, 999, 1000, 1003, 1004, 1006, 1008, 1010, 1015, 1016, 1020, 1023, 1034, 1036, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "aw": 394, "awai": [62, 63, 64, 95, 111, 148, 176, 177, 181, 223, 272, 353, 354, 381, 414, 426, 636, 854, 855, 862, 863, 999, 1000, 1015, 1032], "await": 329, "awalei": 1049, "awar": [48, 54, 171, 185, 272, 346, 360, 384, 386, 388, 398, 401, 415, 420, 424, 575, 576, 656, 662, 663, 664, 666, 667, 677, 688, 858, 887, 1006, 1010, 1016, 1038, 1041, 1042, 1055], "awesom": 1024, "ax": [43, 44, 46, 47, 48, 49, 51, 52, 54, 62, 64, 66, 67, 68, 70, 75, 77, 78, 80, 88, 90, 91, 92, 99, 101, 106, 109, 113, 115, 118, 121, 123, 125, 131, 135, 139, 141, 144, 146, 149, 150, 155, 157, 158, 160, 161, 162, 179, 180, 185, 187, 191, 192, 193, 194, 195, 197, 199, 200, 203, 204, 209, 211, 212, 215, 217, 218, 220, 221, 222, 224, 225, 228, 229, 231, 233, 234, 235, 238, 240, 241, 242, 243, 244, 245, 248, 253, 257, 258, 260, 263, 265, 268, 272, 273, 274, 275, 278, 280, 281, 282, 284, 285, 287, 288, 289, 290, 292, 293, 296, 298, 299, 301, 302, 303, 304, 307, 309, 310, 314, 315, 316, 319, 321, 322, 323, 324, 325, 326, 328, 329, 332, 333, 335, 345, 346, 347, 348, 350, 351, 353, 355, 356, 357, 358, 360, 361, 362, 364, 365, 388, 389, 421, 426, 446, 542, 549, 558, 639, 640, 705, 706, 708, 709, 710, 726, 814, 831, 926, 1000, 1003, 1007, 1033, 1038, 1051, 1057], "ax0": [107, 109, 220, 250, 361, 1030], "ax1": [46, 49, 92, 95, 100, 102, 107, 109, 113, 123, 149, 188, 195, 220, 248, 250, 258, 263, 281, 289, 320, 324, 325, 341, 360, 361, 1030], "ax2": [46, 92, 95, 100, 102, 113, 123, 149, 188, 195, 220, 248, 258, 263, 281, 289, 309, 320, 324, 325, 341, 360], "ax3": [100, 341], "ax4": 100, "ax_": [156, 271, 281, 285, 287, 294, 302, 324, 328, 393, 446, 639, 705, 706, 708, 709, 710, 814, 831], "ax_bc": 323, "ax_bottom": 393, "ax_calibration_curv": [62, 64], "ax_colorbar": 319, "ax_det": 275, "ax_histi": 319, "ax_histx": 319, "ax_histx_zoom": 319, "ax_histy_zoom": 319, "ax_idx": 280, "ax_origin": 323, "ax_qt": 323, "ax_roc": 275, "ax_row": 70, "ax_scatt": 319, "ax_scatter_zoom": 319, "ax_top_left": 393, "ax_top_right": 393, "ax_yj": 323, "ax_zoom_in": 319, "ax_zoom_out": 319, "axa": 0, "axarr": [161, 319], "axes_": [155, 157, 258, 329, 335, 393, 640], "axes_idx": 323, "axes_list": 323, "axes_row": 211, "axesimag": 705, "axhlin": [132, 165, 210, 277, 281], "axi": [2, 43, 44, 46, 50, 51, 53, 54, 55, 57, 62, 63, 72, 74, 75, 82, 83, 85, 87, 88, 89, 90, 96, 105, 106, 109, 115, 118, 122, 123, 125, 126, 127, 128, 129, 134, 141, 142, 146, 148, 156, 159, 163, 167, 170, 180, 185, 187, 191, 192, 201, 205, 207, 209, 212, 213, 214, 220, 225, 229, 232, 234, 235, 237, 238, 241, 242, 245, 247, 251, 252, 256, 263, 265, 267, 268, 274, 275, 279, 280, 285, 287, 288, 298, 299, 304, 305, 306, 309, 310, 311, 317, 319, 323, 326, 335, 339, 341, 343, 345, 348, 349, 352, 354, 355, 356, 358, 360, 361, 365, 366, 367, 368, 381, 388, 395, 400, 414, 416, 424, 428, 446, 453, 472, 475, 539, 541, 544, 545, 547, 549, 551, 553, 554, 558, 593, 620, 639, 640, 693, 694, 709, 771, 787, 788, 789, 790, 814, 831, 840, 881, 882, 889, 890, 892, 897, 898, 899, 901, 902, 903, 926, 928, 932, 933, 951, 975, 981, 990, 1000, 1007, 1010, 1015, 1031, 1033, 1049, 1051, 1053, 1058, 1059], "axis_idx": 43, "axis_list": 127, "axp": 51, "axvlin": [88, 95, 107, 115, 132, 151, 162, 192, 194, 195, 209, 284, 292, 356, 1030], "ayako": 1053, "ayan": 1055, "ayc\u0131": 1059, "aydor": [1048, 1049, 1052], "ayerdi": 1045, "aymer": 1042, "aymericbasset": 1057, "ayomid": 1051, "ayush": [1049, 1054], "ayzenshtat": [1024, 1049], "azaria": [1056, 1057], "azencott": 1055, "azim": [80, 102, 121, 131, 193, 217, 240, 244], "azur": [0, 386], "b": [0, 2, 47, 49, 61, 63, 94, 100, 113, 132, 141, 142, 148, 152, 153, 163, 165, 177, 178, 179, 184, 188, 202, 204, 205, 220, 221, 226, 238, 255, 257, 272, 277, 281, 283, 288, 293, 298, 331, 341, 369, 381, 383, 386, 390, 391, 392, 413, 414, 416, 419, 420, 421, 424, 445, 490, 506, 508, 549, 574, 596, 597, 598, 599, 615, 616, 618, 619, 636, 654, 655, 656, 657, 666, 677, 680, 682, 684, 688, 695, 696, 713, 727, 738, 739, 800, 801, 819, 820, 859, 885, 886, 887, 888, 891, 892, 900, 927, 934, 949, 950, 963, 965, 990, 992, 996, 997, 998, 1000, 1003, 1005, 1010, 1014, 1015, 1029, 1041, 1049, 1052, 1054, 1055, 1056], "b0noi": 1047, "b0rxington": 1056, "b1": [234, 305, 348], "b12": [220, 238], "b1996": 423, "b1998": 423, "b1999": 423, "b2": [234, 305, 348], "b2001": 423, "b2011": 416, "b2c": 1024, "b30065": 321, "b5": 333, "b7a2ff": 323, "b_1": 1004, "b_2": 1004, "b_column": 727, "b_i": 1005, "b_iv_i": 1005, "b_j": 416, "b_k": 416, "b_mask": 287, "b_row": 727, "b_true": 287, "ba": [51, 869, 870, 1004], "baak": 1055, "baam": [1054, 1055], "babino": [1054, 1055], "bac": 51, "bach": [421, 539, 544, 545, 546, 666, 996], "bachant": 1048, "back": [43, 130, 259, 374, 384, 386, 388, 400, 401, 410, 417, 424, 441, 451, 454, 455, 467, 490, 491, 492, 516, 517, 541, 542, 543, 546, 548, 549, 552, 589, 638, 666, 667, 674, 675, 676, 684, 685, 686, 736, 877, 879, 880, 881, 885, 886, 887, 889, 890, 892, 904, 905, 912, 996, 1000, 1004, 1020, 1025, 1034, 1044, 1049, 1051, 1052, 1055], "backend": [2, 374, 389, 400, 476, 910, 966, 970, 1000, 1044, 1049, 1050, 1051, 1052], "background": [44, 50, 82, 101, 156, 317, 321, 381, 386, 394, 416, 501, 502, 997, 1005, 1014, 1051], "background_point": 50, "backlink": 1046, "backport": [390, 395, 1048], "backprop": [1004, 1014], "backpropag": 1004, "backslash": 1056, "backtick": [386, 391], "backup": [516, 1041], "backward": [174, 254, 330, 389, 400, 425, 504, 585, 610, 622, 623, 626, 627, 628, 630, 631, 925, 928, 1004, 1020, 1041, 1044, 1049, 1050, 1051, 1053, 1055, 1057], "bad": [80, 95, 96, 177, 192, 272, 336, 360, 369, 386, 416, 426, 700, 754, 989, 996, 997, 1002, 1008, 1033, 1041], "badaracco": 1054, "badli": [209, 220, 360, 375, 892, 996, 1010], "badr": 1056, "baeza": [598, 738, 1044], "bag": [2, 14, 64, 104, 127, 138, 143, 145, 153, 154, 189, 194, 296, 361, 362, 382, 414, 524, 525, 526, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 749, 813, 838, 921, 998, 1001, 1021, 1022, 1036, 1041, 1043, 1044, 1045, 1046, 1047, 1054, 1055, 1057], "bagai": 1054, "baggingclassifi": [2, 400, 407, 423, 564, 922, 941, 990, 1044, 1047, 1048, 1049, 1052, 1056, 1057, 1059], "baggingregressor": [2, 142, 407, 423, 563, 923, 990, 1044, 1047, 1049, 1052, 1056, 1057, 1059], "baharev": 1046, "bahavior": 360, "bahaviour": 360, "baibak": [1049, 1050], "bail": 1052, "bailei": [416, 712], "bajic": 1056, "baji\u0107": 1056, "bakir2003": 421, "bakiri": [842, 1001], "bak\u0131r": [44, 421, 543], "bala": [1041, 1044], "balakumaran": [1048, 1049], "balanc": [2, 43, 45, 52, 64, 88, 101, 106, 139, 145, 150, 173, 189, 224, 225, 270, 276, 279, 281, 282, 292, 319, 375, 398, 400, 414, 415, 420, 421, 423, 510, 523, 542, 548, 549, 555, 565, 569, 572, 648, 666, 667, 674, 676, 682, 683, 684, 711, 716, 737, 751, 790, 795, 808, 809, 826, 872, 912, 914, 917, 920, 922, 937, 938, 989, 1015, 1016, 1021, 1030, 1041, 1043, 1046, 1047, 1050, 1051, 1055], "balanced_accuraci": [292, 716, 830, 1000, 1049], "balanced_accuracy_scor": [2, 711, 795, 1000, 1049], "balanced_subsampl": [565, 572, 1049], "balaz": [61, 1045], "baldi": 751, "ball": [104, 304, 312, 416, 422, 456, 700, 852, 853, 857, 860, 862, 863, 864, 1041, 1043, 1046, 1052], "ball_tre": [312, 427, 452, 454, 458, 465, 696, 697, 854, 855, 856, 857, 858, 860, 862, 863, 864, 1003, 1041, 1058], "balltre": [2, 427, 452, 454, 458, 465, 696, 697, 707, 854, 855, 856, 857, 858, 860, 862, 863, 864, 997, 1041, 1043, 1045, 1049, 1054, 1057, 1058], "baloo": 997, "baluyot": 1050, "bamidel": 1051, "banana": [48, 1000], "band": [52, 281, 321, 1010], "bandit": 989, "bandol": 325, "bandwidth": [2, 48, 79, 98, 253, 303, 304, 312, 398, 400, 416, 422, 456, 466, 469, 852, 853, 857, 993, 1006, 1052, 1056], "bandwidth_": 857, "bangda": 1049, "banik": 1059, "banilo": [1045, 1046], "bank": [51, 57, 1024], "bannerje": [1057, 1058], "bansal": 1048, "bansod": [1046, 1047, 1048], "bao": [1047, 1055], "baod": 416, "baptbillard": 1054, "baptist": [1044, 1052], "bar": [47, 49, 54, 106, 145, 146, 149, 150, 153, 162, 170, 174, 184, 187, 193, 199, 263, 268, 277, 279, 283, 298, 324, 325, 332, 333, 361, 388, 419, 589, 640, 656, 677, 688, 1000, 1007, 1014, 1016, 1047, 1048, 1049, 1050], "bar_color": 47, "bar_kw": 640, "bar_siz": 360, "baran": 1051, "barang": 1057, "baraniuk": 425, "barankaraku": 1053, "barata": 1057, "barber": 540, "barberogaston": 1053, "bardiya": [1055, 1056], "bare": [381, 997, 1034], "barh": [54, 153, 187, 188, 191, 192, 194, 195, 261, 326, 360, 361, 362], "barikbin": 1057, "barkhorn": 1049, "barklei": 1051, "barmalei": [1045, 1046], "barn": [700, 997, 1046, 1048, 1051, 1059], "barnes_hut": [299, 700, 1048, 1049], "barnett": 1049, "barnhil": [601, 602], "barnowski": [1055, 1056], "barreca": [893, 1010], "barreto": 1055, "barri": [381, 1049], "barrier": 424, "barrycg": 1051, "bars_": 640, "bartelheim": 1052, "barth\u00e9lemi": [1057, 1058], "bartosz": 1050, "bart\u0142omiej": 1056, "barycent": [311, 1041], "basbug": 1048, "base": [2, 14, 19, 23, 30, 31, 32, 34, 40, 44, 51, 52, 53, 54, 55, 58, 62, 63, 64, 70, 84, 91, 92, 93, 102, 104, 105, 109, 113, 121, 125, 126, 137, 139, 140, 145, 150, 151, 152, 153, 155, 158, 160, 163, 168, 171, 172, 176, 181, 182, 184, 191, 193, 194, 195, 198, 199, 205, 206, 208, 209, 214, 215, 220, 221, 228, 237, 238, 240, 247, 254, 255, 257, 275, 276, 281, 296, 298, 299, 312, 317, 319, 320, 322, 324, 330, 332, 336, 343, 347, 353, 361, 364, 373, 374, 380, 381, 382, 383, 384, 387, 388, 389, 394, 398, 400, 401, 403, 410, 414, 415, 417, 421, 422, 424, 426, 427, 428, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 452, 454, 455, 456, 457, 458, 460, 464, 465, 469, 471, 472, 473, 474, 475, 495, 508, 509, 516, 517, 540, 541, 543, 544, 545, 546, 547, 549, 554, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 586, 596, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 615, 616, 618, 619, 624, 625, 626, 629, 632, 640, 641, 643, 644, 652, 653, 654, 655, 656, 658, 659, 660, 661, 662, 663, 664, 666, 672, 677, 679, 680, 681, 682, 683, 688, 690, 691, 693, 694, 695, 698, 700, 712, 725, 734, 743, 744, 745, 747, 749, 763, 764, 765, 793, 796, 803, 807, 808, 810, 811, 812, 814, 815, 817, 822, 826, 827, 828, 829, 836, 838, 842, 843, 846, 854, 855, 856, 858, 860, 862, 863, 864, 869, 870, 873, 874, 877, 884, 885, 887, 891, 892, 893, 901, 904, 905, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 935, 943, 969, 989, 991, 992, 994, 995, 997, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1024, 1029, 1034, 1036, 1037, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1059], "base_classifi": [341, 343, 1013], "base_clf": 445, "base_estim": [330, 388, 414, 561, 562, 563, 564, 843, 846, 909, 989, 1052, 1054, 1055, 1056, 1057], "base_estimator_": [561, 562, 563, 564, 565, 566, 571, 572, 573, 574, 618, 909, 1056], "base_estimator__": 1056, "base_lr": [298, 843], "base_model": 415, "base_x_test": 111, "base_x_train": 111, "basebag": [1047, 1049], "basebal": [57, 381], "basedecisiontre": [1049, 1050, 1053], "basedictionarylearn": 1041, "baseensembl": [1048, 1051], "baseestim": [2, 91, 137, 254, 299, 386, 399, 400, 426, 431, 433, 434, 438, 439, 440, 609, 640, 641, 941, 1041, 1048, 1051, 1053, 1055, 1056], "basegradientboost": 1042, "baselabelpropag": 1048, "baselibsvm": 1051, "baselin": [62, 139, 149, 152, 163, 174, 195, 199, 238, 272, 288, 298, 330, 361, 383, 416, 425, 559, 560, 642, 1000, 1003, 1034, 1057], "baseline_similar": 184, "baseline_similarity_bound": 184, "basemap": [50, 312], "basemixtur": [1049, 1050], "basemultilayerperceptron": [1049, 1051], "basenb": 1051, "baserandomproject": [904, 905], "basesearchcv": [1048, 1049], "basesgd": 1014, "basesgdclassifi": 1050, "baseshufflesplit": 1054, "bash": [374, 394], "bashrc": 394, "basi": [2, 43, 45, 53, 130, 176, 181, 183, 221, 272, 316, 331, 349, 353, 378, 384, 387, 416, 421, 423, 460, 542, 630, 640, 647, 699, 891, 998, 1010, 1015, 1022, 1029, 1030, 1033, 1036, 1049, 1051, 1054], "basic": [152, 175, 176, 181, 182, 185, 188, 189, 218, 292, 326, 354, 373, 375, 386, 388, 390, 398, 400, 416, 420, 421, 423, 619, 630, 908, 920, 921, 922, 923, 989, 990, 1003, 1014, 1018, 1019, 1020, 1021, 1024, 1032], "basicconfig": 125, "basil": 1048, "basis_1": 221, "basis_2": 221, "basri": 521, "bassett": 996, "bastiaan": [1042, 1043], "bastian": 1049, "bat": 384, "batch": [2, 47, 50, 99, 125, 129, 312, 332, 375, 395, 400, 424, 448, 450, 455, 457, 459, 461, 539, 541, 542, 544, 545, 546, 547, 548, 550, 551, 553, 554, 672, 693, 694, 813, 826, 827, 847, 848, 849, 850, 851, 869, 870, 881, 882, 892, 905, 952, 966, 1004, 1005, 1014, 1041, 1045, 1046, 1049, 1050, 1051, 1052, 1054, 1056, 1057], "batch_dict_estim": 125, "batch_pca_estim": 125, "batch_siz": [2, 54, 57, 77, 99, 125, 128, 129, 361, 421, 457, 542, 544, 545, 546, 547, 554, 868, 869, 870, 952, 953, 966, 1042, 1049, 1052, 1054, 1055], "batch_size_": 542, "batchkarov": [1042, 1046], "batiss": 1052, "batista": [1049, 1050, 1054], "batistaki": 416, "batoul": 1054, "battista": 1052, "batula": 1048, "bauk": [1049, 1050], "baum": 454, "baumgartn": 1048, "baxlei": 1048, "bay": [2, 32, 64, 67, 142, 158, 176, 209, 268, 280, 360, 381, 414, 421, 423, 424, 544, 557, 558, 664, 847, 848, 849, 850, 851, 893, 994, 995, 996, 1010, 1022, 1034, 1036, 1041, 1042, 1043, 1044, 1049, 1051, 1054, 1056], "bayer": [0, 1041, 1042, 1046, 1059], "bayesian": [2, 46, 64, 89, 100, 123, 188, 189, 198, 204, 208, 221, 226, 262, 264, 268, 269, 281, 289, 293, 304, 309, 320, 323, 324, 421, 445, 532, 536, 540, 619, 652, 653, 664, 665, 805, 806, 873, 875, 887, 892, 989, 1019, 1021, 1022, 1035, 1036, 1047, 1054], "bayesiangaussianmixtur": [2, 263, 264, 269, 806, 999, 1047, 1049, 1050, 1054, 1055, 1059], "bayesianridg": [2, 89, 187, 199, 200, 204, 330, 635, 652, 996, 1048, 1049, 1050, 1051, 1054, 1055, 1057, 1058], "baz": [388, 589], "baze": 1050, "bbbbbb": 99, "bbox": [48, 51, 70, 80, 131, 263, 264, 265, 268, 269, 321], "bbox_arg": 48, "bbox_to_anchor": [43, 72, 185, 283, 355], "bc": 323, "bcde": 149, "bcross_val": 1041, "bde": 149, "bdegraaff": 1056, "bdt": 141, "beach": 1049, "beam": [142, 1041], "bear": [423, 1019], "bearer": 1049, "beatrizsmg": 1053, "beauchamp": [1042, 1045], "beaugnon": 1051, "becam": [160, 401, 1049], "becaus": [43, 44, 52, 57, 62, 64, 75, 82, 85, 105, 115, 118, 139, 144, 147, 152, 155, 174, 177, 180, 183, 192, 193, 195, 200, 206, 213, 220, 224, 226, 228, 238, 253, 254, 264, 272, 275, 278, 279, 284, 298, 299, 315, 316, 317, 319, 323, 324, 325, 326, 340, 349, 353, 360, 361, 362, 364, 368, 369, 373, 374, 381, 388, 391, 394, 398, 399, 400, 407, 410, 413, 414, 415, 416, 417, 420, 421, 422, 423, 424, 426, 429, 439, 455, 456, 469, 473, 483, 490, 491, 492, 542, 544, 560, 562, 564, 566, 568, 570, 573, 576, 578, 615, 616, 619, 640, 641, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 677, 678, 680, 681, 684, 685, 686, 687, 688, 697, 707, 717, 720, 721, 729, 730, 731, 732, 754, 771, 793, 796, 802, 808, 822, 836, 840, 845, 846, 855, 858, 860, 862, 863, 864, 870, 881, 882, 890, 892, 893, 897, 898, 900, 901, 902, 903, 913, 915, 918, 921, 923, 964, 990, 992, 993, 994, 995, 996, 997, 998, 1000, 1001, 1003, 1005, 1007, 1010, 1015, 1016, 1024, 1033, 1047, 1048, 1050, 1051, 1052, 1053, 1055, 1057], "becker": [416, 1024, 1044, 1053], "becom": [85, 90, 92, 106, 113, 150, 192, 222, 224, 254, 257, 280, 299, 320, 324, 349, 353, 360, 369, 380, 386, 388, 390, 394, 400, 401, 416, 418, 423, 424, 426, 448, 458, 462, 463, 465, 561, 589, 596, 597, 599, 627, 635, 666, 667, 684, 686, 886, 912, 913, 919, 995, 996, 997, 999, 1003, 1010, 1015, 1032, 1034, 1042, 1049, 1050, 1053, 1054, 1055, 1056, 1058], "bednar": 1048, "bedroom": [319, 381], "been": [0, 43, 48, 63, 79, 88, 95, 114, 130, 137, 139, 174, 176, 181, 183, 192, 244, 247, 249, 254, 255, 276, 278, 284, 328, 329, 330, 331, 332, 334, 335, 336, 340, 360, 369, 374, 380, 381, 383, 384, 385, 386, 388, 390, 392, 394, 395, 398, 399, 400, 401, 407, 410, 413, 414, 415, 416, 418, 420, 421, 423, 426, 441, 445, 477, 479, 480, 482, 486, 495, 531, 542, 544, 557, 558, 575, 576, 589, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 619, 641, 642, 666, 667, 674, 675, 676, 681, 683, 684, 685, 686, 728, 786, 787, 788, 801, 808, 811, 812, 814, 822, 830, 831, 836, 837, 861, 909, 912, 990, 992, 993, 995, 996, 997, 1000, 1001, 1003, 1006, 1010, 1012, 1014, 1015, 1020, 1024, 1025, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "befor": [2, 47, 51, 62, 77, 104, 106, 109, 118, 150, 155, 160, 170, 183, 185, 186, 187, 189, 192, 193, 195, 201, 204, 208, 209, 213, 254, 272, 278, 285, 301, 302, 320, 323, 324, 326, 331, 352, 369, 373, 374, 381, 384, 386, 388, 389, 391, 392, 394, 395, 398, 400, 401, 403, 404, 410, 412, 414, 416, 417, 418, 420, 421, 423, 425, 428, 429, 451, 455, 456, 457, 467, 469, 473, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 490, 491, 492, 493, 498, 509, 542, 545, 546, 547, 548, 549, 552, 554, 555, 569, 570, 573, 575, 577, 578, 585, 596, 597, 599, 619, 635, 636, 638, 653, 674, 675, 676, 679, 684, 686, 695, 700, 702, 805, 806, 813, 814, 826, 827, 829, 834, 836, 838, 852, 853, 860, 861, 862, 863, 864, 867, 872, 873, 876, 879, 886, 890, 891, 892, 893, 897, 898, 900, 901, 902, 903, 909, 920, 921, 949, 984, 990, 996, 997, 1000, 1006, 1010, 1014, 1015, 1016, 1020, 1021, 1034, 1041, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "beforehand": [302, 1016], "begin": [57, 137, 174, 176, 273, 280, 298, 331, 360, 369, 386, 391, 392, 400, 413, 416, 423, 561, 562, 567, 569, 570, 674, 675, 684, 685, 686, 989, 992, 996, 1000, 1010, 1012, 1014, 1049, 1055, 1056], "beginn": 1020, "behav": [43, 51, 87, 92, 224, 272, 273, 319, 330, 349, 369, 386, 392, 399, 416, 417, 420, 892, 996, 1010, 1015, 1017, 1020, 1034, 1041, 1048, 1050, 1054, 1055], "behavior": [62, 72, 74, 87, 187, 189, 192, 193, 220, 238, 254, 269, 270, 272, 281, 283, 316, 317, 319, 321, 326, 349, 369, 374, 380, 383, 386, 388, 390, 394, 395, 400, 414, 415, 416, 420, 423, 424, 544, 559, 574, 674, 675, 676, 684, 685, 686, 707, 709, 737, 738, 791, 792, 795, 809, 810, 813, 825, 826, 827, 828, 829, 849, 885, 912, 913, 989, 996, 1000, 1001, 1006, 1010, 1015, 1021, 1024, 1025, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "behaviour": [74, 130, 155, 221, 222, 238, 351, 386, 400, 410, 416, 423, 567, 568, 572, 573, 610, 750, 809, 810, 813, 825, 826, 827, 828, 829, 910, 920, 921, 973, 989, 990, 1000, 1010, 1049, 1052, 1053, 1056, 1057], "behind": [37, 88, 113, 139, 296, 388, 390, 394, 418, 423, 999, 1003, 1012, 1057], "behrend": 1051, "behrouz": 1055, "behzad": 1047, "beier": 1052, "beimportantfew": 1027, "being": [61, 64, 70, 80, 87, 90, 115, 118, 121, 130, 139, 143, 155, 157, 176, 181, 194, 197, 214, 254, 257, 271, 278, 317, 323, 324, 349, 353, 360, 362, 384, 385, 386, 388, 390, 391, 398, 400, 401, 415, 416, 418, 420, 423, 424, 425, 426, 427, 429, 449, 450, 452, 453, 458, 464, 477, 483, 501, 531, 577, 648, 657, 664, 680, 682, 695, 698, 702, 720, 726, 742, 744, 791, 797, 805, 852, 853, 858, 860, 862, 863, 864, 887, 905, 950, 989, 990, 996, 999, 1000, 1003, 1006, 1007, 1010, 1012, 1014, 1015, 1016, 1041, 1042, 1047, 1048, 1049, 1050, 1052, 1053, 1055, 1056, 1057, 1058, 1059], "beings": 360, "beirouti": 1048, "belatedli": 1048, "belief": [57, 278, 868, 1005], "believ": [360, 361, 394, 398, 1024], "belkin": 997, "belkina": [700, 997], "bell": [2, 529, 1049, 1051, 1053, 1054], "bella": 1000, "bella2012": 1000, "bellet": [1048, 1049, 1050], "belmont": [920, 921, 1016], "belong": [61, 64, 66, 90, 95, 257, 278, 328, 334, 340, 380, 381, 413, 414, 416, 417, 419, 420, 423, 431, 448, 451, 455, 456, 457, 459, 461, 531, 720, 739, 815, 821, 833, 879, 893, 956, 957, 996, 999, 1000, 1002, 1003, 1004, 1006, 1015, 1019, 1025, 1032], "below": [0, 2, 48, 52, 62, 63, 64, 68, 70, 90, 95, 104, 109, 113, 120, 121, 125, 137, 143, 146, 147, 152, 169, 191, 193, 203, 216, 217, 220, 222, 236, 237, 241, 245, 249, 254, 257, 259, 261, 273, 276, 281, 283, 284, 285, 319, 323, 328, 329, 330, 331, 332, 333, 334, 335, 336, 354, 360, 368, 369, 374, 379, 380, 384, 386, 388, 390, 391, 395, 400, 401, 404, 416, 418, 419, 420, 421, 423, 424, 425, 426, 452, 454, 456, 479, 480, 486, 499, 500, 502, 503, 504, 505, 506, 508, 509, 510, 512, 513, 518, 539, 545, 550, 556, 590, 603, 604, 605, 606, 607, 608, 641, 654, 660, 666, 667, 675, 676, 681, 683, 700, 707, 713, 751, 771, 805, 806, 808, 819, 822, 841, 872, 875, 885, 886, 889, 895, 901, 989, 990, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1014, 1015, 1016, 1017, 1019, 1027, 1034, 1037, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1059], "beltran": 1059, "ben": [1043, 1044, 1045, 1048, 1049, 1050, 1053, 1058], "ben3940": 1055, "benavoli": 278, "benbihi": 1050, "bench_k_mean": 93, "benchmark": [299, 330, 361, 362, 373, 379, 381, 386, 398, 404, 409, 414, 476, 523, 910], "benchmark_estim": 49, "benchmark_influ": 46, "benchmark_throughput": 49, "bend": 353, "benedek": 1057, "benedikt": 1045, "benediktsson": [1041, 1042, 1043], "benefici": [106, 108, 111, 125, 158, 272, 319, 320, 336, 410, 415, 997], "benefit": [43, 81, 91, 108, 109, 139, 140, 150, 155, 192, 234, 244, 250, 252, 272, 301, 332, 373, 386, 395, 400, 414, 416, 456, 469, 476, 516, 575, 576, 666, 667, 674, 675, 676, 684, 685, 686, 843, 910, 912, 989, 995, 1003, 1010, 1020, 1024, 1041, 1044, 1045, 1046, 1053, 1054, 1055, 1056], "benfield": 1048, "bengio": [278, 869, 870, 989, 1013], "bengtsson": 1045, "benhel": 387, "benhur": 1054, "benign": [174, 383, 508], "benjamin": [649, 1043, 1044, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "benjamini": [603, 1047, 1048], "benjaminirv": 1046, "benjastudio": [1049, 1050], "benn": 1049, "bennett": [174, 383, 1000], "benni": 1055, "benoit": 1058, "beno\u00eet": 1054, "benson": 57, "bentlei": 1003, "bera": 1056, "berei": 1055, "beren": 700, "berenbaum": 1057, "bereng": 1054, "berg": [381, 1042, 1043, 1053, 1058], "bergman": [1058, 1059], "bergstra": [989, 1041, 1042], "berk": 1041, "berkecanrizai": 1056, "berkelei": [649, 920, 921], "berlin": [181, 416, 421, 543, 704, 734, 764, 1000], "bernardo": 1047, "bernd": 1056, "bernhard": [44, 421, 543, 843, 878, 908, 1001, 1006, 1015, 1047], "bernhardsson": 1024, "berni": 1052, "bernoulli": [2, 317, 424, 425, 847, 848, 849, 850, 851, 868, 869, 870, 875, 996, 1010, 1022, 1036, 1041], "bernoullinb": [2, 158, 375, 848, 849, 850, 851, 1001, 1002, 1042, 1043, 1045, 1048, 1053, 1054, 1056], "bernoullirbm": [2, 317, 869, 870, 1005, 1010, 1043, 1044, 1053, 1055, 1058], "bertin": 1024, "bertoncelj": 1052, "bertrand": [0, 405, 1041, 1047, 1048, 1053, 1054], "bertrandhaut": [1049, 1050], "besid": [160, 250, 292, 386, 391, 597, 989, 1049], "bessel": [426, 627], "bessi": 333, "besson": [1046, 1047], "best": [0, 43, 45, 47, 51, 52, 53, 57, 61, 63, 64, 75, 81, 89, 90, 96, 104, 105, 106, 107, 111, 117, 125, 129, 132, 133, 134, 142, 145, 149, 151, 152, 153, 155, 160, 163, 174, 176, 177, 182, 187, 192, 199, 204, 208, 209, 216, 234, 235, 236, 240, 243, 247, 252, 253, 257, 264, 265, 269, 271, 272, 276, 277, 278, 279, 282, 285, 286, 289, 290, 293, 298, 303, 308, 320, 325, 330, 331, 336, 349, 352, 353, 360, 361, 362, 367, 373, 374, 380, 383, 385, 386, 389, 392, 399, 400, 404, 407, 410, 413, 414, 415, 416, 420, 421, 423, 424, 425, 426, 439, 451, 454, 455, 457, 459, 460, 461, 467, 470, 473, 480, 490, 491, 492, 546, 553, 554, 560, 562, 564, 565, 566, 567, 568, 570, 572, 573, 574, 576, 578, 601, 602, 605, 610, 618, 619, 643, 645, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 667, 668, 669, 670, 671, 672, 673, 675, 677, 678, 679, 680, 681, 683, 684, 686, 687, 688, 696, 697, 698, 701, 702, 711, 716, 727, 728, 729, 730, 731, 732, 736, 737, 747, 748, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 764, 791, 792, 793, 795, 798, 799, 800, 801, 802, 804, 805, 806, 808, 811, 812, 822, 835, 837, 840, 845, 846, 855, 863, 869, 870, 913, 915, 918, 920, 921, 922, 923, 989, 994, 995, 996, 997, 1000, 1003, 1004, 1006, 1014, 1016, 1019, 1020, 1024, 1025, 1030, 1034, 1041, 1044, 1047, 1049, 1050, 1051, 1054, 1055, 1056, 1057, 1059], "best_alpha": [1032, 1041], "best_c": 356, "best_c_scal": 356, "best_clf": 107, "best_estim": [808, 811, 812, 822], "best_estimator_": [45, 89, 106, 107, 108, 111, 132, 253, 268, 272, 276, 278, 279, 282, 290, 303, 808, 811, 812, 822, 989, 1029, 1030, 1048], "best_idx": [57, 277], "best_index": [276, 282], "best_index_": [277, 282, 808, 811, 812, 822], "best_loss": [684, 686], "best_loss_": [869, 870, 1056], "best_low_complex": 277, "best_n_it": 467, "best_paramet": 279, "best_parameters_": 268, "best_params_": [105, 107, 152, 176, 253, 268, 276, 282, 330, 349, 399, 808, 811, 812, 822, 989, 1030, 1034], "best_recal": 276, "best_recall_std": 276, "best_recall_threshold": 276, "best_scor": 282, "best_score_": [105, 107, 253, 272, 279, 282, 283, 349, 415, 681, 683, 808, 811, 812, 822, 830, 1029, 1030, 1034, 1052], "best_score_idx": 277, "best_threshold_": [272, 292, 336, 830], "best_validation_score_": [869, 870, 1056], "beta": [2, 81, 117, 191, 224, 392, 414, 416, 419, 544, 546, 548, 555, 652, 737, 738, 744, 750, 791, 803, 805, 1000, 1032, 1043, 1046, 1048, 1050, 1051], "beta_": [224, 421], "beta_1": [869, 870], "beta_2": [869, 870], "beta_k": 421, "beta_loss": [54, 546, 548, 555, 1048], "betatim": [144, 159, 1056], "better": [43, 44, 48, 52, 57, 58, 61, 67, 85, 90, 108, 109, 111, 112, 113, 114, 118, 121, 125, 128, 142, 145, 150, 151, 152, 155, 160, 169, 180, 181, 182, 184, 187, 192, 194, 200, 204, 206, 209, 220, 221, 222, 228, 235, 237, 238, 244, 252, 253, 254, 257, 268, 271, 272, 278, 280, 281, 284, 287, 288, 296, 298, 317, 323, 324, 332, 333, 349, 356, 360, 361, 362, 364, 369, 373, 381, 385, 386, 387, 388, 390, 391, 392, 394, 400, 403, 412, 414, 416, 418, 420, 421, 422, 423, 424, 426, 457, 458, 546, 548, 555, 567, 568, 569, 570, 615, 616, 638, 679, 685, 700, 717, 733, 742, 747, 750, 771, 806, 837, 847, 848, 849, 850, 851, 852, 853, 858, 869, 870, 889, 890, 893, 901, 904, 905, 912, 913, 989, 990, 992, 993, 994, 996, 997, 999, 1000, 1002, 1003, 1004, 1008, 1010, 1013, 1014, 1016, 1020, 1024, 1027, 1029, 1034, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058], "better_prob": 278, "between": [2, 25, 37, 43, 44, 47, 48, 50, 51, 52, 58, 70, 72, 73, 74, 75, 77, 78, 88, 95, 96, 101, 117, 121, 128, 130, 133, 139, 142, 145, 149, 150, 152, 155, 169, 176, 181, 182, 184, 189, 191, 192, 193, 194, 199, 204, 206, 211, 215, 216, 220, 221, 222, 224, 225, 228, 238, 240, 247, 252, 254, 257, 270, 272, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 290, 292, 296, 298, 301, 305, 306, 308, 309, 319, 324, 326, 331, 336, 341, 349, 353, 355, 356, 360, 361, 362, 368, 369, 373, 374, 381, 386, 388, 395, 398, 399, 400, 401, 407, 410, 413, 415, 416, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 437, 448, 449, 452, 453, 454, 455, 458, 460, 461, 462, 464, 465, 466, 471, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 510, 522, 523, 529, 532, 535, 542, 543, 544, 545, 546, 547, 548, 549, 554, 555, 557, 558, 561, 562, 567, 568, 570, 571, 572, 573, 592, 596, 598, 599, 600, 601, 602, 603, 604, 606, 607, 608, 610, 612, 613, 614, 615, 616, 617, 619, 628, 635, 640, 641, 642, 647, 650, 653, 654, 655, 660, 661, 664, 665, 666, 667, 668, 669, 670, 671, 674, 675, 676, 678, 684, 686, 687, 689, 692, 696, 698, 700, 702, 703, 704, 707, 709, 711, 712, 713, 715, 717, 718, 722, 723, 724, 725, 727, 732, 733, 734, 737, 738, 739, 742, 744, 745, 751, 760, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 791, 792, 794, 795, 800, 801, 803, 804, 805, 806, 808, 809, 810, 811, 813, 817, 825, 826, 827, 828, 829, 837, 838, 840, 842, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 869, 870, 876, 879, 880, 882, 883, 885, 886, 889, 890, 891, 893, 898, 901, 902, 906, 912, 913, 917, 920, 921, 922, 923, 925, 946, 957, 958, 969, 989, 992, 994, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1017, 1020, 1021, 1032, 1033, 1041, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "bewar": 425, "beyond": [43, 64, 221, 222, 272, 373, 375, 385, 386, 398, 414, 423, 737, 738, 746, 791, 792, 795, 917, 997, 1001, 1010, 1015, 1020, 1049], "beyst": 1055, "bezuidenhout": 1054, "bf5fff": 123, "bfg": [315, 618, 619, 656, 657, 666, 677, 680, 682, 688, 695, 1003, 1004, 1056], "bgm": 805, "bharat": [420, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1059], "bharathi": 1052, "bhardwaj": [1048, 1049], "bhargav": 1047, "bhaskaran": [1048, 1049], "bhat": [1054, 1056, 1057, 1058], "bhattacharya": 1049, "bhattarai": 1051, "bhavika": 1053, "bhoomika": 1056, "bhsu": 1045, "bhtsne": [700, 1048], "bi": [90, 424], "bia": [43, 64, 111, 127, 138, 146, 147, 152, 155, 189, 192, 194, 199, 200, 202, 283, 314, 353, 356, 369, 381, 388, 400, 414, 418, 422, 423, 426, 532, 564, 567, 568, 615, 616, 622, 650, 656, 657, 666, 667, 677, 678, 688, 869, 870, 885, 887, 891, 897, 898, 900, 901, 902, 903, 921, 995, 996, 999, 1000, 1004, 1005, 1008, 1014, 1021, 1032], "bianca": 64, "bianp": 392, "bias": [48, 115, 128, 152, 159, 191, 192, 194, 283, 381, 403, 414, 423, 532, 557, 868, 892, 903, 995, 999, 1008, 1014, 1016], "bibhash": [1051, 1052], "bibl": 361, "bibliograph": 386, "bibtex": 0, "bic": [2, 165, 189, 198, 204, 206, 208, 214, 228, 425, 509, 659, 661, 662, 663, 664, 806, 873, 892, 989, 999, 1021, 1041, 1048, 1054, 1055], "bic_criterion": 208, "bicker": 1051, "biclust": [2, 6, 59, 104, 340, 342, 360, 361, 362, 424, 431, 457, 459, 461, 496, 519, 521, 599, 727, 803, 1000, 1021, 1035, 1036, 1043, 1047], "bicluster_ncut": 57, "biclustermixin": 2, "biclusters_": [58, 59, 431, 459, 461], "bidu": [1054, 1055], "biernat": 1053, "big": [43, 79, 95, 97, 225, 241, 257, 269, 374, 386, 392, 401, 418, 424, 428, 546, 569, 570, 572, 573, 814, 836, 847, 848, 849, 850, 851, 1020, 1024, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "bigg": [426, 627], "bigger": [47, 75, 95, 233, 278, 317, 353, 358, 361, 372, 374, 424, 446, 447, 516, 546, 858, 1029, 1036], "biggest": [416, 419, 421, 451], "biggest_inertia": [416, 451], "biggio": 1052, "bigram": [279, 424, 596, 597, 599, 1034], "bigram_vector": 424, "bijil": 1055, "bike": 1007, "bike_shar": [43, 52], "bike_sharing_demand": [43, 52, 193], "bilbro": 1048, "bill": [1051, 1052], "billaud": 1049, "billi": 1045, "billing": [1044, 1045, 1046], "billion": 1024, "bimod": [323, 422], "bin": [2, 43, 61, 62, 64, 88, 109, 141, 145, 220, 251, 257, 272, 284, 304, 319, 320, 321, 322, 323, 325, 326, 384, 394, 404, 414, 422, 423, 446, 447, 456, 469, 569, 570, 875, 877, 891, 951, 1033, 1049, 1050, 1051, 1055, 1059], "bin_cent": [88, 220], "bin_edg": 88, "bin_edges_": [88, 320, 877], "bin_seed": [79, 98, 456, 469, 1052], "binar": [2, 36, 285, 287, 288, 378, 380, 762, 847, 876, 877, 879, 883, 885, 893, 896, 1000, 1002, 1025, 1036, 1055, 1057], "binari": [2, 30, 47, 53, 62, 64, 143, 145, 156, 158, 171, 184, 192, 197, 211, 213, 220, 228, 241, 248, 257, 260, 272, 275, 276, 281, 287, 292, 294, 296, 303, 349, 353, 368, 369, 380, 381, 382, 388, 390, 391, 400, 404, 410, 413, 414, 415, 416, 423, 424, 426, 445, 446, 447, 460, 495, 508, 516, 517, 528, 531, 557, 558, 561, 563, 567, 569, 574, 575, 576, 589, 596, 597, 599, 601, 602, 610, 618, 635, 636, 637, 638, 639, 640, 641, 666, 667, 674, 676, 681, 682, 683, 684, 708, 711, 715, 716, 717, 720, 721, 723, 726, 728, 730, 735, 737, 738, 742, 743, 746, 747, 748, 749, 750, 751, 790, 791, 792, 795, 796, 797, 802, 804, 807, 808, 809, 811, 812, 813, 814, 822, 826, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 847, 858, 868, 879, 883, 885, 893, 896, 912, 914, 917, 963, 990, 1001, 1002, 1003, 1004, 1005, 1007, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1025, 1038, 1042, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1055, 1056, 1058, 1059], "binary_crossentropi": 1055, "binary_eros": 53, "binary_onli": [388, 1051, 1052], "binarytre": [857, 1045, 1049, 1053], "bincount": [400, 420, 565, 569, 572, 666, 667, 674, 676, 682, 683, 684, 912, 914, 917, 920, 922, 937, 938, 1048], "bind": [404, 1019, 1041, 1048, 1049], "binder": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368], "binesh": [1057, 1058], "binet": [1051, 1056], "bing": [1047, 1048], "bingham": 1012, "binned_numer": [220, 238], "binom": 996, "binomi": [151, 154, 423, 561, 567, 569, 996, 1055, 1058], "bio": 281, "bioinformat": [636, 990], "biologi": 50, "biometrika": [888, 900], "biostatist": [418, 486], "bipartit": [413, 461, 519, 1005], "biprateep": 1053, "birch": [2, 71, 79, 99, 122, 189, 332, 375, 400, 454, 457, 520, 1021, 1035, 1036, 1045, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058], "birch_model": 77, "bird": [590, 726, 762, 1000], "birodkar": [1046, 1047, 1049], "bischl": 380, "bisect": [2, 71, 75, 92, 94, 95, 96, 185, 189, 274, 451, 455, 520, 1021, 1055], "bisect_km": 332, "bisect_mean": 451, "bisecting_strategi": [416, 451], "bisectingkmean": [2, 78, 416, 1055, 1056, 1057], "bisector": 70, "bishop": [540, 542, 549, 749, 805, 996, 1001, 1015], "bistochast": [413, 459], "biswadip": 1051, "biswaroop": 1056, "bit": [43, 52, 64, 83, 88, 111, 128, 218, 222, 296, 319, 349, 361, 369, 373, 381, 384, 400, 404, 423, 424, 590, 597, 666, 842, 932, 933, 997, 1001, 1018, 1027, 1034, 1041, 1044, 1047, 1049, 1050, 1053, 1054, 1055, 1058, 1059], "bithash": 648, "bithash_": 648, "bitli": 1024, "bitmap": 383, "bittarello": 1054, "bjerr": 1049, "bla": [373, 374, 384, 387, 392, 786, 1041, 1049, 1050, 1052, 1053, 1059], "black": [43, 48, 49, 50, 52, 63, 70, 79, 84, 90, 91, 113, 114, 123, 125, 148, 169, 172, 176, 177, 181, 182, 185, 188, 192, 193, 199, 208, 209, 210, 212, 216, 220, 221, 222, 226, 229, 232, 233, 238, 247, 257, 263, 266, 304, 314, 315, 317, 343, 358, 365, 366, 367, 386, 404, 409, 416, 423, 426, 563, 564, 639, 1006, 1007, 1016, 1019, 1025], "blackberri": 325, "blackburn": [1044, 1047], "blackd0t": 1051, "blair": [45, 381], "blakeflei": 1047, "blame": 386, "blanc": 325, "blanchard": [1045, 1046], "blank": [95, 391, 990, 1016], "bldgtype": 149, "bleed": 1024, "blei": [421, 544, 805], "bleich": [193, 1007], "bleki": 1053, "blend": [148, 160, 325, 400, 420, 1019], "bli": [374, 384, 398], "blind": [124, 127, 189, 219, 360, 421, 541, 549, 1021], "blindli": 390, "blink": 349, "blis_num_thread": 374, "blob": [2, 61, 69, 70, 77, 79, 92, 97, 99, 122, 416, 456, 520], "blobs_param": 247, "block": [2, 304, 319, 332, 381, 383, 386, 391, 394, 400, 413, 416, 419, 422, 460, 461, 470, 481, 487, 488, 496, 497, 519, 521, 703, 1003, 1005], "block_siz": [481, 487, 488, 1045], "blocker": [390, 1059], "blocknum": 47, "blockwis": [413, 996], "blog": [332, 373, 386, 392, 394, 401, 1052], "blogpost": 391, "blondel": [0, 61, 83, 130, 211, 221, 241, 255, 279, 360, 406, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1054], "blood": [174, 248, 383, 1032], "bloom": [395, 965], "blown": 352, "blue": [46, 48, 52, 58, 59, 63, 70, 113, 123, 125, 139, 142, 146, 154, 155, 157, 160, 162, 172, 181, 183, 197, 200, 208, 209, 216, 218, 243, 251, 271, 272, 273, 278, 315, 324, 329, 335, 340, 383, 416, 421, 1058], "blueviolet": [234, 305, 348], "blum": 1048, "blyston": [1051, 1052], "bmaisonn": 1053, "bmalezieux": 1054, "bmatrix": [413, 992], "bmc": 1010, "bmi": [174, 208, 209, 258, 383, 1008], "bmreinig": 1055, "bmug": 57, "bmva": 679, "bmvc": [679, 996], "bo": [63, 1053], "board": 0, "boat": 333, "bob": [1042, 1048], "bobyrev": 1048, "boca": 996, "bodega": 325, "bodenhof": [413, 727], "bodi": [47, 104, 174, 258, 333, 383], "body_bow": 104, "body_stat": 104, "boe": 51, "boechat": 1048, "boenisch": 1052, "boerner": 1055, "boersma": 1047, "bogazici": 383, "bogdan": 1041, "boggavarapu": 1053, "bohl": [1053, 1055], "bohn\u00e9": 1054, "boil": [139, 389, 400, 418], "boilerpl": [254, 388, 1024, 1034], "boisberrang": [0, 405, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "bold": [95, 152, 209, 215, 386], "boll": 996, "bolmier": [1052, 1053, 1057], "boltzmann": [2, 107, 117, 189, 210, 313, 510, 666, 721, 838, 868, 869, 870, 872, 898, 1021, 1035, 1036, 1043], "bommarito": [1044, 1045], "bonald": 1056, "bone": [233, 358], "bonferroni": 278, "bonn": [108, 143, 211, 252, 340, 356], "bonu": [238, 384, 386, 1029, 1034], "bonusmalu": [220, 238], "boo": [174, 383], "book": [83, 104, 451, 455, 457, 842, 847, 851, 996, 997, 998, 1001, 1053], "booktitl": 0, "bool": [84, 101, 114, 188, 238, 368, 386, 428, 429, 430, 431, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 467, 469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 516, 517, 518, 519, 520, 521, 522, 523, 527, 530, 531, 532, 535, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 702, 703, 705, 706, 708, 710, 711, 715, 716, 717, 719, 720, 721, 722, 734, 735, 736, 737, 738, 739, 746, 749, 750, 758, 759, 762, 764, 769, 771, 775, 777, 782, 786, 790, 791, 792, 793, 795, 797, 802, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 822, 826, 827, 830, 831, 832, 835, 836, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 928, 930, 931, 932, 933, 943, 949, 950, 962, 965, 971, 973, 981, 986, 987, 988, 990, 1050, 1053, 1054], "bool_": 222, "boolean": [2, 137, 254, 368, 381, 386, 388, 395, 417, 423, 424, 425, 472, 569, 570, 589, 590, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 615, 616, 637, 640, 641, 644, 657, 679, 707, 786, 841, 847, 868, 875, 895, 928, 984, 990, 996, 1002, 1007, 1010, 1016, 1041, 1044, 1046, 1047, 1048, 1050, 1051, 1052, 1054, 1055, 1056, 1059], "boom": 1059, "boost": [2, 14, 46, 52, 105, 138, 139, 140, 143, 144, 146, 147, 157, 160, 163, 189, 195, 200, 222, 228, 243, 277, 279, 315, 323, 325, 332, 335, 387, 392, 400, 415, 425, 456, 474, 475, 498, 504, 509, 528, 561, 562, 567, 568, 569, 570, 572, 573, 640, 641, 642, 643, 749, 750, 756, 758, 798, 808, 811, 812, 813, 829, 835, 838, 873, 885, 886, 996, 1000, 1019, 1021, 1022, 1036, 1041, 1042, 1044, 1046, 1047, 1048, 1050, 1054], "booster": 1046, "boosting_error": 139, "boostingdecis": 423, "booth": 1048, "bootstrap": [142, 143, 151, 187, 281, 290, 330, 420, 423, 562, 563, 564, 565, 566, 571, 572, 573, 938, 971, 996, 1041, 1042, 1044, 1046, 1049, 1051, 1054], "bootstrap_featur": [423, 563, 564], "bootstrap_indic": 281, "borchmann": 1056, "border": [454, 1051], "borderaxespad": 113, "borderpad": 365, "borderwidth": 145, "borg": [698, 702, 997], "borgn": 1054, "bori": [1045, 1053, 1057], "borja": 1045, "born": 1047, "borovec": 1055, "borovikova": 1052, "bosch": 1054, "bossan": [1053, 1055, 1056, 1057, 1059], "bossch": [0, 405, 1048, 1049, 1050, 1054], "boston": 1024, "bot": [390, 1005, 1055, 1058, 1059], "botelho": 1053, "both": [30, 43, 44, 46, 48, 49, 52, 54, 58, 62, 63, 64, 70, 77, 89, 90, 99, 105, 111, 113, 117, 118, 130, 132, 137, 142, 145, 146, 149, 150, 155, 159, 160, 163, 169, 170, 172, 174, 176, 183, 185, 191, 192, 193, 194, 199, 204, 206, 208, 209, 220, 221, 222, 224, 225, 226, 228, 238, 244, 253, 254, 255, 263, 264, 265, 266, 267, 268, 272, 278, 279, 280, 281, 285, 287, 289, 294, 299, 311, 319, 323, 324, 328, 330, 334, 340, 341, 346, 351, 353, 360, 361, 362, 368, 369, 373, 374, 375, 379, 380, 381, 382, 384, 386, 388, 392, 393, 395, 398, 399, 400, 401, 404, 407, 410, 412, 413, 414, 416, 417, 418, 419, 420, 421, 423, 424, 426, 429, 445, 454, 460, 470, 476, 483, 490, 491, 492, 493, 496, 497, 504, 505, 508, 510, 513, 515, 516, 517, 542, 546, 548, 555, 559, 563, 564, 565, 571, 572, 573, 574, 575, 585, 596, 597, 599, 605, 615, 616, 635, 640, 641, 651, 665, 666, 667, 680, 682, 684, 686, 695, 707, 712, 720, 724, 737, 738, 739, 744, 746, 765, 769, 775, 782, 786, 791, 792, 795, 796, 797, 803, 811, 812, 814, 831, 841, 869, 870, 884, 886, 888, 900, 905, 910, 912, 913, 920, 922, 936, 941, 950, 963, 975, 989, 990, 991, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1019, 1020, 1024, 1029, 1033, 1034, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "botstein": [636, 990], "bottleneck": [373, 392, 423, 456, 869, 870], "bottom": [45, 47, 51, 53, 54, 70, 72, 74, 77, 79, 80, 86, 88, 97, 99, 122, 123, 150, 158, 163, 220, 231, 247, 263, 265, 266, 269, 275, 278, 289, 304, 319, 339, 341, 349, 386, 414, 416, 422, 595, 924, 994, 996, 1000, 1008, 1020, 1030, 1033], "bottom_h": 319, "bottou": [684, 685, 686, 1004, 1014], "bou": [1056, 1057], "boucaud": 1049, "boucher": 1048, "bouckaert": 278, "boukhobza": 1059, "boulard": 1058, "bould": 416, "bouldin": [2, 733], "boulogn": 1044, "boun": 383, "bound": [2, 64, 90, 180, 182, 184, 189, 222, 238, 246, 277, 393, 416, 421, 424, 426, 427, 452, 497, 510, 520, 531, 544, 603, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 640, 643, 645, 658, 662, 666, 685, 713, 743, 796, 805, 806, 852, 853, 889, 901, 904, 905, 906, 914, 915, 916, 919, 936, 996, 999, 1000, 1003, 1012, 1014, 1015, 1017, 1021, 1049, 1052, 1053, 1055], "bound_": 544, "boundari": [2, 50, 53, 62, 63, 64, 67, 70, 93, 95, 138, 141, 148, 158, 162, 167, 177, 178, 180, 189, 193, 203, 221, 229, 247, 252, 255, 281, 293, 294, 307, 309, 310, 312, 314, 319, 321, 324, 337, 342, 344, 346, 347, 348, 349, 351, 357, 358, 365, 382, 414, 423, 424, 426, 458, 464, 512, 544, 557, 558, 577, 596, 597, 599, 639, 743, 769, 808, 841, 854, 860, 862, 863, 864, 887, 891, 908, 909, 914, 916, 917, 920, 936, 994, 1003, 1006, 1010, 1013, 1014, 1015, 1021, 1041, 1043, 1045, 1054, 1055, 1056, 1058], "bounding_ax_": [393, 640], "boundscheck": [374, 387], "bourassa": 423, "bourbeau": [1048, 1049, 1050], "bourboux": 1052, "bourguignat": 1046, "bournhonesqu": 1051, "bousquet": 908, "boutili": 1012, "boutsidi": 421, "bow": 417, "bown": 1047, "bowyer": 1059, "box": [43, 49, 66, 90, 193, 194, 241, 296, 319, 323, 393, 421, 423, 520, 563, 564, 888, 900, 924, 926, 1000, 1001, 1007, 1010, 1016, 1019, 1025, 1049, 1057], "boxplot": [49, 113, 153, 192, 195, 292, 328], "boxplot_runtim": 49, "boxstyl": [48, 321], "boy": 1055, "boyd": 996, "boyl": [1058, 1059], "boyuan": [1045, 1046, 1047], "bp": [49, 153, 174, 208, 209, 383, 1008], "bpo": 886, "br": 141, "br_estim": 187, "bracket": [386, 996], "bradi": 1048, "bradlei": [174, 383, 996], "bradshaw": [1044, 1045, 1048], "bradypu": [50, 312, 381, 506], "bradypus_variegatus_0": 50, "brain": 380, "branch": [373, 384, 386, 389, 390, 416, 423, 450, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 920, 921, 922, 923, 925, 1003, 1007, 1016], "branching_factor": 450, "brand": [401, 404], "brandon": [1047, 1048, 1055, 1056], "brandt": 1052, "brandyn": 1041, "brault": 1048, "braun": 1049, "bravi": 1047, "braycurti": [458, 465, 707, 786, 787, 788, 1003], "braycurtisdist": 707, "brc": [416, 450], "bre": [2, 642, 1016], "bread": 1024, "breadth": [852, 853, 857, 1024, 1043], "breadth_first": [852, 853, 857], "break": [2, 55, 74, 81, 104, 114, 189, 209, 212, 226, 254, 265, 296, 331, 339, 344, 360, 362, 386, 388, 390, 392, 399, 416, 477, 520, 647, 782, 786, 789, 805, 885, 892, 897, 914, 917, 996, 999, 1008, 1010, 1015, 1020, 1021, 1041, 1042, 1048, 1049, 1051, 1053, 1057], "break_ti": [357, 914, 917, 1015, 1051], "breakdown": [113, 114, 237, 687, 996], "breakdown_": 687, "breast": [2, 174, 379, 508, 1008, 1036, 1046], "breast_canc": 341, "breast_cancer_data": 174, "brecht": 649, "bredin": 1045, "breiman": [194, 420, 423, 524, 525, 526, 563, 564, 572, 573, 642, 920, 921, 1008, 1016], "brekk": 1056, "bremen": [61, 62, 63, 64, 176, 177, 179, 180, 181, 182, 183, 185, 253], "brendan": [73, 448, 462, 1057, 1058, 1059], "brenden": 1055, "brenner": 1000, "breno": [1048, 1049], "brent": [1045, 1049, 1050], "brentfagan": 1050, "brett": [1044, 1046, 1047, 1048, 1049, 1056], "brettingen": 1047, "breuer": 1052, "breunig": [416, 458, 465, 858, 1006], "breve": 1057, "brevin": [1057, 1058], "brew": [151, 384, 404], "brian": [0, 81, 406, 716, 1000, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1051, 1052, 1054, 1055], "brice": [1053, 1054], "bridg": [398, 997, 1019], "brief": [386, 998], "briefli": [287, 385, 399, 423, 989, 1051], "brier": [2, 61, 62, 64, 414, 717], "brier1950": 1000, "brier_scor": 61, "brier_score_loss": [2, 61, 62, 414, 1000, 1049, 1050, 1051, 1059], "brigata": 383, "bright": 349, "brighter": 184, "brigi": [1052, 1053], "brigitta": [1051, 1052, 1053, 1057], "bring": [192, 319, 421, 684, 686, 997, 1019, 1024], "british": 424, "brittl": [74, 416], "broad": [386, 400, 1019], "broadcast": 635, "broader": [321, 996, 1023], "broadli": [400, 416], "brocchini": 1053, "brochart": 1058, "brockherd": 1043, "brodersen": 716, "broke": 1048, "broken": [404, 420, 607, 608, 643, 728, 928, 1000, 1016, 1044, 1048, 1049, 1050, 1052, 1055], "brook": [1044, 1045, 1053], "brought": [191, 561, 562, 565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923], "brown": [50, 123, 312, 381, 506, 636, 990, 1046, 1048, 1049, 1050, 1053], "brows": 390, "browser": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 386, 394, 1010, 1058], "broyden": 996, "brr": 199, "brr_poli": 199, "brr_score": 199, "bruce": [1051, 1052], "brucher": [0, 406, 1041], "brummitt": [1048, 1049], "brunak": 751, "brunner": 1045, "bruno": [1052, 1053, 1054, 1059], "brutal": 349, "brute": [299, 398, 411, 420, 427, 452, 454, 458, 465, 640, 641, 696, 697, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 1007, 1036, 1045, 1049, 1053, 1056, 1057, 1058, 1059], "bry": [212, 229], "bryan": [1041, 1044, 1050, 1051, 1054], "br\u00f6mmel": [1055, 1056], "br\u00fblade": 325, "bsa": 772, "bsas_in_radian": 772, "bscikit": 1041, "bsd": [44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 61, 62, 63, 64, 66, 67, 68, 72, 74, 75, 77, 80, 81, 82, 83, 86, 87, 88, 89, 92, 96, 100, 101, 102, 104, 105, 107, 108, 109, 115, 120, 121, 125, 127, 129, 130, 131, 132, 135, 137, 139, 140, 141, 142, 143, 144, 145, 150, 151, 153, 154, 155, 159, 160, 174, 176, 177, 179, 180, 181, 182, 183, 185, 188, 197, 202, 203, 205, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 221, 222, 225, 227, 228, 236, 237, 241, 242, 243, 245, 247, 250, 252, 253, 255, 257, 263, 265, 279, 282, 284, 291, 298, 299, 301, 307, 308, 309, 311, 312, 314, 317, 319, 320, 321, 322, 323, 324, 338, 339, 340, 341, 343, 353, 354, 356, 357, 360, 361, 362, 392, 398], "bsh": 1056, "bsmtfinsf1": [149, 160], "bsmtfinsf2": 149, "bsmthalfbath": 149, "bsmtunfsf": 160, "bspline": 891, "bsplines_": [221, 891], "bsr": [932, 933, 1054], "bt": 424, "btol": [680, 682], "buck": 635, "budarz": 1054, "buddha": 1046, "budget": [0, 149, 847, 848, 849, 850, 851, 989], "bueno": 772, "buffer": [85, 1054], "buffer_mb": 1041, "bug": [254, 328, 329, 330, 331, 332, 333, 334, 335, 336, 384, 388, 389, 391, 394, 398, 400, 1020, 1041, 1042, 1043, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "bugfix": [390, 1041, 1055], "buguen": 1041, "buhmann": 716, "build": [0, 2, 7, 17, 35, 43, 46, 55, 68, 78, 90, 102, 108, 129, 139, 148, 150, 157, 163, 171, 173, 186, 187, 189, 192, 228, 283, 286, 296, 298, 299, 316, 317, 320, 325, 326, 362, 369, 373, 374, 375, 382, 388, 389, 390, 391, 392, 400, 404, 409, 416, 420, 423, 424, 450, 498, 509, 511, 532, 561, 562, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 593, 594, 596, 597, 599, 635, 636, 638, 699, 721, 722, 809, 813, 817, 826, 832, 834, 873, 890, 892, 920, 921, 922, 923, 925, 945, 989, 990, 997, 1000, 1004, 1006, 1010, 1015, 1016, 1019, 1020, 1021, 1023, 1024, 1026, 1028, 1032, 1033, 1041, 1044, 1046, 1047, 1048, 1050, 1053], "build_analyz": [424, 596, 597, 599, 1051], "build_clib": 384, "build_ext": [384, 392], "build_numb": 374, "build_preprocessor": [424, 596, 597, 599, 1051], "build_projection_oper": 53, "build_token": [57, 424, 596, 597, 599], "build_tool": 390, "builder": [47, 49, 356, 390], "buildtool": 384, "built": [2, 25, 66, 118, 137, 139, 140, 148, 150, 194, 228, 281, 296, 312, 328, 365, 368, 373, 381, 384, 386, 387, 388, 390, 392, 394, 395, 398, 399, 400, 404, 410, 416, 417, 420, 423, 425, 453, 511, 561, 562, 563, 564, 567, 568, 569, 570, 596, 597, 601, 605, 647, 648, 649, 650, 651, 654, 655, 660, 666, 668, 669, 670, 671, 680, 681, 682, 683, 689, 811, 812, 819, 843, 846, 852, 853, 922, 923, 984, 996, 1000, 1001, 1013, 1014, 1016, 1019, 1024, 1034, 1041, 1044, 1045, 1047, 1053], "builtin": 1015, "buitinck": [0, 54, 360, 361, 362, 406, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048], "bulk": [287, 427, 452], "bulk_benchmark": 49, "bulk_benchmark_estim": 49, "bulk_runtim": 49, "bull": 1048, "buluttekin": 1051, "bumblebe": 1054, "bunch": [2, 50, 254, 379, 380, 381, 472, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 515, 518, 575, 576, 577, 578, 640, 641, 642, 871, 872, 920, 921, 922, 923, 957, 960, 1024, 1034, 1046, 1048, 1051, 1053, 1057], "bundl": [1049, 1050], "bupu": 193, "burden": [386, 884, 1020], "bureau": 381, "buri": 386, "burjek": 1041, "burk": [0, 370, 1056], "burn": [1048, 1049], "burst": 1000, "busch": [1049, 1050, 1052], "bush": [45, 381], "busi": [43, 220, 278, 336, 394, 398, 415, 796, 996, 1000, 1024], "business_metr": 272, "business_scor": 272, "bussonni": [1041, 1053], "butler": [482, 1044, 1052, 1053], "butlerdavi": 482, "butter": 1024, "button": [386, 394], "butyugina": 1057, "buuren": [635, 990], "buzenet": [1056, 1057], "bv_bunch": 50, "bwignal": 1044, "bydat": 1034, "bypass": [415, 417, 607, 654, 660, 830, 920, 921, 922, 923, 1057], "byproduct": 244, "byrd": 666, "byron": 1053, "byte": [83, 88, 424, 495, 511, 516, 517, 590, 596, 597, 599, 965, 1032, 1034, 1041, 1048, 1049, 1056, 1059], "bz2": [55, 516, 517], "bz2file": 55, "bzip2": 1041, "b\u00e9gude": 325, "c": [2, 43, 45, 46, 47, 50, 51, 52, 57, 61, 62, 64, 66, 67, 70, 74, 75, 77, 78, 80, 87, 91, 92, 94, 95, 96, 100, 105, 106, 108, 118, 121, 122, 123, 130, 131, 139, 141, 142, 148, 149, 156, 158, 159, 161, 162, 167, 174, 177, 178, 179, 180, 184, 197, 203, 205, 210, 211, 212, 213, 215, 217, 218, 227, 229, 231, 232, 233, 234, 236, 237, 240, 241, 242, 244, 245, 252, 253, 255, 259, 264, 266, 267, 268, 269, 271, 272, 273, 275, 276, 277, 278, 281, 283, 287, 289, 299, 302, 304, 305, 307, 308, 309, 310, 311, 312, 314, 315, 317, 319, 320, 321, 324, 328, 329, 330, 331, 332, 333, 334, 335, 336, 340, 343, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 360, 365, 366, 367, 373, 374, 380, 381, 383, 384, 386, 387, 388, 389, 391, 394, 395, 398, 404, 407, 413, 414, 416, 417, 418, 419, 420, 421, 423, 425, 429, 445, 450, 451, 454, 455, 457, 467, 476, 483, 531, 536, 542, 546, 548, 549, 555, 557, 558, 598, 615, 616, 618, 639, 647, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 678, 680, 681, 687, 693, 694, 696, 697, 700, 701, 716, 722, 723, 726, 739, 743, 749, 750, 766, 767, 808, 822, 831, 837, 839, 847, 848, 849, 850, 851, 852, 853, 859, 861, 868, 883, 885, 886, 887, 891, 893, 907, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 923, 927, 932, 933, 963, 989, 992, 993, 995, 996, 997, 998, 1000, 1002, 1003, 1005, 1007, 1010, 1012, 1014, 1015, 1016, 1019, 1024, 1025, 1029, 1030, 1032, 1033, 1041, 1042, 1044, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1057], "c0": [149, 250, 325], "c1": [100, 149, 184, 250, 325], "c2": [100, 149, 184, 250, 325], "c22": 333, "c26": 333, "c3": [100, 149, 325], "c4": [100, 325, 1022, 1036], "c5": [100, 1022, 1036], "c56poni": 1051, "c6": 100, "c99": 1019, "c_": [50, 62, 63, 64, 93, 113, 126, 148, 151, 157, 158, 167, 178, 218, 233, 236, 247, 305, 322, 324, 343, 349, 357, 358, 416, 667, 722, 723, 726, 1000, 1029, 1032, 1033], "c_0": [992, 998], "c_1": 997, "c_2": [416, 997], "c_2d_rang": 349, "c_e": 416, "c_i": [416, 1003], "c_j": [416, 1005], "c_jh_j": 1005, "c_k": 557, "c_option": 106, "c_p": 996, "c_q": 416, "c_rang": 349, "c_scale": 356, "ca": [174, 383, 416, 450, 920, 921, 1012, 1016], "cabernet": 325, "cabin": 333, "cablevis": 51, "cabrera": 1051, "cach": [2, 52, 89, 101, 189, 279, 299, 300, 302, 307, 311, 373, 374, 381, 400, 449, 453, 458, 476, 494, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 510, 516, 517, 808, 854, 856, 872, 873, 910, 914, 915, 916, 917, 918, 985, 1003, 1015, 1021, 1044, 1048, 1049, 1050, 1051, 1053, 1054, 1056, 1057, 1059], "cache_path": 1003, "cache_s": [476, 910, 914, 915, 916, 917, 918, 1015], "cached_pip": [106, 417], "cachedir": [89, 106, 395, 417], "caching_dir": 985, "caherrera": 1054, "cai": 1054, "caicedo": 1041, "caio": [1047, 1049, 1051], "caj": 51, "caje": 1042, "cal_clf": 63, "cal_clf_prob": 63, "cal_hous": 381, "cal_scor": 63, "calcot": 1054, "calcsiz": 384, "calcul": [2, 46, 61, 63, 69, 81, 94, 113, 137, 138, 139, 143, 161, 188, 189, 195, 216, 224, 225, 237, 252, 254, 277, 278, 284, 288, 293, 298, 347, 353, 354, 369, 373, 393, 400, 407, 413, 414, 416, 420, 421, 423, 427, 446, 451, 452, 454, 456, 458, 459, 461, 463, 464, 479, 480, 486, 489, 544, 555, 561, 572, 577, 605, 619, 628, 640, 641, 642, 652, 653, 654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 680, 681, 682, 683, 687, 689, 692, 696, 698, 700, 702, 715, 724, 737, 738, 743, 744, 746, 752, 758, 759, 762, 772, 777, 779, 780, 781, 782, 786, 789, 791, 792, 795, 796, 797, 800, 801, 803, 815, 817, 833, 837, 850, 852, 853, 890, 891, 892, 898, 902, 912, 913, 938, 951, 992, 994, 996, 997, 998, 1000, 1002, 1003, 1004, 1008, 1010, 1013, 1015, 1021, 1029, 1032, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "cald": 907, "caleb": 1053, "calibr": [2, 52, 66, 142, 155, 162, 238, 250, 272, 278, 280, 400, 407, 445, 446, 447, 520, 523, 572, 577, 666, 667, 684, 717, 737, 749, 792, 795, 796, 807, 830, 838, 850, 909, 912, 940, 989, 996, 1000, 1013, 1015, 1021, 1022, 1036, 1038, 1045, 1047], "calibrated_classifi": 63, "calibrated_classifiers_": [63, 414, 445], "calibrated_clf": 445, "calibrated_df": [62, 64], "calibrated_forest": 989, "calibratedclassifiercv": [2, 61, 62, 63, 369, 400, 407, 414, 684, 807, 830, 989, 1015, 1020, 1045, 1047, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "calibratedclassifiercvifittedcalibratedclassifiercv": 63, "calibration_curv": [2, 61, 414, 445, 446, 1050, 1055, 1059], "calibration_displai": [62, 64], "calibrationdisplai": [2, 62, 64, 414, 940, 1054, 1055, 1059], "california": [2, 150, 184, 187, 188, 319, 325, 330, 379, 383, 498, 1036], "calinski": [2, 718, 1047], "calinski_harabasz_scor": [2, 416, 1049], "calinski_harabaz_scor": [1047, 1049], "cali\u0144ski": 416, "call": [52, 53, 55, 81, 83, 85, 89, 105, 123, 137, 144, 151, 171, 176, 180, 182, 184, 191, 193, 208, 220, 221, 224, 238, 254, 258, 260, 261, 272, 278, 279, 287, 293, 294, 296, 299, 301, 324, 326, 330, 331, 360, 361, 362, 368, 373, 374, 375, 381, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 404, 407, 412, 414, 415, 416, 417, 418, 419, 420, 421, 423, 424, 426, 428, 439, 448, 451, 454, 455, 457, 458, 459, 460, 461, 462, 465, 468, 470, 472, 473, 476, 477, 482, 490, 491, 492, 496, 499, 500, 503, 505, 511, 516, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 585, 590, 591, 596, 597, 599, 605, 610, 615, 616, 618, 619, 622, 628, 635, 636, 637, 638, 639, 640, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 683, 684, 685, 686, 687, 688, 697, 698, 699, 700, 701, 702, 703, 705, 707, 708, 709, 712, 740, 750, 763, 779, 782, 786, 787, 788, 789, 801, 805, 806, 807, 808, 810, 811, 812, 813, 814, 820, 822, 823, 824, 825, 826, 827, 828, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 855, 857, 858, 861, 863, 868, 869, 870, 871, 872, 875, 876, 877, 879, 881, 882, 884, 889, 892, 893, 896, 901, 902, 903, 904, 905, 909, 912, 913, 914, 915, 917, 918, 921, 923, 939, 943, 948, 949, 957, 958, 960, 966, 967, 971, 974, 984, 989, 990, 992, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1008, 1010, 1012, 1013, 1015, 1016, 1019, 1024, 1025, 1029, 1032, 1033, 1034, 1036, 1038, 1041, 1042, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "callabl": [2, 268, 282, 336, 400, 420, 423, 424, 425, 427, 428, 449, 451, 452, 453, 454, 455, 457, 458, 460, 465, 467, 468, 472, 473, 474, 475, 539, 541, 543, 545, 547, 553, 554, 565, 566, 567, 568, 569, 570, 572, 573, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 618, 619, 628, 636, 638, 642, 647, 651, 667, 674, 679, 681, 683, 696, 699, 700, 704, 719, 727, 740, 750, 779, 782, 786, 787, 788, 789, 800, 801, 808, 811, 812, 814, 822, 830, 831, 834, 835, 836, 837, 839, 852, 853, 854, 855, 856, 858, 860, 861, 862, 863, 864, 876, 885, 907, 908, 914, 915, 916, 917, 918, 961, 967, 970, 984, 989, 1000, 1010, 1041, 1045, 1048, 1049, 1050, 1051, 1053, 1055, 1057], "callback": [539, 545, 547, 553, 554, 861, 966, 1020, 1057], "callbl": 854, "calle": [2, 254, 958], "caller": [2, 254, 417, 654, 655, 660, 668, 669, 670, 689, 902, 903, 957, 958, 976, 977, 978, 1050], "callgrin": 392, "callgrind": 389, "calm": 51, "caltech": 360, "calvin": [1044, 1045], "calvo": [1049, 1050], "cambridg": [381, 421, 598, 847, 851, 996, 998, 1002], "came": 999, "camera_ind": 53, "camil": [1049, 1057, 1058], "camila": 1051, "camilaagw": 1051, "camilo": 1047, "campello": [416, 454], "campustrampu": 1048, "can": [0, 11, 19, 25, 37, 43, 44, 46, 47, 48, 49, 51, 52, 54, 57, 58, 61, 62, 63, 64, 67, 68, 69, 72, 75, 77, 78, 81, 83, 84, 88, 90, 91, 92, 93, 95, 96, 97, 98, 100, 104, 105, 106, 107, 111, 112, 113, 114, 115, 118, 121, 126, 128, 129, 130, 132, 134, 135, 137, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 169, 170, 171, 172, 173, 174, 176, 181, 182, 183, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 204, 205, 208, 209, 211, 213, 215, 216, 218, 220, 221, 222, 223, 224, 225, 226, 228, 236, 237, 238, 240, 241, 242, 247, 248, 249, 250, 251, 253, 254, 257, 258, 261, 263, 264, 265, 266, 268, 269, 271, 272, 273, 274, 275, 276, 278, 279, 280, 281, 282, 285, 287, 289, 290, 292, 293, 294, 296, 298, 299, 301, 303, 304, 305, 306, 308, 315, 316, 317, 319, 320, 321, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 339, 340, 342, 343, 346, 347, 349, 352, 353, 356, 360, 361, 362, 366, 367, 368, 369, 373, 374, 375, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 394, 395, 399, 400, 401, 403, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 439, 441, 445, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 460, 462, 464, 465, 466, 467, 469, 470, 472, 473, 474, 475, 476, 480, 490, 491, 492, 495, 504, 507, 511, 516, 517, 520, 529, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 557, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 587, 588, 589, 590, 591, 592, 596, 597, 599, 600, 602, 603, 604, 605, 606, 607, 608, 610, 611, 612, 614, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 638, 640, 642, 643, 646, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 692, 695, 697, 699, 700, 701, 702, 703, 706, 707, 708, 709, 710, 712, 715, 717, 719, 720, 726, 728, 729, 730, 731, 732, 734, 735, 737, 738, 740, 741, 745, 746, 747, 748, 750, 751, 754, 760, 763, 764, 765, 766, 767, 771, 787, 788, 790, 791, 792, 793, 795, 796, 797, 802, 803, 805, 806, 807, 808, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 822, 823, 824, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 869, 870, 871, 872, 875, 876, 877, 879, 880, 881, 885, 886, 887, 890, 891, 892, 897, 904, 905, 910, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 924, 925, 928, 930, 932, 936, 938, 943, 946, 948, 949, 955, 957, 960, 963, 966, 970, 971, 974, 981, 984, 985, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1019, 1020, 1023, 1024, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1033, 1034, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "canberra": [458, 465, 707, 786, 787, 788, 1003], "canberradist": 707, "cancel": [423, 424, 771], "cancer": [2, 174, 379, 415, 508, 601, 602, 859, 1008, 1036, 1046], "candela": 383, "candid": [108, 268, 276, 279, 286, 330, 375, 386, 390, 416, 423, 456, 458, 808, 811, 812, 820, 822, 996, 1003, 1016, 1047], "candidate_idx": 277, "cannon": 1056, "cannot": [43, 52, 75, 91, 109, 115, 125, 130, 147, 192, 193, 204, 220, 238, 254, 319, 349, 356, 375, 385, 387, 392, 398, 400, 401, 410, 416, 417, 418, 420, 421, 423, 424, 426, 473, 529, 546, 547, 548, 551, 555, 618, 621, 622, 623, 625, 627, 628, 630, 631, 633, 659, 663, 690, 700, 719, 725, 786, 811, 812, 859, 860, 862, 863, 864, 872, 873, 877, 882, 883, 894, 930, 932, 933, 989, 990, 994, 996, 997, 1000, 1001, 1006, 1010, 1015, 1016, 1020, 1024, 1027, 1029, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "canon": [2, 51, 400, 414, 423, 490, 491, 493, 776, 1020, 1022, 1036], "canonic": 400, "cant": [1058, 1059], "cantor": [636, 990], "canuma": 1054, "canva": 51, "cao": 416, "cap": [413, 416, 763, 1000, 1050], "capabl": [90, 91, 118, 155, 181, 224, 244, 388, 400, 404, 1001, 1004, 1015, 1016, 1024, 1041, 1050, 1058], "capac": [155, 176, 194], "capit": [49, 62, 335, 504, 814, 831], "capitain": 1059, "cappion": [700, 997], "cappuzzo": 1058, "capsiz": 341, "caption": 104, "captur": [2, 43, 48, 51, 52, 72, 74, 118, 152, 157, 169, 181, 192, 199, 204, 220, 224, 269, 298, 329, 349, 353, 394, 416, 423, 424, 425, 579, 596, 597, 599, 858, 967, 1000, 1005, 1013, 1017, 1032, 1053], "car": 220, "carbal": 1058, "card": 1049, "cardin": [72, 146, 147, 153, 194, 195, 325, 326, 334, 416, 423, 471, 561, 562, 565, 566, 567, 568, 572, 573, 574, 687, 885, 886, 893, 920, 921, 922, 923, 1000, 1001, 1008, 1010, 1055, 1056], "cardiotocogram": 257, "care": [47, 90, 153, 192, 272, 296, 353, 373, 375, 390, 392, 398, 400, 401, 410, 415, 416, 418, 424, 445, 468, 477, 648, 666, 667, 674, 675, 676, 684, 685, 686, 703, 912, 997, 1015, 1024, 1057], "carefulli": [292, 373, 421, 1015], "carei": [1044, 1045, 1046, 1047, 1048], "carett": 1048, "cari": 1053, "carl": [181, 426, 618, 619, 622, 627, 630], "carla": 1057, "carlo": [0, 252, 376, 423, 426, 619, 649, 650, 992, 1005, 1041, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "carlson": 1048, "carlsson": 1044, "carmen": 325, "carnegi": 907, "caro": 1046, "carodorum": 325, "carol": [1047, 1048], "carolin": 1004, "caro\u00e7o": 1060, "carrascosa": [1024, 1045], "carre\u00f1o": 1056, "carri": [51, 67, 139, 188, 272, 278, 281, 286, 315, 321, 362, 401, 424, 565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923, 1024, 1033], "carrillo": 1046, "carsten": 1054, "cart": [1022, 1036], "carter": [1047, 1048, 1056], "cartesian": [105, 413, 641, 1003, 1056], "cartman_nabana": 1051, "cartograph": 197, "cartographi": 996, "caruana": [62, 64, 414, 445, 447], "carvaj": 1041, "casado": 1052, "casagrand": [1049, 1050], "casalegno": 1053, "cascad": 383, "case": [2, 30, 43, 46, 47, 52, 62, 64, 70, 72, 84, 87, 90, 92, 96, 101, 105, 106, 114, 118, 130, 132, 142, 144, 145, 152, 153, 160, 171, 173, 174, 176, 183, 192, 193, 195, 204, 206, 209, 211, 220, 221, 222, 224, 225, 228, 234, 236, 237, 238, 247, 251, 252, 253, 254, 257, 258, 268, 271, 272, 275, 277, 278, 279, 281, 284, 285, 287, 296, 299, 302, 306, 316, 319, 321, 324, 326, 328, 331, 336, 353, 360, 361, 362, 368, 369, 373, 374, 375, 380, 381, 386, 387, 388, 390, 391, 392, 393, 395, 398, 399, 400, 401, 404, 407, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 426, 427, 428, 445, 448, 451, 452, 454, 455, 459, 461, 471, 472, 473, 475, 482, 504, 516, 517, 523, 547, 549, 550, 551, 556, 557, 558, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 589, 590, 596, 599, 601, 602, 605, 610, 614, 617, 618, 619, 633, 635, 636, 638, 640, 655, 656, 661, 664, 665, 666, 667, 669, 671, 674, 676, 677, 680, 682, 683, 684, 688, 690, 691, 692, 693, 694, 695, 707, 711, 716, 717, 720, 726, 728, 729, 731, 734, 736, 737, 738, 742, 743, 746, 750, 751, 753, 754, 756, 758, 761, 762, 764, 771, 786, 789, 791, 792, 793, 795, 796, 797, 798, 802, 804, 806, 808, 811, 812, 814, 822, 826, 831, 832, 833, 834, 835, 836, 837, 839, 841, 849, 852, 853, 854, 855, 856, 858, 860, 861, 862, 863, 864, 872, 879, 881, 882, 885, 886, 887, 890, 891, 892, 893, 896, 902, 903, 904, 905, 912, 914, 917, 920, 921, 927, 928, 938, 949, 950, 989, 990, 992, 994, 995, 997, 998, 999, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1014, 1015, 1016, 1019, 1020, 1024, 1025, 1034, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "caselli": [1049, 1050], "cash": 996, "cashman": 1051, "casino": [1055, 1056], "cass": 1047, "cassi": 325, "cast": [50, 52, 88, 220, 241, 380, 401, 424, 504, 652, 653, 654, 660, 664, 665, 668, 669, 670, 671, 672, 673, 681, 683, 965, 1048, 1049, 1050, 1051, 1054, 1056, 1058], "castachick": 1052, "castello": 1045, "castor": 1052, "caswel": [1054, 1057], "cat": [51, 105, 193, 194, 257, 331, 332, 333, 334, 335, 336, 381, 424, 496, 590, 720, 726, 762, 791, 893, 1000, 1010, 1050, 1051, 1053], "cat_column": 257, "cat_linear_processor": 160, "cat_proc": [249, 329], "cat_selector": 160, "cat_str": 57, "cat_tree_processor": 160, "catajara": 1051, "catalfo": 1049, "catalin": 650, "catastroph": [272, 326, 771, 1020], "catch": [79, 97, 316, 374, 394, 395], "catch_warn": [79, 97, 254, 315, 316], "categor": [2, 43, 105, 138, 144, 155, 160, 189, 192, 193, 194, 220, 238, 257, 259, 261, 272, 326, 331, 333, 334, 375, 378, 380, 381, 388, 391, 400, 417, 424, 474, 475, 497, 498, 504, 513, 569, 570, 589, 590, 615, 616, 640, 641, 656, 666, 667, 677, 688, 717, 835, 847, 848, 849, 850, 851, 873, 875, 879, 880, 883, 885, 886, 893, 907, 908, 990, 996, 1007, 1008, 1016, 1019, 1020, 1021, 1022, 1023, 1024, 1034, 1036, 1041, 1042, 1045, 1046, 1049, 1051, 1053, 1056, 1057, 1058, 1059], "categori": [2, 25, 57, 79, 97, 104, 105, 149, 160, 192, 193, 220, 228, 235, 257, 272, 279, 315, 316, 321, 325, 326, 330, 333, 335, 342, 360, 361, 362, 380, 381, 395, 416, 417, 423, 424, 426, 496, 504, 505, 511, 569, 570, 656, 666, 667, 677, 688, 751, 766, 767, 848, 885, 886, 893, 990, 996, 997, 998, 1002, 1008, 1025, 1034, 1047, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1060], "categorical_column": [43, 149, 192, 194, 257, 475], "categorical_columns_selector": 257, "categorical_columns_subset": 149, "categorical_crossentropi": [1051, 1055], "categorical_encod": 194, "categorical_featur": [43, 105, 149, 155, 193, 272, 325, 330, 331, 332, 333, 335, 391, 423, 569, 570, 640, 641, 1007, 1049, 1053, 1056, 1058], "categorical_preprocessor": [259, 325], "categorical_transform": 105, "categoricalnb": [2, 847, 849, 850, 851, 1002, 1051, 1052, 1053, 1054, 1056], "categories_": [885, 886, 893, 1010, 1049, 1056], "category_1_fold": 511, "category_2_fold": 511, "category_count_": 848, "category_s": 361, "categr": 1008, "caterpillar": 51, "cathi": [1045, 1051], "catindex": 193, "catplot": 268, "caught": [386, 394, 410], "caus": [43, 62, 64, 152, 177, 192, 218, 220, 224, 225, 238, 298, 326, 353, 362, 369, 384, 391, 414, 416, 421, 422, 424, 426, 451, 455, 457, 467, 517, 540, 590, 597, 618, 619, 786, 847, 848, 849, 851, 876, 885, 887, 890, 891, 932, 933, 989, 990, 996, 1000, 1008, 1010, 1013, 1020, 1025, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1057, 1058], "causal": [189, 190, 215, 665, 793, 838, 1021], "causat": 192, "caution": [192, 272, 390, 448, 462, 1049], "cautiou": 1048, "caveat": [420, 426], "cawlei": [283, 1000], "cax": [66, 179, 289], "ca\u00f1ardo": 1044, "cb": [179, 251, 267], "cbar_ax": 289, "cbar_kw": [199, 204], "cc": [75, 384], "cc18": 380, "cc_home": [920, 921], "cca": [2, 255, 419, 491, 493, 1001, 1045, 1049, 1050, 1051, 1053, 1055, 1059], "ccat": 381, "ccf2002": 992, "cclauss": 1049, "cco": 360, "ccp_alpha": [328, 364, 565, 566, 567, 568, 572, 573, 920, 921, 922, 923, 1016, 1051], "ccp_path": [920, 921, 922, 923], "cd": [125, 174, 383, 384, 386, 390, 392, 421, 479, 480, 486, 539, 545, 547, 548, 551, 553, 554, 555, 996, 1034, 1046, 1056], "cdef": 387, "cdf": 278, "cdist": 1054, "cdivis": 387, "cdot": [278, 353, 413, 416, 421, 422, 426, 622, 623, 627, 630, 631, 878, 992, 994, 1000, 1004, 1010], "cdrig": 1055, "cdt": 57, "cea": [847, 1002], "ceballo": 1055, "ceder": [796, 1000], "ceethinwa": [1053, 1054], "ceh": 1056, "ceil": [155, 257, 565, 566, 567, 568, 571, 572, 573, 574, 602, 679, 811, 812, 920, 921, 922, 923, 1014], "celelibi": 1050, "celeo": 1045, "celeux": 536, "cell": [50, 51, 58, 63, 68, 105, 106, 144, 146, 147, 156, 157, 160, 163, 171, 174, 181, 192, 193, 194, 201, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 312, 317, 325, 329, 330, 332, 333, 335, 340, 368, 383, 391, 700, 1000, 1001, 1047, 1055], "cellular": 53, "celsiu": [193, 1007], "cemlyn": 1059, "cen": 751, "censor": 1019, "censu": 381, "center": [0, 2, 36, 43, 46, 47, 48, 53, 61, 63, 69, 70, 72, 73, 75, 77, 78, 80, 83, 84, 85, 88, 90, 91, 94, 95, 96, 98, 99, 114, 122, 130, 131, 134, 150, 151, 152, 153, 172, 174, 188, 193, 201, 212, 214, 220, 221, 231, 232, 243, 244, 247, 248, 257, 263, 266, 267, 273, 279, 289, 304, 307, 309, 315, 319, 321, 322, 332, 340, 347, 349, 350, 351, 355, 361, 362, 381, 382, 383, 391, 416, 418, 419, 421, 422, 423, 429, 448, 450, 451, 454, 455, 456, 457, 460, 462, 467, 468, 469, 470, 471, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 490, 491, 492, 493, 509, 520, 532, 542, 543, 549, 552, 558, 614, 617, 618, 619, 640, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 674, 675, 676, 679, 680, 681, 682, 683, 684, 686, 698, 702, 704, 805, 877, 878, 881, 890, 892, 902, 903, 912, 913, 994, 996, 997, 999, 1007, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1054, 1055, 1058], "center1": 101, "center2": 101, "center3": 101, "center4": 101, "center_": 890, "center_box": [95, 520], "centers_0": 322, "centers_1": 322, "centers_init": 94, "cento": 384, "centr": 159, "central": [0, 53, 222, 381, 387, 416, 1006, 1019], "centrality_scor": 55, "centroid": [2, 77, 80, 92, 93, 111, 189, 300, 307, 322, 332, 345, 361, 382, 407, 416, 450, 451, 454, 455, 456, 457, 460, 467, 468, 470, 512, 557, 639, 859, 1021, 1022, 1036, 1041, 1045, 1048, 1053, 1057], "centroids_": [450, 454, 859], "ceo": 1024, "cerda": 1055, "certain": [52, 90, 150, 155, 192, 225, 237, 254, 278, 299, 323, 353, 369, 381, 382, 390, 400, 403, 410, 416, 421, 425, 646, 657, 661, 666, 671, 692, 872, 877, 912, 989, 992, 996, 997, 1000, 1001, 1004, 1010, 1015, 1019, 1025, 1029, 1046, 1050, 1053, 1056], "certainli": [88, 104, 192, 361, 415], "certainti": [278, 388, 750, 1000], "ceshin": 1047, "cetina": 1053, "cf": [326, 415, 416, 419, 450, 708, 996, 1010, 1020], "cflag": 384, "cft": 416, "cftree": 450, "cg": [317, 666, 667, 680, 682, 695, 996, 1045, 1046, 1048, 1052, 1054, 1055, 1058, 1059], "cga": 184, "cgi": 905, "cgohlk": [1044, 1045], "cgroup": [1054, 1055], "cgsavard": [1051, 1052], "ch": [222, 341, 343], "ch6": 538, "chacon": 713, "chac\u00f3n": 713, "chad": 1058, "chadi": 1049, "chai": [1053, 1056, 1057], "chain": [2, 35, 103, 109, 139, 166, 189, 250, 286, 289, 297, 299, 302, 317, 369, 378, 398, 400, 426, 504, 510, 549, 619, 635, 666, 746, 808, 838, 841, 843, 844, 845, 846, 872, 873, 892, 989, 990, 1001, 1005, 1017, 1019, 1021, 1024, 1034, 1036], "chain_jaccard_scor": 298, "chain_method": [843, 1059], "chain_method_": 843, "chaitanya": 1052, "chaitanyamog": 1053, "chakhchoukh": 114, "chakravarti": [643, 645], "chalearn": 1000, "challeng": [51, 160, 176, 193, 199, 238, 247, 375, 381, 382, 410, 416, 418, 470, 480, 1000, 1006, 1024, 1025], "chalmer": 1055, "chalmerlow": 1044, "chalulu": 1056, "chan": [0, 850, 892], "chanc": [2, 55, 71, 73, 84, 139, 169, 189, 195, 220, 228, 235, 238, 278, 284, 287, 288, 325, 356, 361, 369, 385, 415, 416, 420, 708, 710, 712, 713, 716, 724, 763, 765, 794, 803, 837, 1000, 1008, 1016, 1021, 1057], "chance_level_": [708, 710, 1057], "chance_level_kw": [257, 708, 710, 1057], "chandra": [1051, 1052, 1055], "chang": [2, 46, 62, 63, 64, 125, 129, 130, 142, 145, 153, 177, 187, 191, 192, 195, 221, 222, 224, 225, 258, 259, 272, 273, 278, 285, 288, 292, 323, 328, 329, 330, 331, 332, 333, 334, 335, 336, 339, 349, 353, 362, 368, 369, 373, 374, 375, 381, 388, 389, 390, 391, 394, 398, 400, 407, 416, 420, 423, 424, 426, 428, 441, 445, 448, 451, 452, 455, 457, 460, 462, 467, 470, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 501, 502, 504, 512, 516, 517, 520, 521, 522, 530, 535, 539, 541, 542, 543, 544, 545, 546, 547, 548, 549, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 583, 585, 586, 587, 588, 589, 590, 596, 597, 598, 599, 601, 602, 605, 610, 618, 619, 621, 622, 623, 625, 627, 628, 630, 631, 633, 635, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 698, 700, 702, 708, 712, 715, 720, 724, 725, 737, 738, 744, 745, 763, 765, 786, 792, 793, 795, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 817, 822, 826, 827, 829, 830, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 857, 858, 859, 862, 863, 869, 870, 871, 872, 874, 875, 876, 877, 878, 879, 884, 885, 891, 892, 893, 900, 901, 906, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 930, 932, 933, 944, 949, 959, 966, 967, 970, 989, 990, 991, 999, 1000, 1001, 1003, 1010, 1013, 1014, 1015, 1016, 1020, 1025, 1034, 1039, 1040, 1060], "changed_onli": 1052, "changedbehaviorwarn": 1053, "changedbehaviourwarn": 1050, "changelog": [333, 390, 400, 1039], "changing_param": 46, "changing_param_valu": 46, "changyao": [1056, 1057], "channel": [374, 381, 384, 404, 424, 501, 502, 591, 592, 594, 595, 1023], "channel_prior": 384, "chapman": 996, "chapter": [125, 369, 388, 416, 421, 423, 426, 538, 540, 542, 622, 627, 630, 651, 990, 993, 996, 1015, 1016], "char": [424, 596, 597, 599, 1041], "char_wb": [424, 596, 597, 599], "charact": [362, 386, 391, 400, 424, 511, 516, 517, 596, 597, 599, 924, 1005, 1034, 1041, 1054, 1056], "character": [75, 238, 364, 416, 420, 997], "characteris": 1003, "characterist": [2, 79, 97, 174, 181, 189, 247, 248, 260, 270, 272, 273, 275, 319, 369, 381, 383, 391, 414, 415, 420, 423, 426, 511, 512, 631, 646, 666, 710, 714, 716, 735, 790, 796, 797, 827, 838, 841, 879, 917, 996, 1021], "chardet": 424, "chardetect": 424, "charg": [0, 272, 386], "charikar": 992, "charl": [64, 272, 772, 1041, 1044, 1047, 1051, 1053, 1056], "charli": [1048, 1049, 1057], "charlton": 1048, "charra": [1056, 1058, 1059], "charron": [1024, 1044, 1045, 1052, 1053, 1054], "charset": [1041, 1043], "charset_error": 1043, "chart": [72, 150, 283, 1001, 1027, 1044], "chartbeat": 1024, "chase": [51, 1041], "chasnovski": 1052, "chat": 1024, "chatterje": 1052, "chaudhuri": 454, "chauhan": [1049, 1050, 1056, 1057], "chaumond": [1024, 1049], "chauvin": 751, "chavez": [45, 381], "chawla": 1051, "chayant": 1048, "chazalon": 1055, "cheaper": [193, 416, 426, 681, 992, 996], "cheat": [52, 349, 1004, 1014, 1027, 1043], "chebee7i": 1045, "chebyshev": [458, 465, 707, 786, 787, 788, 1003], "chebyshevdist": 707, "check": [2, 41, 43, 44, 47, 55, 81, 88, 91, 129, 137, 145, 160, 176, 189, 191, 193, 194, 206, 208, 209, 220, 241, 254, 264, 270, 272, 287, 296, 331, 340, 368, 373, 374, 384, 385, 386, 387, 388, 389, 390, 392, 393, 395, 396, 398, 400, 404, 407, 410, 417, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 499, 510, 516, 517, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558, 559, 560, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 603, 604, 605, 606, 607, 608, 611, 618, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 695, 696, 697, 698, 699, 700, 701, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 836, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 932, 933, 934, 943, 944, 955, 956, 957, 961, 962, 984, 985, 986, 988, 995, 996, 997, 1000, 1015, 1016, 1020, 1021, 1024, 1036, 1041, 1042, 1044, 1048, 1052, 1053, 1054, 1055, 1056, 1058], "check_arrai": [2, 388, 395, 476, 542, 910, 1045, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "check_classifier_multioutput": 1051, "check_consistent_length": 2, "check_cv": [2, 400, 1046], "check_decision_proba_consist": 1048, "check_estim": [2, 328, 388, 400, 944, 1048, 1049, 1050, 1051, 1052, 1053, 1055, 1056], "check_estimator_sparse_arrai": 1059, "check_estimator_sparse_data": 1059, "check_estimator_sparse_matrix": 1059, "check_estimators_fit_returns_self": 944, "check_estimators_pickl": 1058, "check_fit_idempot": 1050, "check_increas": 2, "check_input": [542, 556, 654, 655, 660, 668, 669, 670, 689, 695, 920, 921, 922, 923, 1049], "check_invers": [417, 473, 876, 1010, 1049, 1055, 1056], "check_is_fit": [2, 91, 137, 254, 389, 395, 400, 1051, 1054, 1055], "check_memori": [2, 395, 400, 1048], "check_metadata": 254, "check_methods_sample_order_invari": [1053, 1055], "check_methods_subset_invari": [1049, 1055], "check_nam": 388, "check_pairwise_arrai": 1050, "check_random_st": [2, 96, 236, 242, 250, 256, 388, 395, 400], "check_regressor_multioutput": 1051, "check_requires_y_non": 1055, "check_sample_weights_pandas_seri": 1049, "check_scalar": [2, 1055], "check_scor": [2, 400, 1059, 1060], "check_set_param": 1049, "check_symmetr": 2, "check_transformer_data_not_an_arrai": 1051, "check_transformers_unfitted_stateless": 1057, "check_x_i": [2, 388, 395, 1045, 1049, 1050, 1055], "checked_cv": 832, "checker": [2, 390, 832], "checkerboard": [2, 58, 413, 459, 461, 519, 521], "checking_statu": 272, "checkingclassifi": 1051, "checklist": 389, "checkout": [384, 386, 390, 394], "checkpoint": 1019, "checks_gener": 943, "checksum": 1053, "cheeseman": 383, "chege": 1055, "chemic": 383, "chemometr": 383, "chen": [111, 112, 418, 423, 429, 483, 734, 764, 992, 1000, 1044, 1047, 1048, 1049, 1051, 1054, 1055, 1056, 1057], "chenal": [1050, 1051, 1053], "cherkasski": 996, "chernyi": 1055, "cherri": 390, "cherti": 1045, "cherubin": 1047, "chestervil": 333, "cheuk": [1049, 1050], "cheung": [81, 1042], "chevali": 1053, "chevalli": 1058, "chevron": 51, "chi": [2, 105, 113, 139, 323, 378, 425, 527, 600, 603, 604, 606, 607, 608, 612, 613, 614, 617, 646, 647, 648, 649, 650, 766, 767, 1036, 1041, 1046, 1047], "chi2": [2, 105, 424, 425, 460, 589, 600, 603, 604, 606, 607, 608, 613, 614, 617, 628, 646, 647, 648, 649, 650, 651, 767, 773, 782, 1041, 1048, 1055], "chi2_featur": 650, "chi2_kernel": [2, 646, 650, 766, 773, 998, 1042], "chi2_stat": 612, "chi2sampl": 646, "chiang": 1049, "chiara": [0, 377, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "chibuik": 1054, "chief": 1024, "chieh": [1048, 1049], "chigurupati": 1053, "chih": [666, 1046], "chilamkurthi": 1047, "child": [155, 254, 360, 368, 374, 398, 400, 407, 416, 423, 450, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 920, 921, 922, 923, 957, 958, 960, 1016, 1048], "child_idx": 76, "children": [368, 416, 423, 449, 453, 471, 574, 1045, 1058], "children_": [76, 449, 453, 471], "children_left": 368, "children_right": 368, "chime": 385, "chin": [383, 1045], "china": [83, 416, 514, 515, 592, 595], "chines": 1019, "chinmaya": 1048, "chinthala": 1048, "chiotelli": 1050, "chip": [412, 1024], "chirag": 91, "chisquar": 323, "chitteti": 1055, "chkoar": 1048, "chloe": 1055, "cho": 1052, "choe": 1050, "choi": [996, 1059], "choic": [2, 43, 46, 64, 75, 81, 90, 100, 104, 111, 132, 155, 176, 177, 183, 187, 209, 221, 257, 271, 272, 276, 278, 281, 292, 304, 326, 330, 360, 361, 369, 373, 384, 388, 391, 400, 404, 416, 418, 420, 422, 423, 425, 426, 460, 470, 479, 480, 481, 482, 483, 484, 486, 546, 548, 549, 555, 567, 646, 655, 656, 664, 666, 667, 669, 677, 688, 700, 713, 750, 841, 854, 855, 860, 862, 863, 889, 892, 901, 903, 912, 913, 936, 989, 994, 996, 997, 998, 999, 1000, 1001, 1003, 1006, 1008, 1013, 1014, 1015, 1016, 1048, 1051, 1052, 1056, 1057], "choleski": [112, 220, 238, 395, 479, 480, 486, 535, 619, 656, 658, 659, 662, 663, 664, 666, 667, 677, 680, 682, 688, 690, 691, 695, 805, 806, 996, 1044, 1048, 1050, 1053, 1056, 1057], "cholesky_delet": 395, "cholesterol": [174, 383], "chong": 544, "choo": [1056, 1057], "choos": [43, 50, 51, 79, 81, 85, 88, 95, 97, 101, 111, 131, 148, 160, 165, 174, 192, 195, 213, 255, 272, 273, 283, 290, 364, 369, 373, 374, 375, 388, 391, 394, 400, 410, 415, 416, 418, 420, 423, 424, 427, 451, 452, 455, 457, 467, 531, 540, 546, 567, 568, 590, 610, 666, 667, 680, 682, 687, 695, 696, 697, 701, 734, 764, 808, 811, 812, 822, 879, 912, 913, 920, 921, 922, 923, 990, 991, 995, 996, 997, 998, 999, 1003, 1010, 1013, 1014, 1015, 1026, 1028, 1032, 1033, 1043, 1044, 1048, 1050, 1052], "choose_check_classifiers_label": 1051, "choose_random_sampl": 388, "choraria": 1053, "chose": [77, 192, 1029], "chosen": [47, 58, 81, 107, 160, 177, 192, 193, 209, 221, 237, 255, 271, 272, 273, 275, 281, 292, 361, 369, 373, 398, 415, 416, 418, 419, 423, 426, 448, 454, 457, 459, 461, 462, 468, 504, 531, 543, 565, 566, 567, 568, 569, 570, 572, 573, 655, 661, 664, 666, 667, 669, 671, 679, 684, 685, 686, 687, 688, 698, 702, 802, 805, 806, 808, 811, 812, 822, 842, 861, 912, 913, 920, 921, 922, 923, 949, 989, 992, 994, 996, 997, 999, 1001, 1006, 1007, 1014, 1029, 1030, 1032, 1033, 1049, 1057, 1058], "chou": [1048, 1049], "choudhari": [1045, 1046, 1055, 1057], "choudhri": 1059, "chowdhuri": [1049, 1055], "choyal": [1048, 1049], "chri": [0, 406, 1041, 1044, 1049, 1050, 1051, 1052, 1055], "chrissobel": 1054, "christ": 57, "christian": [0, 57, 221, 222, 360, 361, 381, 405, 1024, 1034, 1041, 1042, 1045, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "christianwaldmann": 1056, "christin": [1056, 1057], "christo": [91, 1050, 1051, 1053, 1055, 1058], "christof": [1045, 1046], "christoph": [193, 421, 426, 540, 618, 619, 622, 627, 630, 805, 996, 1001, 1042, 1046, 1049, 1052, 1053, 1054, 1055, 1056], "christopherlim98": 1055, "chrome": 1010, "chronolog": [381, 505], "chu": [859, 1057], "chuan": 1004, "chugh": 1053, "chuliang": 1054, "chun": [1052, 1053, 1055, 1056, 1057], "chung": [1048, 1049], "chunk": [2, 47, 85, 373, 374, 416, 421, 427, 452, 457, 476, 546, 786, 789, 840, 841, 847, 848, 849, 850, 851, 910, 1002, 1048, 1049, 1050, 1051, 1052], "chunk_siz": 1042, "chunker": 424, "church": [905, 1012], "chyi": [54, 1044, 1045, 1046, 1047, 1048], "chyikwei": 54, "ci": [90, 374, 389, 390, 394, 1002, 1047, 1049], "ciccolella": [700, 997], "cice": [1007, 1055], "cichocki": [421, 546, 548, 555], "cimport": [387, 395, 1049], "cindi": [1046, 1054, 1058, 1059], "cio": 380, "cipri\u00e1n": 1055, "circl": [2, 70, 95, 130, 158, 159, 167, 245, 255, 306, 309, 315, 319, 321, 340, 353, 367, 382, 390, 394, 416, 460, 470, 522, 530, 772, 1015], "circle1": 101, "circle2": 101, "circle3": 101, "circle4": 101, "circleci": [141, 180, 182, 184, 185, 264, 317, 354, 386], "circlecl": 0, "circuit": [57, 997], "circular": 53, "circumst": [132, 238, 1003, 1019], "circumstanti": 220, "cirru": [0, 386], "cisco": 51, "citat": [0, 380, 383, 398], "cite": [380, 398, 416], "citi": [417, 424, 474, 1034], "citizen": 1010, "city_categori": 417, "city_london": 417, "city_pari": 417, "city_sallisaw": 417, "cityblock": [75, 79, 416, 458, 465, 770, 786, 787, 788, 1003], "cividi": 75, "ciyou": 666, "cj": [1002, 1044, 1045, 1046, 1047, 1048], "cjlin": [197, 380, 495, 516, 517, 666, 1044], "ckdtree": [427, 452, 1043], "cl": [0, 47, 51, 393, 400, 922], "cla": 131, "clabel": [179, 231], "clae": 1049, "clai": [338, 339, 340, 343, 1041], "claim": [189, 198, 386, 472, 504, 560, 656, 677, 688, 714, 753, 758, 760, 838, 873, 876, 877, 885, 892, 996, 1021], "claimamount": 238, "claimnb": [220, 238], "clair": 1041, "clamp": [908, 1013], "clang": [384, 387], "clara": [380, 1053], "clare": 1051, "clarifi": [394, 401, 801], "clariti": [172, 386, 394], "clark": 51, "class": [2, 4, 27, 30, 43, 47, 48, 49, 50, 53, 57, 60, 61, 62, 64, 66, 70, 75, 89, 90, 91, 93, 105, 106, 121, 122, 123, 130, 133, 135, 137, 138, 145, 147, 155, 156, 161, 174, 176, 177, 179, 180, 184, 185, 187, 189, 192, 193, 197, 198, 210, 211, 212, 228, 232, 235, 236, 241, 247, 254, 255, 257, 263, 264, 265, 270, 271, 272, 273, 278, 280, 284, 288, 289, 292, 296, 298, 299, 302, 304, 305, 307, 308, 309, 310, 324, 328, 332, 334, 335, 336, 338, 340, 341, 344, 345, 347, 349, 350, 353, 357, 360, 361, 362, 365, 368, 375, 378, 380, 381, 382, 383, 386, 387, 388, 390, 391, 392, 393, 395, 398, 399, 404, 407, 410, 411, 412, 414, 416, 417, 419, 421, 425, 426, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 469, 472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 496, 497, 499, 500, 501, 502, 503, 504, 505, 508, 510, 511, 512, 516, 517, 518, 520, 522, 523, 527, 530, 531, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 582, 583, 585, 589, 590, 591, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 705, 706, 707, 708, 709, 710, 711, 712, 713, 715, 716, 717, 720, 721, 722, 723, 724, 725, 726, 728, 730, 735, 737, 738, 739, 741, 743, 744, 745, 746, 747, 748, 749, 750, 751, 762, 763, 765, 790, 791, 792, 794, 795, 796, 797, 802, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 835, 836, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 937, 938, 939, 940, 941, 943, 944, 956, 957, 958, 961, 966, 968, 970, 971, 984, 986, 989, 990, 991, 992, 994, 995, 996, 997, 999, 1001, 1002, 1004, 1007, 1008, 1010, 1011, 1013, 1016, 1020, 1021, 1022, 1024, 1025, 1029, 1032, 1034, 1036, 1038, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "class1_1": 162, "class2_1": 162, "class_0": [228, 383, 518], "class_1": [228, 383, 518], "class_2": [383, 518], "class_count_": [847, 848, 849, 850, 851], "class_id": [287, 288], "class_index": 90, "class_label": [400, 565, 569, 572, 666, 667, 674, 676, 682, 683, 684, 807, 830, 920, 922, 938, 1015], "class_likelihood_ratio": [2, 281, 1000, 1056], "class_log_prior_": [847, 848, 849, 851], "class_memb": 73, "class_member_mask": 84, "class_nam": [141, 271, 893, 924, 925, 926, 1016, 1057], "class_name0": [432, 450, 451, 453, 455, 457, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 647, 648, 649, 650, 696, 697, 700, 856, 861, 864, 868, 878, 904, 905], "class_name1": [432, 450, 451, 453, 455, 457, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 647, 648, 649, 650, 696, 697, 700, 856, 861, 864, 868, 878, 904, 905], "class_name2": [432, 450, 451, 453, 455, 457, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 647, 648, 649, 650, 696, 697, 700, 856, 861, 864, 868, 878, 904, 905], "class_of_interest": [66, 287, 639, 1058], "class_prior": [381, 847, 848, 849, 851, 1042, 1045], "class_prior_": [559, 850], "class_protein_loc": 296, "class_sep": [173, 309, 523, 807, 830], "class_weight": [2, 45, 351, 400, 565, 569, 572, 666, 667, 674, 676, 682, 683, 684, 685, 912, 914, 917, 919, 920, 922, 937, 938, 989, 1014, 1015, 1030, 1041, 1042, 1044, 1045, 1046, 1047, 1049, 1055, 1056], "class_weight_": [914, 917, 1056], "class_weight_vect": 937, "classes_": [137, 212, 229, 248, 254, 287, 338, 339, 386, 388, 400, 441, 445, 446, 557, 558, 559, 561, 563, 565, 567, 569, 572, 575, 577, 601, 602, 618, 639, 666, 667, 674, 676, 682, 683, 684, 705, 708, 710, 796, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 847, 848, 849, 850, 851, 854, 859, 862, 869, 872, 879, 880, 883, 893, 907, 908, 909, 912, 914, 917, 920, 922, 925, 1000, 1011, 1014, 1042, 1045, 1046, 1048, 1051, 1053], "classic": [55, 215, 244, 263, 269, 353, 383, 390, 418, 420, 421, 451, 455, 457, 467, 500, 508, 512, 518, 549, 640, 641, 922, 923, 994, 996, 999, 1002, 1010, 1019, 1028, 1041, 1042, 1046, 1055], "classif": [2, 14, 19, 30, 31, 38, 40, 42, 45, 46, 49, 57, 60, 61, 62, 64, 67, 70, 80, 91, 105, 106, 107, 111, 112, 117, 119, 123, 128, 137, 139, 141, 143, 145, 146, 147, 148, 153, 155, 156, 158, 162, 164, 167, 169, 170, 171, 173, 174, 175, 181, 182, 183, 192, 193, 197, 198, 210, 211, 212, 213, 220, 228, 230, 232, 233, 235, 246, 248, 252, 253, 254, 257, 260, 266, 267, 270, 271, 275, 276, 277, 278, 279, 287, 292, 293, 294, 296, 297, 300, 301, 307, 308, 309, 311, 312, 313, 314, 315, 316, 321, 322, 323, 324, 338, 343, 344, 345, 349, 352, 354, 355, 356, 357, 359, 361, 362, 369, 373, 375, 379, 380, 381, 383, 388, 391, 395, 399, 400, 411, 414, 415, 416, 417, 420, 421, 423, 424, 425, 433, 445, 477, 483, 490, 495, 496, 497, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511, 512, 518, 520, 522, 523, 527, 528, 530, 531, 549, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 572, 573, 574, 575, 577, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 612, 613, 614, 617, 618, 619, 621, 622, 630, 639, 640, 641, 651, 666, 667, 674, 676, 682, 683, 684, 705, 711, 713, 716, 720, 721, 723, 724, 726, 734, 735, 737, 738, 742, 743, 746, 749, 750, 751, 762, 764, 766, 767, 769, 790, 791, 792, 794, 795, 796, 797, 802, 804, 807, 808, 809, 811, 812, 813, 814, 822, 826, 827, 830, 831, 832, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 846, 847, 848, 849, 850, 851, 854, 859, 861, 862, 868, 869, 870, 872, 876, 879, 884, 885, 886, 887, 892, 893, 896, 898, 907, 908, 909, 912, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 935, 938, 946, 989, 990, 992, 993, 994, 997, 998, 1002, 1005, 1007, 1008, 1010, 1011, 1013, 1018, 1019, 1021, 1022, 1023, 1024, 1025, 1026, 1030, 1031, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "classifi": [2, 30, 45, 46, 47, 48, 60, 63, 65, 66, 68, 70, 91, 104, 105, 106, 107, 108, 121, 130, 135, 139, 140, 141, 142, 143, 146, 147, 148, 151, 158, 161, 162, 167, 170, 171, 172, 173, 178, 189, 194, 195, 197, 198, 210, 211, 212, 218, 220, 227, 229, 232, 235, 238, 247, 250, 252, 254, 260, 271, 272, 276, 277, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 294, 296, 297, 301, 307, 308, 310, 314, 317, 321, 330, 331, 335, 337, 338, 339, 341, 342, 344, 345, 347, 348, 350, 351, 352, 353, 357, 358, 362, 381, 383, 386, 388, 391, 398, 400, 407, 415, 416, 417, 420, 424, 425, 426, 433, 441, 442, 443, 444, 445, 446, 447, 496, 497, 504, 512, 520, 522, 523, 530, 539, 544, 545, 550, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 569, 571, 572, 574, 575, 576, 577, 578, 601, 602, 610, 614, 618, 630, 637, 639, 640, 641, 657, 666, 667, 674, 676, 679, 680, 681, 682, 683, 684, 705, 706, 708, 710, 711, 715, 716, 717, 719, 720, 721, 726, 728, 730, 734, 735, 737, 738, 740, 742, 743, 746, 747, 748, 749, 750, 751, 762, 764, 790, 791, 792, 795, 796, 797, 802, 804, 807, 808, 811, 812, 814, 822, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 859, 860, 862, 863, 868, 869, 870, 872, 873, 879, 892, 893, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 926, 941, 943, 989, 990, 992, 995, 996, 997, 1000, 1001, 1002, 1005, 1008, 1010, 1013, 1014, 1015, 1016, 1019, 1020, 1021, 1022, 1024, 1025, 1026, 1028, 1029, 1030, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1058, 1059], "classification_data": 46, "classification_report": [2, 45, 68, 104, 171, 276, 317, 338, 339, 830, 1000, 1030, 1034, 1043, 1045, 1049, 1050, 1051, 1053, 1057, 1059], "classificationcriterion": 1049, "classifier_": [91, 254], "classifier_01": 336, "classifier_05": 336, "classifier__c": 105, "classifier__criterion": 259, "classifier__max_depth": 259, "classifier__max_featur": 259, "classifier__min_samples_leaf": 194, "classifier__n_estim": 259, "classifier__n_neighbor": 301, "classifier_idx": 66, "classifier_model": 301, "classifier_other_threshold": 807, "classifier_tun": 830, "classifierchain": [2, 298, 400, 407, 844, 846, 1048, 1053, 1056, 1058, 1059], "classifiermixin": [2, 137, 254, 386, 388, 400, 420, 1052], "classify__c": 106, "classmethod": [393, 446, 639, 640, 705, 706, 707, 708, 709, 710, 814, 831], "classnameprefixfeaturesoutmixin": [2, 388, 440, 1056], "claudio": [383, 1055, 1056, 1058, 1059], "claus": [44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 62, 64, 66, 67, 68, 72, 74, 75, 77, 80, 81, 82, 83, 86, 87, 88, 89, 92, 96, 100, 101, 102, 104, 105, 107, 108, 109, 115, 120, 121, 125, 127, 129, 130, 131, 132, 135, 137, 139, 140, 141, 142, 143, 144, 145, 150, 151, 153, 154, 155, 159, 160, 174, 176, 177, 179, 180, 181, 182, 183, 185, 188, 197, 202, 203, 205, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 221, 222, 225, 227, 228, 236, 237, 241, 242, 247, 252, 253, 255, 257, 263, 265, 279, 284, 291, 298, 299, 301, 307, 308, 309, 311, 312, 314, 319, 320, 321, 322, 323, 324, 353, 354, 356, 357, 360, 361, 362, 398], "clauss": 1058, "clb": 193, "clean": [87, 105, 219, 369, 378, 384, 422, 1006, 1010, 1051], "cleaner": 101, "cleanli": [97, 1041], "cleanup": [386, 1041], "clear": [43, 90, 95, 106, 192, 193, 324, 381, 385, 386, 388, 398, 399, 400, 414, 417, 422, 926, 927, 989, 994, 1052, 1053, 1054, 1059], "clear_data_hom": 2, "clearer": [245, 1015], "clearli": [43, 95, 128, 193, 252, 353, 385, 386, 398, 400, 421, 423, 1001, 1007], "clegg": 1044, "clemen": 1045, "clement": [1048, 1049, 1053], "clenaghan": [1046, 1047], "cleveland": 381, "cleverless": 1043, "clf": [45, 49, 50, 51, 61, 62, 63, 64, 67, 68, 73, 83, 86, 89, 93, 98, 105, 131, 143, 151, 154, 156, 161, 165, 167, 170, 171, 173, 178, 180, 195, 210, 212, 213, 217, 218, 224, 227, 229, 232, 233, 234, 235, 236, 243, 248, 249, 252, 255, 261, 267, 275, 279, 283, 284, 286, 289, 290, 302, 305, 306, 307, 310, 314, 321, 324, 328, 329, 330, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 360, 364, 365, 368, 373, 381, 399, 400, 410, 417, 420, 423, 425, 446, 557, 558, 561, 563, 565, 567, 569, 571, 572, 575, 601, 602, 605, 640, 642, 646, 647, 648, 649, 650, 652, 653, 656, 660, 666, 667, 668, 669, 670, 674, 676, 677, 680, 681, 682, 683, 684, 685, 688, 705, 706, 708, 710, 719, 796, 808, 811, 812, 822, 840, 841, 842, 844, 847, 848, 849, 850, 851, 858, 859, 869, 912, 914, 916, 917, 920, 924, 926, 990, 992, 996, 1000, 1001, 1003, 1004, 1006, 1007, 1014, 1015, 1016, 1025, 1029, 1030, 1034], "clf1": [69, 161, 162, 423, 577], "clf2": [69, 161, 162, 388, 423, 577], "clf3": [69, 161, 162, 388, 423, 577], "clf__": 279, "clf__alpha": [279, 1034], "clf__c": 417, "clf_descr": 360, "clf_en_lr": 211, "clf_err": 143, "clf_isoton": 61, "clf_isotonic_scor": 61, "clf_l1_lr": 211, "clf_l2_lr": 211, "clf_list": [62, 64], "clf_name": [49, 360], "clf_no_weight": 358, "clf_pf": 850, "clf_prob": 63, "clf_sample_weight": 254, "clf_score": 61, "clf_sel": 195, "clf_select": 170, "clf_sgd": 234, "clf_sigmoid": 61, "clf_sigmoid_scor": 61, "clf_weight": 358, "cli": 1026, "click": [249, 259, 279, 329, 335, 386, 388, 394, 1024, 1025, 1027], "clickabl": 1055, "client": 388, "clifford": 1054, "cliffordemmanuel": 1054, "clim": 179, "climatologi": 414, "climb": [416, 456, 469], "clinton": 57, "clip": [62, 64, 238, 250, 319, 349, 643, 684, 749, 882, 1010, 1045, 1052, 1053], "clmbst": 1053, "clock": 43, "clone": [2, 91, 152, 184, 193, 254, 317, 335, 369, 384, 386, 389, 390, 392, 394, 400, 414, 417, 426, 445, 473, 577, 578, 605, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 814, 831, 836, 839, 843, 846, 872, 873, 909, 1020, 1041, 1047, 1049, 1053, 1057, 1058], "clone_kernel": [618, 619, 1051], "clone_with_theta": [184, 426, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633], "cloned_classifi": 441, "close": [8, 47, 51, 55, 61, 62, 64, 73, 74, 81, 89, 95, 101, 111, 112, 115, 130, 142, 149, 152, 156, 160, 176, 177, 180, 181, 182, 183, 184, 192, 194, 204, 224, 226, 241, 247, 253, 257, 263, 269, 278, 279, 292, 305, 306, 319, 328, 349, 353, 354, 361, 369, 381, 386, 388, 394, 398, 400, 401, 414, 416, 419, 420, 423, 426, 458, 463, 480, 516, 517, 540, 571, 636, 651, 655, 669, 680, 682, 695, 713, 754, 805, 826, 827, 847, 848, 849, 851, 858, 933, 989, 993, 994, 996, 997, 999, 1000, 1001, 1003, 1006, 1007, 1010, 1015, 1019, 1024, 1032, 1044, 1048, 1049, 1050], "close_pric": 51, "closer": [43, 72, 128, 130, 159, 174, 176, 193, 199, 224, 353, 362, 414, 416, 421, 457, 561, 636, 720, 854, 855, 860, 862, 863, 864, 1015, 1048], "closest": [64, 81, 99, 224, 388, 416, 448, 450, 451, 455, 456, 457, 467, 661, 787, 788, 842, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 991, 994, 1001, 1003, 1032], "closur": 55, "cloud": [78, 117, 124, 126, 189, 394, 421, 541, 549, 700, 1000, 1018, 1019, 1021, 1033], "cloudpickl": 1036, "clouldpickl": 410, "cls_info": 49, "cls_name": [47, 49], "cls_runtim": 47, "cls_stat": 47, "cls_valu": 49, "club": 383, "clue": [381, 394, 997], "clump": 244, "clust": [100, 458, 465], "cluster": [2, 47, 48, 53, 54, 55, 56, 58, 61, 64, 77, 78, 81, 83, 85, 86, 88, 89, 92, 94, 96, 97, 104, 113, 120, 121, 122, 131, 137, 141, 148, 156, 169, 184, 195, 217, 241, 243, 244, 245, 251, 254, 257, 263, 264, 265, 266, 279, 299, 305, 306, 308, 322, 329, 333, 338, 339, 340, 341, 342, 351, 359, 360, 362, 368, 375, 379, 381, 383, 386, 388, 391, 398, 400, 411, 417, 422, 424, 427, 430, 431, 434, 442, 443, 444, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 496, 510, 511, 512, 519, 520, 521, 522, 523, 530, 538, 549, 552, 561, 572, 574, 597, 598, 599, 639, 699, 700, 703, 712, 713, 718, 722, 723, 725, 727, 733, 739, 744, 745, 763, 765, 786, 787, 794, 800, 801, 803, 805, 806, 864, 865, 873, 877, 884, 892, 941, 943, 961, 984, 990, 997, 999, 1003, 1006, 1008, 1010, 1013, 1017, 1019, 1020, 1021, 1024, 1025, 1028, 1031, 1034, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1060], "cluster_1": 156, "cluster_2": 156, "cluster_al": [456, 469], "cluster_cent": [73, 96, 98, 99, 469], "cluster_center_indic": [448, 462], "cluster_centers_": [77, 78, 83, 85, 93, 95, 96, 98, 99, 125, 332, 361, 448, 451, 455, 456, 457, 1033], "cluster_centers_indic": [73, 462], "cluster_centers_indices_": [73, 448], "cluster_data": 94, "cluster_doc": 57, "cluster_hierarchy_": [416, 458], "cluster_id": [195, 361], "cluster_id_to_feature_id": 195, "cluster_label": [91, 95], "cluster_method": 458, "cluster_optics_dbscan": [2, 100, 416], "cluster_optics_xi": 2, "cluster_qr": [81, 416, 460, 470, 1055], "cluster_s": 361, "cluster_selection_epsilon": 454, "cluster_selection_method": 454, "cluster_std": [63, 73, 79, 84, 90, 91, 92, 94, 95, 97, 98, 99, 232, 247, 266, 322, 351, 520], "cluster_word": 57, "clusterer_": 91, "clustering_algorithm": [78, 79, 97], "clustering_metr": 93, "clustermixin": [2, 388, 1058], "clusters_std": 351, "clyde": 1046, "cl\u00e9ment": [1050, 1054, 1056], "cm": [43, 45, 50, 51, 53, 58, 59, 61, 66, 67, 68, 73, 74, 81, 82, 84, 85, 86, 87, 88, 89, 90, 93, 95, 96, 102, 113, 115, 120, 125, 128, 131, 141, 147, 148, 167, 172, 179, 180, 193, 203, 212, 229, 232, 233, 236, 241, 242, 243, 248, 251, 252, 256, 261, 271, 272, 273, 299, 302, 303, 305, 309, 312, 314, 316, 317, 319, 321, 330, 333, 338, 339, 343, 345, 346, 347, 349, 350, 351, 357, 358, 365, 383, 417, 705, 925, 1000, 1010, 1016, 1030, 1031], "cm2013": 416, "cm_bright": [67, 314, 321], "cm_displai": 248, "cm_piyg": 321, "cmap": [43, 44, 45, 50, 51, 53, 58, 59, 66, 67, 68, 70, 74, 75, 81, 82, 85, 86, 88, 89, 93, 113, 115, 120, 125, 128, 131, 135, 141, 147, 148, 167, 172, 179, 180, 193, 199, 203, 204, 211, 212, 229, 232, 233, 234, 236, 241, 242, 243, 251, 252, 256, 271, 273, 299, 303, 305, 307, 308, 310, 312, 314, 316, 317, 319, 321, 338, 339, 343, 345, 346, 347, 348, 349, 350, 351, 354, 357, 358, 365, 705, 1030, 1031], "cmap_bold": [307, 310], "cmap_cv": 273, "cmap_data": 273, "cmap_light": [307, 310], "cmcsa": 51, "cmd": 384, "cmu": 907, "cname": 77, "cnb": 1002, "cnp": 387, "cnx": 1049, "co": [2, 43, 51, 53, 56, 58, 74, 75, 104, 157, 159, 181, 189, 192, 221, 242, 278, 293, 332, 342, 360, 361, 362, 367, 390, 422, 424, 457, 459, 461, 496, 519, 599, 707, 727, 772, 803, 995, 1010, 1021, 1024, 1035, 1036], "co2": [175, 183, 189, 426, 504, 619, 623, 630, 631, 633, 1021, 1048], "co2_data": 181, "co2_kernel": 181, "coars": [43, 148, 392, 456, 469], "coarser": [148, 152], "coast": [50, 312], "coastlin": [50, 174, 312, 383], "coca": 51, "cock": [160, 1050], "cockburn": 1043, "coclust": [57, 413, 459, 521], "cocoa": 1024, "code": [0, 2, 30, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 380, 384, 385, 387, 389, 390, 395, 398, 400, 401, 404, 407, 410, 412, 415, 416, 423, 424, 450, 451, 455, 457, 467, 504, 534, 538, 539, 545, 546, 550, 551, 553, 554, 556, 574, 580, 589, 590, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 672, 673, 690, 691, 693, 694, 719, 840, 841, 842, 879, 886, 997, 1001, 1010, 1012, 1014, 1015, 1019, 1020, 1021, 1023, 1024, 1026, 1034, 1041, 1043, 1044, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "code_book_": 842, "code_init": [539, 553], "code_s": [296, 842, 1001], "codebas": [334, 369, 386, 387, 388, 424, 1041, 1047], "codebook": [83, 296, 574, 842], "codebook_random": 83, "codecov": 394, "codeofconduct": 386, "coder": [134, 550, 724], "codevig": 1047, "coef": [49, 89, 134, 191, 192, 199, 204, 207, 211, 212, 214, 219, 223, 224, 225, 229, 235, 236, 261, 291, 316, 334, 357, 532, 654, 655, 657, 660, 661, 667, 668, 669, 670, 671, 677, 680, 682, 688, 689, 690, 691, 692, 693, 694, 695, 1004], "coef0": [197, 353, 355, 460, 543, 647, 648, 651, 783, 785, 914, 915, 916, 917, 918, 998, 1015], "coef_": [46, 49, 53, 89, 117, 170, 171, 174, 191, 192, 199, 202, 204, 205, 206, 210, 211, 212, 213, 214, 215, 216, 219, 223, 224, 225, 229, 235, 236, 255, 261, 291, 292, 326, 332, 347, 354, 357, 360, 369, 381, 388, 400, 419, 425, 473, 490, 491, 492, 557, 601, 602, 605, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 912, 913, 914, 915, 916, 917, 918, 984, 994, 996, 1014, 1015, 1032, 1041, 1043, 1046, 1048, 1053, 1055, 1058, 1059], "coef_agglomeration_": 89, "coef_en_lr": 211, "coef_i": 192, "coef_init": [654, 655, 660, 661, 668, 669, 670, 671, 674, 675, 676, 684, 685, 686, 689, 692], "coef_l": 205, "coef_l1_lr": 211, "coef_l2_lr": 211, "coef_lasso_": 214, "coef_multi_task_lasso_": 214, "coef_p": 205, "coef_path": [661, 671, 692], "coef_path_": [658, 659, 662, 663, 996], "coef_path_continu": [661, 671, 692], "coef_path_lar": [661, 671, 692], "coef_pl": 205, "coef_ridg": 202, "coef_selection_": 89, "coeff": 688, "coeff_diff": 206, "coeffeci": 1050, "coeffici": [2, 25, 46, 49, 73, 84, 93, 95, 111, 112, 115, 125, 128, 165, 171, 176, 189, 190, 191, 198, 202, 204, 205, 206, 207, 211, 213, 214, 215, 216, 217, 218, 222, 223, 235, 238, 261, 278, 291, 292, 316, 326, 330, 331, 332, 353, 356, 360, 361, 362, 373, 382, 388, 400, 403, 418, 419, 421, 425, 426, 429, 439, 460, 473, 475, 481, 483, 484, 486, 487, 488, 489, 490, 491, 492, 504, 532, 534, 535, 539, 543, 545, 547, 550, 551, 556, 560, 562, 564, 566, 568, 570, 573, 576, 578, 590, 597, 601, 605, 617, 619, 622, 635, 643, 644, 647, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 699, 709, 711, 724, 727, 737, 742, 746, 751, 758, 761, 783, 785, 793, 794, 796, 800, 801, 804, 823, 835, 838, 845, 846, 855, 863, 870, 873, 885, 892, 912, 913, 914, 915, 916, 917, 918, 921, 923, 991, 994, 996, 1014, 1015, 1021, 1032, 1041, 1045, 1046, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1058], "coefs_": [213, 316, 869, 870, 1004, 1046], "coefs_cf": 326, "coefs_enet": 205, "coefs_lasso": 205, "coefs_no_cf": 326, "coefs_path": 667, "coefs_paths_": [667, 1051], "coefs_positive_enet": 205, "coefs_positive_lasso": 205, "coelho": [1042, 1044, 1045, 1049], "coelhudo": 1053, "cognit": [174, 383], "cohen": [2, 724, 1049], "cohen_kappa_scor": [2, 1000, 1046, 1048], "coher": 416, "cohort": 163, "coin": [51, 53, 55, 59, 71, 74, 75, 76, 79, 83, 88, 89, 97, 101, 102, 189, 416, 424, 449, 470, 1012, 1021, 1033], "coincid": [180, 222, 426], "col": [52, 57, 62, 64, 73, 77, 84, 90, 94, 98, 99, 104, 107, 145, 161, 181, 240, 257, 357, 519, 521], "col_compl": 57, "col_idx": 59, "col_idx_shuffl": 58, "col_ind": [431, 459, 461], "col_indic": 155, "col_nam": 52, "col_split": 52, "cola": 51, "cold": 299, "cole": 1050, "coleman": [1042, 1043], "colgat": [51, 55], "colin": [45, 381, 1047], "colin_powel": 1030, "colinear": 558, "collabor": 386, "collaps": [43, 193, 257, 319, 349, 398], "colleagu": 278, "collect": [2, 41, 46, 49, 51, 52, 57, 62, 107, 143, 155, 156, 163, 174, 181, 188, 195, 208, 213, 243, 250, 281, 285, 361, 362, 373, 381, 383, 390, 404, 420, 421, 423, 424, 454, 472, 561, 562, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 577, 578, 589, 591, 592, 596, 597, 598, 599, 640, 737, 738, 746, 786, 791, 792, 795, 810, 814, 815, 817, 831, 958, 971, 974, 989, 995, 996, 1000, 1006, 1011, 1020, 1024, 1029, 1034, 1043, 1053], "colleg": [0, 191], "college_degre": 191, "collid": 424, "collier": 1034, "collin": 1044, "collinear": [192, 195, 225, 238, 423, 575, 656, 677, 688, 885, 996, 1041], "collis": [361, 362, 424, 590, 597], "collot": [1055, 1056], "colombia": [50, 312, 381, 506], "colon": 386, "coloni": 381, "color": [43, 45, 46, 47, 48, 49, 50, 51, 52, 58, 61, 62, 63, 64, 67, 69, 70, 71, 73, 75, 77, 79, 81, 82, 84, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 111, 112, 113, 114, 115, 118, 121, 122, 123, 125, 126, 127, 128, 129, 131, 132, 133, 134, 139, 140, 145, 148, 149, 151, 154, 155, 156, 157, 158, 160, 162, 165, 167, 172, 176, 178, 179, 180, 181, 182, 183, 184, 185, 188, 189, 192, 194, 195, 199, 200, 202, 203, 204, 205, 207, 208, 209, 210, 212, 214, 216, 218, 220, 221, 222, 223, 224, 225, 226, 229, 230, 231, 232, 234, 237, 238, 241, 242, 243, 245, 247, 251, 252, 253, 255, 258, 263, 264, 265, 266, 267, 268, 269, 272, 273, 277, 279, 281, 282, 283, 284, 285, 287, 288, 289, 291, 292, 298, 301, 304, 305, 306, 307, 310, 311, 312, 314, 319, 320, 321, 323, 324, 325, 329, 335, 340, 341, 343, 347, 348, 349, 350, 351, 353, 355, 356, 357, 365, 366, 380, 381, 383, 394, 416, 423, 424, 455, 501, 502, 514, 591, 592, 787, 974, 1014, 1016, 1021, 1046, 1051, 1053, 1058], "color_continuous_scal": 279, "color_intens": 48, "color_it": [264, 268, 269], "color_map": 343, "color_palett": [72, 140, 155, 268], "colorbar": [43, 50, 66, 75, 125, 135, 147, 156, 172, 177, 179, 180, 182, 193, 240, 251, 267, 289, 319, 349, 705, 1053], "colorbarbas": 319, "colorblind": [72, 140, 155], "coloring_matrix": [111, 112], "colormap": [125, 141, 184, 349, 354, 705, 1054], "colors_": 77, "colors_list": 145, "colour": [266, 383, 424, 595, 1001], "colt": [734, 764, 1000], "colton": 992, "columbia": 0, "column": [2, 43, 52, 58, 59, 95, 103, 106, 109, 121, 146, 148, 149, 152, 155, 157, 160, 174, 181, 187, 189, 191, 192, 193, 194, 195, 209, 220, 221, 224, 228, 238, 249, 256, 257, 258, 261, 268, 272, 278, 279, 289, 290, 292, 298, 316, 324, 325, 326, 330, 331, 332, 333, 335, 336, 360, 361, 362, 373, 380, 381, 383, 386, 388, 392, 395, 398, 399, 400, 413, 416, 417, 419, 421, 423, 424, 425, 428, 431, 459, 461, 472, 474, 475, 479, 480, 486, 495, 496, 497, 498, 499, 500, 502, 504, 508, 509, 510, 512, 513, 516, 517, 518, 519, 521, 523, 534, 539, 542, 545, 549, 550, 556, 563, 565, 566, 569, 570, 572, 573, 574, 575, 589, 590, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 615, 616, 618, 635, 638, 640, 641, 642, 654, 656, 660, 666, 668, 670, 672, 673, 677, 688, 693, 694, 705, 721, 726, 727, 737, 738, 746, 762, 771, 776, 777, 778, 781, 791, 792, 795, 796, 808, 811, 812, 822, 833, 838, 843, 846, 847, 848, 849, 850, 851, 852, 853, 872, 876, 877, 878, 879, 885, 886, 887, 891, 892, 893, 894, 896, 897, 898, 902, 903, 912, 914, 917, 920, 922, 928, 932, 933, 938, 949, 963, 976, 977, 979, 987, 989, 990, 992, 996, 998, 1000, 1001, 1008, 1010, 1015, 1020, 1021, 1041, 1043, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "column_labels_": [58, 59, 413, 459, 461], "column_nam": 238, "column_or_1d": [2, 395, 1052, 1056], "column_result": 279, "column_stack": [76, 314, 321], "column_to_drop": 192, "column_tran": [238, 417], "column_transform": 336, "columnar": [380, 472, 1019], "columns_": [57, 413, 431, 459, 461], "columns_to_drop": 272, "columntransform": [2, 43, 104, 105, 160, 192, 193, 194, 220, 238, 249, 257, 259, 261, 325, 329, 331, 332, 333, 335, 378, 380, 398, 399, 407, 474, 475, 637, 877, 989, 990, 1020, 1036, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "columntransformercolumntransform": [105, 160, 192, 194, 249, 259, 325, 329, 332], "columntransformerinot": [160, 193], "columnwis": 421, "com": [46, 47, 50, 51, 54, 58, 59, 61, 77, 83, 92, 100, 104, 105, 137, 139, 140, 141, 142, 143, 144, 151, 153, 154, 159, 160, 176, 179, 181, 183, 185, 188, 200, 222, 227, 237, 241, 243, 245, 250, 263, 265, 266, 279, 282, 299, 319, 320, 323, 324, 360, 361, 381, 384, 386, 390, 391, 392, 394, 398, 416, 450, 542, 549, 679, 713, 1048, 1051], "coma": 1024, "comaniciu": [98, 416, 456], "comapar": 416, "comb": 1055, "combat": [314, 421], "combin": [2, 19, 43, 51, 52, 58, 62, 64, 96, 104, 105, 107, 108, 109, 121, 125, 133, 134, 138, 149, 150, 154, 155, 163, 176, 182, 187, 188, 189, 192, 204, 220, 224, 237, 238, 244, 247, 249, 252, 278, 279, 287, 289, 290, 308, 315, 325, 330, 331, 333, 352, 353, 362, 365, 373, 378, 382, 383, 386, 391, 399, 400, 413, 414, 416, 417, 420, 421, 422, 423, 424, 425, 426, 428, 429, 453, 472, 474, 475, 481, 483, 484, 487, 488, 489, 497, 504, 516, 517, 523, 529, 532, 534, 539, 545, 546, 548, 550, 555, 557, 568, 570, 573, 575, 576, 618, 622, 624, 629, 632, 638, 642, 651, 654, 655, 660, 661, 666, 667, 668, 669, 670, 671, 674, 676, 680, 681, 682, 683, 684, 686, 687, 689, 692, 700, 709, 738, 796, 808, 811, 812, 819, 820, 833, 835, 839, 856, 871, 872, 873, 877, 885, 886, 887, 892, 912, 974, 989, 992, 993, 996, 1000, 1001, 1003, 1006, 1010, 1013, 1014, 1016, 1017, 1021, 1024, 1030, 1032, 1034, 1041, 1046, 1049, 1052, 1053, 1054, 1056, 1057], "combinator": 818, "combined_featur": 108, "combsccod": 1055, "comcast": 51, "come": [84, 102, 104, 113, 118, 130, 174, 176, 252, 292, 328, 360, 361, 373, 375, 379, 383, 386, 387, 390, 394, 398, 400, 404, 410, 415, 416, 420, 423, 424, 447, 458, 464, 480, 558, 713, 803, 829, 914, 917, 989, 990, 994, 997, 999, 1003, 1006, 1015, 1025, 1041, 1052, 1055, 1057], "comedi": 883, "comfort": [90, 423], "command": [251, 373, 374, 384, 386, 390, 392, 394, 404, 424, 516, 1019, 1034, 1043], "comment": [81, 360, 384, 385, 386, 387, 389, 390, 394, 495, 587, 1000], "commerc": 1024, "commerci": [420, 1024], "commit": [386, 390, 394, 1023, 1041, 1042, 1043, 1044], "committ": [386, 1041], "commod": 1000, "common": [2, 52, 54, 55, 57, 128, 171, 174, 189, 190, 191, 216, 224, 225, 273, 278, 285, 296, 330, 353, 360, 362, 368, 373, 380, 386, 388, 394, 396, 398, 399, 403, 404, 407, 413, 414, 416, 417, 420, 422, 425, 426, 455, 473, 475, 504, 598, 640, 661, 680, 681, 709, 754, 761, 777, 809, 810, 813, 823, 825, 826, 827, 828, 829, 835, 838, 873, 875, 883, 884, 885, 890, 892, 897, 898, 900, 901, 902, 903, 951, 989, 990, 996, 1003, 1006, 1010, 1015, 1016, 1019, 1020, 1021, 1024, 1025, 1036, 1041, 1049, 1051, 1052, 1056], "common_nod": 368, "common_node_id": 368, "common_param": [92, 152, 155, 193, 253, 280, 281, 353], "commonli": [220, 275, 353, 379, 400, 416, 417, 426, 622, 766, 767, 805, 841, 884, 997, 998, 1000, 1001, 1003, 1057], "commun": [254, 379, 385, 391, 394, 400, 401, 416, 423, 546, 548, 555, 700, 718, 884, 990, 997, 1003, 1010, 1014, 1019, 1023, 1024, 1049, 1050], "commut": [43, 52], "comp": [57, 117, 118, 128, 135, 317, 342, 360, 361, 362, 381, 1034], "comp_cov": [477, 478, 479, 480, 481, 482, 483, 484], "compact": [174, 197, 319, 373, 383, 852, 853, 1016, 1043], "compani": [220, 238, 415, 416, 1024], "companion": [386, 1010], "companioni": 1041, "compar": [43, 44, 48, 52, 57, 58, 61, 62, 64, 70, 71, 72, 74, 75, 76, 78, 82, 84, 87, 89, 90, 92, 93, 99, 102, 105, 106, 107, 108, 113, 114, 116, 118, 122, 123, 128, 132, 134, 138, 139, 140, 142, 144, 148, 149, 150, 152, 154, 155, 156, 158, 160, 163, 166, 174, 180, 187, 188, 189, 192, 193, 194, 195, 198, 200, 202, 204, 208, 209, 215, 217, 220, 221, 223, 224, 226, 228, 230, 234, 237, 238, 240, 241, 244, 246, 249, 252, 255, 257, 258, 260, 265, 266, 270, 273, 275, 276, 277, 279, 281, 283, 285, 287, 289, 290, 293, 296, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 313, 316, 318, 320, 323, 324, 326, 330, 353, 360, 361, 362, 367, 368, 369, 375, 381, 383, 386, 388, 410, 413, 414, 415, 416, 418, 419, 420, 421, 423, 425, 426, 448, 449, 450, 452, 453, 454, 456, 457, 458, 460, 466, 471, 472, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 498, 504, 510, 512, 520, 522, 530, 532, 536, 539, 545, 547, 549, 553, 554, 559, 560, 569, 570, 571, 572, 573, 639, 647, 652, 653, 661, 663, 665, 666, 671, 674, 676, 684, 685, 692, 703, 713, 720, 723, 739, 746, 751, 794, 806, 808, 813, 822, 835, 838, 845, 854, 858, 861, 865, 869, 870, 872, 873, 880, 881, 882, 884, 885, 886, 887, 888, 889, 890, 892, 893, 897, 898, 899, 900, 901, 902, 903, 912, 913, 914, 916, 917, 989, 992, 993, 994, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1010, 1011, 1014, 1015, 1016, 1018, 1019, 1021, 1032, 1033, 1041, 1043, 1048, 1049, 1054], "comparison": [51, 53, 57, 60, 61, 62, 63, 65, 69, 71, 73, 75, 77, 83, 85, 92, 93, 94, 95, 96, 98, 104, 112, 121, 124, 126, 127, 129, 135, 139, 142, 145, 152, 155, 158, 162, 163, 168, 175, 181, 183, 185, 189, 194, 202, 204, 206, 208, 211, 218, 220, 224, 235, 238, 239, 242, 243, 244, 245, 246, 250, 251, 265, 270, 272, 273, 274, 275, 282, 290, 292, 298, 308, 314, 321, 323, 324, 328, 330, 343, 346, 355, 359, 360, 361, 369, 381, 383, 400, 414, 416, 418, 419, 421, 425, 426, 445, 446, 451, 454, 455, 457, 490, 491, 492, 496, 512, 520, 522, 523, 530, 533, 543, 549, 557, 558, 561, 572, 573, 589, 590, 596, 597, 598, 599, 614, 616, 618, 619, 623, 630, 633, 639, 647, 651, 667, 680, 696, 697, 698, 699, 700, 712, 746, 751, 787, 796, 808, 809, 810, 811, 813, 814, 822, 824, 825, 826, 827, 828, 829, 838, 847, 850, 854, 869, 870, 873, 885, 886, 890, 892, 893, 897, 898, 899, 900, 901, 902, 903, 912, 914, 915, 917, 918, 920, 989, 993, 994, 997, 1000, 1002, 1003, 1006, 1015, 1021, 1038], "compat": [254, 281, 299, 329, 380, 389, 395, 396, 398, 400, 404, 407, 410, 424, 471, 477, 516, 574, 585, 597, 611, 622, 623, 626, 627, 628, 630, 631, 640, 641, 642, 666, 667, 681, 683, 782, 786, 809, 810, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829, 856, 857, 872, 877, 885, 886, 924, 925, 928, 963, 997, 1003, 1005, 1019, 1020, 1024, 1036, 1041, 1044, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1060], "compens": [114, 191, 193, 197, 220, 238, 279, 418, 421], "compet": [43, 192], "competit": [43, 152, 360, 423, 652, 1003], "compil": [160, 299, 362, 373, 374, 387, 388, 389, 394, 395, 398, 1019, 1041], "compl": 93, "complain": 1059, "complement": [2, 193, 288, 360, 640, 641, 810, 825, 828, 838, 847, 848, 849, 850, 851, 1007, 1022, 1036, 1049], "complementari": [43, 424], "complementnb": [2, 279, 360, 847, 848, 850, 851, 1002, 1049, 1053, 1054, 1056], "complementnbcomplementnb": 279, "complet": [0, 2, 43, 72, 73, 74, 79, 84, 87, 93, 97, 118, 155, 158, 169, 171, 174, 189, 194, 195, 226, 246, 247, 254, 257, 272, 276, 324, 326, 328, 361, 369, 381, 386, 390, 391, 394, 398, 417, 420, 421, 423, 424, 449, 453, 457, 460, 470, 471, 472, 475, 503, 544, 545, 546, 547, 552, 554, 566, 577, 578, 589, 595, 596, 597, 599, 635, 636, 637, 638, 653, 657, 665, 679, 681, 712, 713, 723, 724, 725, 737, 739, 744, 745, 765, 794, 803, 840, 843, 846, 855, 871, 872, 873, 874, 935, 985, 989, 994, 996, 1000, 1001, 1003, 1015, 1016, 1021, 1025, 1034, 1041, 1044, 1048, 1049, 1050, 1051, 1052, 1053, 1054], "completed_fac": 256, "completeness_scor": [2, 73, 84, 93, 329, 361, 416, 744, 745, 803, 1000], "complex": [42, 48, 49, 54, 58, 106, 145, 160, 173, 176, 181, 187, 189, 224, 234, 237, 246, 253, 254, 257, 270, 276, 279, 282, 287, 320, 328, 331, 332, 336, 337, 349, 353, 362, 363, 368, 382, 386, 391, 398, 416, 417, 421, 423, 427, 448, 452, 455, 456, 458, 475, 497, 508, 509, 510, 522, 542, 549, 559, 565, 566, 567, 568, 570, 572, 573, 612, 638, 646, 664, 666, 684, 685, 742, 758, 808, 838, 840, 868, 872, 873, 877, 885, 892, 908, 912, 915, 918, 920, 921, 922, 923, 989, 990, 992, 993, 995, 997, 999, 1001, 1006, 1010, 1013, 1020, 1021, 1022, 1024, 1036, 1042, 1044, 1050, 1051, 1054], "complexity_comput": [46, 49], "complexity_label": [46, 49], "compli": [386, 400, 943, 1020], "complianc": [0, 155], "compliant": [333, 386, 1059, 1060], "complic": [64, 254, 314, 392, 426, 702, 1003], "compon": [2, 11, 43, 44, 55, 79, 93, 97, 104, 107, 116, 117, 121, 126, 127, 129, 130, 131, 132, 133, 135, 158, 166, 181, 189, 191, 204, 240, 251, 252, 255, 263, 264, 267, 268, 269, 277, 279, 300, 301, 302, 310, 311, 317, 324, 330, 373, 378, 381, 386, 388, 392, 395, 410, 412, 416, 417, 419, 424, 426, 428, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 470, 471, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 510, 512, 523, 529, 534, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 581, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 703, 805, 806, 807, 808, 811, 812, 822, 830, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 948, 949, 992, 997, 999, 1010, 1012, 1015, 1019, 1020, 1021, 1022, 1024, 1028, 1034, 1035, 1036, 1041, 1043, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "component_1": 268, "component_2": 268, "component_indices_": [647, 1054], "components_": [45, 54, 93, 118, 125, 127, 128, 135, 251, 252, 317, 324, 332, 400, 417, 421, 452, 539, 540, 541, 542, 544, 545, 546, 547, 548, 549, 551, 552, 647, 861, 868, 904, 905, 992, 1012, 1030, 1045, 1047, 1053, 1056, 1059], "components_col": 107, "compos": [2, 43, 44, 62, 103, 104, 105, 109, 118, 141, 149, 160, 189, 192, 193, 194, 220, 222, 238, 249, 257, 259, 261, 292, 296, 325, 329, 331, 332, 333, 335, 336, 399, 407, 416, 417, 420, 472, 473, 474, 475, 523, 561, 620, 999, 1001, 1021, 1041], "composit": [7, 35, 249, 329, 378, 420, 666, 796, 990, 996, 1009, 1036, 1042], "compound": [43, 238, 424, 618, 620, 688, 732, 760, 996, 1034], "compoundkernel": [2, 618, 1055], "comprehens": [353, 424, 766, 767, 998, 1024, 1049], "compress": [42, 50, 55, 83, 101, 189, 296, 319, 381, 410, 416, 421, 424, 425, 660, 680, 700, 842, 885, 971, 974, 986, 996, 1010, 1021, 1033, 1041, 1050], "compressed_raccoon_kmean": 88, "compressed_raccoon_uniform": 88, "compris": [104, 152, 276, 360, 361, 362, 381, 398, 421, 423, 523, 815, 997], "compromis": [48, 64, 193, 373, 386, 655, 687, 1003, 1044], "comput": [0, 2, 27, 43, 45, 46, 50, 52, 53, 58, 63, 72, 74, 76, 77, 81, 87, 89, 92, 93, 95, 96, 104, 106, 112, 113, 114, 115, 126, 134, 142, 146, 147, 150, 151, 152, 153, 154, 155, 173, 174, 176, 181, 183, 184, 187, 192, 193, 194, 195, 197, 200, 201, 204, 205, 206, 207, 208, 209, 220, 222, 224, 228, 234, 237, 238, 241, 244, 248, 250, 251, 253, 257, 258, 260, 272, 274, 276, 278, 279, 280, 281, 285, 287, 289, 299, 301, 303, 305, 306, 308, 309, 312, 319, 328, 332, 333, 336, 339, 341, 349, 353, 356, 360, 361, 362, 368, 374, 375, 380, 381, 383, 386, 391, 392, 393, 395, 398, 399, 400, 403, 404, 410, 411, 412, 413, 414, 416, 418, 419, 421, 422, 423, 424, 425, 426, 427, 428, 429, 445, 446, 447, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 460, 465, 467, 469, 470, 471, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 491, 524, 539, 540, 542, 543, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 582, 590, 593, 594, 597, 598, 599, 601, 602, 607, 608, 611, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 635, 637, 638, 639, 640, 641, 642, 645, 646, 647, 648, 649, 650, 652, 653, 654, 655, 656, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 679, 680, 681, 682, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 720, 721, 723, 724, 725, 726, 727, 728, 733, 734, 735, 737, 738, 739, 742, 744, 746, 747, 748, 750, 751, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 794, 795, 796, 797, 800, 801, 802, 804, 805, 806, 807, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 852, 853, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 865, 866, 868, 869, 870, 877, 878, 881, 882, 887, 888, 889, 890, 891, 892, 896, 897, 899, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 914, 917, 919, 920, 921, 922, 923, 946, 947, 948, 949, 965, 966, 973, 975, 981, 989, 992, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1024, 1029, 1030, 1033, 1034, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "computation": [37, 53, 111, 125, 145, 151, 160, 176, 299, 353, 360, 372, 387, 398, 416, 417, 420, 421, 423, 426, 546, 640, 641, 679, 771, 808, 810, 811, 812, 822, 835, 996, 997, 999, 1007, 1008, 1012, 1033, 1036, 1045], "compute_class_weight": [2, 400, 1044, 1055], "compute_corrected_ttest": 278, "compute_dist": [449, 453, 1053], "compute_full_tre": [449, 453, 1045], "compute_import": 1043, "compute_inverse_compon": [904, 905, 1012], "compute_inverse_transform": 1055, "compute_label": [450, 457], "compute_node_depth": 368, "compute_optics_graph": [2, 463, 464, 1058], "compute_sample_weight": [2, 1055], "compute_scor": [109, 132, 199, 200, 652, 653, 1050], "compute_sourc": 428, "computed_scor": 653, "con": [597, 999], "concat": [43, 187, 191, 209, 238, 885], "concaten": [2, 63, 70, 74, 85, 96, 103, 106, 114, 141, 156, 170, 184, 189, 199, 202, 212, 234, 235, 241, 247, 263, 267, 268, 274, 283, 285, 286, 287, 288, 304, 317, 323, 326, 339, 348, 352, 360, 417, 472, 475, 512, 517, 539, 545, 549, 550, 607, 789, 808, 871, 872, 874, 877, 885, 917, 1001, 1021, 1029, 1033, 1042], "concav": [174, 336, 383], "concentr": [46, 48, 100, 123, 130, 139, 158, 181, 188, 189, 245, 262, 264, 269, 289, 309, 321, 340, 382, 386, 423, 451, 527, 805, 999, 1006, 1021], "concentrations_prior": 263, "concept": [2, 114, 145, 150, 254, 287, 386, 398, 416, 422, 424, 992, 1000, 1003, 1016, 1024], "conceptu": [383, 423, 998], "concern": [37, 56, 71, 110, 116, 119, 124, 136, 138, 168, 175, 186, 189, 196, 198, 239, 262, 268, 272, 295, 297, 300, 313, 318, 337, 344, 359, 363, 373, 388, 410, 997, 1012], "concis": [64, 220, 386, 391, 1052, 1054], "conclud": [139, 192, 200, 238, 278, 362, 369, 401, 872], "conclus": [43, 130, 192, 194, 220, 222, 278, 280, 369, 423, 1028], "concomit": [657, 996], "concret": [224, 387, 401, 415, 425, 676, 682, 683, 684, 685, 904, 905, 996, 1014, 1019], "concurr": [400, 424, 966, 1053, 1055], "conda": [328, 329, 330, 331, 332, 333, 334, 335, 336, 374, 386, 387, 389, 390, 392, 394, 404, 409, 410, 1016], "conda_prefix": 392, "condarc": 384, "condens": [197, 454], "condit": [2, 43, 51, 52, 62, 64, 115, 147, 152, 189, 190, 192, 209, 222, 225, 238, 254, 258, 281, 331, 368, 392, 398, 403, 413, 414, 415, 416, 418, 421, 423, 425, 459, 472, 479, 480, 481, 486, 504, 521, 531, 532, 544, 547, 548, 549, 551, 553, 555, 557, 558, 570, 635, 640, 641, 651, 658, 659, 660, 662, 663, 664, 678, 680, 681, 682, 683, 690, 691, 695, 705, 720, 725, 726, 744, 745, 803, 847, 848, 849, 850, 851, 870, 873, 876, 885, 886, 889, 893, 949, 972, 994, 996, 997, 998, 1000, 1002, 1003, 1005, 1010, 1016, 1019, 1021, 1032, 1036, 1042, 1044, 1045, 1046, 1048, 1049, 1051, 1053, 1055, 1056, 1057, 1059], "condition": [51, 64, 220, 414, 418, 766, 994], "condition2": 160, "conduct": [191, 278, 426, 1023, 1055], "conf": [46, 64, 390, 414, 420, 847, 1002, 1055], "confer": [272, 278, 381, 416, 421, 427, 447, 452, 458, 519, 543, 571, 704, 716, 734, 764, 868, 869, 870, 1000, 1006, 1012, 1016], "confid": [52, 61, 62, 63, 64, 155, 181, 183, 264, 278, 281, 341, 401, 414, 426, 644, 666, 667, 674, 676, 679, 682, 683, 684, 706, 710, 715, 728, 734, 735, 747, 748, 764, 797, 840, 879, 912, 914, 917, 996, 999, 1000, 1001, 1006, 1013, 1014, 1015, 1024, 1034, 1051], "config": [52, 374, 384, 386, 387, 394, 634, 1049], "config_context": [2, 261, 373, 374, 412, 634, 910, 1048, 1054, 1057], "configur": [2, 3, 46, 49, 64, 105, 106, 193, 254, 259, 261, 292, 326, 360, 372, 384, 386, 388, 392, 394, 398, 400, 404, 407, 412, 417, 424, 425, 440, 450, 451, 453, 455, 457, 460, 470, 472, 476, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 574, 575, 576, 577, 578, 589, 590, 591, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 634, 635, 636, 637, 638, 640, 643, 646, 647, 648, 649, 650, 696, 697, 698, 699, 700, 702, 703, 796, 856, 861, 864, 868, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 910, 966, 967, 997, 1000, 1010, 1015, 1019, 1034, 1036, 1045, 1048, 1049, 1050, 1051, 1053, 1055, 1056, 1057, 1058], "confirm": [43, 52, 118, 142, 149, 152, 155, 194, 220, 222, 272, 281, 284, 287, 324, 362, 390, 989, 1010, 1049], "conflict": [384, 386, 390, 394, 404, 1048, 1049], "conform": [52, 589, 636, 840, 841, 1000, 1019, 1020, 1048, 1054], "confound": [191, 192], "confus": [2, 68, 189, 248, 270, 272, 287, 338, 339, 360, 400, 476, 512, 639, 660, 705, 721, 723, 726, 737, 738, 746, 762, 792, 795, 838, 910, 917, 1021, 1034, 1041, 1042, 1046, 1050, 1051, 1053, 1054, 1055, 1056], "confusingli": 384, "confusion_matrix": [2, 68, 248, 271, 272, 336, 338, 339, 705, 721, 762, 807, 835, 1000, 1034, 1042, 1047, 1048, 1051, 1052, 1054, 1058], "confusion_matrix_scor": 1000, "confusionmatrixdisplai": [2, 45, 68, 271, 331, 336, 338, 360, 639, 726, 1000, 1030, 1051, 1052, 1054, 1055, 1056], "congruenc": [662, 663, 664, 690, 691], "conjug": [278, 460, 470, 680, 682, 695, 703, 996], "conjunct": [407, 416, 602, 814, 830, 831, 833, 834, 835, 836, 839, 967, 990, 996, 1056], "connect": [2, 51, 74, 79, 82, 86, 89, 97, 101, 102, 384, 386, 395, 400, 418, 449, 453, 460, 470, 471, 593, 594, 703, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 998, 1003, 1005, 1013, 1023, 1045, 1054, 1058], "connected_compon": 1048, "connectionist": [869, 870], "conner": 1054, "connor": [1049, 1054, 1058, 1059], "connossor": [1049, 1050], "conocophillip": 51, "conort": 1024, "conquer": 949, "conrad": [1041, 1042, 1056, 1059], "conroi": 1056, "consecut": [139, 150, 221, 398, 414, 420, 424, 451, 455, 457, 458, 460, 464, 467, 470, 545, 546, 547, 554, 610, 653, 674, 675, 676, 684, 685, 686, 805, 806, 813, 847, 848, 849, 850, 851, 869, 870, 989, 1010, 1034, 1049], "consensu": [2, 58, 59, 72, 385, 386, 401, 413, 416, 657, 679, 686, 687, 727, 1000], "consensus_scor": [2, 58, 59, 413, 1043], "consequ": [92, 132, 238, 278, 279, 319, 346, 369, 414, 415, 421, 423, 569, 570, 574, 663, 664, 990, 996, 1000, 1008, 1016, 1050, 1052, 1057, 1059], "conserv": [50, 400, 590, 597, 904, 905, 999, 1012], "consid": [0, 43, 51, 52, 53, 58, 62, 74, 90, 101, 105, 114, 121, 125, 129, 149, 152, 169, 173, 174, 188, 193, 220, 222, 254, 272, 278, 281, 285, 289, 292, 299, 302, 305, 306, 319, 330, 336, 346, 353, 354, 356, 360, 369, 373, 374, 375, 378, 385, 386, 388, 392, 394, 398, 400, 401, 407, 410, 412, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 446, 452, 454, 458, 465, 482, 516, 517, 529, 541, 549, 557, 558, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 593, 594, 596, 597, 599, 601, 615, 616, 628, 639, 640, 641, 654, 660, 666, 667, 668, 670, 679, 687, 696, 697, 698, 700, 701, 702, 704, 708, 710, 713, 715, 717, 723, 734, 738, 742, 764, 794, 796, 802, 854, 855, 856, 858, 860, 862, 863, 864, 867, 869, 870, 875, 885, 886, 893, 907, 908, 917, 918, 920, 921, 922, 923, 984, 989, 995, 996, 997, 998, 1000, 1001, 1003, 1006, 1007, 1008, 1010, 1014, 1015, 1016, 1020, 1025, 1032, 1044, 1045, 1049, 1053, 1054, 1056, 1057, 1058], "consider": [154, 155, 177, 180, 257, 273, 279, 285, 386, 415, 426, 627, 808, 822, 830, 989, 996, 1002, 1006, 1014, 1024, 1058], "consist": [2, 43, 46, 63, 68, 72, 91, 92, 104, 113, 121, 123, 125, 145, 149, 155, 156, 163, 174, 179, 181, 184, 188, 195, 220, 238, 253, 257, 284, 287, 316, 324, 328, 331, 356, 361, 369, 373, 379, 381, 383, 386, 388, 392, 393, 394, 395, 399, 400, 401, 414, 416, 418, 422, 423, 424, 434, 435, 438, 439, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 498, 505, 539, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 562, 564, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 599, 619, 635, 636, 637, 638, 643, 646, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 682, 685, 686, 687, 695, 696, 697, 698, 699, 708, 743, 805, 806, 815, 840, 841, 842, 844, 845, 846, 847, 855, 856, 858, 860, 863, 864, 870, 875, 876, 877, 879, 883, 884, 887, 888, 890, 891, 893, 904, 905, 908, 912, 913, 915, 916, 918, 921, 923, 932, 934, 955, 971, 974, 989, 992, 993, 994, 996, 997, 999, 1000, 1001, 1003, 1004, 1010, 1013, 1015, 1016, 1018, 1020, 1024, 1025, 1032, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "consol": [148, 384, 1026], "consolid": [0, 400, 401, 1041], "consolidate_scor": 52, "consortium": [0, 1024], "constant": [2, 43, 134, 142, 155, 179, 183, 188, 192, 208, 221, 222, 224, 238, 249, 254, 259, 281, 311, 315, 317, 320, 322, 329, 356, 358, 369, 378, 388, 395, 400, 413, 423, 426, 439, 454, 473, 490, 491, 492, 519, 521, 542, 546, 548, 555, 557, 558, 559, 560, 562, 564, 566, 568, 570, 573, 576, 578, 598, 614, 617, 619, 621, 635, 638, 640, 641, 643, 648, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 681, 684, 685, 686, 687, 688, 695, 697, 701, 703, 729, 731, 732, 736, 740, 783, 785, 793, 807, 830, 845, 846, 855, 863, 869, 870, 877, 888, 891, 900, 912, 913, 914, 915, 916, 917, 918, 919, 921, 923, 992, 994, 996, 997, 1000, 1002, 1003, 1010, 1014, 1016, 1036, 1044, 1049, 1051, 1053, 1054, 1055, 1057, 1059], "constant_": 560, "constant_valu": [426, 621, 625], "constant_value_bound": [426, 619, 621, 625], "constantini": 1057, "constantkernel": [2, 179, 185, 426, 619, 625, 629, 632], "constantli": [72, 220, 1024], "constitu": 383, "constitut": [85, 400, 420, 423, 458, 464, 596, 597, 599, 1004], "constrain": [25, 82, 125, 149, 155, 157, 193, 211, 314, 329, 335, 347, 349, 379, 400, 416, 421, 423, 517, 569, 570, 643, 666, 667, 698, 702, 830, 837, 996, 999, 1045], "constrained_layout": [125, 193, 240, 325, 326, 333], "constraint": [90, 92, 102, 125, 138, 189, 215, 224, 257, 258, 273, 315, 316, 317, 329, 386, 398, 421, 424, 495, 516, 517, 565, 566, 569, 570, 572, 573, 640, 643, 826, 827, 920, 921, 922, 923, 969, 989, 991, 996, 997, 1014, 1021, 1045, 1048, 1049, 1052, 1054, 1056, 1058], "constru": 424, "construct": [2, 43, 50, 104, 106, 139, 141, 143, 147, 160, 174, 238, 248, 254, 259, 261, 312, 320, 322, 329, 332, 380, 383, 388, 395, 400, 416, 417, 420, 421, 423, 424, 427, 441, 449, 450, 452, 453, 458, 460, 465, 471, 473, 475, 527, 543, 549, 552, 563, 564, 589, 595, 647, 696, 698, 699, 822, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 871, 872, 873, 874, 876, 917, 931, 933, 948, 949, 959, 963, 989, 990, 992, 996, 997, 1000, 1001, 1003, 1010, 1013, 1015, 1016, 1020, 1025, 1029, 1046, 1048, 1049, 1052, 1055], "construct_grid": [50, 312], "constructor": [30, 31, 106, 250, 374, 388, 400, 417, 424, 472, 475, 557, 558, 563, 575, 576, 577, 578, 589, 590, 596, 597, 605, 676, 684, 685, 807, 854, 855, 856, 858, 860, 862, 863, 864, 871, 872, 873, 874, 989, 1001, 1010, 1015, 1020, 1025, 1041, 1042, 1044, 1045, 1046, 1048, 1051, 1052, 1053, 1054, 1055, 1056, 1058], "consult": 1000, "consum": [2, 125, 369, 380, 388, 400, 407, 416, 420, 423, 457, 811, 812, 872, 873, 956, 957, 966, 996, 1024, 1046, 1058], "consumpt": [47, 373, 400, 416, 542, 565, 566, 572, 573, 808, 822, 833, 834, 835, 920, 921, 922, 923, 966, 1025, 1041, 1043, 1047, 1049, 1050, 1055], "contact": [323, 398, 1019], "contain": [2, 49, 57, 61, 64, 69, 75, 84, 91, 93, 104, 105, 141, 143, 147, 155, 156, 182, 192, 193, 195, 197, 211, 224, 238, 247, 254, 257, 258, 261, 268, 272, 276, 278, 284, 287, 288, 298, 305, 306, 308, 319, 331, 339, 342, 360, 361, 379, 380, 381, 383, 386, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 410, 412, 414, 416, 417, 419, 420, 421, 423, 424, 425, 426, 428, 430, 440, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 470, 472, 473, 474, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 504, 508, 510, 511, 512, 516, 517, 518, 522, 523, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 693, 694, 696, 697, 698, 699, 700, 704, 705, 706, 708, 709, 710, 717, 720, 743, 744, 745, 780, 787, 788, 796, 802, 805, 806, 807, 808, 811, 812, 814, 822, 826, 827, 830, 831, 835, 836, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 928, 931, 932, 933, 952, 953, 955, 956, 963, 966, 967, 969, 989, 990, 992, 998, 1001, 1004, 1006, 1008, 1010, 1011, 1013, 1016, 1019, 1023, 1025, 1034, 1041, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058, 1059], "container": 410, "container_fold": 511, "container_path": 511, "contamin": [48, 113, 114, 247, 257, 305, 306, 477, 571, 858, 1006, 1049, 1057, 1058], "content": [2, 7, 55, 324, 360, 362, 381, 386, 390, 392, 410, 424, 494, 511, 516, 517, 596, 597, 599, 679, 926, 1009, 1024, 1034, 1042, 1051], "context": [2, 93, 261, 272, 299, 336, 373, 374, 380, 385, 387, 399, 400, 416, 417, 422, 423, 424, 426, 427, 445, 452, 454, 456, 458, 460, 465, 466, 469, 472, 475, 476, 480, 539, 543, 544, 545, 547, 550, 551, 552, 553, 554, 556, 563, 564, 565, 566, 571, 572, 573, 574, 575, 576, 577, 578, 602, 610, 615, 616, 618, 634, 635, 638, 640, 642, 647, 655, 659, 661, 663, 665, 666, 667, 669, 671, 673, 674, 676, 684, 687, 696, 697, 698, 699, 700, 701, 702, 782, 786, 789, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 844, 845, 854, 855, 858, 860, 862, 863, 865, 866, 871, 874, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 990, 996, 1000, 1006, 1010, 1014, 1020, 1023, 1024, 1032, 1041, 1048, 1049, 1054, 1057], "contigu": [43, 59, 388, 398, 413, 420, 424, 451, 455, 457, 467, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 789, 827, 852, 853, 912, 914, 915, 916, 917, 918, 1015, 1044, 1051, 1055, 1059], "contin": [422, 722, 1010], "conting": [2, 722, 723, 739, 763, 1047], "contingency_matrix": [2, 416, 763, 1049], "continu": [0, 2, 52, 55, 57, 77, 123, 149, 176, 189, 193, 200, 221, 228, 238, 241, 244, 257, 258, 260, 264, 268, 269, 316, 318, 324, 325, 330, 331, 368, 374, 381, 384, 388, 389, 390, 391, 394, 398, 400, 401, 404, 416, 421, 423, 476, 500, 600, 603, 604, 607, 608, 615, 616, 617, 640, 654, 655, 660, 661, 665, 668, 669, 670, 671, 734, 750, 764, 820, 822, 875, 877, 879, 881, 882, 891, 892, 893, 909, 910, 921, 963, 989, 996, 997, 1000, 1001, 1003, 1004, 1010, 1016, 1020, 1021, 1024, 1025, 1032, 1038, 1041, 1043, 1044, 1049, 1054, 1055, 1056, 1058, 1060], "continuous_featur": 391, "contour": [48, 50, 70, 81, 82, 113, 148, 167, 174, 179, 180, 182, 231, 232, 233, 234, 247, 252, 267, 305, 312, 347, 348, 350, 351, 353, 354, 383, 393, 639, 640, 1006, 1014], "contour_kw": 640, "contourf": [50, 148, 234, 252, 305, 312, 314, 321, 322, 343, 348, 354, 358, 639, 640], "contours_": [393, 640], "contract": [220, 238, 353, 374, 400, 1020], "contradict": [195, 1020], "contrari": [43, 53, 192, 241, 245, 257, 263, 281, 319, 360, 380, 416, 504, 552, 614, 825, 893, 996, 1002, 1006], "contrast": [133, 193, 222, 253, 257, 278, 280, 308, 324, 361, 400, 414, 416, 419, 423, 426, 457, 460, 470, 627, 651, 822, 868, 990, 993, 995, 996, 1000, 1003, 1005, 1008, 1010, 1013, 1014, 1016, 1051], "contrib": [334, 386, 388, 394, 398, 400, 416, 454, 1019, 1020, 1057], "contribut": [0, 53, 58, 153, 181, 204, 224, 287, 324, 383, 384, 388, 389, 390, 394, 400, 401, 404, 421, 422, 423, 455, 457, 561, 562, 567, 568, 734, 737, 764, 994, 1000, 1003, 1008, 1015, 1019, 1020, 1023, 1024, 1032, 1041, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "contributor": [374, 389, 390, 391, 394, 398, 400, 1000, 1020, 1042, 1043, 1044, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "control": [37, 51, 70, 96, 129, 130, 145, 165, 181, 183, 204, 221, 224, 228, 250, 251, 279, 281, 296, 301, 317, 329, 331, 353, 364, 366, 367, 373, 374, 379, 382, 386, 388, 391, 394, 398, 400, 404, 415, 416, 419, 420, 421, 422, 425, 426, 441, 448, 457, 462, 479, 480, 486, 539, 544, 545, 546, 547, 548, 551, 553, 554, 555, 556, 558, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 601, 602, 604, 622, 627, 633, 635, 640, 642, 647, 649, 650, 654, 655, 657, 658, 659, 660, 662, 663, 664, 680, 682, 684, 685, 690, 691, 695, 700, 709, 717, 805, 806, 808, 810, 811, 812, 813, 814, 822, 823, 824, 825, 826, 827, 828, 830, 831, 833, 834, 835, 836, 838, 839, 842, 843, 846, 869, 870, 891, 893, 904, 905, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 926, 966, 987, 989, 996, 997, 999, 1000, 1001, 1003, 1006, 1007, 1010, 1012, 1014, 1015, 1016, 1019, 1020, 1022, 1032, 1036, 1041, 1043, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055], "convei": [67, 245, 321, 1032], "conveni": [90, 224, 257, 378, 394, 398, 417, 420, 424, 426, 431, 451, 455, 457, 459, 461, 472, 497, 619, 684, 686, 707, 736, 793, 871, 872, 974, 990, 992, 996, 997, 1007, 1024, 1034, 1041], "convent": [2, 137, 155, 272, 278, 386, 388, 389, 390, 392, 400, 412, 434, 435, 438, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 477, 478, 479, 480, 481, 482, 483, 484, 516, 517, 539, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 555, 571, 574, 577, 578, 589, 590, 591, 596, 597, 599, 635, 636, 637, 638, 685, 696, 697, 698, 699, 726, 805, 806, 840, 841, 856, 858, 860, 864, 876, 884, 887, 888, 890, 893, 904, 905, 916, 943, 944, 1000, 1026, 1041, 1048, 1049, 1052, 1054, 1055, 1057, 1058], "convention": [347, 400, 908], "converg": [2, 55, 92, 96, 111, 112, 150, 152, 155, 176, 182, 185, 213, 222, 228, 236, 264, 266, 315, 316, 319, 324, 339, 375, 395, 400, 413, 416, 421, 424, 426, 428, 448, 451, 454, 455, 456, 457, 460, 462, 467, 468, 469, 470, 479, 480, 486, 490, 491, 492, 541, 543, 544, 545, 546, 547, 554, 561, 579, 618, 652, 653, 654, 655, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 676, 680, 682, 684, 686, 690, 691, 695, 696, 698, 699, 702, 703, 805, 806, 861, 869, 870, 907, 908, 914, 990, 995, 996, 997, 999, 1004, 1014, 1041, 1044, 1045, 1046, 1048, 1049, 1052, 1054, 1055, 1056, 1057, 1058, 1059], "converged_": [805, 806, 1059], "convergence_it": [448, 462], "convergencewarn": [2, 180, 182, 184, 185, 228, 235, 264, 315, 316, 321, 395, 400, 805, 806, 1049, 1050, 1053], "convers": [2, 55, 152, 211, 360, 369, 375, 380, 386, 388, 394, 398, 400, 410, 424, 580, 867, 876, 884, 932, 933, 986, 997, 1020, 1024, 1049, 1050, 1051, 1054, 1057], "convert": [2, 52, 55, 70, 81, 83, 101, 105, 128, 181, 195, 220, 240, 257, 260, 264, 265, 268, 269, 292, 312, 336, 373, 380, 381, 395, 398, 400, 410, 424, 448, 451, 452, 455, 457, 458, 459, 460, 467, 472, 473, 504, 542, 549, 561, 562, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 580, 589, 590, 596, 597, 598, 599, 601, 602, 614, 635, 636, 637, 638, 654, 660, 666, 667, 668, 670, 674, 675, 676, 678, 682, 684, 685, 686, 700, 786, 807, 830, 867, 876, 877, 879, 883, 885, 886, 887, 889, 912, 920, 921, 922, 923, 930, 932, 933, 955, 985, 986, 989, 996, 997, 998, 1000, 1010, 1011, 1015, 1016, 1034, 1041, 1043, 1044, 1045, 1046, 1047, 1049, 1051, 1052, 1053, 1056, 1057, 1058, 1059], "convex": [134, 151, 152, 189, 198, 227, 240, 357, 361, 416, 418, 421, 429, 454, 460, 470, 481, 483, 484, 487, 488, 489, 666, 684, 700, 996, 997, 1003, 1004, 1014, 1021, 1054], "convinc": 192, "convolut": [45, 184, 1030], "convolv": 317, "coo": [400, 561, 562, 700, 879, 928, 932, 933, 1003, 1042, 1058], "coo_matrix": [53, 206, 460, 593, 594, 971, 974], "cook": [383, 502, 1041, 1047], "cookbook": [426, 630, 631], "cool": [424, 1041], "coolwarm": [273, 346], "cooman": 383, "coordin": [2, 50, 51, 53, 89, 130, 159, 180, 205, 240, 279, 312, 373, 381, 421, 426, 451, 455, 456, 457, 469, 479, 480, 486, 539, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 558, 622, 654, 655, 659, 660, 661, 662, 663, 664, 666, 668, 669, 670, 671, 689, 690, 691, 692, 696, 697, 698, 701, 702, 714, 772, 777, 912, 996, 997, 1015, 1032, 1041, 1044, 1045, 1046, 1050, 1052, 1054, 1055, 1056], "cop": 51, "cope": [247, 375, 381, 996], "copeland": [1049, 1050], "copi": [44, 51, 55, 79, 97, 109, 128, 142, 155, 174, 187, 188, 192, 193, 194, 206, 213, 226, 236, 238, 241, 254, 299, 338, 339, 341, 343, 361, 365, 374, 383, 386, 388, 390, 391, 392, 398, 400, 441, 445, 448, 450, 451, 452, 454, 455, 457, 462, 467, 490, 491, 492, 493, 508, 510, 518, 540, 541, 542, 543, 549, 556, 561, 562, 567, 569, 570, 580, 598, 605, 615, 616, 618, 619, 636, 638, 652, 653, 654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 666, 668, 669, 670, 671, 673, 679, 680, 682, 687, 689, 692, 693, 694, 740, 777, 800, 808, 822, 852, 853, 867, 875, 878, 881, 882, 883, 884, 888, 889, 890, 892, 895, 897, 898, 899, 900, 901, 902, 903, 907, 908, 912, 914, 915, 916, 917, 918, 927, 930, 932, 933, 959, 971, 973, 974, 1010, 1015, 1016, 1020, 1026, 1029, 1034, 1041, 1044, 1047, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "copy_": 1041, "copy_cov": 556, "copy_gram": [690, 691, 694], "copy_x": [451, 455, 467, 543, 652, 653, 654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 680, 682, 687, 689, 690, 691, 692, 693, 1043, 1049, 1050, 1060], "copy_x_train": [618, 619], "copy_xi": 694, "copybutton": [386, 404, 409], "copyright": [55, 115], "corani": 278, "cordier": 1048, "core": [42, 49, 84, 90, 91, 100, 105, 137, 139, 145, 147, 148, 184, 189, 192, 193, 254, 272, 333, 372, 374, 386, 389, 394, 400, 404, 410, 416, 421, 423, 424, 427, 452, 454, 457, 458, 463, 465, 504, 507, 546, 597, 602, 666, 667, 674, 676, 684, 847, 848, 849, 850, 851, 856, 864, 996, 1003, 1006, 1015, 1020, 1021, 1022, 1024, 1032, 1034, 1036, 1043, 1045, 1046, 1048, 1051, 1055, 1056, 1057], "core_dist": [100, 463, 464, 465], "core_distances_": [100, 458, 463, 465], "core_sampl": 427, "core_sample_indices_": [84, 452], "core_samples_mask": 84, "corei": [1042, 1049, 1050], "corentin": 1055, "cori": 1046, "corneil": 1054, "corner": [50, 53, 63, 88, 191, 275, 279, 287, 288, 312, 335, 381, 386, 506, 924, 926, 1000, 1055], "cornerston": 1024, "cornflowerblu": [159, 214, 223, 230, 264, 266, 269, 285, 287, 304, 310, 366, 367], "corollari": 388, "corona": 1054, "corpora": 421, "corpu": [54, 361, 362, 381, 421, 596, 597, 598, 599, 1034, 1042], "corr": [117, 195, 278], "corrcoef": [117, 135], "correct": [2, 30, 52, 63, 64, 92, 114, 139, 150, 184, 192, 204, 209, 220, 238, 263, 271, 272, 278, 285, 287, 296, 298, 349, 351, 360, 369, 383, 386, 388, 390, 401, 414, 416, 420, 421, 423, 424, 433, 439, 458, 464, 477, 482, 496, 509, 511, 643, 675, 684, 686, 711, 712, 716, 720, 721, 726, 729, 731, 732, 736, 737, 738, 742, 746, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 791, 792, 793, 795, 798, 799, 802, 804, 840, 841, 842, 849, 857, 883, 985, 996, 1000, 1001, 1015, 1025, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "correct_covari": [477, 482], "corrected_std": 278, "corrected_var": 278, "correctli": [2, 169, 173, 220, 238, 254, 285, 287, 293, 309, 326, 340, 349, 386, 395, 421, 423, 433, 445, 477, 501, 557, 558, 559, 561, 563, 565, 567, 569, 572, 575, 577, 618, 666, 674, 676, 682, 683, 684, 711, 802, 804, 807, 830, 840, 841, 842, 843, 847, 848, 849, 850, 851, 854, 859, 862, 869, 892, 907, 908, 912, 914, 915, 916, 917, 918, 920, 922, 950, 997, 1000, 1003, 1004, 1010, 1015, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "correl": [2, 51, 64, 115, 117, 118, 135, 146, 147, 155, 157, 170, 173, 181, 189, 190, 191, 193, 194, 204, 209, 215, 238, 278, 284, 298, 325, 329, 330, 341, 379, 382, 383, 391, 400, 403, 413, 418, 420, 425, 458, 465, 490, 491, 493, 501, 502, 508, 532, 572, 614, 617, 635, 642, 643, 644, 690, 691, 751, 765, 786, 787, 788, 838, 852, 853, 889, 890, 892, 901, 991, 996, 1001, 1007, 1010, 1014, 1016, 1020, 1021, 1022, 1036, 1041, 1042, 1043, 1054, 1055], "correlation_coeffici": 617, "correlation_model": 1048, "correspond": [2, 50, 52, 53, 58, 63, 64, 68, 76, 88, 100, 111, 115, 127, 139, 142, 145, 146, 148, 156, 170, 173, 174, 177, 182, 185, 192, 209, 212, 220, 221, 224, 229, 238, 248, 253, 254, 261, 268, 272, 277, 279, 281, 282, 287, 288, 292, 312, 324, 330, 331, 332, 361, 364, 365, 369, 374, 380, 381, 382, 385, 386, 388, 390, 393, 394, 399, 400, 401, 413, 414, 415, 416, 418, 419, 420, 421, 423, 424, 425, 426, 431, 437, 445, 447, 449, 453, 456, 459, 461, 467, 469, 471, 472, 475, 480, 490, 491, 492, 498, 499, 500, 501, 502, 503, 504, 542, 549, 552, 553, 554, 557, 558, 560, 563, 565, 567, 568, 569, 572, 590, 592, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 625, 638, 640, 641, 643, 651, 654, 655, 656, 660, 666, 667, 668, 669, 670, 676, 677, 679, 680, 681, 682, 683, 684, 686, 688, 689, 690, 691, 695, 698, 699, 700, 702, 711, 718, 721, 732, 733, 742, 746, 750, 760, 762, 782, 786, 790, 796, 797, 802, 804, 805, 806, 807, 808, 811, 812, 814, 822, 830, 831, 833, 841, 843, 844, 847, 848, 849, 850, 851, 852, 853, 857, 858, 859, 861, 869, 870, 879, 882, 883, 885, 886, 889, 893, 901, 912, 913, 914, 917, 920, 921, 922, 923, 937, 943, 957, 960, 975, 989, 990, 992, 993, 994, 996, 997, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1010, 1011, 1014, 1015, 1018, 1025, 1031, 1034, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "correspondingli": 1058, "corri": 1052, "corrobor": 398, "corrupt": [44, 132, 204, 226, 237, 398, 868, 996, 1008], "cort": [1052, 1053, 1056, 1057], "cortex": 421, "cos_transform": 43, "cosin": [2, 43, 75, 293, 299, 304, 378, 381, 400, 416, 421, 422, 449, 453, 458, 465, 543, 598, 599, 628, 704, 768, 769, 770, 773, 778, 779, 782, 786, 787, 788, 852, 853, 857, 884, 1003, 1016, 1036, 1051], "cosine_dist": [2, 704, 770, 1003, 1047], "cosine_similar": [2, 353, 412, 768, 773, 998, 1046, 1060], "cosinesimil": 299, "cosmo": 57, "cost": [43, 74, 128, 145, 155, 176, 189, 197, 240, 248, 252, 270, 280, 282, 285, 287, 292, 328, 336, 349, 361, 362, 363, 368, 386, 392, 394, 398, 415, 416, 423, 486, 504, 508, 545, 546, 547, 554, 559, 565, 566, 567, 568, 569, 572, 573, 610, 618, 627, 635, 654, 655, 660, 661, 666, 668, 669, 670, 671, 676, 680, 682, 684, 686, 695, 696, 700, 708, 710, 726, 750, 792, 795, 807, 808, 830, 838, 873, 892, 910, 912, 913, 914, 917, 920, 921, 922, 923, 949, 992, 996, 997, 1000, 1003, 1013, 1014, 1015, 1021, 1022, 1036, 1047, 1050, 1051], "cost_complexity_pruning_path": [364, 920, 921, 922, 923], "costa": [1049, 1054], "costin": 1041, "costli": [106, 111, 146, 187, 272, 279, 357, 374, 387, 392, 416, 451, 635, 816, 818, 904, 905, 949, 1000, 1003, 1012, 1020], "costlier": 679, "costs_": [479, 480, 1057], "could": [0, 43, 48, 52, 53, 64, 72, 77, 88, 105, 106, 125, 128, 140, 141, 149, 152, 155, 171, 176, 181, 188, 191, 192, 193, 220, 221, 224, 229, 238, 244, 252, 253, 254, 271, 272, 278, 298, 307, 310, 331, 345, 346, 360, 364, 375, 386, 392, 394, 400, 404, 410, 414, 420, 423, 424, 428, 482, 541, 546, 615, 616, 637, 679, 810, 815, 817, 989, 990, 996, 997, 1007, 1008, 1010, 1015, 1020, 1033, 1038, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "couldn": [1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "count": [2, 23, 43, 52, 54, 62, 64, 76, 84, 88, 104, 105, 123, 161, 162, 192, 193, 220, 222, 238, 251, 261, 272, 287, 292, 296, 299, 329, 330, 361, 362, 368, 381, 383, 390, 395, 400, 401, 414, 416, 421, 423, 424, 454, 457, 497, 504, 544, 552, 589, 596, 597, 598, 599, 602, 612, 625, 648, 705, 713, 723, 726, 737, 738, 746, 762, 791, 792, 794, 795, 847, 851, 852, 853, 861, 864, 875, 924, 926, 951, 965, 989, 992, 996, 1000, 1002, 1003, 1010, 1016, 1024, 1034, 1041, 1044, 1046, 1049, 1050, 1052, 1053], "count_nonzero": [46, 49, 373], "count_onli": [852, 853], "count_vect": 1034, "counter": [57, 139, 285, 416, 684, 685, 686, 1054], "counterpart": [384, 989, 997, 1015, 1029], "countlagged_count_1hlagged_count_2hlagged_count_3hlagged_count_1dlagged_count_1d_1hlagged_count_7dlagged_count_7d_1hlagged_mean_24hlagged_max_24hlagged_min_24hlagged_mean_7dlagged_max_7dlagged_min_7di64i64i64i64i64i64i64i64f64i64i64f64i64i6416nullnullnullnullnullnullnullnullnullnullnullnullnull4016nullnullnullnullnullnullnullnullnullnullnullnull324016nullnullnullnullnullnullnullnullnullnullnull13324016nullnullnullnullnullnullnullnullnullnull1133240nullnullnullnullnullnullnullnullnullnull111332nullnullnullnullnullnullnullnullnullnull21113nullnullnullnullnullnullnullnullnullnull3211nullnullnullnullnullnullnullnullnullnull8321nullnullnullnullnullnullnullnullnullnull14832nullnullnullnullnullnullnullnullnullnul": 52, "countlagged_count_1hlagged_count_2hlagged_count_3hlagged_count_1dlagged_count_1d_1hlagged_count_7dlagged_count_7d_1hlagged_mean_24hlagged_max_24hlagged_min_24hlagged_mean_7dlagged_max_7dlagged_min_7di64i64i64i64i64i64i64i64f64i64i64f64i64i642472032241571601697013593": 52, "countri": [325, 335, 504, 997], "counts_": 1053, "countvector": [2, 54, 342, 362, 381, 391, 417, 421, 424, 472, 497, 544, 590, 597, 598, 599, 1034, 1041, 1043, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1059], "coupl": [54, 87, 88, 90, 241, 380, 381, 413, 414, 416, 425, 597, 918, 989, 1015], "cournapeau": [0, 406, 1041, 1044], "cours": [47, 48, 197, 292, 373, 386, 388, 415, 421, 424, 425, 990, 995, 996, 1024], "coursecentr": [416, 450], "courtesi": 386, "couvreur": [1050, 1051], "cov": [70, 115, 118, 141, 268, 386, 400, 404, 409, 419, 429, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 527, 540, 542, 549, 556], "cov_": [50, 115], "cov_class_1": 70, "cov_class_2": 70, "cov_init": 1057, "cov_test": 50, "cov_train": 50, "cov_typ": [265, 499], "covar": [263, 264, 269], "covari": [2, 48, 51, 65, 69, 112, 117, 132, 135, 154, 156, 176, 183, 223, 247, 262, 264, 266, 267, 268, 269, 285, 310, 335, 395, 400, 407, 416, 419, 421, 426, 429, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 512, 523, 527, 535, 540, 542, 549, 556, 557, 558, 571, 618, 619, 621, 630, 631, 639, 652, 653, 658, 662, 664, 690, 691, 694, 697, 701, 805, 806, 808, 827, 999, 1006, 1010, 1021, 1022, 1035, 1036, 1041, 1043, 1044, 1045, 1046, 1048, 1050], "covariance_": [51, 70, 113, 115, 477, 478, 479, 480, 481, 482, 483, 484, 557, 558, 994, 1048], "covariance_correct": [477, 482], "covariance_eigh": [336, 549, 1059], "covariance_estim": [69, 557, 994, 1053], "covariance_prior": [269, 805], "covariance_prior_": 805, "covariance_reweight": [477, 482], "covariance_typ": [79, 264, 265, 267, 268, 269, 805, 806, 1057], "covariances_": [263, 264, 265, 268, 269, 805, 806, 1048], "cover": [0, 87, 197, 220, 238, 369, 378, 381, 386, 399, 643, 728, 802, 1000, 1001, 1018], "coverag": [2, 50, 52, 152, 155, 220, 238, 312, 381, 389, 412, 506, 635, 728], "coverage_error": [2, 1000, 1045, 1055], "coverage_fract": 152, "coverages_land": 50, "covertyp": [2, 379, 499, 1036], "covtyp": 197, "cow": 1042, "cowlei": 1051, "cowton": 1055, "cox": [319, 323, 888, 900, 1010, 1049, 1057], "cp": 1034, "cpickl": 1034, "cpo": [174, 383], "cpp": 392, "cppflag": 384, "cpu": [0, 96, 279, 299, 333, 373, 374, 392, 400, 404, 412, 424, 504, 640, 655, 659, 661, 663, 666, 667, 669, 671, 673, 674, 676, 684, 687, 808, 822, 833, 834, 835, 856, 864, 905, 1000, 1025, 1029, 1034, 1046, 1055, 1056, 1058, 1059], "cpu_count": [77, 145, 299], "cpuexecutionprovid": 410, "cpython": [386, 387, 392, 1056], "craft": 389, "craig": [1012, 1044, 1049], "crall": [1048, 1054], "crammer": [674, 675, 743, 996, 1000, 1015], "crammer06a": [674, 675], "crammer_sing": [912, 1001, 1015, 1041], "cranenburgh": 1045, "crash": [51, 386, 410, 476, 902, 903, 910, 1010, 1045, 1049, 1057, 1058], "crawl": [529, 941], "craze": 1048, "crc": 996, "creat": [2, 43, 44, 47, 50, 58, 59, 63, 64, 66, 68, 70, 72, 74, 76, 78, 79, 81, 84, 87, 93, 95, 97, 105, 106, 113, 118, 121, 127, 130, 141, 144, 148, 149, 150, 152, 156, 159, 173, 176, 178, 181, 182, 183, 185, 188, 191, 193, 199, 201, 203, 206, 216, 221, 222, 232, 233, 242, 252, 254, 257, 258, 260, 268, 272, 273, 274, 276, 278, 288, 292, 307, 309, 310, 321, 323, 324, 328, 331, 332, 343, 345, 346, 350, 351, 354, 356, 357, 358, 362, 364, 366, 367, 369, 374, 381, 382, 384, 385, 386, 388, 390, 391, 392, 393, 394, 395, 399, 400, 404, 410, 414, 416, 417, 420, 422, 423, 424, 426, 446, 459, 461, 473, 474, 507, 523, 524, 525, 526, 554, 561, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 596, 597, 599, 605, 636, 638, 639, 640, 641, 705, 706, 708, 709, 710, 790, 797, 808, 810, 814, 818, 822, 826, 830, 831, 833, 834, 842, 873, 885, 914, 917, 920, 921, 922, 923, 927, 930, 952, 953, 959, 973, 985, 990, 996, 999, 1000, 1001, 1003, 1007, 1010, 1011, 1012, 1014, 1015, 1016, 1019, 1020, 1024, 1030, 1032, 1033, 1038, 1041, 1042, 1044, 1047, 1051, 1054, 1055, 1056, 1057, 1058, 1059], "create_ax": 319, "create_species_bunch": 50, "createindex": 299, "creation": [388, 519, 520, 521, 523, 527, 528, 529, 531, 532, 533, 534, 535, 536, 537, 538, 664, 852, 853, 1024, 1048, 1049, 1050, 1054], "creativ": 380, "creator": [174, 380, 383], "cred_int_df": 278, "cred_interv": 278, "credibl": 278, "credit": [381, 394, 423, 996, 1024], "credit_amount": 272, "credit_card": 272, "credit_gain": 272, "credit_gain_scor": 272, "credit_histori": 272, "creighton": 333, "crfsuit": 1019, "crispinlogan": [1053, 1056, 1057, 1059], "cristian": 650, "cristina": 1053, "criteria": [92, 145, 189, 198, 209, 228, 268, 278, 394, 416, 425, 449, 474, 490, 491, 492, 509, 565, 566, 567, 568, 572, 573, 654, 660, 664, 666, 667, 679, 700, 873, 892, 912, 913, 920, 921, 922, 923, 990, 999, 1004, 1014, 1021, 1033, 1044, 1049, 1052], "criterion": [64, 111, 112, 195, 208, 228, 268, 290, 329, 388, 395, 400, 416, 421, 449, 453, 457, 460, 467, 470, 540, 545, 547, 554, 561, 562, 565, 566, 567, 568, 572, 573, 574, 614, 635, 652, 653, 656, 664, 674, 675, 676, 677, 679, 680, 682, 684, 685, 686, 688, 699, 703, 718, 806, 909, 914, 915, 916, 917, 918, 920, 921, 922, 923, 996, 999, 1000, 1008, 1013, 1016, 1022, 1033, 1036, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1057, 1058], "criterion_": [208, 209, 664], "critic": [380, 386, 399, 423, 700, 997, 1000, 1008, 1015, 1024, 1052], "crockett": 1056, "crombach": 1043, "crop": [394, 1056], "cross": [2, 9, 29, 52, 53, 64, 70, 89, 92, 93, 105, 106, 108, 109, 111, 115, 118, 123, 132, 145, 148, 149, 151, 152, 155, 164, 168, 171, 172, 174, 192, 193, 198, 204, 206, 208, 214, 220, 222, 228, 238, 255, 260, 265, 266, 268, 270, 275, 278, 279, 280, 282, 284, 285, 286, 287, 290, 291, 292, 293, 296, 303, 317, 318, 320, 325, 328, 330, 335, 341, 349, 356, 381, 386, 388, 395, 398, 399, 400, 410, 411, 414, 417, 418, 421, 423, 424, 425, 426, 445, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 501, 509, 510, 512, 523, 549, 575, 576, 583, 601, 602, 605, 610, 614, 617, 650, 651, 654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 680, 681, 682, 683, 684, 686, 687, 689, 690, 691, 692, 693, 694, 709, 710, 714, 721, 736, 749, 793, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 843, 846, 872, 873, 877, 892, 893, 910, 912, 914, 917, 955, 999, 1000, 1003, 1004, 1008, 1010, 1015, 1016, 1019, 1020, 1021, 1022, 1024, 1025, 1028, 1036, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059], "cross_decomposit": [2, 116, 117, 118, 189, 255, 490, 491, 492, 493, 1001, 1021, 1045, 1046, 1048, 1049, 1050], "cross_val": 1041, "cross_val_predict": [2, 160, 274, 328, 407, 414, 420, 423, 445, 575, 576, 834, 835, 1045, 1046, 1047, 1048, 1050, 1052, 1054, 1058], "cross_val_scor": [2, 52, 132, 187, 188, 189, 270, 274, 283, 293, 334, 352, 369, 386, 388, 398, 407, 420, 423, 480, 528, 583, 711, 750, 808, 833, 835, 920, 921, 989, 1000, 1021, 1029, 1041, 1042, 1043, 1044, 1045, 1048, 1049, 1050, 1053, 1054, 1057, 1058], "cross_valid": [2, 43, 52, 149, 155, 160, 192, 222, 254, 274, 281, 292, 296, 325, 335, 386, 399, 407, 583, 833, 834, 1000, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1056, 1057, 1058], "crossentropi": 569, "crossvalid": [278, 293], "crowd": [394, 401, 997, 1020], "crucial": [51, 155, 191, 224, 273, 373, 385, 386, 400, 401, 416, 426, 1015], "crude": 1052, "crunch": 392, "cruz": 184, "crypt": [57, 381], "cryptograph": 395, "cs_": 667, "cs_note": 425, "cs_point": 148, "csail": [416, 674, 675, 684, 849], "csc": [2, 373, 398, 400, 424, 535, 559, 561, 562, 678, 700, 879, 881, 887, 892, 895, 897, 903, 928, 932, 933, 963, 975, 976, 978, 979, 980, 981, 1003, 1010, 1049, 1050, 1052, 1055], "csc_matrix": [460, 565, 566, 571, 572, 573, 574, 889, 920, 921, 922, 923, 990, 1010, 1016, 1046], "csco": 51, "csgraph": [400, 1054], "csie": [197, 380, 495, 516, 517, 666], "csizsek": 1048, "csr": [2, 55, 336, 362, 373, 380, 381, 395, 398, 400, 424, 427, 451, 454, 455, 457, 458, 467, 505, 516, 531, 535, 561, 562, 565, 566, 572, 573, 574, 598, 638, 666, 700, 722, 776, 800, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 867, 875, 879, 881, 883, 884, 885, 887, 890, 891, 892, 895, 896, 897, 899, 902, 905, 920, 921, 922, 923, 928, 932, 933, 955, 963, 975, 976, 977, 978, 979, 980, 981, 982, 983, 1003, 1010, 1014, 1041, 1042, 1047, 1049, 1050, 1056, 1057, 1058], "csr_arrai": 982, "csr_matrix": [299, 329, 448, 452, 460, 504, 542, 552, 565, 566, 567, 568, 571, 572, 573, 574, 596, 601, 602, 722, 838, 867, 885, 887, 914, 915, 917, 918, 920, 921, 922, 923, 950, 955, 972, 975, 976, 977, 978, 979, 980, 981, 982, 983, 986, 1001, 1010, 1014, 1015, 1016, 1056], "css": 1053, "cst": 994, "cstr": 850, "cstride": 193, "csv": [51, 380, 383, 391, 1049, 1054], "csytraci": 1044, "ct": [53, 184, 261, 417, 472, 474, 475], "ctc": 184, "cttt": 184, "cube": [428, 541], "cubic": [113, 426], "cuda": [398, 412], "cue": 999, "culprit": 398, "cultiv": 383, "cultur": 381, "cum_claim": [220, 238], "cum_exposur": 220, "cumsum": [151, 220, 238, 1048], "cumtim": 392, "cumul": [2, 151, 220, 238, 416, 734, 743, 764, 889, 901, 1010, 1014, 1048, 1050, 1051], "cumulated_claim": 220, "cumulated_claim_amount": 238, "cumulated_exposur": 220, "cumulated_sampl": 238, "cunha": [1042, 1043], "cup": [381, 1000], "cupi": [333, 336, 398, 412, 1058, 1059], "cupy_to_ndarrai": 412, "curat": [386, 389, 390], "cure": 996, "curic": [1049, 1050], "current": [0, 2, 7, 47, 81, 139, 181, 192, 238, 319, 328, 374, 375, 381, 384, 386, 387, 388, 391, 395, 398, 400, 401, 412, 413, 416, 420, 423, 424, 425, 426, 448, 454, 458, 476, 477, 478, 479, 480, 481, 482, 483, 484, 540, 543, 549, 561, 562, 565, 566, 567, 568, 570, 572, 573, 574, 584, 599, 601, 618, 625, 634, 635, 654, 666, 675, 679, 683, 684, 685, 686, 796, 805, 806, 857, 861, 869, 870, 888, 900, 910, 920, 921, 922, 923, 926, 967, 975, 989, 994, 996, 1000, 1003, 1004, 1010, 1020, 1023, 1032, 1049, 1053, 1055, 1056, 1057], "current_count": 76, "current_month": 181, "current_sklearn_vers": 584, "current_sz_mb": 47, "currentcontrolset": 404, "currentmodul": 386, "curs": [360, 361, 416, 422, 1002, 1003, 1028, 1033], "cursor": [145, 279], "curv": [2, 29, 47, 50, 60, 61, 63, 72, 109, 111, 142, 144, 145, 151, 156, 189, 198, 199, 210, 220, 238, 240, 242, 245, 246, 248, 250, 257, 258, 262, 263, 264, 265, 267, 268, 270, 272, 278, 288, 315, 320, 323, 328, 336, 349, 353, 366, 393, 411, 415, 420, 422, 445, 446, 447, 510, 518, 523, 529, 533, 572, 640, 653, 666, 706, 708, 710, 714, 715, 716, 717, 735, 737, 749, 750, 790, 792, 795, 796, 797, 805, 806, 814, 825, 831, 836, 838, 839, 850, 873, 892, 912, 917, 996, 997, 999, 1000, 1006, 1016, 1021, 1022, 1024, 1036, 1038, 1043, 1044, 1047, 1051, 1053, 1054, 1055, 1056, 1057], "curvatur": 314, "cusick": 1051, "custom": [2, 15, 30, 41, 136, 171, 173, 189, 203, 258, 270, 272, 277, 279, 282, 285, 286, 290, 301, 306, 310, 328, 344, 346, 347, 349, 350, 352, 360, 362, 378, 381, 384, 388, 393, 394, 395, 398, 399, 400, 407, 410, 416, 417, 420, 426, 476, 497, 501, 502, 510, 512, 546, 548, 555, 557, 565, 566, 572, 573, 579, 581, 610, 638, 639, 698, 707, 721, 786, 808, 838, 876, 910, 917, 984, 989, 994, 1000, 1003, 1019, 1020, 1021, 1024, 1034, 1036, 1041, 1045, 1046, 1048, 1049, 1051, 1052, 1053, 1056, 1057, 1058, 1059], "custom_combin": 885, "custom_cv": 420, "custom_cv_2fold": 420, "custom_fnames_enc": 885, "custom_nam": 360, "custom_scor": 336, "custom_scorer_modul": 1000, "custom_scoring_funct": 1000, "customestim": 137, "customkernel": 626, "customvector": 424, "cut": [57, 78, 81, 100, 101, 173, 174, 189, 242, 270, 281, 296, 336, 341, 390, 398, 413, 415, 416, 454, 460, 461, 470, 504, 596, 599, 666, 699, 703, 824, 830, 835, 873, 892, 1010, 1021], "cut_dist": [90, 454], "cutler": [920, 921], "cutoff": [199, 954, 1010, 1050], "cutoffs_x0": 319, "cutoffs_x1": 319, "cv": [2, 43, 51, 52, 61, 62, 63, 64, 89, 105, 106, 107, 108, 111, 132, 145, 149, 151, 155, 165, 173, 187, 188, 192, 209, 219, 222, 254, 272, 274, 276, 277, 278, 279, 280, 281, 283, 284, 288, 292, 293, 296, 325, 333, 335, 336, 349, 356, 399, 400, 407, 414, 415, 420, 423, 425, 445, 480, 575, 576, 602, 610, 655, 659, 661, 663, 667, 669, 671, 673, 681, 683, 808, 810, 811, 812, 813, 814, 822, 823, 824, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 839, 843, 846, 893, 920, 921, 989, 992, 995, 996, 1000, 1010, 1020, 1029, 1030, 1034, 1043, 1047, 1048, 1049, 1050, 1051, 1053, 1055, 1057, 1058, 1059, 1060], "cv_alpha": [659, 663], "cv_alphas_": [209, 659, 663, 1053], "cv_best_it": 151, "cv_clf": 151, "cv_color": 151, "cv_estim": 151, "cv_line": 151, "cv_mape_scor": 52, "cv_model": 192, "cv_result": [43, 52, 105, 145, 155, 173, 276, 277, 279, 281, 407, 822, 835, 1000], "cv_results_": [105, 106, 107, 115, 145, 165, 173, 268, 272, 276, 277, 278, 279, 282, 286, 289, 290, 301, 349, 480, 602, 681, 683, 808, 811, 812, 822, 830, 1034, 1047, 1051, 1053, 1054, 1059], "cv_results_ecoc": 296, "cv_results_lr": 222, "cv_results_ovo": 296, "cv_results_ovr": 296, "cv_results_qr": 222, "cv_results_tre": 296, "cv_results_tuned_model": 292, "cv_results_vanilla_model": 292, "cv_score": [151, 292], "cv_test_scor": 836, "cv_train_scor": 836, "cv_valu": 1049, "cv_values_": [681, 683, 1059], "cvc": 51, "cve": 1054, "cvx": 51, "cwitt": 1049, "cxx": 384, "cxxflag": 384, "cyan": [111, 142, 192, 310], "cybernet": 777, "cycl": [0, 16, 43, 77, 79, 85, 97, 125, 205, 264, 269, 285, 287, 331, 332, 386, 390, 407, 421, 587, 588, 635, 811, 812, 928, 989, 990, 1049, 1050, 1051, 1053, 1054, 1055, 1056], "cycler": 73, "cyclic": [43, 654, 655, 660, 661, 668, 669, 670, 671, 1053], "cyclic_cossin_linear_pipelin": 43, "cyclic_cossin_linear_predict": 43, "cyclic_cossin_transform": 43, "cyclic_hour": 43, "cyclic_month": 43, "cyclic_spline_interactions_pipelin": 43, "cyclic_spline_linear_pipelin": 43, "cyclic_spline_linear_predict": 43, "cyclic_spline_poly_pipelin": 43, "cyclic_spline_poly_predict": 43, "cyclic_spline_transform": 43, "cyclic_weekdai": 43, "cyl": [50, 312], "cynthias13w": 1058, "cyt": 296, "cython": [41, 332, 373, 374, 384, 386, 389, 395, 398, 404, 409, 412, 416, 423, 516, 1010, 1011, 1014, 1015, 1019, 1020, 1041, 1044, 1045, 1047, 1053, 1056, 1057, 1058], "cython3": 384, "cythonx": 387, "c\u00e8sar": 1000, "d": [0, 2, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 67, 68, 72, 73, 77, 83, 84, 85, 95, 96, 98, 104, 105, 115, 120, 123, 125, 128, 132, 134, 176, 184, 192, 220, 228, 236, 238, 245, 248, 250, 251, 252, 253, 266, 277, 278, 286, 292, 298, 305, 306, 312, 316, 338, 339, 342, 349, 353, 354, 362, 380, 381, 383, 386, 388, 392, 398, 414, 416, 418, 419, 421, 423, 424, 426, 427, 452, 454, 455, 460, 468, 471, 496, 501, 511, 534, 542, 544, 565, 566, 573, 574, 589, 590, 598, 622, 623, 627, 630, 631, 652, 653, 656, 677, 678, 679, 688, 696, 697, 700, 701, 705, 707, 713, 716, 729, 730, 731, 732, 734, 764, 772, 786, 789, 796, 820, 847, 849, 851, 852, 853, 868, 879, 883, 885, 886, 888, 900, 905, 922, 923, 927, 992, 994, 996, 997, 998, 999, 1000, 1002, 1008, 1010, 1012, 1015, 1016, 1030, 1031, 1032, 1044, 1046, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1057, 1059], "d1997": 423, "d2": [730, 731, 1000], "d2_absolute_error_scor": [2, 731, 1000, 1055], "d2_log_loss_scor": [2, 1000, 1059], "d2_pinball_scor": [2, 1000, 1055], "d2_pinball_score_08": 1000, "d2_tweedie_scor": [2, 1000, 1054], "d2_tweedie_score_15": 1000, "d55e00": 263, "d81b60": 323, "d83": 383, "d_": [113, 416, 421, 656, 677, 688, 786, 997, 1002], "d_c": 416, "d_chunk": 789, "d_fit": 696, "d_fix": 134, "d_m": 416, "d_multi": 134, "da": [381, 1056, 1057, 1059], "dae": 996, "dagm": 992, "dagstuhl": 1000, "dai": [43, 51, 52, 155, 181, 193, 221, 374, 383, 386, 891, 1024, 1047, 1048, 1055, 1056], "daiki": 1045, "daili": [51, 155, 1024], "dakota": 1051, "dale": [222, 1054], "dalla": 1049, "dalmia": [1047, 1048, 1049], "damag": 424, "damicelli": 1056, "damink": 1058, "daml": [416, 460, 470], "damp": [79, 416, 448, 462], "dan": [55, 1041, 1045, 1046, 1047, 1049, 1050], "danfrankj": 1045, "dang": [687, 996, 1059], "danger": [221, 420], "dangi": 1058, "dangl": 55, "dangonite57": [1056, 1057], "daniel": [197, 333, 373, 893, 1010, 1024, 1041, 1042, 1043, 1044, 1046, 1047, 1048, 1049, 1051, 1053, 1055, 1058], "daniela": [1055, 1056], "danielgaerb": 1056, "danielsen": 1048, "danielweitzenfeld": 1044, "daniil": 1048, "danil": 1049, "dani\u00ebl": 1052, "danna": 1051, "danni": [1044, 1045, 1046], "dantzig": 356, "danylo": 1050, "dao": 1049, "daphn": 1052, "dare": 1051, "darioka": [1053, 1055, 1056], "dariu": [1048, 1049], "dark": [142, 192, 349, 381, 1058], "dark2": [62, 64, 241], "darkblu": 310, "darkorang": [112, 129, 133, 134, 221, 231, 243, 264, 265, 266, 269, 285, 287, 304, 310, 311, 340, 366], "darkorchid": 230, "darkr": [234, 305, 348], "darpa": 381, "darren": [1055, 1056], "darshan": 1053, "dart": 1019, "dartmouth": 0, "dasarathi": 383, "dasgupta": [424, 454, 906, 1012], "dash": [69, 113, 139, 151, 162, 176, 179, 181, 192, 207, 212, 215, 221, 222, 229, 232, 233, 257, 272, 278, 288, 351, 1014], "dashdot": [151, 176, 179, 257], "dask": [1020, 1049], "data": [0, 2, 10, 17, 22, 26, 36, 37, 38, 42, 45, 47, 50, 52, 53, 54, 57, 59, 62, 64, 66, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 86, 87, 88, 89, 91, 94, 95, 96, 97, 100, 103, 105, 106, 108, 112, 114, 121, 123, 124, 125, 128, 129, 133, 135, 137, 139, 141, 142, 144, 145, 148, 149, 151, 152, 157, 158, 159, 161, 163, 165, 166, 167, 171, 175, 176, 177, 178, 180, 181, 183, 185, 187, 189, 192, 193, 198, 199, 202, 203, 204, 205, 209, 210, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 228, 229, 233, 234, 236, 237, 238, 240, 241, 242, 243, 244, 247, 250, 251, 252, 254, 256, 257, 258, 261, 263, 264, 265, 266, 267, 269, 271, 272, 276, 278, 280, 281, 282, 283, 286, 292, 293, 296, 298, 299, 303, 305, 307, 308, 309, 310, 312, 315, 316, 318, 320, 321, 322, 326, 328, 330, 332, 333, 334, 336, 339, 340, 342, 343, 345, 346, 348, 353, 354, 360, 365, 366, 367, 368, 372, 374, 378, 379, 380, 382, 383, 386, 388, 389, 392, 393, 394, 395, 399, 404, 407, 410, 412, 413, 414, 415, 418, 419, 421, 422, 423, 424, 426, 427, 428, 429, 430, 431, 433, 434, 435, 440, 441, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 467, 468, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 519, 521, 522, 523, 528, 529, 530, 531, 532, 534, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 580, 581, 589, 590, 591, 592, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 615, 616, 617, 618, 619, 625, 626, 630, 633, 635, 636, 637, 638, 639, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 704, 705, 706, 707, 708, 709, 710, 712, 713, 715, 716, 718, 719, 721, 725, 726, 728, 733, 735, 736, 737, 738, 739, 742, 744, 745, 746, 748, 749, 762, 763, 765, 769, 771, 772, 777, 786, 791, 792, 793, 795, 796, 797, 801, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 928, 930, 931, 932, 933, 936, 937, 938, 946, 948, 949, 963, 966, 971, 972, 974, 975, 976, 977, 978, 979, 980, 981, 987, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1011, 1012, 1013, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1026, 1027, 1029, 1030, 1032, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "data1010": 1046, "data_filenam": [509, 513], "data_hom": [494, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 1048, 1057], "data_home_path": 507, "data_id": [44, 149, 181, 192, 220, 238, 248, 272, 292, 296, 325, 380, 504], "data_ind": 53, "data_max": 1046, "data_max_": [882, 1046], "data_min": 1046, "data_min_": [882, 1046], "data_nam": 404, "data_path": 47, "data_rang": 1046, "data_range_": [882, 1046], "data_sampl": 54, "data_set": 315, "data_size_mb": 362, "data_stream": 47, "data_test": [252, 272, 279, 360, 517], "data_test_size_mb": 360, "data_train": [252, 272, 279, 360, 517], "data_train_size_mb": 360, "data_transform": 647, "data_transpos": [1055, 1057], "data_unravel_indic": 53, "data_vers": 404, "databas": [47, 174, 324, 373, 375, 381, 383, 416, 421, 423, 424, 427, 450, 452, 518, 563, 564, 905, 1012], "dataconversionwarn": 2, "datadimensionalitywarn": 2, "datafram": [2, 43, 52, 62, 104, 105, 106, 139, 145, 149, 152, 157, 173, 181, 187, 191, 192, 193, 194, 199, 204, 209, 224, 228, 238, 258, 261, 268, 272, 276, 278, 279, 281, 289, 290, 292, 296, 324, 325, 326, 331, 332, 333, 356, 360, 361, 380, 381, 386, 388, 391, 400, 417, 423, 440, 450, 451, 453, 455, 457, 472, 474, 475, 476, 490, 491, 492, 493, 497, 498, 499, 500, 504, 508, 509, 510, 512, 513, 518, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 569, 570, 574, 575, 576, 577, 578, 589, 590, 591, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 696, 697, 700, 808, 811, 812, 822, 838, 856, 861, 864, 868, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 910, 928, 955, 971, 974, 989, 990, 1020, 1034, 1044, 1045, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "dataia": 0, "datalim": 265, "datapoint": [43, 77, 87, 91, 180, 183, 203, 252, 253, 257, 273, 278, 298, 426, 454, 510, 565, 566, 567, 568, 572, 573, 574, 619, 920, 921, 922, 923, 993], "dataset": [2, 37, 45, 46, 48, 49, 50, 53, 54, 55, 57, 58, 59, 63, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 102, 105, 106, 107, 108, 109, 113, 114, 115, 118, 124, 127, 128, 129, 130, 131, 132, 134, 135, 138, 140, 141, 142, 143, 144, 146, 147, 150, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 170, 171, 172, 173, 174, 175, 177, 179, 182, 184, 187, 188, 194, 195, 197, 198, 201, 203, 205, 206, 207, 208, 210, 211, 212, 213, 216, 217, 218, 219, 223, 224, 225, 227, 228, 230, 232, 233, 234, 235, 236, 237, 242, 244, 245, 246, 248, 251, 253, 255, 256, 260, 261, 263, 265, 266, 267, 269, 271, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 286, 287, 288, 289, 290, 291, 294, 299, 301, 302, 303, 305, 306, 307, 308, 309, 310, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 344, 345, 347, 349, 350, 351, 352, 354, 356, 357, 358, 361, 362, 363, 364, 366, 367, 368, 369, 374, 375, 388, 389, 390, 392, 399, 400, 403, 404, 410, 412, 413, 414, 415, 416, 417, 420, 421, 422, 423, 424, 425, 428, 431, 436, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 466, 467, 477, 478, 481, 482, 483, 484, 486, 489, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 553, 554, 557, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 591, 592, 595, 596, 597, 598, 600, 601, 602, 603, 604, 606, 607, 608, 609, 610, 611, 613, 614, 615, 616, 617, 618, 619, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 636, 639, 640, 641, 642, 643, 646, 647, 648, 651, 653, 654, 655, 657, 659, 660, 661, 663, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 679, 680, 681, 682, 683, 684, 685, 687, 689, 690, 691, 693, 694, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 708, 709, 710, 711, 712, 716, 718, 719, 737, 763, 765, 795, 796, 800, 801, 803, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 822, 823, 824, 825, 826, 827, 828, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 847, 848, 849, 850, 851, 854, 855, 856, 858, 860, 861, 862, 863, 864, 865, 868, 869, 870, 872, 873, 876, 877, 885, 886, 890, 892, 894, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 932, 933, 937, 938, 989, 990, 992, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1021, 1024, 1026, 1028, 1029, 1030, 1033, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048], "dataset_nam": [257, 299], "datasets_nam": 257, "datastructur": [412, 1049, 1053], "datastuctur": 1058, "datatyp": [472, 474, 1048, 1051], "date": [43, 104, 155, 174, 181, 193, 381, 383, 386, 390, 401, 417, 1020], "dateco2datef641958": 181, "daten": [458, 1049, 1050], "datenbergwerk": 1051, "datetim": [43, 55, 181, 193], "dauphin": [317, 1043], "dave": [1041, 1048, 1049, 1055, 1057], "davi": [2, 482, 733, 1000, 1045], "david": [0, 72, 92, 114, 145, 155, 199, 204, 222, 257, 279, 281, 324, 360, 361, 362, 381, 406, 416, 423, 426, 470, 540, 544, 575, 576, 630, 631, 636, 733, 805, 909, 990, 996, 1004, 1013, 1024, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "davidblnc": [1056, 1057], "davidleon123": 1059, "davies_bouldin_scor": [2, 416, 1049], "davis2006": 1000, "daw": [0, 139, 140, 141, 406, 1041, 1042, 1043, 1044, 1045], "dawson": 1045, "dayn": [1056, 1057], "db": [84, 90, 416], "dbauer9": 1052, "dberenbaum": 1057, "dbg": 392, "dbpedia": 55, "dbpedia_resource_prefix_len": 55, "dbscan": [2, 71, 72, 73, 79, 90, 95, 98, 100, 189, 334, 340, 398, 400, 454, 458, 460, 463, 520, 712, 713, 725, 745, 801, 803, 864, 892, 1003, 1021, 1035, 1036, 1041, 1043, 1045, 1046, 1048, 1049, 1050, 1057, 1058], "dbscan_clust": 454, "dcc": 381, "dcg": [734, 764, 1000, 1048], "dcg_score": [2, 764, 1000, 1048, 1051], "dd": [50, 51, 158, 312, 506], "ddof": [278, 892, 903], "de": [0, 51, 61, 62, 63, 64, 108, 143, 160, 176, 177, 179, 180, 181, 182, 183, 185, 211, 252, 253, 325, 340, 356, 383, 643, 696, 772, 996, 997, 1020, 1042, 1043, 1044, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058, 1059], "dea": [1055, 1056, 1057], "deactiv": [259, 380, 387, 392, 404, 417, 811, 812, 1055], "dead": 1059, "deadlock": 401, "deal": [62, 92, 105, 155, 187, 192, 204, 244, 292, 296, 353, 362, 386, 391, 417, 424, 425, 426, 482, 504, 711, 716, 771, 795, 878, 949, 996, 1024, 1031, 1044, 1056, 1057], "dealloc": 1058, "dean": [160, 1049, 1055, 1057, 1059], "deap": 1019, "death": 381, "debian": [0, 373, 384, 392], "debias": 134, "deborah": [1047, 1048, 1058], "debug": [2, 369, 374, 387, 389, 392, 400, 403, 635, 911, 1019, 1034, 1049, 1053], "debugg": [389, 394], "dec": [221, 296, 685, 891, 916, 1015], "decad": [192, 1020], "decai": [181, 552, 869, 870, 949, 1000, 1014, 1045], "decal": 1053, "decemb": [114, 155, 181, 381, 672, 693, 694, 1041, 1049, 1051, 1053, 1054, 1056], "decent": [247, 277, 381, 1002], "deci": 287, "decid": [43, 50, 92, 95, 105, 150, 155, 269, 275, 278, 285, 381, 386, 401, 410, 415, 424, 426, 458, 465, 567, 568, 619, 643, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 679, 689, 692, 805, 854, 855, 856, 858, 860, 862, 863, 864, 875, 999, 1006, 1024, 1054, 1057], "decil": [640, 1052], "deciles_hlines_": 640, "deciles_vlines_": 640, "decim": [62, 182, 479, 480, 925, 1048, 1049], "decis": [0, 2, 40, 43, 62, 64, 67, 70, 76, 91, 93, 95, 129, 138, 141, 142, 143, 144, 150, 158, 159, 160, 162, 163, 167, 173, 174, 178, 180, 192, 202, 203, 212, 229, 230, 233, 247, 248, 250, 258, 270, 281, 282, 284, 285, 296, 307, 310, 314, 319, 320, 321, 324, 337, 341, 342, 345, 346, 347, 348, 349, 350, 351, 357, 358, 360, 373, 382, 383, 386, 400, 410, 411, 414, 416, 423, 445, 477, 504, 508, 512, 527, 544, 557, 558, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 601, 602, 639, 640, 641, 652, 653, 654, 655, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 679, 680, 681, 682, 683, 684, 685, 706, 708, 710, 711, 715, 726, 728, 734, 735, 743, 747, 748, 750, 764, 790, 792, 795, 796, 797, 802, 807, 808, 811, 812, 822, 824, 830, 835, 838, 840, 841, 843, 854, 873, 892, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 994, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1013, 1014, 1015, 1019, 1020, 1021, 1022, 1024, 1032, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1050, 1051, 1054, 1055, 1057, 1058, 1059], "decision_funct": [48, 50, 62, 64, 91, 141, 156, 167, 232, 233, 234, 248, 257, 272, 285, 292, 305, 306, 314, 321, 335, 347, 348, 349, 353, 354, 358, 388, 400, 414, 415, 423, 445, 477, 557, 558, 561, 563, 567, 569, 571, 575, 601, 602, 639, 640, 641, 666, 667, 674, 676, 682, 683, 684, 685, 706, 708, 710, 715, 728, 734, 735, 743, 747, 748, 750, 764, 790, 796, 797, 802, 807, 808, 811, 812, 822, 830, 833, 840, 841, 842, 843, 858, 872, 879, 909, 912, 914, 916, 917, 996, 1000, 1006, 1007, 1014, 1015, 1032, 1041, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1058], "decision_function_shap": [328, 357, 914, 917, 1015, 1046, 1047, 1050, 1051], "decision_path": [368, 565, 566, 572, 573, 574, 920, 921, 922, 923, 1047, 1052], "decision_threshold": [272, 292], "decision_tre": [924, 925, 926, 1016], "decision_tree_learn": [920, 921, 1016], "decisionboundarydisplai": [2, 48, 66, 67, 70, 91, 141, 156, 161, 203, 212, 229, 234, 281, 302, 307, 310, 324, 345, 346, 347, 348, 350, 351, 353, 365, 1055, 1056, 1058, 1059], "decisiontre": [148, 561, 1046], "decisiontreeclassifi": [2, 67, 139, 141, 148, 161, 282, 296, 334, 364, 365, 368, 400, 415, 423, 561, 563, 565, 567, 569, 572, 639, 719, 814, 836, 921, 922, 924, 925, 926, 990, 1001, 1016, 1042, 1043, 1045, 1046, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "decisiontreeclassifierifitteddecisiontreeclassifi": 368, "decisiontreeregressor": [2, 140, 142, 258, 320, 328, 334, 366, 367, 391, 562, 564, 566, 567, 568, 570, 572, 573, 640, 641, 920, 923, 925, 944, 990, 1001, 1016, 1042, 1043, 1046, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "decisiontreeregressorifitteddecisiontreeregressor": 330, "declan": 1053, "declar": [91, 241, 254, 369, 386, 387, 388, 392, 400, 451, 454, 455, 467, 479, 480, 486, 698, 702, 1048, 1052], "decod": [47, 312, 381, 400, 511, 577, 596, 597, 599, 1041, 1042], "decode_error": [47, 424, 511, 596, 597, 599, 1043], "decompos": [11, 125, 129, 142, 321, 542, 546, 717, 833, 949, 995, 996, 1000, 1017, 1035, 1036], "decomposit": [2, 9, 44, 45, 54, 55, 85, 93, 104, 106, 107, 108, 118, 121, 123, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 138, 158, 197, 240, 241, 243, 252, 255, 256, 259, 277, 303, 308, 324, 332, 335, 336, 361, 375, 379, 392, 395, 400, 412, 413, 414, 417, 423, 428, 457, 459, 460, 461, 470, 490, 491, 492, 503, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 564, 619, 658, 659, 660, 661, 662, 663, 664, 671, 672, 673, 680, 681, 682, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 703, 704, 805, 806, 861, 868, 871, 874, 890, 921, 948, 949, 996, 997, 1000, 1017, 1019, 1021, 1022, 1028, 1030, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048], "decompress": [410, 1041], "decor": [2, 193, 328, 386, 387, 388, 395, 814, 831, 939, 943, 944, 961, 967, 1051, 1054, 1057, 1059], "decoupl": [423, 1002], "decreas": [63, 74, 81, 90, 93, 101, 109, 155, 157, 173, 174, 184, 192, 193, 195, 228, 250, 251, 280, 285, 291, 314, 321, 324, 328, 364, 373, 375, 386, 414, 416, 423, 449, 453, 471, 529, 542, 543, 549, 565, 566, 567, 568, 569, 570, 572, 573, 574, 610, 643, 644, 645, 684, 685, 686, 714, 720, 735, 790, 797, 869, 870, 920, 921, 922, 923, 989, 991, 992, 996, 997, 1000, 1003, 1004, 1007, 1008, 1014, 1015, 1024, 1032, 1043, 1048, 1051, 1054], "dede00": [79, 97, 98], "dedic": [43, 276, 358, 384, 390, 392, 398, 401, 412, 416, 592, 680, 682, 695, 989, 996, 1019, 1025, 1049, 1058], "deduc": 46, "deduct": 1004, "dedupl": 1045, "deeksha": 1053, "deem": [286, 287, 542, 1008, 1054], "deep": [220, 388, 400, 410, 423, 430, 441, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 777, 805, 806, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 1004, 1005, 1019, 1020, 1024, 1046, 1052, 1053, 1055], "deepcopi": 388, "deeper": [360, 1016], "deepest": [569, 570, 1052], "deeplook": 1051, "deeppink": 287, "def": [43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 57, 62, 64, 69, 70, 72, 75, 76, 83, 87, 90, 91, 93, 96, 104, 109, 123, 125, 127, 128, 132, 134, 137, 139, 142, 144, 149, 151, 152, 155, 160, 179, 182, 184, 185, 188, 195, 200, 208, 209, 212, 217, 220, 221, 228, 229, 230, 238, 240, 241, 254, 255, 257, 263, 264, 265, 266, 268, 269, 272, 273, 276, 277, 278, 279, 281, 286, 289, 293, 299, 304, 306, 309, 312, 315, 317, 319, 321, 324, 325, 328, 336, 342, 345, 349, 353, 358, 360, 361, 362, 373, 381, 386, 388, 392, 393, 398, 417, 420, 424, 428, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 516, 517, 541, 605, 609, 618, 619, 626, 789, 885, 939, 944, 961, 1000, 1007, 1015, 1030], "default": [2, 43, 52, 54, 62, 66, 77, 80, 81, 83, 90, 94, 125, 145, 170, 176, 187, 193, 199, 200, 209, 220, 221, 238, 249, 251, 257, 259, 261, 266, 272, 273, 281, 287, 292, 298, 299, 319, 323, 326, 328, 329, 333, 335, 336, 353, 356, 357, 360, 361, 362, 364, 369, 373, 374, 380, 381, 384, 388, 389, 390, 391, 392, 393, 395, 398, 399, 400, 404, 407, 410, 414, 415, 416, 417, 420, 421, 423, 424, 425, 427, 428, 429, 430, 432, 433, 434, 435, 437, 438, 439, 440, 441, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 715, 716, 717, 719, 720, 721, 722, 724, 726, 727, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 739, 742, 743, 744, 746, 747, 748, 749, 750, 751, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 779, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 819, 820, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 936, 938, 939, 941, 943, 948, 949, 950, 951, 952, 953, 954, 963, 965, 966, 969, 970, 971, 973, 974, 975, 981, 984, 986, 987, 989, 990, 992, 994, 996, 999, 1000, 1001, 1003, 1004, 1006, 1007, 1010, 1012, 1014, 1015, 1016, 1025, 1029, 1032, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "default_bas": [79, 97], "default_rng": 281, "default_scor": 391, "default_target_attribut": 380, "default_tim": [235, 266], "defaultdict": [49, 52, 57, 62, 195, 281, 361, 362], "defazio": [666, 996], "defens": 296, "defer": 386, "defici": [997, 1014], "defin": [8, 27, 46, 51, 64, 70, 88, 90, 92, 101, 104, 105, 107, 118, 125, 130, 137, 139, 140, 160, 174, 176, 183, 184, 185, 193, 194, 195, 199, 221, 228, 237, 238, 247, 251, 254, 258, 260, 263, 268, 272, 278, 279, 281, 285, 287, 288, 289, 290, 292, 296, 299, 317, 319, 329, 335, 336, 349, 353, 356, 360, 361, 373, 382, 385, 386, 387, 388, 392, 393, 395, 398, 399, 400, 410, 411, 412, 413, 415, 416, 417, 418, 420, 421, 422, 423, 424, 426, 431, 432, 433, 435, 436, 437, 438, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 464, 467, 471, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 497, 527, 528, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 617, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 630, 631, 635, 636, 637, 638, 640, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 704, 705, 707, 716, 718, 719, 724, 729, 730, 731, 732, 733, 736, 739, 746, 749, 753, 754, 756, 758, 759, 761, 762, 765, 768, 774, 789, 793, 798, 799, 800, 801, 805, 806, 807, 808, 811, 812, 814, 822, 830, 831, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 872, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 899, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 936, 938, 941, 947, 958, 960, 984, 989, 990, 996, 997, 998, 999, 1001, 1002, 1003, 1005, 1006, 1007, 1008, 1010, 1012, 1014, 1015, 1016, 1020, 1030, 1033, 1036, 1038, 1043, 1047, 1048, 1049, 1051, 1052, 1053, 1055, 1056, 1057, 1058], "definit": [2, 93, 114, 208, 220, 285, 299, 361, 386, 387, 388, 400, 403, 416, 418, 419, 421, 535, 537, 543, 619, 636, 700, 716, 726, 736, 766, 805, 806, 989, 992, 994, 996, 998, 1000, 1003, 1014, 1018, 1036, 1045, 1049, 1056], "definitelyuncertain": 1047, "deflat": [192, 419, 428, 541], "defoi": 1054, "deform": [156, 268, 358], "degener": [123, 264, 428, 448, 462, 541, 728, 996, 1000, 1050, 1054, 1055], "degrad": [155, 193, 247, 319, 356, 361, 422, 786, 1008], "degre": [43, 70, 127, 141, 181, 187, 191, 192, 193, 197, 199, 204, 208, 209, 221, 224, 253, 259, 263, 264, 265, 268, 269, 278, 293, 317, 330, 331, 346, 353, 355, 421, 425, 454, 460, 506, 543, 549, 647, 648, 651, 664, 783, 805, 808, 858, 887, 891, 914, 915, 916, 917, 918, 992, 993, 995, 996, 997, 998, 1000, 1001, 1003, 1006, 1007, 1010, 1013, 1015, 1032, 1044, 1050, 1054, 1055, 1058], "degrees_of_freedom_": 805, "degrees_of_freedom_prior": 805, "degrees_of_freedom_prior_": 805, "dei": 1053, "deil": [1042, 1052, 1053], "dein": 424, "dekel": [674, 675, 996], "del": [55, 392, 1053, 1054], "delai": [2, 386, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 808, 822, 833, 834, 1055, 1056, 1059], "delalleau": 1013, "delanou": 1052, "delattr": 1053, "delayed_funct": 966, "delbert": [73, 448, 462], "deleg": [91, 392, 440, 441, 925, 1045, 1047, 1053], "delet": [2, 106, 339, 341, 390, 391, 477, 482, 494], "delete_index": 339, "delete_indic": 339, "deleteri": 1048, "deli": 410, "deliber": 996, "delimit": [386, 1006, 1056], "deliv": [80, 373, 1024], "deliveri": 390, "dell": 51, "delong": [1053, 1054], "delta": [419, 460], "delta_": 997, "delta_k": 419, "delteil": 1045, "delv": [869, 870], "demand": [151, 155, 400, 424, 808, 822, 833, 834], "demarc": 95, "demiraj": [1056, 1057], "demo": [52, 53, 56, 71, 72, 74, 75, 76, 79, 80, 81, 83, 88, 89, 94, 95, 96, 97, 99, 102, 156, 189, 195, 204, 226, 251, 266, 268, 279, 287, 324, 340, 341, 360, 361, 388, 413, 416, 424, 448, 449, 452, 454, 455, 456, 458, 459, 461, 463, 466, 510, 519, 520, 521, 549, 712, 713, 725, 727, 745, 801, 803, 873, 892, 893, 1021], "demo_param": 388, "demonstr": [46, 52, 57, 58, 59, 62, 68, 71, 75, 78, 90, 96, 104, 106, 120, 139, 143, 150, 153, 171, 172, 184, 185, 189, 195, 221, 222, 254, 260, 261, 265, 269, 270, 274, 281, 284, 287, 293, 301, 304, 311, 318, 320, 321, 323, 326, 330, 337, 339, 340, 343, 347, 353, 360, 361, 362, 369, 375, 381, 382, 386, 391, 398, 407, 412, 416, 420, 423, 455, 510, 520, 528, 705, 711, 721, 750, 806, 808, 877, 908, 920, 989, 990, 994, 1000, 1001, 1002, 1003, 1010, 1013, 1016, 1018, 1021], "dem\u0161ar": 278, "den": [0, 405, 1042, 1043, 1048, 1049, 1050, 1053, 1054], "dendrit": [416, 718], "dendro": 195, "dendro_idx": 195, "dendrogram": [71, 102, 189, 195, 368, 416, 449, 453, 512, 1021, 1053], "denero": 743, "deng": [1045, 1046, 1047], "dengemann": 1042, "dengyong": 908, "deni": [132, 1043, 1044, 1048, 1049, 1050, 1056, 1057], "denni": 1055, "denois": [42, 83, 85, 86, 88, 124, 130, 189, 421, 504, 543, 545, 549, 592, 595, 838, 882, 1021], "denomin": [285, 423, 424, 429, 483, 598, 712, 765, 994], "denot": [172, 395, 400, 404, 414, 416, 420, 423, 596, 597, 599, 808, 814, 822, 831, 885, 886, 985, 989, 992, 996, 998, 1000, 1001, 1010, 1013, 1025, 1058], "dens": [51, 90, 189, 198, 204, 214, 332, 333, 342, 373, 395, 400, 416, 421, 423, 425, 451, 454, 455, 457, 472, 475, 504, 531, 532, 535, 542, 543, 552, 574, 615, 616, 637, 638, 660, 665, 666, 667, 674, 675, 676, 680, 681, 684, 685, 686, 695, 696, 697, 700, 701, 768, 769, 775, 787, 800, 869, 870, 877, 884, 885, 887, 889, 890, 891, 892, 901, 902, 903, 904, 905, 912, 913, 914, 915, 917, 918, 950, 971, 974, 990, 993, 996, 997, 1000, 1001, 1003, 1006, 1010, 1012, 1013, 1014, 1015, 1016, 1021, 1041, 1043, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058, 1059], "dense_lasso": 206, "dense_output": [769, 775, 905, 950, 1049], "denser": 452, "densif": 1050, "densifi": [400, 666, 667, 674, 675, 676, 684, 685, 686, 912, 990, 1043], "densiti": [2, 50, 84, 90, 95, 100, 109, 134, 172, 174, 189, 206, 220, 235, 238, 244, 247, 251, 262, 263, 269, 278, 284, 296, 300, 305, 306, 319, 349, 360, 381, 383, 395, 400, 416, 423, 427, 435, 452, 454, 456, 458, 460, 472, 475, 506, 510, 544, 549, 557, 558, 805, 806, 808, 852, 853, 857, 858, 905, 994, 996, 999, 1003, 1005, 1006, 1012, 1019, 1021, 1022, 1025, 1035, 1036, 1043, 1045, 1049, 1050, 1056, 1057], "density_": 905, "densityestim": 435, "densitymixin": 2, "denton": 1043, "deodhar": 1053, "deoli": 1054, "depart": [184, 416], "depedend": 1058, "depend": [2, 25, 43, 44, 46, 52, 64, 72, 88, 109, 129, 145, 149, 152, 153, 155, 157, 160, 169, 173, 182, 187, 189, 190, 192, 195, 197, 200, 204, 238, 241, 246, 247, 253, 257, 268, 272, 278, 279, 283, 284, 285, 292, 299, 315, 319, 324, 330, 333, 336, 346, 353, 356, 361, 362, 369, 373, 374, 375, 379, 386, 388, 389, 394, 395, 398, 399, 400, 401, 403, 404, 409, 410, 412, 416, 418, 420, 421, 423, 424, 425, 426, 427, 446, 447, 448, 452, 454, 455, 457, 458, 460, 462, 465, 467, 468, 470, 472, 477, 492, 497, 498, 499, 501, 504, 508, 509, 510, 512, 513, 518, 542, 543, 549, 552, 559, 567, 568, 570, 596, 597, 598, 599, 610, 612, 615, 616, 619, 635, 640, 641, 646, 648, 656, 666, 667, 677, 679, 681, 684, 685, 686, 688, 695, 698, 699, 702, 703, 719, 737, 738, 746, 786, 789, 791, 792, 795, 800, 801, 805, 806, 827, 837, 854, 855, 856, 858, 860, 861, 862, 863, 864, 870, 871, 873, 885, 886, 889, 892, 906, 913, 914, 917, 921, 930, 989, 990, 992, 993, 994, 996, 997, 999, 1000, 1002, 1003, 1004, 1005, 1008, 1012, 1014, 1015, 1016, 1021, 1025, 1032, 1034, 1036, 1038, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1056, 1057, 1058], "dependen": 356, "depict": [139, 280, 423, 999], "deploi": [272, 336, 373, 403, 410, 415, 1020, 1024], "deploy": [394, 410, 1019, 1020, 1024], "depot": 51, "deprec": [2, 16, 331, 374, 388, 389, 390, 395, 400, 407, 449, 453, 454, 455, 458, 465, 467, 490, 491, 492, 493, 535, 544, 545, 546, 547, 548, 554, 561, 577, 578, 587, 588, 590, 635, 666, 667, 674, 681, 683, 684, 685, 687, 700, 717, 750, 758, 759, 786, 787, 788, 790, 808, 811, 812, 822, 833, 834, 835, 836, 859, 871, 872, 877, 914, 917, 928, 943, 944, 989, 990, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "deprecated_api_refer": 386, "deprecationwarn": 1051, "dept": 383, "depth": [43, 144, 149, 153, 156, 161, 296, 364, 366, 367, 368, 373, 384, 386, 390, 399, 423, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 852, 853, 857, 920, 921, 922, 923, 924, 926, 954, 1005, 1006, 1016, 1043, 1044, 1052], "der": [700, 704, 997, 1044, 1045, 1049], "derek": 1049, "deriv": [43, 57, 134, 135, 151, 181, 184, 194, 208, 209, 213, 221, 374, 381, 388, 418, 420, 422, 423, 424, 426, 428, 449, 453, 454, 473, 541, 614, 625, 630, 656, 677, 684, 688, 869, 870, 885, 891, 912, 913, 994, 996, 997, 1000, 1004, 1006, 1015, 1041, 1042, 1043, 1048, 1049, 1050, 1056], "deros": 1052, "derouich": 1041, "derweh": 1059, "desai": [1048, 1050, 1053, 1054, 1056, 1057], "desalvo": 989, "descamp": 1049, "descend": [148, 635, 1051], "descent": [2, 46, 53, 150, 189, 198, 205, 208, 247, 252, 305, 331, 348, 421, 423, 479, 480, 486, 496, 504, 511, 539, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 639, 647, 654, 655, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 676, 680, 682, 684, 685, 686, 689, 690, 691, 692, 695, 702, 838, 869, 870, 873, 912, 916, 974, 997, 1004, 1006, 1015, 1021, 1022, 1032, 1036, 1041, 1044, 1045, 1046, 1048, 1050, 1052, 1054, 1055, 1056], "descr": [174, 379, 380, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 508, 509, 510, 511, 512, 513, 515, 518, 1031, 1049], "describ": [2, 43, 52, 91, 160, 174, 192, 238, 252, 278, 287, 369, 373, 374, 379, 381, 383, 385, 386, 388, 391, 394, 400, 401, 413, 416, 418, 419, 420, 421, 423, 424, 470, 477, 481, 482, 499, 501, 503, 504, 505, 508, 509, 510, 511, 512, 513, 518, 524, 525, 526, 536, 615, 616, 653, 667, 676, 722, 805, 806, 847, 849, 887, 949, 989, 992, 995, 996, 999, 1000, 1002, 1006, 1014, 1015, 1016, 1023, 1025, 1031, 1032, 1049, 1051], "descript": [2, 52, 174, 192, 325, 379, 380, 385, 386, 390, 391, 394, 400, 416, 424, 460, 470, 472, 475, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 508, 509, 510, 511, 512, 513, 515, 518, 552, 638, 684, 770, 773, 786, 1000, 1014, 1015, 1020, 1023, 1034, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "descriptor": [400, 516, 517], "deseri": 410, "deserv": [386, 392], "deshmukh": 1054, "deshpand": [1046, 1047], "design": [0, 2, 53, 58, 113, 139, 160, 179, 191, 192, 201, 254, 268, 272, 319, 325, 368, 375, 380, 386, 391, 398, 399, 400, 401, 403, 404, 409, 410, 416, 423, 425, 523, 536, 640, 641, 656, 673, 677, 684, 688, 693, 808, 826, 827, 847, 849, 990, 996, 997, 1000, 1001, 1010, 1019, 1020, 1024, 1027, 1043, 1050, 1059], "desir": [50, 61, 141, 174, 188, 220, 222, 319, 323, 336, 379, 386, 388, 390, 394, 410, 413, 416, 419, 420, 421, 425, 511, 546, 548, 552, 555, 575, 601, 610, 611, 672, 678, 693, 694, 707, 716, 744, 852, 853, 857, 872, 877, 879, 882, 883, 885, 886, 888, 889, 893, 896, 898, 900, 901, 936, 969, 992, 994, 997, 1003, 1010, 1014, 1015, 1016, 1025, 1027, 1041, 1049, 1050, 1051, 1054], "desislava": 1055, "desktop": 384, "despit": [64, 118, 218, 220, 238, 253, 308, 400, 407, 418, 635, 636, 638, 996, 1003, 1024, 1049, 1050], "dessyvv": 1055, "dest": 333, "destin": 1024, "destroi": [284, 424, 803, 881, 1010], "det": [2, 189, 260, 270, 287, 288, 386, 418, 523, 572, 706, 710, 735, 797, 838, 873, 892, 912, 947, 1021, 1053], "det_curv": [2, 275, 706, 790, 797, 1000, 1053, 1054, 1059], "detail": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 64, 92, 139, 140, 142, 146, 148, 153, 160, 189, 193, 208, 209, 224, 245, 249, 252, 253, 257, 259, 261, 269, 272, 276, 285, 292, 302, 305, 306, 325, 328, 329, 330, 331, 332, 333, 334, 335, 336, 364, 366, 367, 369, 373, 374, 375, 378, 379, 380, 381, 384, 386, 388, 390, 391, 392, 394, 398, 399, 400, 401, 404, 410, 412, 415, 416, 419, 420, 421, 423, 424, 425, 426, 427, 440, 441, 445, 451, 452, 454, 455, 456, 458, 460, 465, 466, 467, 469, 470, 472, 473, 474, 475, 476, 480, 504, 512, 532, 539, 543, 544, 545, 547, 549, 550, 551, 552, 553, 554, 556, 557, 561, 562, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 575, 576, 577, 578, 602, 605, 610, 615, 616, 618, 622, 627, 630, 635, 636, 638, 639, 640, 642, 647, 648, 653, 654, 655, 659, 661, 663, 664, 665, 666, 667, 669, 671, 673, 674, 676, 679, 680, 681, 682, 683, 684, 686, 687, 695, 696, 697, 698, 699, 700, 701, 702, 703, 709, 719, 721, 782, 786, 787, 788, 789, 806, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 844, 845, 850, 854, 855, 857, 858, 860, 862, 863, 865, 866, 868, 871, 872, 874, 876, 877, 889, 893, 901, 907, 908, 910, 914, 917, 920, 921, 922, 923, 943, 966, 989, 990, 994, 996, 998, 999, 1000, 1001, 1003, 1004, 1006, 1008, 1013, 1022, 1023, 1024, 1025, 1031, 1034, 1036, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "detcurvedisplai": [2, 275, 331, 735, 1053, 1054, 1058, 1059], "detect": [2, 14, 42, 47, 49, 58, 70, 98, 100, 113, 114, 115, 146, 149, 156, 189, 201, 224, 234, 246, 260, 270, 272, 278, 281, 287, 288, 300, 319, 325, 336, 348, 381, 384, 386, 390, 398, 400, 414, 415, 416, 418, 420, 424, 438, 454, 457, 472, 474, 477, 478, 481, 482, 483, 484, 496, 497, 499, 500, 504, 518, 520, 523, 530, 545, 546, 547, 554, 571, 572, 596, 599, 604, 639, 647, 685, 706, 710, 735, 797, 838, 858, 862, 873, 882, 885, 886, 890, 891, 892, 912, 916, 992, 996, 1019, 1020, 1021, 1022, 1024, 1029, 1034, 1035, 1036, 1041, 1044, 1047, 1048, 1049, 1051, 1053, 1054, 1056, 1057, 1060], "detection_error_tradeoff": 1000, "detector": [381, 400, 858], "determin": [2, 48, 50, 53, 57, 81, 90, 113, 139, 141, 145, 155, 172, 181, 192, 199, 200, 216, 223, 278, 319, 324, 353, 362, 368, 369, 385, 386, 388, 395, 399, 400, 413, 414, 416, 420, 421, 423, 424, 425, 426, 439, 445, 449, 450, 451, 453, 455, 457, 458, 464, 467, 468, 469, 473, 477, 478, 480, 481, 482, 483, 484, 490, 491, 492, 496, 499, 500, 503, 505, 511, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 545, 547, 550, 551, 560, 561, 562, 564, 566, 567, 568, 569, 570, 571, 573, 575, 576, 578, 590, 591, 592, 596, 599, 602, 610, 615, 616, 618, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 635, 643, 644, 648, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 676, 677, 678, 680, 681, 682, 683, 684, 686, 687, 688, 695, 697, 698, 700, 701, 702, 715, 719, 731, 737, 738, 746, 791, 792, 793, 795, 796, 801, 808, 810, 811, 812, 814, 822, 830, 831, 832, 833, 834, 835, 836, 837, 839, 843, 845, 846, 848, 855, 857, 858, 863, 868, 869, 870, 876, 877, 885, 886, 887, 889, 893, 901, 912, 913, 915, 918, 921, 923, 926, 947, 963, 969, 971, 974, 989, 992, 994, 999, 1003, 1005, 1006, 1008, 1010, 1013, 1014, 1016, 1025, 1041, 1046, 1049, 1050, 1052, 1053, 1054, 1060], "determinist": [93, 152, 374, 382, 388, 400, 416, 451, 455, 457, 459, 460, 461, 466, 467, 470, 559, 567, 568, 572, 573, 591, 592, 699, 703, 819, 820, 868, 920, 921, 992, 996, 1042, 1045, 1047, 1049, 1050, 1053, 1056, 1057], "detlefsen": 1055, "detomaso": 1048, "detriment": [46, 173, 292, 374, 425, 996], "dev": [185, 192, 238, 283, 288, 384, 386, 390, 392, 394, 1000, 1024, 1037, 1048, 1053, 1056, 1057], "dev0": [384, 390, 1023, 1037], "dev514": 1055, "devansh": [1048, 1049], "devanshkyada27": 1058, "devashish": 1047, "devel": 384, "develop": [41, 47, 91, 184, 238, 272, 276, 278, 296, 299, 328, 334, 360, 373, 381, 385, 386, 392, 398, 400, 401, 403, 407, 410, 413, 418, 419, 423, 424, 430, 433, 440, 501, 808, 984, 996, 1000, 1003, 1016, 1019, 1020, 1021, 1023, 1024, 1032, 1041, 1049, 1050, 1051, 1056, 1059, 1060], "developing_estim": 1021, "devi": 1053, "devianc": [2, 151, 154, 220, 238, 334, 423, 561, 566, 567, 569, 570, 573, 656, 677, 688, 729, 731, 732, 755, 757, 760, 921, 923, 996, 1016, 1042, 1051, 1052, 1054, 1055, 1057], "deviant": [226, 1006], "deviat": [52, 58, 70, 96, 113, 142, 145, 146, 147, 148, 150, 174, 176, 181, 183, 185, 192, 199, 226, 257, 275, 276, 277, 278, 279, 281, 305, 306, 319, 324, 378, 382, 383, 391, 395, 400, 420, 423, 426, 458, 480, 509, 519, 520, 521, 522, 524, 525, 526, 530, 532, 533, 538, 560, 602, 619, 642, 652, 653, 679, 732, 760, 814, 831, 858, 881, 882, 892, 901, 902, 903, 996, 1000, 1006, 1010, 1032, 1047, 1048, 1049, 1052, 1053, 1054], "devic": [420, 590, 1019, 1059], "devnani": 1053, "deweight": 951, "dexter": 1051, "dezub": 1048, "df": [43, 52, 62, 64, 155, 160, 191, 193, 199, 204, 220, 238, 268, 278, 323, 325, 335, 361, 391, 424, 474, 598, 599, 989, 990, 1058], "df_": 238, "df_freq": 238, "df_max_": [62, 64], "df_min_": [62, 64], "df_out": 335, "df_sev": 238, "df_std": 361, "df_test": [220, 238], "df_train": [220, 238], "dfrac": [1004, 1010], "dgemm": 373, "dgesdd": 392, "dhanshre": 1056, "dhillon": [2, 57, 413, 459, 461, 519], "dhingra": [1049, 1050, 1053, 1058], "di": [400, 416, 421, 539, 545, 672, 693, 694, 905, 1045, 1054], "dia": 1058, "diabet": [2, 46, 153, 163, 164, 174, 188, 189, 207, 208, 209, 216, 217, 274, 291, 379, 423, 509, 660, 661, 808, 813, 833, 834, 835, 1008, 1021, 1025, 1029, 1036], "diabetes_i": [216, 1032], "diabetes_x": [216, 1032], "diabetes_x_test": [216, 1032], "diabetes_x_train": [216, 1032], "diabetes_y_pr": 216, "diabetes_y_test": [216, 1032], "diabetes_y_train": [216, 1032], "diadochokinet": 1056, "diag": [51, 115, 184, 265, 268, 421, 426, 540, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 805, 806, 996, 1056], "diag_kind": [191, 192], "diagnos": [174, 281, 383, 394, 403, 417], "diagnosi": [174, 281, 383, 859], "diagnost": [174, 195, 281, 379, 400, 415, 508, 720, 834, 835, 1000, 1008, 1019, 1020, 1036], "diagon": [2, 43, 62, 64, 75, 115, 117, 238, 257, 265, 268, 269, 271, 349, 413, 416, 418, 426, 461, 479, 480, 486, 489, 519, 521, 535, 540, 558, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 658, 659, 662, 663, 664, 690, 691, 709, 723, 800, 805, 806, 856, 864, 992, 994, 996, 999, 1000, 1003, 1010, 1047, 1049, 1050, 1051], "diagram": [2, 62, 64, 105, 259, 329, 335, 388, 414, 416, 446, 447, 476, 910, 1010, 1052, 1053, 1058, 1059], "diamet": 416, "diamond": 266, "diaz": 1049, "dice": [458, 465, 707, 786, 787, 788, 1003], "dicedist": 707, "dichotomis": 1016, "dickerson": 1042, "dickson": 1048, "dico": 128, "dict": [48, 49, 50, 51, 55, 63, 74, 80, 104, 107, 108, 131, 145, 150, 152, 154, 218, 226, 247, 256, 265, 276, 277, 279, 282, 285, 287, 299, 303, 321, 325, 332, 342, 349, 353, 361, 362, 375, 378, 380, 388, 398, 400, 417, 420, 427, 428, 430, 434, 438, 440, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 504, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 705, 706, 708, 709, 710, 719, 721, 770, 773, 779, 787, 788, 805, 806, 807, 808, 811, 812, 814, 819, 820, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 927, 937, 938, 954, 957, 960, 989, 1000, 1010, 1029, 1030, 1034, 1036, 1041, 1047, 1048, 1057, 1058, 1059], "dict_count_vector": 362, "dict_init": [539, 545, 553, 554], "dict_kei": 634, "dict_learn": [2, 395, 539, 545, 554, 1042, 1049, 1051, 1054, 1055, 1057], "dict_learning_onlin": [2, 553, 1042, 1051, 1054, 1055, 1058], "dict_pos_code_estim": 125, "dict_pos_dict_estim": 125, "dict_pos_estim": 125, "dict_typ": 589, "dictat": 416, "dictionari": [2, 44, 46, 47, 71, 83, 86, 88, 124, 126, 155, 157, 189, 219, 254, 256, 272, 361, 362, 379, 380, 381, 388, 398, 400, 416, 424, 457, 472, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 515, 518, 534, 539, 545, 546, 547, 548, 550, 551, 552, 553, 554, 556, 575, 576, 577, 578, 589, 590, 592, 595, 596, 597, 602, 640, 641, 642, 672, 693, 694, 709, 719, 721, 808, 811, 812, 819, 820, 822, 830, 835, 871, 876, 885, 920, 921, 922, 923, 927, 937, 957, 960, 989, 996, 1000, 1015, 1021, 1025, 1034, 1035, 1036, 1041, 1049, 1052, 1053, 1054, 1055, 1056], "dictionarylearn": [2, 421, 545, 547, 548, 550, 551, 552, 553, 554, 1042, 1046, 1048, 1051, 1054, 1055, 1056, 1057], "dictlearn": 1046, "dictvector": [2, 57, 104, 189, 359, 360, 361, 381, 424, 496, 590, 596, 597, 598, 599, 885, 1021, 1041, 1042, 1045, 1051, 1053, 1054, 1057, 1058], "did": [152, 176, 192, 195, 220, 228, 238, 264, 272, 326, 381, 410, 635, 720, 827, 914, 1033, 1042, 1043, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1056], "didact": [386, 1020], "didi": [1047, 1048, 1049, 1050], "didn": [254, 369, 400, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "die": 997, "diebold": 278, "diederik": [869, 870, 1004, 1056], "diederikwp": 1056, "diego": [1042, 1043], "diegodlh": [1048, 1049], "diemert": [46, 47, 49, 1024, 1043, 1044], "diesel": [220, 238], "dietterich": [278, 842, 1001], "diff": [389, 1000], "diff_embed": 309, "differ": [2, 25, 43, 44, 46, 49, 51, 53, 54, 58, 61, 64, 66, 67, 70, 71, 72, 74, 76, 77, 78, 80, 81, 82, 84, 87, 88, 90, 92, 93, 95, 99, 100, 101, 102, 104, 105, 106, 108, 113, 117, 118, 121, 122, 123, 125, 127, 128, 130, 132, 133, 134, 139, 142, 144, 145, 148, 149, 150, 152, 154, 155, 160, 161, 162, 163, 165, 167, 169, 174, 175, 176, 177, 178, 181, 182, 183, 187, 188, 189, 191, 192, 194, 197, 199, 200, 203, 206, 207, 208, 209, 211, 217, 220, 221, 222, 224, 225, 226, 227, 228, 237, 238, 240, 241, 242, 243, 245, 247, 249, 252, 253, 254, 257, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 292, 293, 294, 296, 298, 299, 302, 305, 306, 308, 314, 315, 318, 320, 321, 323, 324, 328, 336, 343, 344, 345, 347, 348, 349, 351, 352, 356, 357, 360, 361, 362, 369, 373, 374, 375, 380, 381, 383, 384, 385, 386, 389, 391, 393, 395, 399, 400, 404, 410, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 429, 441, 445, 448, 449, 450, 451, 452, 454, 455, 456, 457, 458, 459, 460, 461, 466, 467, 470, 472, 483, 486, 498, 501, 502, 504, 511, 512, 516, 517, 520, 522, 530, 545, 546, 547, 548, 554, 555, 557, 558, 563, 564, 571, 589, 590, 596, 597, 598, 599, 602, 619, 621, 622, 623, 627, 630, 631, 635, 639, 640, 641, 642, 646, 651, 652, 653, 655, 657, 659, 661, 663, 666, 669, 674, 675, 676, 680, 682, 684, 685, 686, 688, 698, 700, 702, 706, 708, 709, 712, 713, 714, 715, 717, 723, 725, 726, 735, 736, 737, 738, 739, 742, 743, 745, 751, 765, 766, 767, 769, 786, 790, 791, 792, 794, 795, 797, 800, 801, 803, 806, 808, 810, 811, 812, 813, 814, 817, 822, 823, 824, 825, 826, 827, 828, 830, 831, 833, 835, 836, 839, 847, 848, 849, 850, 851, 852, 853, 854, 855, 858, 862, 865, 868, 872, 877, 881, 882, 884, 885, 886, 887, 888, 889, 890, 892, 893, 897, 898, 899, 900, 901, 902, 903, 912, 913, 914, 917, 920, 921, 922, 923, 957, 964, 989, 990, 992, 993, 995, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1017, 1019, 1020, 1021, 1024, 1025, 1027, 1028, 1029, 1033, 1034, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "difference_plot": 283, "differenti": [121, 285, 423, 426, 567, 568, 627, 630], "difficult": [90, 139, 192, 228, 257, 386, 394, 414, 421, 423, 561, 562, 567, 569, 570, 995, 997, 999, 1003, 1005, 1007, 1016, 1024, 1041, 1055], "difficulti": [48, 64, 238, 319, 375, 386, 414, 869, 870, 999, 1003], "diffus": 181, "digest": [386, 1056], "digg": [1024, 1048], "digicosm": 0, "digit": [2, 44, 51, 52, 65, 71, 74, 80, 83, 86, 88, 94, 96, 97, 106, 107, 117, 119, 128, 144, 164, 172, 174, 189, 210, 211, 227, 236, 239, 240, 242, 244, 251, 252, 266, 271, 276, 277, 280, 303, 308, 309, 313, 315, 316, 334, 337, 340, 361, 379, 386, 392, 416, 422, 423, 425, 449, 453, 455, 510, 549, 552, 557, 574, 666, 696, 697, 698, 699, 700, 705, 712, 713, 721, 725, 726, 745, 801, 803, 838, 854, 861, 868, 872, 873, 882, 892, 898, 905, 908, 917, 924, 925, 926, 989, 995, 997, 1000, 1003, 1005, 1013, 1021, 1025, 1029, 1032, 1033, 1036, 1045], "digraph": 924, "dijkstra": [395, 696, 997], "dilemma": 995, "dillon": [1049, 1050, 1051], "dilut": [195, 383], "dilutedsauc": 1049, "dim": [229, 251, 307, 308, 310, 345, 346, 535, 707, 1058], "dim_reduction_method": 308, "dimens": [2, 37, 48, 51, 52, 54, 72, 75, 88, 115, 117, 121, 125, 174, 178, 180, 182, 184, 193, 203, 204, 218, 242, 244, 247, 251, 252, 258, 264, 265, 303, 304, 308, 322, 353, 360, 361, 362, 381, 383, 387, 400, 416, 421, 422, 426, 428, 450, 451, 453, 455, 456, 457, 460, 472, 473, 490, 491, 492, 501, 502, 523, 532, 533, 537, 538, 541, 549, 557, 590, 591, 592, 593, 595, 597, 605, 619, 627, 630, 649, 652, 667, 698, 699, 700, 702, 703, 707, 772, 833, 852, 853, 857, 871, 904, 905, 906, 914, 915, 916, 917, 918, 932, 933, 934, 963, 971, 974, 990, 992, 994, 996, 997, 998, 1001, 1003, 1004, 1006, 1012, 1015, 1025, 1032, 1033, 1048, 1050, 1051, 1053], "dimension": [2, 11, 37, 45, 48, 49, 57, 67, 75, 79, 89, 90, 92, 93, 97, 103, 105, 107, 108, 117, 118, 123, 125, 132, 133, 139, 144, 158, 166, 167, 174, 176, 178, 179, 183, 189, 204, 216, 221, 237, 239, 241, 242, 244, 247, 251, 252, 255, 264, 265, 300, 303, 307, 309, 321, 346, 353, 360, 369, 373, 378, 381, 382, 383, 386, 395, 400, 413, 414, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 453, 455, 457, 473, 477, 481, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 505, 508, 509, 510, 512, 513, 518, 523, 527, 540, 542, 543, 546, 547, 548, 549, 552, 555, 557, 571, 574, 581, 607, 615, 639, 648, 649, 650, 660, 696, 697, 698, 699, 700, 701, 702, 704, 707, 718, 733, 805, 806, 808, 838, 852, 853, 854, 857, 860, 861, 868, 872, 873, 876, 882, 887, 892, 904, 905, 906, 912, 916, 949, 986, 991, 992, 995, 996, 1001, 1002, 1006, 1012, 1013, 1014, 1015, 1016, 1021, 1022, 1024, 1025, 1026, 1028, 1030, 1031, 1033, 1034, 1035, 1036, 1041, 1042, 1043, 1044, 1046, 1047, 1048, 1050, 1053, 1056, 1057], "dimensionalityreduct": 383, "dimensionalityreductiondimension": 1027, "diminish": 424, "dimitri": [1054, 1055, 1056, 1057, 1058], "dimmick": 383, "dingwal": 1048, "dionisi": 1055, "diop": 1051, "dipan": 1059, "direct": [51, 117, 118, 125, 127, 133, 174, 226, 263, 269, 275, 308, 317, 324, 349, 354, 384, 386, 387, 390, 394, 401, 404, 416, 419, 421, 424, 425, 460, 470, 479, 480, 486, 542, 549, 557, 596, 597, 599, 610, 649, 696, 861, 994, 995, 996, 1001, 1003, 1005, 1020, 1033, 1041, 1044], "direction": 1059, "direction_vector": 317, "directli": [0, 45, 57, 64, 80, 81, 91, 105, 144, 149, 174, 184, 204, 208, 220, 226, 238, 248, 283, 317, 319, 332, 335, 336, 362, 369, 373, 384, 386, 387, 388, 390, 392, 399, 400, 401, 412, 413, 414, 416, 417, 418, 419, 420, 424, 426, 450, 460, 470, 472, 477, 482, 535, 575, 576, 577, 578, 605, 619, 628, 640, 651, 654, 655, 660, 661, 668, 669, 670, 671, 672, 685, 689, 692, 698, 782, 786, 789, 800, 801, 807, 808, 811, 812, 822, 836, 855, 857, 871, 872, 873, 879, 889, 891, 894, 901, 989, 996, 998, 1003, 1005, 1007, 1010, 1015, 1016, 1020, 1026, 1029, 1030, 1041, 1049, 1050, 1052, 1053, 1054, 1057, 1058], "director": 1024, "directori": [0, 2, 47, 301, 380, 384, 386, 388, 392, 394, 400, 404, 417, 449, 453, 458, 494, 507, 872, 873, 1055], "direr": [1044, 1045, 1048, 1049], "dirichlet": [2, 42, 45, 189, 263, 264, 269, 273, 424, 496, 544, 546, 548, 596, 599, 805, 1019, 1021, 1035, 1036, 1041, 1046, 1047], "dirichlet_distribut": [263, 805, 999, 1047], "dirichlet_process": [263, 269, 805, 999, 1047], "disabl": [143, 254, 272, 326, 335, 360, 384, 386, 407, 424, 457, 468, 476, 545, 546, 547, 554, 567, 568, 569, 570, 871, 889, 901, 910, 932, 933, 1010, 1047, 1050, 1054, 1056, 1059], "disadvantag": [421, 426, 996, 997, 1004, 1014, 1015, 1016], "disagre": [743, 1007], "disambigu": [386, 840, 909, 1013, 1056], "disappear": [996, 1041], "disappoint": 43, "discard": [47, 90, 201, 281, 373, 413, 418, 425, 516, 517, 557, 605, 635, 638, 652, 885, 889, 901, 990, 996, 1049, 1053, 1059], "disclaim": 1019, "disclos": 399, "disconnect": 1054, "discontinu": [43, 398], "discord": [713, 1023], "discount": [2, 381, 416, 734, 764, 1048, 1051], "discounted_cumulative_gain": 734, "discourag": [224, 398, 404, 697], "discov": [361, 416, 421, 424, 427, 452, 456, 1025, 1056, 1059], "discoveri": [2, 278, 381, 392, 395, 416, 423, 425, 427, 452, 519, 563, 564, 571, 600, 603, 604, 606, 607, 608, 614, 728, 748, 791, 940, 941, 942, 1000, 1012, 1024, 1055, 1056], "discrep": [424, 1034, 1045], "discret": [2, 43, 47, 67, 81, 91, 123, 134, 137, 139, 158, 175, 189, 193, 200, 220, 238, 254, 258, 296, 314, 318, 322, 375, 378, 381, 382, 390, 399, 400, 416, 421, 424, 426, 446, 447, 456, 460, 468, 469, 470, 500, 522, 523, 530, 561, 567, 596, 597, 600, 603, 604, 607, 608, 615, 616, 618, 619, 620, 624, 625, 626, 665, 666, 750, 808, 819, 830, 838, 847, 848, 851, 873, 877, 885, 886, 889, 892, 901, 912, 917, 921, 963, 989, 996, 997, 998, 1000, 1001, 1003, 1016, 1019, 1021, 1025, 1036, 1043, 1046, 1054, 1055, 1056], "discrete_featur": [615, 616], "discrim": 220, "discrimin": [2, 12, 48, 49, 65, 111, 112, 113, 114, 115, 133, 169, 171, 174, 189, 197, 235, 241, 255, 268, 308, 383, 414, 423, 483, 520, 557, 558, 574, 639, 791, 861, 989, 997, 1000, 1003, 1014, 1016, 1021, 1022, 1032, 1036, 1044], "discriminant_analysi": [2, 67, 69, 70, 133, 241, 308, 369, 412, 544, 557, 558, 861, 994, 1001, 1041, 1044, 1045, 1046, 1047, 1048], "discriminatori": 414, "discuss": [43, 88, 93, 174, 192, 209, 240, 245, 272, 281, 296, 360, 369, 375, 381, 383, 386, 391, 392, 394, 398, 400, 401, 415, 416, 418, 422, 423, 426, 506, 690, 691, 854, 855, 860, 862, 863, 990, 994, 996, 997, 1000, 1003, 1010, 1017, 1020, 1023, 1044], "diseas": [46, 163, 174, 188, 281, 383, 720, 1000, 1032], "disentangl": 997, "disjoint": [414, 416, 417, 445, 712, 739, 763, 765, 997], "disk": [45, 53, 381, 386, 391, 400, 410, 1030], "disp": [43, 66, 68, 141, 155, 156, 157, 271, 281, 294, 302, 324, 329, 335, 346, 351, 446, 639, 705, 708, 709, 861], "disp1": 640, "disp2": 640, "dispar": [698, 702, 997], "dispatch": [105, 272, 400, 412, 476, 808, 822, 833, 834, 835, 910, 966, 967, 1029, 1036, 1056, 1059], "dispatch_next": 966, "dispatch_one_batch": 966, "dispers": [70, 292, 416, 718, 733, 996], "displai": [2, 51, 62, 64, 70, 72, 81, 83, 95, 105, 114, 115, 117, 118, 120, 125, 145, 156, 157, 160, 187, 189, 192, 193, 205, 207, 238, 246, 247, 257, 261, 267, 275, 279, 280, 285, 287, 288, 293, 309, 325, 329, 330, 348, 365, 373, 386, 388, 389, 393, 395, 404, 417, 421, 424, 425, 430, 446, 472, 475, 476, 504, 549, 572, 638, 639, 640, 666, 695, 705, 706, 708, 709, 710, 721, 726, 790, 797, 808, 814, 822, 831, 838, 872, 873, 885, 887, 892, 910, 917, 924, 925, 926, 940, 966, 987, 1000, 1004, 1019, 1021, 1027, 1036, 1050, 1052, 1053, 1055, 1056], "display_label": [45, 271, 705, 1030, 1053], "dispos": [989, 1034], "disproportion": 422, "disput": 145, "disregard": [360, 400, 424, 439, 473, 490, 491, 492, 560, 562, 564, 566, 568, 570, 573, 576, 578, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 729, 730, 731, 732, 793, 845, 846, 855, 863, 870, 881, 882, 888, 889, 892, 897, 900, 901, 903, 913, 915, 918, 921, 923, 1000, 1049], "disrupt": [374, 384], "dissemin": 1019, "dissimilar": [243, 353, 400, 413, 460, 698, 702, 997, 1047, 1057], "dissimilarity_matrix_": 698, "dist": [113, 241, 251, 390, 477, 478, 479, 480, 481, 482, 483, 484, 707, 771, 777, 852, 853], "dist_": [477, 482], "dist_embed": 309, "dist_linkag": 195, "dist_matrix": 460, "dist_matrix_": 696, "distanc": [2, 37, 74, 75, 90, 92, 95, 96, 100, 102, 110, 114, 130, 174, 187, 189, 195, 206, 221, 223, 240, 242, 245, 251, 257, 299, 301, 302, 307, 309, 311, 312, 319, 324, 328, 332, 333, 353, 360, 361, 373, 383, 395, 398, 400, 413, 416, 418, 421, 422, 426, 427, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 460, 463, 464, 465, 466, 467, 469, 470, 471, 476, 477, 478, 479, 480, 481, 482, 483, 484, 546, 548, 555, 615, 616, 623, 627, 628, 630, 631, 636, 666, 667, 674, 676, 682, 683, 684, 685, 686, 696, 697, 698, 700, 701, 702, 703, 704, 707, 711, 733, 742, 766, 768, 770, 771, 772, 773, 776, 777, 778, 779, 780, 781, 786, 787, 788, 789, 800, 801, 804, 841, 852, 853, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 865, 866, 867, 891, 906, 910, 912, 914, 916, 917, 918, 920, 921, 922, 923, 990, 994, 997, 998, 1000, 1003, 1006, 1010, 1012, 1014, 1015, 1020, 1021, 1032, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "distance_matrix": 195, "distance_metr": [2, 786, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 865, 866], "distance_threshold": [76, 449, 453, 1050, 1053], "distancemetr": [2, 400, 422, 855, 1003, 1049, 1053, 1054, 1055, 1058], "distancemetric64": [852, 853], "distances_": [76, 449, 453, 1053], "distant": [416, 700, 717, 1003], "distil": 245, "distinct": [95, 278, 340, 360, 362, 381, 388, 391, 400, 401, 420, 423, 424, 597, 809, 818, 826, 886, 887, 907, 908, 989, 996, 1003, 1006, 1034, 1049], "distinguish": [43, 58, 75, 113, 123, 130, 222, 275, 296, 381, 388, 400, 401, 426, 989, 1000, 1003, 1006], "distort": [37, 219, 251, 383, 414, 889, 901, 906, 997, 1010, 1012], "distribut": [2, 25, 37, 42, 43, 47, 48, 49, 52, 58, 64, 70, 72, 74, 79, 87, 88, 90, 92, 97, 109, 112, 113, 114, 118, 123, 139, 141, 152, 156, 169, 174, 176, 185, 189, 191, 192, 195, 197, 199, 220, 222, 224, 242, 244, 247, 251, 257, 263, 268, 269, 272, 274, 278, 284, 286, 292, 296, 300, 304, 318, 319, 321, 324, 334, 338, 339, 354, 356, 360, 373, 374, 379, 382, 383, 384, 386, 387, 390, 391, 392, 400, 414, 416, 418, 420, 421, 422, 428, 455, 457, 477, 478, 479, 480, 481, 482, 483, 484, 496, 506, 511, 523, 524, 525, 526, 527, 531, 540, 541, 544, 558, 559, 560, 571, 619, 633, 648, 650, 652, 653, 656, 666, 667, 677, 687, 688, 696, 697, 698, 700, 714, 716, 732, 760, 797, 805, 806, 812, 813, 820, 822, 826, 827, 838, 848, 851, 857, 861, 868, 875, 888, 889, 890, 891, 892, 900, 901, 902, 907, 908, 916, 927, 951, 989, 994, 996, 998, 999, 1000, 1002, 1003, 1005, 1006, 1012, 1013, 1019, 1020, 1021, 1025, 1029, 1033, 1035, 1036, 1041, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1057], "district": [188, 381], "distutils_use_sdk": 384, "ditenberg": 1048, "div": [257, 945], "dive": [118, 386, 392], "diverg": [54, 151, 240, 245, 304, 546, 548, 555, 700, 868, 997, 999, 1000, 1005, 1007, 1048, 1049, 1054], "divers": [400, 423], "divid": [72, 78, 83, 122, 125, 171, 181, 220, 257, 263, 361, 369, 382, 383, 413, 415, 416, 420, 421, 423, 477, 478, 479, 480, 481, 482, 483, 484, 520, 527, 542, 549, 684, 685, 686, 727, 734, 742, 746, 764, 802, 804, 869, 870, 914, 917, 949, 952, 953, 989, 997, 999, 1000, 1003, 1010, 1014, 1034, 1041, 1048, 1049, 1052], "dividend": 1000, "divis": [332, 416, 424, 598, 599, 602, 720, 721, 737, 738, 746, 754, 791, 792, 795, 1000, 1033, 1045, 1049, 1050, 1053, 1057, 1058], "divisor": 1000, "divo": 1051, "divyanshu": 1054, "divyaprabha": 1052, "diwakar": 1055, "dixon": [777, 1051, 1052], "dizietasahi": 1051, "di\u1ec5n": 1056, "djipei": [1046, 1047], "dl": 684, "dlabal": 1045, "dll": 1055, "dlovel": 1049, "dmallia17": 1054, "dmitri": [1046, 1048, 1049, 1050, 1054, 1057, 1058], "dmitrij": 1045, "dmytro": 1054, "dn": [0, 1003], "dna": [398, 636, 990], "dnf": 404, "do": [0, 30, 43, 49, 52, 62, 64, 77, 90, 96, 102, 108, 121, 129, 131, 134, 143, 146, 148, 152, 153, 155, 160, 171, 181, 187, 192, 193, 194, 217, 220, 224, 238, 240, 242, 254, 255, 257, 269, 272, 273, 276, 279, 281, 298, 299, 301, 305, 331, 335, 343, 346, 349, 353, 354, 356, 360, 361, 362, 368, 369, 373, 374, 375, 381, 383, 385, 386, 387, 388, 389, 390, 392, 393, 394, 400, 401, 410, 414, 416, 417, 418, 419, 420, 423, 424, 425, 435, 458, 469, 472, 475, 511, 544, 546, 550, 552, 560, 563, 589, 590, 596, 597, 599, 640, 641, 653, 654, 660, 663, 664, 666, 667, 674, 676, 684, 745, 771, 786, 790, 825, 828, 844, 845, 849, 876, 877, 879, 886, 890, 892, 897, 898, 900, 901, 902, 903, 920, 921, 922, 923, 931, 974, 989, 992, 994, 996, 997, 1000, 1001, 1003, 1004, 1008, 1010, 1015, 1016, 1019, 1020, 1023, 1024, 1025, 1032, 1033, 1034, 1041, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "do_early_stopping_": [569, 570], "doc": [0, 43, 47, 52, 57, 360, 362, 374, 386, 390, 391, 394, 400, 404, 409, 424, 596, 597, 599, 786, 789, 800, 801, 835, 1034, 1041, 1045, 1055], "doc_it": 47, "doc_topic_distr": [544, 1048], "doc_topic_prior": [421, 544], "doc_topic_prior_": 544, "docker": [394, 410, 1054, 1055], "dock\u00e8": [1050, 1051, 1052, 1058, 1059], "docs_new": 1034, "docs_test": 1034, "docstr": [386, 388, 392, 400, 456, 469, 480, 707, 709, 939, 989, 1000, 1003, 1004, 1014, 1041, 1048, 1049, 1054, 1055, 1058], "doctest": [386, 400, 1026, 1041], "doctest_mod": 1026, "document": [2, 17, 42, 45, 46, 49, 51, 54, 56, 59, 63, 67, 72, 80, 86, 91, 92, 93, 95, 96, 104, 105, 106, 107, 120, 121, 123, 125, 137, 144, 146, 147, 156, 157, 160, 163, 171, 181, 184, 192, 193, 194, 201, 203, 217, 218, 235, 248, 249, 250, 251, 254, 255, 257, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 316, 317, 325, 329, 332, 333, 335, 340, 342, 354, 356, 362, 368, 373, 374, 375, 380, 381, 382, 384, 385, 387, 388, 389, 390, 391, 392, 394, 398, 400, 401, 404, 407, 410, 413, 416, 421, 424, 427, 452, 455, 456, 457, 458, 461, 465, 472, 496, 497, 507, 509, 519, 529, 531, 544, 552, 572, 596, 597, 598, 599, 612, 639, 647, 651, 666, 674, 676, 682, 684, 704, 705, 707, 711, 713, 725, 745, 766, 767, 777, 786, 787, 788, 801, 803, 808, 811, 812, 814, 822, 831, 842, 849, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 865, 866, 873, 884, 912, 917, 928, 931, 933, 946, 966, 989, 996, 998, 1000, 1001, 1002, 1003, 1004, 1008, 1014, 1017, 1018, 1021, 1024, 1027, 1032, 1034, 1042, 1043, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "document_clust": 1047, "document_nam": 57, "doddington": 1000, "doe": [27, 43, 46, 47, 48, 51, 52, 61, 62, 67, 70, 75, 81, 88, 90, 92, 104, 106, 107, 118, 135, 139, 144, 145, 148, 149, 150, 154, 155, 160, 174, 182, 192, 193, 204, 217, 220, 226, 238, 240, 241, 242, 245, 247, 250, 251, 252, 254, 255, 257, 265, 266, 272, 273, 278, 280, 281, 285, 287, 288, 298, 299, 312, 319, 321, 323, 325, 326, 331, 332, 341, 342, 347, 349, 356, 358, 360, 361, 362, 373, 374, 380, 384, 386, 387, 388, 390, 394, 399, 400, 407, 410, 414, 416, 417, 420, 421, 423, 424, 425, 426, 441, 448, 450, 454, 455, 457, 458, 462, 464, 473, 475, 481, 487, 495, 507, 511, 516, 535, 543, 545, 546, 547, 552, 554, 557, 558, 561, 562, 565, 566, 567, 568, 569, 570, 572, 573, 589, 590, 591, 596, 597, 599, 601, 602, 605, 610, 614, 618, 640, 646, 657, 658, 659, 662, 663, 664, 667, 679, 690, 691, 706, 708, 710, 715, 736, 737, 738, 742, 744, 746, 751, 754, 786, 791, 792, 795, 796, 802, 808, 811, 812, 822, 869, 873, 874, 875, 877, 879, 881, 884, 885, 886, 889, 892, 893, 901, 904, 905, 909, 912, 913, 920, 921, 922, 923, 927, 932, 936, 949, 952, 953, 966, 984, 989, 990, 992, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1008, 1010, 1014, 1015, 1016, 1027, 1034, 1041, 1042, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "doepk": 1048, "doesn": [47, 192, 220, 254, 264, 298, 316, 349, 394, 400, 404, 410, 416, 424, 425, 429, 441, 483, 640, 641, 674, 676, 684, 724, 836, 839, 844, 854, 855, 869, 881, 882, 999, 1000, 1016, 1045, 1058], "dog": [331, 332, 334, 335, 336, 590, 791, 893, 1010], "dohmatob": [1046, 1047, 1048], "dohri": [1058, 1059], "doi": [197, 220, 238, 386, 416, 684], "dok": [561, 562, 879, 1054], "dokato": 1048, "dolan": 381, "dollar": [192, 381], "dolmatov": 1051, "dolphin": 360, "domain": [155, 220, 292, 325, 400, 403, 420, 643, 729, 731, 732, 809, 810, 815, 816, 817, 996, 1020], "domin": [145, 188, 195, 220, 225, 257, 287, 324, 381, 392, 414, 892, 1002, 1010, 1016, 1057], "domingo": [64, 796, 1000], "dominik": [1048, 1057], "don": [51, 64, 89, 104, 155, 192, 241, 254, 255, 272, 278, 299, 341, 346, 350, 360, 361, 373, 380, 386, 388, 390, 392, 394, 399, 404, 407, 415, 417, 424, 654, 660, 840, 920, 921, 922, 923, 964, 989, 996, 999, 1001, 1004, 1006, 1014, 1034, 1045, 1050, 1057, 1058, 1059], "don86": 1048, "donald": [45, 381, 416, 733, 990], "donald_rumsfeld": 1030, "donat": 248, "done": [45, 47, 48, 50, 52, 54, 55, 57, 83, 85, 87, 88, 128, 155, 171, 174, 181, 192, 193, 197, 199, 204, 206, 224, 237, 253, 254, 268, 276, 279, 282, 287, 299, 322, 330, 360, 361, 362, 369, 374, 380, 384, 386, 388, 390, 393, 394, 395, 398, 400, 407, 416, 418, 420, 421, 423, 449, 450, 453, 458, 460, 480, 490, 491, 492, 493, 497, 543, 569, 570, 590, 614, 615, 616, 636, 638, 640, 642, 651, 652, 653, 667, 730, 749, 805, 806, 808, 822, 827, 828, 830, 876, 890, 985, 989, 990, 993, 996, 997, 1000, 1002, 1003, 1004, 1010, 1013, 1014, 1015, 1016, 1020, 1025, 1029, 1030, 1032, 1034, 1041, 1043, 1048, 1051, 1053, 1057], "dong": 1051, "donn": 1046, "donoho": [697, 701, 997], "donor": [174, 383], "donovan": 1047, "dor": 1049, "dorin": [98, 456], "dormagen": 1051, "dot": [2, 55, 68, 69, 79, 84, 89, 92, 97, 111, 112, 113, 115, 117, 118, 126, 127, 128, 132, 134, 139, 142, 176, 177, 183, 184, 192, 201, 204, 212, 214, 215, 227, 252, 264, 265, 267, 268, 272, 282, 345, 347, 353, 373, 388, 392, 395, 400, 413, 421, 424, 541, 546, 548, 555, 598, 599, 622, 654, 655, 658, 660, 661, 662, 665, 668, 669, 670, 671, 689, 692, 695, 769, 771, 884, 924, 950, 998, 1002, 1010, 1014, 1015, 1033, 1050], "dot_data": [924, 1016], "dot_product": 950, "dotproduct": [2, 179, 180, 185, 426, 619, 633], "dotson": 1046, "doubl": [70, 145, 290, 386, 400, 421, 546, 548, 549, 555, 852, 853, 863, 984, 990, 1015, 1016, 1041, 1051, 1052], "doubt": [386, 387, 390, 996, 1006, 1019], "doucet": 1055, "douetteau": 1024, "doug": [1042, 1043, 1053], "dougal": [1043, 1045, 1046, 1048, 1049, 1050, 1051], "dougla": 1049, "douillard": 1048, "doumouro": 1050, "douriez": [1051, 1052], "dowl": 1047, "down": [81, 82, 114, 139, 235, 236, 242, 251, 252, 254, 281, 296, 317, 319, 353, 369, 380, 389, 394, 400, 418, 421, 451, 458, 464, 598, 601, 602, 647, 657, 782, 786, 789, 881, 882, 887, 890, 891, 902, 914, 917, 924, 996, 1025, 1033, 1049], "downarrow": 1002, "download": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 379, 381, 383, 384, 390, 391, 394, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 518, 1016, 1027, 1030, 1032, 1034, 1036, 1045, 1046, 1049, 1053, 1054, 1055], "download_20newsgroup": 1045, "download_if_miss": [496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 1048], "download_url": 47, "downsampl": 128, "downscal": 1034, "downsid": 362, "downstream": [43, 113, 326, 362, 424, 539, 542, 545, 549, 550, 614, 885, 1010, 1051], "downweight": [418, 544], "dowon": [1049, 1050], "dozen": [399, 426], "do\u0161ilovi\u0107": [1058, 1059], "dp": [264, 269], "dpgmm": [264, 269, 1041, 1045, 1047], "dpi": [231, 926, 1054], "dpy_debug": 392, "dqd": 392, "dr": [0, 174, 383, 416, 1055], "draft": [386, 390, 401], "drag": 1027, "dragon": 1010, "drama": 424, "dramat": 375, "dramsch": 1051, "drastic": [176, 251, 286, 416, 420, 1003, 1013], "draw": [43, 46, 95, 185, 192, 216, 258, 280, 285, 349, 393, 419, 421, 422, 423, 563, 564, 565, 566, 571, 572, 573, 574, 619, 642, 709, 814, 831, 924, 926, 999, 1019, 1028, 1054, 1055], "drawback": [147, 237, 992, 995], "drawcoastlin": [50, 312], "drawcountri": [50, 312], "drawn": [46, 87, 113, 142, 173, 176, 185, 191, 258, 285, 303, 360, 382, 416, 422, 423, 426, 428, 477, 478, 479, 480, 481, 482, 483, 484, 523, 531, 541, 563, 564, 565, 566, 571, 572, 573, 574, 619, 635, 640, 649, 848, 904, 905, 922, 923, 996, 1010, 1012, 1044], "drawstyl": [364, 708], "draxu": 1041, "drew": 1050, "drewhogg": 1056, "drewmjohnston": 1050, "drgfreeman": 1051, "driessen": [418, 477, 482, 1006], "drift": 1020, "drivag": [220, 238], "drive": [375, 421, 422, 557, 1014, 1024, 1034], "driven": [0, 195, 1024], "driver": [220, 238, 1056], "drop": [43, 44, 52, 105, 109, 118, 155, 181, 191, 192, 193, 195, 220, 224, 238, 257, 261, 272, 288, 325, 330, 333, 335, 361, 390, 394, 417, 421, 423, 472, 475, 575, 576, 577, 578, 703, 708, 710, 790, 797, 871, 885, 891, 990, 996, 1000, 1010, 1019, 1041, 1042, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "drop_binary_enc": 885, "drop_dupl": 290, "drop_enc": [885, 1010], "drop_first": 703, "drop_idx": 885, "drop_idx_": [885, 1052, 1056], "drop_intermedi": [708, 710, 790, 797, 1057], "drop_nul": [52, 181], "dropdown": [174, 386], "dropped_result": 149, "dropper": 149, "dror": 1050, "dross": 542, "dro\u017cd\u017c": 1044, "drskd": 1055, "druck": 1055, "drucker": [140, 423, 562], "drug": 996, "dry": 193, "dryden": 104, "ds_ana": 1054, "ds_cnt": [67, 321, 322], "dschult": 55, "dscullei": 457, "dseg": 104, "dsouza": [1052, 1053, 1054, 1055], "dsquareindia": 1047, "dss": 1024, "dt": [85, 128, 161, 181, 423, 424, 1016], "dtreeviz": 1019, "dtype": [43, 47, 49, 50, 55, 83, 84, 88, 100, 104, 105, 149, 151, 153, 154, 156, 177, 178, 179, 188, 192, 193, 222, 238, 261, 263, 272, 276, 282, 286, 292, 296, 306, 312, 325, 331, 332, 334, 339, 368, 380, 381, 386, 388, 398, 400, 412, 417, 420, 423, 431, 432, 434, 437, 450, 451, 455, 456, 457, 458, 459, 461, 467, 472, 474, 475, 477, 480, 482, 496, 497, 498, 499, 504, 505, 506, 508, 509, 510, 512, 513, 514, 515, 516, 517, 518, 522, 530, 550, 556, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 589, 590, 593, 594, 596, 597, 599, 601, 602, 609, 610, 614, 635, 636, 637, 638, 640, 641, 648, 649, 652, 653, 654, 660, 664, 665, 668, 669, 670, 671, 672, 673, 679, 681, 683, 705, 707, 713, 722, 723, 739, 746, 749, 763, 794, 814, 833, 835, 836, 848, 852, 853, 855, 863, 877, 883, 885, 886, 892, 893, 895, 897, 898, 899, 900, 901, 902, 903, 906, 914, 915, 916, 917, 918, 920, 921, 922, 923, 929, 930, 932, 933, 965, 975, 976, 977, 978, 981, 987, 990, 1010, 1013, 1015, 1025, 1042, 1044, 1045, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "dtype_exclud": [105, 474], "dtype_includ": [105, 149, 160, 257, 417, 474], "du": [0, 405, 406, 1041, 1042, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "dua": 1050, "dual": [104, 106, 328, 356, 360, 424, 425, 479, 480, 486, 619, 654, 655, 660, 661, 666, 667, 668, 669, 670, 671, 689, 692, 852, 853, 912, 913, 914, 917, 1015, 1043, 1052, 1055, 1057], "dual_coef_": [543, 651, 914, 915, 916, 917, 918, 1015, 1045], "dual_gap": [479, 480, 486, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692], "dual_gap_": [654, 655, 660, 661, 668, 669, 670, 671, 1054], "dualiti": [480, 996], "dualtre": [852, 853], "duan": [1050, 1052], "duart": [1046, 1054, 1056, 1059], "dubai": 424, "duboi": [1047, 1049], "dubou": 1051, "dubourg": [0, 179, 183, 406, 1024, 1041, 1045], "duchesnai": [0, 406, 1041], "duck": [388, 400, 1051], "ducktyp": [1045, 1058], "duckworth": 1041, "ducout": 1055, "duda": [383, 994], "due": [48, 52, 63, 64, 88, 90, 95, 109, 139, 142, 176, 192, 193, 199, 204, 211, 218, 220, 222, 237, 238, 251, 257, 264, 286, 287, 292, 298, 299, 324, 325, 353, 356, 360, 361, 362, 386, 392, 398, 400, 404, 414, 415, 416, 420, 421, 423, 426, 451, 454, 455, 467, 543, 547, 551, 552, 582, 679, 808, 811, 812, 816, 818, 822, 833, 834, 837, 840, 844, 845, 877, 881, 882, 892, 990, 996, 997, 999, 1000, 1001, 1003, 1007, 1014, 1015, 1020, 1033, 1041, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1060], "dueck": [73, 448, 462], "dugnat": 1055, "duhaim": 1049, "dummi": [2, 139, 140, 220, 238, 254, 272, 281, 388, 391, 411, 559, 560, 740, 885, 894, 1001, 1010, 1016, 1036, 1042, 1044, 1045, 1046, 1048], "dummy_classifiers_misclassification_error": 139, "dummy_clf": [139, 559], "dummy_leaf_": 450, "dummy_regr": 560, "dummy_sev": 238, "dummybiclust": 431, "dummyclassifi": [2, 139, 272, 281, 560, 740, 1000, 1042, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1059], "dummyestim": [567, 568], "dummyregressor": [2, 220, 238, 559, 1000, 1001, 1042, 1044, 1045, 1048, 1049, 1051, 1054, 1055, 1059], "dumont": 1016, "dump": [2, 55, 410, 495, 852, 853], "dump_svmlight_fil": [2, 1041, 1042, 1046, 1056, 1058], "duong": [1058, 1059], "duplic": [374, 385, 386, 387, 400, 416, 427, 452, 456, 457, 523, 643, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 836, 883, 986, 1003, 1041, 1044, 1053, 1055, 1057, 1058, 1060], "dupont": 51, "dupr": [212, 228, 299, 301, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057], "dupr\u00e9": [0, 321, 322, 405, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "duqu": 1054, "durat": [43, 47, 220, 238, 257, 272, 301, 362, 374, 966, 967, 996], "duration_sec": 49, "duration_test": 360, "duration_train": 360, "dure": [0, 43, 44, 51, 52, 85, 90, 93, 106, 109, 118, 130, 143, 149, 150, 155, 157, 171, 176, 181, 192, 193, 195, 209, 221, 228, 272, 276, 280, 292, 299, 330, 331, 353, 373, 375, 384, 386, 388, 391, 400, 401, 416, 417, 421, 423, 424, 426, 427, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 467, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 621, 622, 623, 625, 627, 628, 630, 631, 633, 635, 636, 637, 638, 640, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 708, 797, 805, 806, 807, 808, 811, 812, 822, 830, 833, 834, 835, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 897, 903, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 989, 990, 992, 996, 997, 1003, 1010, 1012, 1016, 1029, 1034, 1036, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "duron": 1055, "duti": 401, "dutt": 1057, "dutta": [1058, 1059], "duv2014": 426, "duvenaud": [426, 630, 631], "dwight": 1056, "dx": [51, 53, 707], "dx_c": 1007, "dy": [51, 707], "dye": 1054, "dylan": [1048, 1051], "dynam": [51, 52, 193, 563, 564, 565, 566, 571, 572, 573, 574, 587, 588, 684, 685, 686, 1016, 1024, 1047, 1053, 1058], "dzi": 1059, "dziki": 1044, "d\u00b2": 238, "d\u00f6pfert": 1049, "e": [0, 25, 43, 47, 49, 50, 52, 62, 63, 64, 68, 70, 88, 90, 92, 96, 104, 111, 113, 114, 115, 117, 118, 121, 128, 130, 139, 142, 149, 151, 152, 155, 156, 165, 170, 173, 174, 184, 191, 192, 193, 197, 200, 204, 209, 210, 220, 221, 222, 224, 238, 240, 241, 253, 254, 272, 274, 278, 279, 281, 283, 284, 293, 294, 296, 298, 305, 312, 321, 324, 328, 330, 336, 356, 362, 366, 367, 368, 369, 373, 374, 375, 378, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 398, 399, 400, 404, 407, 410, 412, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 445, 447, 449, 451, 452, 453, 455, 457, 458, 462, 471, 473, 474, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 504, 506, 508, 509, 510, 511, 532, 541, 542, 543, 544, 545, 546, 547, 548, 549, 554, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 585, 589, 590, 596, 597, 598, 599, 601, 602, 605, 611, 612, 613, 614, 615, 616, 617, 618, 619, 625, 630, 631, 638, 641, 642, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 692, 695, 696, 698, 700, 702, 705, 707, 709, 712, 713, 716, 717, 736, 737, 738, 739, 746, 749, 750, 763, 771, 775, 786, 793, 796, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 817, 821, 822, 826, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 862, 863, 864, 868, 869, 870, 872, 875, 877, 878, 879, 880, 882, 883, 884, 885, 886, 887, 888, 890, 891, 892, 893, 895, 897, 898, 899, 900, 901, 902, 903, 907, 908, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 927, 943, 948, 949, 951, 954, 955, 957, 960, 975, 986, 989, 990, 992, 994, 995, 996, 997, 998, 999, 1000, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1014, 1015, 1016, 1020, 1023, 1024, 1032, 1033, 1034, 1041, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "e0129126": 380, "e11": 381, "e2": [906, 996], "e41a1c": [79, 97], "e501": [174, 360], "e_": 421, "each": [2, 27, 43, 46, 47, 49, 50, 51, 52, 54, 55, 58, 62, 63, 64, 68, 70, 72, 76, 78, 79, 82, 84, 88, 90, 93, 95, 96, 104, 105, 107, 108, 109, 117, 118, 120, 121, 122, 123, 125, 126, 130, 132, 133, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 153, 155, 156, 158, 159, 160, 161, 162, 163, 170, 174, 178, 180, 185, 187, 188, 191, 192, 193, 195, 197, 199, 206, 207, 209, 214, 218, 220, 221, 222, 224, 225, 228, 235, 238, 241, 247, 248, 251, 252, 253, 254, 255, 257, 258, 259, 261, 263, 266, 268, 271, 272, 273, 274, 276, 278, 279, 281, 283, 284, 287, 288, 292, 296, 298, 299, 302, 304, 308, 310, 312, 314, 315, 317, 319, 320, 321, 322, 324, 325, 326, 328, 330, 331, 332, 334, 335, 336, 338, 339, 340, 343, 349, 353, 356, 361, 362, 364, 365, 368, 369, 373, 374, 375, 380, 381, 382, 383, 384, 386, 387, 388, 390, 391, 392, 394, 395, 398, 399, 400, 407, 410, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 433, 434, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 467, 468, 469, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512, 513, 516, 517, 518, 519, 520, 521, 522, 523, 527, 530, 531, 534, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 694, 695, 696, 697, 698, 699, 700, 701, 702, 704, 715, 716, 718, 721, 727, 733, 736, 737, 738, 746, 747, 753, 754, 756, 758, 759, 761, 762, 766, 767, 770, 771, 772, 773, 774, 776, 777, 778, 779, 781, 782, 784, 786, 787, 788, 789, 791, 792, 793, 795, 796, 798, 799, 800, 801, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 822, 823, 824, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 897, 898, 899, 901, 902, 903, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 938, 943, 944, 949, 951, 952, 956, 957, 976, 977, 978, 981, 990, 992, 994, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1024, 1025, 1029, 1031, 1032, 1033, 1034, 1041, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "eager": 272, "eargl": 1055, "earl": 1044, "earli": [43, 46, 54, 79, 97, 138, 139, 145, 148, 189, 198, 208, 323, 329, 400, 423, 449, 453, 457, 471, 498, 504, 544, 545, 546, 547, 554, 561, 562, 567, 568, 569, 570, 635, 653, 664, 674, 675, 676, 684, 686, 700, 758, 838, 869, 870, 974, 997, 1003, 1010, 1018, 1020, 1021, 1024, 1041, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1055, 1056, 1058], "earlier": [145, 193, 224, 380, 386, 419, 843, 846, 1010, 1039, 1042, 1054, 1056], "earliest": [380, 997], "early_exager": 1048, "early_exagger": 700, "early_stop": [145, 155, 193, 228, 314, 331, 360, 400, 423, 569, 570, 674, 675, 676, 684, 685, 686, 869, 870, 1014, 1049, 1052, 1055, 1056], "earn": [191, 192, 401], "earth": [242, 361, 772, 1019], "eas": [106, 195, 268, 324, 386, 389, 392, 996, 1014, 1019, 1020, 1024, 1052, 1053, 1055], "easi": [122, 193, 228, 238, 266, 276, 278, 349, 360, 369, 381, 386, 392, 394, 398, 399, 410, 416, 423, 508, 512, 518, 879, 989, 995, 999, 1007, 1010, 1019, 1020, 1024, 1034, 1051, 1056, 1057], "easier": [79, 97, 101, 115, 149, 199, 205, 249, 257, 275, 276, 319, 349, 360, 369, 381, 386, 388, 391, 394, 398, 404, 418, 420, 476, 523, 910, 943, 995, 1000, 1007, 1016, 1020, 1024, 1034, 1050, 1055], "easiest": [388, 394, 417, 997], "easili": [43, 48, 67, 121, 171, 195, 223, 236, 252, 254, 258, 261, 278, 280, 287, 304, 321, 386, 388, 400, 401, 410, 417, 423, 424, 426, 457, 994, 996, 997, 1010, 1014, 1015, 1016, 1023, 1026, 1029, 1034, 1047], "easlii": 248, "ec": [319, 538], "ecat": 381, "echo": [384, 390], "eckert": 1046, "eckhart": 502, "eclf": [161, 162, 423], "eclf1": 577, "eclf2": 577, "eclf3": 577, "ecml": 0, "ecoc": 296, "ecolog": [50, 312, 381, 506], "econom": [191, 192, 278], "econometr": 996, "econometrica": 996, "ecosystem": [386, 394, 990, 1018, 1024], "ecuador": [50, 312, 381, 506], "ed": [143, 154, 416, 423, 528, 567, 568, 1012, 1041, 1048], "eddi": [1044, 1058, 1059], "eden": 1056, "edern": [1056, 1057], "edg": [51, 63, 81, 101, 128, 149, 172, 243, 285, 394, 400, 413, 416, 418, 461, 569, 570, 593, 594, 596, 597, 599, 805, 849, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 877, 925, 1010, 1013, 1024, 1047, 1049, 1052, 1055], "edge_model": 51, "edgecolor": [51, 61, 66, 67, 70, 77, 80, 91, 95, 102, 122, 123, 131, 141, 148, 156, 158, 159, 161, 162, 167, 169, 177, 178, 180, 184, 193, 203, 212, 222, 229, 232, 233, 234, 251, 252, 253, 255, 257, 263, 266, 278, 281, 293, 302, 305, 306, 307, 310, 314, 321, 322, 324, 343, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 358, 365, 366, 367, 639], "edit": [77, 383, 384, 385, 386, 390, 394, 398, 404, 538, 542, 842, 994, 996, 1001, 1007, 1034], "editor": [386, 394, 398], "edm": 996, "edoardo": [1056, 1058, 1059, 1060], "edouard": [0, 406, 1041], "edson": [1000, 1046], "edu": [45, 47, 50, 55, 81, 174, 183, 197, 202, 240, 266, 277, 296, 304, 312, 323, 360, 380, 381, 383, 416, 457, 495, 508, 510, 516, 517, 518, 542, 649, 652, 657, 666, 674, 675, 684, 687, 690, 691, 847, 849, 850, 851, 861, 868, 905, 907, 920, 921, 996, 998, 1030], "eduardo": [1044, 1046, 1054, 1055], "educ": [191, 192, 335, 386, 504, 724, 1001], "edvardlindelof": 1051, "edward": [181, 622, 627, 630, 1044, 1049, 1050, 1051, 1052, 1056, 1059], "edwinensa": 1047, "edwinwenink": 1054, "eec": [457, 649], "ef": 1056, "eff": 1016, "effect": [43, 45, 64, 72, 74, 75, 80, 81, 88, 92, 97, 100, 103, 107, 118, 128, 130, 139, 150, 152, 154, 157, 173, 176, 177, 181, 183, 189, 190, 192, 193, 195, 204, 215, 220, 221, 222, 224, 225, 226, 237, 239, 242, 244, 250, 257, 261, 264, 268, 272, 274, 278, 279, 280, 283, 286, 287, 292, 299, 317, 318, 320, 323, 329, 337, 349, 353, 354, 356, 357, 358, 360, 361, 362, 369, 374, 386, 388, 391, 398, 400, 414, 416, 417, 421, 422, 423, 424, 426, 427, 445, 451, 452, 454, 455, 457, 458, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 498, 504, 508, 522, 532, 533, 541, 542, 549, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 597, 598, 599, 602, 614, 617, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 698, 699, 700, 709, 711, 761, 793, 805, 807, 809, 810, 813, 815, 817, 819, 826, 827, 830, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 858, 859, 862, 863, 869, 870, 872, 875, 876, 877, 878, 879, 881, 882, 884, 888, 889, 890, 891, 892, 893, 897, 898, 899, 900, 901, 902, 903, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 932, 933, 949, 966, 974, 989, 994, 996, 997, 999, 1000, 1001, 1003, 1007, 1008, 1010, 1013, 1015, 1016, 1021, 1030, 1032, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "effective_learning_r": [869, 870], "effective_metric_": [854, 855, 856, 858, 860, 862, 863, 864, 1003], "effective_metric_params_": [854, 855, 856, 858, 860, 862, 863, 864], "effective_rank": [529, 532], "efficaci": 209, "effici": [37, 43, 44, 51, 53, 77, 81, 88, 90, 125, 140, 145, 150, 158, 197, 209, 213, 222, 228, 304, 336, 360, 373, 378, 380, 386, 388, 389, 391, 392, 398, 400, 410, 413, 416, 421, 422, 423, 426, 428, 450, 451, 454, 455, 457, 458, 460, 462, 465, 467, 469, 470, 504, 541, 542, 543, 546, 548, 549, 552, 571, 574, 582, 589, 590, 596, 597, 599, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 640, 641, 642, 646, 648, 663, 666, 667, 672, 674, 675, 676, 681, 683, 684, 685, 686, 687, 693, 694, 696, 734, 764, 771, 787, 788, 805, 806, 808, 822, 841, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 877, 889, 901, 905, 912, 921, 923, 949, 989, 992, 994, 996, 997, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1019, 1024, 1025, 1029, 1032, 1033, 1034, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "efficiencywarn": [2, 867, 1056], "effort": [330, 386, 392, 1019, 1024, 1052, 1054], "efron": [174, 383, 690, 691, 996], "eg": 984, "egashira": 1056, "egehan": 1059, "egg": 1049, "egger": 1059, "egin": 416, "egli": [1048, 1058], "egor": 1053, "ehrenheim": [1048, 1049], "eib": [843, 1001], "eickenberg": [1041, 1043, 1044, 1045, 1046], "eig": 1048, "eig_tol": 1042, "eig_val": 263, "eig_vec": 263, "eigen": [460, 557, 681, 699, 703, 994, 1047, 1050], "eigen_solv": [51, 79, 81, 101, 240, 241, 421, 460, 470, 543, 696, 697, 699, 701, 703, 997, 1042, 1051, 1054, 1055, 1056], "eigen_tol": [81, 460, 470, 699, 703, 1042, 1055, 1056], "eigendecompos": 421, "eigendecomposit": [470, 681, 699, 703, 878, 992], "eigenfac": [42, 54, 189, 253, 256, 381, 421, 502, 549, 705, 721, 822, 838, 892, 917, 1017, 1021, 1028, 1041], "eigenface_titl": [45, 1030], "eigenmap": [240, 697, 699, 701, 703, 1035, 1036, 1042], "eigensolv": [421, 460, 470, 543, 552, 703, 997], "eigenvalu": [121, 268, 335, 413, 416, 418, 460, 470, 477, 478, 479, 480, 481, 482, 483, 484, 543, 549, 557, 681, 696, 697, 699, 701, 703, 878, 992, 997, 1010, 1043, 1047, 1050, 1051, 1052, 1053], "eigenvalues_": [543, 1054], "eigenvector": [2, 42, 81, 118, 121, 189, 263, 416, 460, 470, 542, 543, 549, 558, 696, 697, 699, 703, 997, 1021, 1041, 1045, 1055], "eigenvector_centr": 55, "eigenvectors_": [543, 1054], "eigh": [70, 263, 264, 265, 268, 269, 421, 428, 541, 543, 1056], "eight": 1034, "eighteenth": 416, "eighth": [571, 1006], "eigsh": [421, 543, 1047, 1048], "eiler": 1010, "einsum": 309, "eitan": 1058, "either": [43, 49, 64, 105, 145, 148, 149, 192, 208, 210, 248, 257, 272, 273, 282, 287, 292, 304, 356, 360, 368, 373, 374, 378, 381, 384, 386, 387, 388, 392, 400, 407, 410, 414, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 428, 450, 455, 460, 495, 504, 520, 532, 541, 542, 544, 552, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 576, 590, 591, 592, 596, 597, 598, 599, 601, 602, 605, 610, 615, 616, 618, 619, 630, 635, 638, 640, 641, 658, 662, 664, 672, 684, 686, 690, 691, 698, 705, 706, 710, 714, 715, 720, 728, 732, 734, 735, 736, 737, 738, 743, 746, 747, 748, 750, 760, 764, 777, 782, 786, 790, 791, 792, 793, 795, 796, 797, 802, 808, 811, 812, 814, 822, 831, 832, 833, 834, 835, 836, 837, 839, 842, 872, 902, 903, 909, 912, 913, 920, 921, 922, 923, 927, 957, 961, 989, 996, 1000, 1001, 1002, 1003, 1004, 1005, 1008, 1010, 1014, 1015, 1025, 1033, 1034, 1041, 1044, 1050, 1051, 1052, 1055, 1059], "ekaterina": [1047, 1048, 1049, 1050, 1052, 1057], "ekman": [1043, 1047], "el": [536, 1054, 1056, 1057], "elabonga": [1057, 1058], "elabor": 1001, "elad": [672, 693, 694], "elaps": [50, 82, 102, 145, 146, 147, 373, 472, 475, 577, 578, 871, 872, 873, 874], "elapsed_tim": [46, 74, 102, 146, 147, 160, 237], "elast": [2, 25, 189, 198, 204, 207, 211, 231, 251, 291, 479, 480, 486, 509, 532, 654, 655, 660, 665, 666, 667, 668, 669, 670, 671, 676, 684, 686, 689, 692, 989, 1000, 1014, 1021, 1022, 1036, 1041, 1046, 1050, 1051], "elastic_net": 231, "elastic_net_color": 231, "elastic_net_contour": 231, "elasticnet": [2, 46, 49, 201, 211, 286, 291, 373, 392, 398, 421, 655, 660, 665, 666, 667, 668, 669, 670, 671, 676, 684, 686, 689, 996, 1001, 1014, 1041, 1042, 1045, 1046, 1047, 1049, 1050, 1052, 1053, 1054, 1055, 1059], "elasticnetcv": [2, 204, 400, 407, 654, 660, 668, 669, 670, 671, 689, 996, 1041, 1044, 1052, 1054, 1055, 1058, 1059], "elasticnetifittedelasticnet": 201, "elbo": 421, "eldar": [418, 429, 483], "eleanor": 1056, "elec2": 155, "electr": [51, 155, 383, 416], "electron": [57, 174, 381, 383, 546, 548, 555, 635], "element": [2, 89, 125, 142, 143, 154, 249, 271, 277, 285, 287, 329, 361, 364, 368, 383, 385, 386, 388, 395, 401, 413, 416, 420, 421, 423, 424, 427, 452, 454, 460, 472, 495, 516, 520, 522, 528, 530, 534, 535, 539, 545, 546, 548, 558, 565, 566, 567, 568, 572, 573, 574, 575, 576, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 625, 640, 666, 667, 674, 675, 676, 684, 685, 686, 715, 725, 735, 742, 744, 754, 771, 777, 786, 790, 796, 797, 842, 852, 853, 854, 855, 856, 858, 860, 862, 863, 867, 869, 870, 875, 891, 892, 895, 899, 912, 917, 920, 921, 922, 923, 951, 952, 953, 971, 973, 974, 986, 994, 996, 1000, 1001, 1004, 1007, 1010, 1011, 1012, 1016, 1024, 1025, 1046, 1047, 1049, 1051, 1052, 1053, 1055, 1057], "elementari": [906, 1012], "elementwis": [421, 546, 548, 555], "elena": 1048, "eleni": 1054, "eleph": 590, "elev": [80, 102, 121, 131, 193, 217, 240, 244, 499], "eleven": 1020, "elfner": 1055, "eli5": 1019, "elia": 1047, "eliaschiavon": 1056, "eliasi": [1056, 1057, 1058], "elicit": 1000, "elif": [46, 47, 200, 222, 255, 265, 304, 888], "elimin": [2, 18, 165, 168, 171, 174, 189, 273, 276, 277, 283, 292, 303, 416, 420, 456, 510, 523, 601, 602, 605, 610, 666, 811, 812, 827, 872, 882, 986, 1000, 1021, 1022, 1024, 1036, 1041], "elisabeth": [333, 1058], "elizabeth": [1048, 1050, 1053], "elkan": [64, 272, 329, 414, 445, 451, 455, 467, 684, 1047, 1051, 1052, 1054, 1055], "ell": [70, 263, 264, 265, 269, 413], "ell_": 996, "ell_0": [996, 1000], "ell_1": [421, 996], "ell_2": 996, "ella": 1012, "ellen": 1048, "elli": [1047, 1050], "elliot": [1058, 1059], "elliott": 1048, "ellips": [70, 247, 263, 264, 265, 268, 269, 1006], "ellipsoid": [48, 65, 69, 113, 114, 115, 189, 262, 263, 265, 266, 267, 268, 269, 557, 558, 639, 805, 806, 994, 999, 1021], "ellipt": [92, 996], "ellipticenvelop": [2, 48, 247, 478, 481, 482, 483, 484, 571, 1006, 1041, 1044, 1048, 1049, 1054], "eln": 1052, "elong": 416, "els": [2, 43, 47, 50, 51, 52, 57, 70, 76, 79, 84, 90, 91, 97, 115, 129, 142, 148, 149, 152, 184, 192, 193, 209, 212, 222, 235, 238, 241, 247, 251, 253, 254, 255, 256, 257, 273, 278, 279, 282, 289, 299, 304, 312, 314, 315, 321, 353, 360, 361, 368, 386, 390, 392, 423, 424, 426, 428, 436, 445, 457, 516, 528, 541, 577, 626, 633, 652, 653, 654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 675, 676, 678, 680, 681, 682, 684, 687, 689, 690, 691, 692, 711, 717, 796, 802, 804, 811, 812, 838, 876, 888, 891, 899, 912, 913, 927, 962, 964, 966, 987, 1016], "elsewher": [400, 470, 471, 479, 480, 486], "eltermann": 1044, "elucid": 992, "elvezio": [657, 996], "elvi": [1046, 1047, 1048], "em": [264, 265, 269, 451, 455, 467, 544, 805, 806, 999, 1055], "emad": 1059, "email": [0, 360, 386, 398, 424, 847, 1002, 1024], "emami": 1055, "emanuel": 1042, "emb": [176, 241, 251, 308, 379, 380, 470, 703, 997], "embark": [105, 194, 261, 328, 332, 333], "embed": [2, 26, 37, 71, 74, 79, 81, 90, 97, 120, 144, 176, 189, 239, 242, 244, 246, 299, 308, 338, 339, 392, 400, 416, 449, 460, 470, 497, 510, 552, 557, 574, 590, 647, 696, 697, 698, 699, 700, 701, 702, 703, 704, 861, 873, 882, 904, 905, 906, 992, 1003, 1006, 1012, 1017, 1019, 1021, 1035, 1036, 1041, 1042, 1052, 1053, 1055], "embedding_": [243, 400, 696, 697, 698, 699, 700], "emerg": [416, 1024], "emeritu": 401, "emiko": 1055, "emil": 1055, "emili": [1052, 1053], "emipr": 805, "emir": [1056, 1057], "emit": [1052, 1059], "emlearn": 1019, "emma": 1058, "emmanouil": 1055, "emmanuel": [53, 101, 1041, 1048, 1049, 1050, 1058], "emoji": 1027, "emp_cov": [111, 113, 115, 486, 489], "emp_cov_contour": 113, "emp_mah": 113, "emphas": [192, 358, 392, 421, 1000], "emphasi": [358, 415, 419, 914, 915, 916, 917, 918, 1007, 1019], "empir": [2, 48, 52, 61, 62, 70, 71, 77, 78, 99, 110, 112, 113, 115, 155, 189, 200, 238, 284, 319, 414, 420, 423, 426, 455, 457, 468, 477, 478, 479, 482, 485, 486, 540, 542, 547, 549, 551, 557, 559, 573, 598, 611, 647, 657, 675, 679, 686, 687, 724, 729, 731, 732, 837, 847, 848, 849, 851, 870, 893, 935, 974, 992, 994, 1000, 1002, 1004, 1010, 1012, 1014, 1021, 1035, 1036], "empirical_covari": [2, 111, 418, 486, 487, 489, 1057], "empiricalcovari": [2, 111, 113, 114, 418, 477, 481, 482, 483, 484, 1006], "emploi": [51, 176, 253, 400, 418, 424, 458, 486, 590, 597, 1024, 1033, 1047], "employ": [192, 272], "empti": [96, 104, 134, 232, 341, 373, 381, 388, 390, 416, 428, 491, 541, 569, 570, 639, 819, 877, 917, 919, 927, 932, 933, 939, 959, 960, 990, 1015, 1032, 1043, 1045, 1049, 1050, 1052, 1053, 1055, 1056, 1057], "emptyset": 1000, "emul": [192, 394], "en": [55, 61, 394, 539, 545, 603, 644, 672, 676, 679, 693, 694, 703, 713, 854, 855, 860, 861, 862, 863, 890, 906, 920, 921, 996, 1000, 1015, 1016], "enabl": [2, 16, 52, 66, 85, 106, 155, 193, 228, 242, 254, 321, 329, 331, 332, 334, 335, 336, 357, 384, 386, 391, 394, 398, 400, 404, 407, 412, 416, 417, 421, 423, 424, 457, 472, 476, 542, 543, 549, 567, 568, 569, 570, 571, 587, 588, 598, 599, 610, 618, 805, 806, 808, 811, 833, 834, 835, 836, 872, 873, 885, 886, 909, 910, 912, 913, 914, 915, 916, 917, 918, 927, 960, 967, 990, 992, 997, 999, 1000, 1003, 1010, 1011, 1014, 1015, 1020, 1024, 1041, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "enable_cython_pairwise_dist": [476, 910], "enable_halving_search_cv": [2, 152, 289, 290, 330, 390, 811, 812, 989], "enable_hist_gradient_boost": [390, 1050], "enable_iterative_imput": [2, 187, 188, 390, 635, 990, 1050], "enable_metadata_rout": [254, 272, 335, 407, 445, 451, 452, 455, 457, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 598, 599, 602, 605, 618, 619, 635, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 807, 808, 809, 810, 811, 812, 815, 817, 822, 826, 830, 833, 834, 835, 836, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 871, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 1057], "enable_my_experimental_featur": 390, "enc": [320, 322, 332, 334, 885, 886, 1010], "enc_auto": 893, "enc_high_smooth": 893, "enc_low_smooth": 893, "encapsul": [393, 417, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 603, 604, 605, 606, 607, 608, 611, 618, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923], "enclos": 989, "encod": [2, 43, 47, 50, 83, 90, 105, 125, 144, 155, 160, 189, 192, 193, 194, 219, 220, 257, 272, 287, 292, 318, 320, 321, 322, 330, 332, 333, 349, 360, 362, 378, 380, 382, 388, 391, 398, 400, 417, 420, 421, 423, 424, 426, 472, 495, 504, 511, 534, 539, 545, 547, 548, 550, 552, 553, 554, 556, 559, 569, 570, 574, 575, 577, 589, 596, 597, 599, 638, 656, 666, 667, 677, 680, 688, 743, 810, 815, 817, 835, 838, 872, 873, 875, 877, 879, 880, 883, 885, 886, 893, 896, 910, 989, 990, 996, 997, 1000, 1002, 1003, 1005, 1014, 1019, 1020, 1021, 1036, 1042, 1043, 1049, 1053, 1055, 1056, 1057, 1058, 1059], "encoded_missing_valu": [160, 194, 886, 1010, 1055, 1056], "encodings_": [334, 893, 1010], "encompass": [400, 458, 464, 563, 564, 997], "encount": [374, 384, 404, 410, 416, 423, 424, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 569, 570, 589, 847, 848, 849, 851, 885, 975, 1010, 1014, 1019, 1023, 1024, 1034, 1049, 1052], "encourag": [192, 224, 314, 349, 385, 386, 398, 1015, 1019, 1059], "encrypt": 1019, "encyclopedia": 1000, "end": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 384, 386, 388, 390, 398, 400, 401, 404, 407, 413, 416, 417, 419, 423, 458, 464, 476, 496, 497, 516, 517, 545, 554, 565, 566, 567, 568, 572, 573, 574, 653, 654, 655, 658, 659, 660, 661, 662, 663, 668, 669, 670, 671, 689, 690, 691, 692, 808, 811, 812, 822, 829, 833, 870, 872, 910, 920, 921, 922, 923, 953, 954, 984, 989, 992, 996, 997, 999, 1000, 1010, 1012, 1014, 1019, 1024, 1031, 1034, 1046, 1048, 1051, 1054, 1055], "end_": 47, "end_bodi": 47, "end_d": 47, "end_idx": [51, 243], "end_reut": 47, "end_titl": 47, "end_top": 47, "endian": 1053, "endo": 1054, "endpoint": [53, 320, 352, 643], "enemi": 386, "energi": [51, 155, 394, 868, 1005, 1032], "enet": [204, 291], "enet_path": [2, 205, 400, 654, 655, 660, 668, 669, 670, 1043, 1045, 1054], "enet_tol": [479, 480, 486, 1046], "enforc": [43, 51, 70, 88, 125, 155, 181, 214, 308, 373, 386, 418, 421, 423, 433, 439, 516, 535, 539, 545, 547, 550, 551, 553, 554, 556, 565, 566, 569, 570, 572, 573, 876, 891, 920, 921, 922, 923, 932, 933, 990, 997, 1043, 1049, 1051, 1053, 1057], "enforce_estimator_tags_i": 1051, "eng": 1049, "engag": [392, 401], "engemann": [132, 1043, 1044, 1048], "engin": [42, 75, 144, 149, 155, 181, 189, 192, 193, 221, 373, 380, 383, 416, 422, 424, 472, 504, 570, 647, 681, 709, 829, 835, 870, 871, 873, 876, 877, 882, 885, 887, 891, 990, 992, 1000, 1010, 1021, 1047], "english": [54, 57, 104, 360, 361, 362, 391, 424, 596, 597, 599, 1019, 1020, 1034, 1054], "enh": 390, "enhanc": [125, 224, 385, 386, 390, 398, 400, 416, 1000, 1039, 1040, 1041, 1042, 1043, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "enjoi": [77, 272], "enough": [2, 43, 52, 64, 72, 79, 97, 145, 148, 155, 176, 187, 193, 194, 209, 220, 252, 255, 257, 272, 323, 360, 362, 369, 384, 386, 390, 401, 414, 416, 418, 420, 423, 575, 576, 597, 808, 811, 812, 814, 822, 836, 949, 989, 994, 997, 999, 1006, 1010, 1015, 1019, 1024, 1047, 1057, 1058], "enrich": 353, "ensembl": [2, 43, 46, 49, 52, 63, 64, 67, 91, 139, 140, 141, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 187, 188, 193, 194, 195, 220, 241, 247, 256, 257, 259, 260, 272, 275, 290, 296, 298, 321, 325, 328, 329, 330, 331, 332, 333, 334, 335, 360, 365, 366, 369, 373, 390, 391, 399, 400, 407, 410, 414, 416, 420, 425, 445, 512, 523, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 640, 641, 643, 666, 710, 811, 812, 830, 838, 842, 843, 873, 876, 885, 916, 920, 922, 923, 941, 989, 1000, 1001, 1006, 1007, 1016, 1019, 1020, 1021, 1022, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1060], "ensemble_clf": 143, "ensemble_jaccard_scor": 298, "ensembleregressorsensembl": 1027, "ensta": [54, 55, 72, 83, 96, 241, 279, 281, 360, 361, 362], "ensur": [0, 58, 76, 92, 115, 123, 139, 145, 146, 155, 195, 220, 241, 272, 273, 281, 316, 368, 369, 373, 374, 386, 388, 390, 391, 392, 401, 404, 407, 414, 416, 417, 420, 428, 477, 541, 542, 549, 619, 635, 704, 713, 790, 796, 797, 833, 905, 932, 933, 949, 955, 966, 996, 997, 1000, 1010, 1016, 1029, 1043, 1045, 1046, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "ensure_2d": [932, 933], "ensure_min_featur": [932, 933], "ensure_min_sampl": [932, 933], "entail": [272, 399, 890, 892, 1014], "enter": [387, 390, 416, 450, 1007], "entertain": 996, "entic": 192, "entir": [68, 187, 220, 228, 272, 317, 319, 329, 353, 368, 369, 380, 387, 388, 400, 410, 416, 420, 422, 424, 480, 500, 542, 596, 597, 598, 599, 655, 659, 661, 663, 666, 667, 669, 671, 673, 674, 676, 684, 690, 691, 742, 804, 830, 840, 841, 844, 869, 871, 872, 885, 897, 898, 900, 901, 902, 903, 969, 989, 990, 1000, 1010, 1014, 1016, 1032, 1050, 1051], "entireti": 400, "entiti": [401, 734, 764], "entitl": [292, 302, 415, 455, 619, 854, 992], "entri": [0, 105, 109, 155, 160, 188, 192, 193, 272, 274, 328, 361, 369, 390, 392, 394, 399, 400, 413, 414, 416, 421, 423, 426, 471, 472, 475, 480, 504, 539, 540, 545, 553, 554, 569, 570, 596, 599, 602, 619, 628, 640, 646, 648, 655, 659, 661, 663, 664, 667, 669, 671, 672, 673, 681, 683, 690, 691, 693, 694, 707, 712, 715, 717, 720, 723, 724, 726, 734, 737, 738, 739, 742, 743, 746, 751, 764, 766, 767, 791, 793, 796, 797, 800, 801, 821, 836, 852, 853, 860, 861, 862, 863, 864, 883, 889, 901, 986, 989, 990, 996, 1000, 1003, 1010, 1015, 1020, 1025, 1048, 1051, 1052, 1054, 1058], "entropi": [2, 50, 64, 259, 290, 312, 330, 338, 339, 369, 381, 416, 423, 428, 506, 541, 565, 572, 615, 616, 666, 725, 744, 745, 749, 803, 920, 922, 996, 997, 1000, 1004, 1016, 1043, 1045, 1049, 1050, 1055, 1057, 1058], "entrypoint_to_bug_reproduc": 387, "enumer": [43, 47, 49, 50, 51, 53, 54, 55, 57, 62, 64, 66, 67, 72, 74, 75, 76, 77, 78, 79, 80, 85, 90, 94, 95, 96, 97, 100, 104, 112, 114, 115, 118, 126, 128, 134, 142, 145, 150, 151, 153, 154, 155, 165, 178, 180, 185, 195, 200, 202, 211, 220, 241, 242, 245, 247, 252, 256, 257, 263, 264, 265, 266, 268, 269, 272, 273, 280, 281, 287, 288, 304, 308, 309, 311, 317, 321, 322, 338, 339, 341, 343, 347, 349, 355, 356, 360, 365, 381, 567, 568, 572, 573, 789, 809, 810, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829], "env": [384, 394, 404], "environ": [0, 3, 51, 63, 105, 106, 144, 146, 147, 156, 157, 160, 163, 171, 181, 192, 193, 194, 201, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 333, 335, 340, 368, 373, 381, 383, 384, 386, 388, 392, 394, 398, 404, 412, 417, 507, 1020, 1024, 1036, 1048, 1049, 1058], "environment": [50, 204, 238], "environmenterror": 1057, "eom": 454, "ep": [67, 79, 81, 84, 90, 100, 203, 205, 243, 251, 398, 416, 427, 452, 458, 463, 479, 480, 486, 639, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 689, 690, 691, 692, 698, 702, 722, 749, 864, 904, 905, 906, 1012, 1056, 1057], "epanechnikov": [304, 422, 852, 853, 857], "ephemer": 394, "ephrem": 1056, "epimorph": 1058, "epistem": 52, "epoch": [235, 400, 544, 674, 675, 676, 684, 685, 686, 869, 870, 1014, 1048, 1049, 1054], "epp": [416, 712], "eps_": [668, 670], "eps_rang": 251, "epsilon": [2, 90, 100, 202, 243, 253, 334, 355, 421, 454, 463, 651, 657, 675, 684, 686, 754, 869, 870, 913, 915, 918, 993, 996, 1000, 1004, 1014, 1015, 1032, 1041], "epsilon_": 850, "epsilon_i": 1000, "epsilon_insensit": [675, 684, 686, 913, 996, 1014], "epsilon_valu": 202, "eq": [272, 429, 483, 729, 731, 732], "equal": [43, 50, 51, 63, 70, 72, 74, 88, 95, 113, 118, 139, 152, 179, 192, 221, 222, 231, 237, 258, 265, 268, 271, 276, 278, 287, 309, 321, 325, 349, 351, 357, 361, 381, 382, 386, 388, 400, 413, 414, 416, 420, 421, 423, 424, 429, 445, 448, 449, 450, 451, 453, 455, 457, 462, 467, 468, 471, 477, 482, 487, 488, 511, 520, 523, 527, 540, 541, 542, 547, 549, 551, 552, 557, 558, 559, 563, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 577, 578, 596, 601, 602, 605, 607, 608, 615, 616, 633, 636, 637, 640, 641, 642, 643, 645, 649, 650, 657, 666, 667, 679, 707, 726, 728, 737, 791, 795, 796, 802, 804, 808, 809, 811, 812, 821, 822, 826, 833, 840, 844, 845, 852, 853, 854, 855, 860, 861, 862, 863, 864, 869, 870, 875, 876, 877, 884, 887, 890, 891, 892, 893, 895, 902, 909, 912, 913, 919, 920, 921, 922, 923, 938, 949, 975, 981, 994, 996, 1000, 1001, 1003, 1004, 1006, 1010, 1014, 1015, 1016, 1033, 1034, 1042, 1045, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "equat": [2, 64, 356, 386, 416, 421, 423, 565, 566, 567, 568, 572, 573, 574, 598, 635, 666, 667, 690, 691, 695, 771, 892, 920, 921, 922, 923, 990, 997, 1000, 1005, 1049], "equi": 999, "equiangular": 996, "equidist": [149, 700], "equip": 1024, "equiv": [992, 1015], "equival": [43, 54, 70, 90, 92, 149, 156, 173, 176, 181, 192, 204, 238, 268, 287, 299, 324, 353, 362, 369, 373, 392, 395, 399, 400, 410, 416, 417, 418, 419, 420, 421, 423, 425, 426, 449, 451, 452, 453, 454, 455, 457, 458, 465, 472, 477, 482, 517, 542, 549, 566, 569, 570, 571, 572, 573, 596, 599, 621, 624, 627, 629, 632, 654, 655, 656, 660, 662, 666, 667, 674, 675, 676, 677, 680, 684, 685, 688, 691, 695, 696, 701, 716, 717, 731, 742, 750, 755, 756, 757, 769, 778, 787, 788, 805, 806, 811, 812, 816, 818, 843, 846, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 869, 875, 881, 882, 884, 887, 888, 889, 890, 892, 900, 902, 903, 936, 947, 986, 989, 994, 996, 997, 998, 1000, 1006, 1010, 1014, 1015, 1016, 1049, 1050, 1051, 1052, 1054, 1055, 1058], "er": 578, "era": 1020, "eras": [567, 568, 654, 660, 666, 668, 670, 674, 675, 676, 684, 685, 686, 869, 870], "ereg": [163, 423], "eren": [0, 58, 59, 1043, 1044], "eric": [323, 1044, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1059], "ericchang2017": 323, "ericellwang": [1054, 1055], "erich": [458, 1045, 1046, 1049, 1050, 1052, 1053, 1054, 1055, 1059], "erick": 1046, "erik": [381, 1024, 1044], "eriksson": 1048, "erin": [296, 1053], "erl": 296, "erlbaum": 272, "erling": 1046, "ermolaevpa": [1055, 1056], "ernst": [423, 565, 566, 573, 574, 922, 923], "err": [55, 117, 129, 139], "err_cov_emp_ful": 114, "err_cov_emp_pur": 114, "err_cov_mcd": 114, "err_loc_emp_ful": 114, "err_loc_emp_pur": 114, "err_loc_mcd": 114, "errno": 404, "erron": [113, 114, 421, 996, 1042, 1049, 1053], "error": [2, 15, 25, 30, 43, 44, 46, 52, 53, 55, 64, 89, 109, 111, 112, 114, 129, 134, 138, 142, 145, 146, 149, 151, 153, 155, 174, 176, 187, 189, 192, 204, 209, 216, 219, 220, 222, 226, 227, 234, 238, 250, 253, 254, 260, 269, 270, 272, 274, 278, 279, 283, 287, 288, 293, 296, 305, 306, 332, 335, 348, 356, 360, 361, 374, 383, 384, 386, 388, 389, 390, 391, 395, 398, 400, 407, 410, 414, 416, 417, 418, 420, 421, 423, 424, 425, 445, 451, 452, 455, 457, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 511, 523, 532, 539, 541, 542, 545, 550, 551, 553, 554, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 583, 589, 590, 596, 598, 599, 600, 602, 603, 604, 606, 607, 608, 614, 618, 619, 637, 640, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 693, 696, 697, 698, 700, 701, 704, 706, 709, 710, 717, 719, 720, 728, 729, 731, 735, 748, 751, 752, 753, 754, 755, 756, 758, 759, 761, 772, 786, 790, 796, 797, 798, 799, 807, 808, 809, 810, 811, 812, 814, 815, 817, 822, 826, 830, 831, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 857, 859, 860, 862, 863, 864, 867, 869, 870, 871, 872, 873, 875, 877, 878, 879, 884, 885, 886, 891, 892, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 930, 931, 932, 933, 936, 963, 984, 987, 989, 990, 991, 993, 994, 995, 997, 1001, 1004, 1008, 1010, 1014, 1015, 1016, 1021, 1022, 1032, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "error_": [539, 551], "error_i": [145, 279], "error_norm": [112, 114, 477, 478, 479, 480, 481, 482, 483, 484], "error_on_new": 637, "error_r": 143, "error_scor": [808, 811, 812, 814, 822, 831, 834, 835, 836, 839, 989, 1045, 1049, 1053, 1056], "error_x": [145, 279], "errorbar": [72, 96, 107, 112, 114, 173, 182, 183, 301, 341, 352, 814, 831], "errorbar_": [814, 831], "errorbar_kw": [814, 831], "errorbarcontain": [814, 831], "errors_coef": 224, "errors_lines_": 709, "erwan": 1058, "erwin": 1044, "escal": 401, "escalant": 1000, "escalera": 1000, "escap": [1054, 1056], "eschibli": 1053, "eschlbeck": 1055, "esdi": 57, "esp": [416, 1041], "especi": [43, 47, 52, 90, 91, 149, 152, 155, 192, 220, 254, 325, 333, 361, 369, 374, 380, 386, 394, 398, 400, 414, 416, 424, 451, 457, 509, 546, 565, 566, 567, 568, 572, 573, 574, 654, 655, 656, 658, 660, 661, 662, 666, 667, 668, 669, 670, 671, 677, 688, 703, 713, 754, 847, 848, 849, 850, 851, 920, 921, 922, 923, 996, 1002, 1003, 1010, 1024, 1044, 1049, 1053, 1054, 1055], "espinoza": [1042, 1043], "essenc": [615, 616, 751, 997, 1000], "essenti": [278, 333, 384, 388, 416, 420, 421, 517, 1000, 1003, 1020, 1024, 1049], "est": [80, 160, 192, 212, 235, 254, 256, 272, 292, 321, 330, 369, 410, 423, 570, 743, 877, 989, 1000, 1010, 1014, 1052, 1053], "est1": [400, 640], "est2": [400, 640], "est_freq": 238, "est_idx": 321, "est_sev": 238, "establish": [394, 398, 401, 990], "estefania": 1055, "ester": [416, 427, 452], "estev": [1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058, 1059], "estim": [2, 4, 7, 8, 13, 16, 25, 29, 30, 31, 35, 43, 45, 46, 47, 48, 49, 50, 51, 52, 61, 63, 64, 66, 69, 70, 72, 73, 79, 80, 84, 89, 90, 91, 92, 93, 96, 98, 105, 106, 107, 108, 117, 118, 125, 126, 127, 132, 134, 138, 139, 143, 144, 145, 146, 148, 150, 152, 153, 154, 155, 157, 160, 161, 162, 163, 165, 172, 173, 174, 175, 176, 177, 181, 183, 185, 186, 187, 191, 192, 198, 201, 204, 208, 209, 210, 215, 220, 222, 224, 225, 227, 228, 237, 238, 246, 247, 248, 253, 259, 261, 262, 263, 265, 266, 268, 269, 270, 271, 272, 275, 276, 278, 279, 280, 281, 282, 283, 285, 287, 288, 289, 290, 291, 292, 293, 295, 298, 299, 300, 306, 310, 319, 321, 331, 332, 334, 336, 352, 353, 356, 361, 362, 365, 367, 373, 374, 375, 378, 384, 386, 389, 390, 393, 394, 395, 396, 404, 407, 410, 411, 414, 415, 416, 419, 421, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 466, 469, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 498, 499, 500, 503, 504, 506, 509, 510, 532, 535, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 583, 584, 585, 587, 588, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 615, 616, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 692, 695, 696, 697, 698, 699, 700, 705, 706, 708, 709, 710, 715, 716, 719, 720, 721, 724, 726, 728, 729, 731, 732, 734, 735, 736, 737, 738, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 764, 790, 791, 792, 793, 795, 796, 797, 798, 799, 802, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 819, 820, 822, 824, 826, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 897, 898, 900, 901, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 931, 932, 933, 935, 937, 938, 941, 943, 944, 945, 956, 957, 958, 960, 984, 988, 995, 997, 999, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1016, 1017, 1020, 1021, 1022, 1024, 1025, 1026, 1028, 1030, 1032, 1033, 1034, 1035, 1036, 1038, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "estimate_bandwidth": [2, 79, 98, 416, 456, 469], "estimated_coef": [654, 655, 660, 668, 669, 670, 689, 690, 691], "estimated_param_": 1031, "estimator_": [223, 254, 292, 436, 561, 562, 563, 564, 565, 566, 571, 572, 573, 574, 601, 602, 605, 679, 807, 830, 984, 1056], "estimator__alpha": 152, "estimator__max_depth": [400, 989], "estimator_alpha": 148, "estimator_check": [2, 328, 388, 400, 943, 944, 1048, 1049, 1051, 1052, 1055, 1056, 1057, 1059], "estimator_conf": 49, "estimator_config": 49, "estimator_dict": 228, "estimator_errors_": [139, 561, 562], "estimator_html_repr": [2, 388, 417, 1052, 1053, 1054, 1055, 1058], "estimator_modul": 388, "estimator_nam": [49, 228, 388, 393, 446, 584, 706, 708, 710, 931], "estimator_samples_": 1052, "estimator_weights_": [139, 561, 562], "estimatorcv": [400, 1020], "estimators_": [146, 148, 212, 235, 255, 328, 400, 423, 561, 562, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 575, 576, 577, 578, 840, 841, 842, 843, 844, 845, 846, 1042, 1048, 1055], "estimators_early_stop": 150, "estimators_features_": [563, 564, 571], "estimators_samples_": [563, 564, 565, 566, 571, 572, 573, 574, 1047, 1049, 1052, 1058], "est\u00e8v": [0, 405, 1049, 1052, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "esuli": [1048, 1053], "esvhd": 1050, "et": [0, 2, 50, 111, 112, 139, 154, 208, 312, 381, 383, 413, 416, 418, 421, 423, 424, 425, 459, 506, 527, 528, 536, 543, 549, 552, 571, 690, 691, 727, 728, 847, 849, 869, 870, 905, 948, 949, 996, 997, 1000, 1006, 1010, 1012, 1015, 1016, 1049, 1057], "eta": [421, 544, 684, 685, 686, 1004, 1014, 1046], "eta0": [676, 684, 685, 686, 1014], "eta_0": 1014, "etc": [2, 149, 220, 238, 273, 282, 283, 336, 369, 373, 375, 386, 388, 390, 391, 398, 399, 400, 407, 410, 413, 417, 420, 424, 497, 511, 535, 565, 566, 572, 573, 676, 684, 700, 726, 779, 808, 822, 843, 846, 876, 887, 920, 921, 922, 923, 924, 926, 932, 933, 943, 989, 990, 994, 1000, 1003, 1019, 1020, 1024, 1041, 1048, 1050, 1051], "eth": 1051, "ethan": [1044, 1047], "ethic": 155, "ethz": [341, 343], "etiquett": 386, "etl": [1020, 1024], "euclidean": [2, 37, 75, 92, 93, 206, 251, 257, 299, 302, 307, 328, 333, 353, 361, 413, 416, 421, 422, 423, 424, 426, 448, 449, 452, 453, 454, 458, 460, 465, 468, 471, 539, 545, 553, 554, 597, 623, 627, 630, 631, 684, 686, 698, 700, 703, 704, 707, 770, 771, 777, 778, 779, 780, 786, 787, 788, 789, 800, 801, 852, 853, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 865, 866, 906, 990, 994, 998, 1001, 1003, 1012, 1020, 1045, 1048, 1049, 1050, 1051, 1057, 1058], "euclidean_dist": [2, 243, 251, 388, 458, 462, 465, 696, 702, 770, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 1041, 1046, 1049, 1050, 1058], "euclideandist": 707, "eugen": [383, 1042, 1047], "eunji": 1049, "eunseop": 1051, "euro": 336, "europ": [424, 1010], "european": [734, 764, 1000], "eustach": [46, 47, 49, 1024, 1043, 1044], "eval_and_print_metr": 342, "eval_gradi": [184, 426, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633], "evalml": 1019, "evalu": [2, 27, 29, 43, 44, 45, 49, 50, 55, 61, 68, 71, 73, 77, 78, 84, 90, 99, 105, 106, 128, 139, 145, 146, 147, 149, 150, 152, 155, 169, 170, 179, 189, 195, 197, 200, 209, 222, 227, 238, 246, 270, 271, 275, 276, 277, 278, 281, 283, 284, 285, 287, 289, 290, 292, 293, 298, 306, 308, 312, 319, 324, 326, 330, 334, 335, 342, 349, 353, 360, 369, 379, 381, 388, 392, 400, 403, 417, 424, 425, 426, 455, 457, 472, 474, 496, 499, 500, 501, 504, 517, 528, 544, 559, 569, 570, 571, 575, 576, 599, 602, 610, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 639, 640, 641, 642, 655, 661, 667, 681, 683, 705, 707, 709, 710, 711, 712, 713, 719, 721, 722, 723, 725, 726, 734, 735, 744, 745, 750, 762, 763, 764, 765, 794, 803, 805, 806, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 838, 839, 843, 849, 852, 853, 858, 870, 872, 873, 879, 882, 885, 886, 890, 891, 892, 897, 898, 900, 901, 902, 903, 914, 917, 920, 935, 943, 974, 992, 996, 998, 1002, 1003, 1006, 1007, 1008, 1011, 1014, 1016, 1019, 1021, 1024, 1025, 1026, 1029, 1030, 1032, 1035, 1036, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054], "evaluate_everi": 544, "evaluate_model_and_stor": 325, "evaluation_std": 361, "evaluations_std": 361, "even": [37, 43, 52, 53, 64, 75, 77, 87, 109, 118, 128, 145, 152, 182, 192, 193, 194, 209, 220, 221, 228, 238, 244, 245, 253, 254, 264, 284, 296, 319, 321, 323, 324, 343, 356, 360, 361, 362, 369, 375, 381, 385, 386, 387, 388, 390, 391, 394, 398, 400, 410, 414, 416, 417, 418, 420, 421, 423, 424, 426, 449, 451, 453, 454, 455, 456, 457, 467, 469, 540, 543, 565, 566, 567, 568, 572, 573, 590, 597, 602, 635, 636, 638, 647, 666, 667, 703, 708, 713, 720, 751, 769, 775, 782, 786, 789, 794, 796, 835, 872, 873, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 920, 921, 922, 923, 949, 969, 989, 990, 992, 994, 996, 999, 1000, 1003, 1005, 1006, 1008, 1010, 1012, 1014, 1015, 1016, 1024, 1034, 1048, 1049, 1050, 1053, 1055, 1058], "evenli": [2, 47, 74, 87, 152, 195, 224, 273, 424, 953, 1034], "event": [0, 43, 220, 238, 281, 414, 416, 596, 597, 644, 847, 937, 996, 1001, 1002, 1019, 1024, 1047], "eventu": [7, 266, 416, 425, 601, 1024], "ever": [145, 159, 395, 423, 1024], "everi": [43, 125, 155, 181, 187, 218, 221, 241, 253, 264, 269, 287, 331, 335, 369, 381, 386, 388, 390, 394, 400, 416, 418, 420, 421, 424, 448, 462, 516, 539, 544, 547, 553, 565, 567, 568, 569, 570, 572, 598, 599, 611, 654, 655, 657, 660, 661, 667, 668, 669, 670, 671, 672, 673, 674, 676, 680, 681, 682, 683, 684, 693, 694, 695, 700, 704, 762, 779, 787, 788, 821, 861, 920, 922, 924, 926, 938, 993, 995, 1000, 1001, 1002, 1010, 1016, 1024, 1029, 1041, 1045, 1047, 1050, 1054, 1058], "everingham": 1000, "everingham2010": 1000, "everybodi": [380, 386], "everyon": [386, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "everyth": [338, 369, 390, 392, 398, 410, 472, 955, 1019, 1020, 1041], "everywher": 400, "evgeni": 1052, "evid": [284, 360, 394, 416, 420, 421, 423, 652, 805, 999], "evol": 1000, "evolut": [47, 49, 290, 373, 375], "evolutionari": 1019, "evolv": [395, 1056], "ex": [104, 384, 387, 404, 1045, 1046], "exabyt": 1032, "exact": [44, 46, 115, 130, 145, 181, 224, 252, 272, 299, 335, 369, 373, 374, 380, 386, 388, 395, 398, 399, 400, 416, 423, 425, 441, 490, 491, 492, 496, 504, 542, 543, 549, 569, 570, 646, 650, 654, 700, 808, 822, 833, 834, 835, 914, 917, 989, 992, 996, 997, 1006, 1010, 1014, 1015, 1048, 1049, 1051], "exactli": [105, 139, 191, 199, 204, 213, 220, 224, 269, 272, 286, 320, 356, 360, 386, 388, 413, 416, 420, 421, 424, 429, 454, 461, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 523, 534, 598, 599, 623, 684, 686, 711, 713, 771, 809, 826, 833, 992, 996, 997, 998, 1000, 1001, 1016, 1033, 1034, 1041, 1047, 1048, 1054], "exagger": [74, 192, 700, 997], "examin": [170, 392, 394, 416, 861], "exampl": [2, 30, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 373, 374, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 394, 395, 396, 399, 400, 403, 404, 409, 410, 413, 414, 416, 417, 418, 419, 420, 421, 422, 423, 425, 427, 428, 429, 431, 432, 434, 435, 437, 438, 441, 442, 443, 444, 447, 464, 465, 467, 469, 471, 479, 486, 488, 489, 493, 494, 495, 501, 505, 511, 513, 515, 516, 517, 524, 525, 526, 536, 537, 539, 553, 554, 555, 556, 563, 580, 581, 585, 591, 593, 594, 600, 603, 604, 606, 609, 611, 617, 620, 624, 628, 629, 632, 634, 637, 644, 645, 646, 650, 658, 659, 662, 668, 669, 671, 675, 683, 691, 693, 694, 695, 702, 703, 704, 707, 716, 718, 719, 722, 723, 724, 728, 729, 731, 732, 733, 734, 736, 738, 739, 741, 744, 747, 748, 751, 752, 755, 759, 762, 764, 766, 767, 768, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 788, 789, 791, 799, 802, 804, 815, 816, 817, 818, 819, 820, 821, 832, 844, 846, 848, 852, 853, 862, 863, 864, 866, 867, 874, 875, 878, 880, 883, 894, 895, 897, 899, 900, 902, 903, 904, 907, 911, 913, 914, 922, 923, 924, 925, 928, 929, 930, 931, 932, 933, 934, 936, 937, 938, 939, 940, 941, 942, 943, 945, 947, 948, 949, 950, 951, 952, 954, 955, 962, 963, 964, 965, 969, 971, 972, 973, 975, 976, 977, 978, 979, 980, 981, 982, 983, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1017, 1020, 1021, 1022, 1024, 1026, 1029, 1030, 1032, 1034, 1036, 1038, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1051, 1054, 1056, 1057, 1058], "example_funct": 386, "example_gaussian_process_plot_gp_probabilistic_classification_after_regress": 1041, "example_gaussian_process_plot_gp_regress": 1041, "exampleclassifi": 254, "exampleclassifierexampleclassifi": 254, "exampleestim": 386, "exampleregressor": 254, "examples_pattern": 386, "exampletransform": 254, "exc": [296, 984], "exce": [117, 298, 329, 426, 450, 523, 610, 657, 666, 1050, 1053, 1055], "exceed": [811, 812, 1047], "excel": [158, 380, 386, 423, 698, 702, 996, 1024], "except": [2, 50, 79, 88, 128, 137, 145, 155, 228, 235, 247, 254, 286, 299, 312, 315, 316, 319, 321, 333, 379, 386, 388, 389, 390, 391, 398, 400, 407, 410, 413, 417, 420, 421, 423, 424, 426, 439, 468, 473, 476, 490, 491, 492, 517, 562, 564, 565, 566, 568, 570, 572, 573, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 619, 635, 638, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 695, 719, 786, 815, 845, 846, 852, 853, 855, 858, 863, 869, 870, 876, 890, 892, 910, 913, 915, 918, 921, 923, 931, 953, 984, 986, 996, 1000, 1015, 1025, 1033, 1034, 1042, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1058, 1059, 1060], "exception": 238, "excerpt": [45, 1012, 1030], "excess": [224, 454, 1010, 1048], "exchang": [410, 1023], "excit": 1048, "exclud": [47, 57, 191, 319, 386, 390, 400, 454, 472, 474, 737, 738, 746, 791, 792, 795, 821, 829, 887, 975, 1000, 1003, 1050, 1057], "exclus": [374, 398, 400, 421, 423, 635, 636, 638, 989, 996, 1000, 1001, 1024, 1048, 1052], "exec": 398, "execut": [64, 187, 204, 209, 253, 283, 374, 384, 386, 392, 410, 412, 416, 421, 427, 451, 469, 808, 814, 822, 831, 833, 834, 835, 836, 839, 857, 966, 967, 1010, 1013, 1021, 1026, 1034, 1043, 1046, 1049], "exemplar": [416, 448, 462, 1033], "exemplari": [161, 162], "exemplifi": 400, "exercis": [2, 107, 148, 158, 178, 180, 230, 233, 291, 314, 315, 343, 354, 357, 358, 375, 383, 386, 509, 510, 512, 513, 660, 661, 666, 808, 813, 854, 917, 1021, 1026, 1044], "exercise_01_language_train_model": 1034, "exercise_02_senti": 1034, "exercise_xx_script": 1034, "exhaust": [2, 174, 279, 328, 329, 330, 331, 332, 333, 334, 335, 336, 373, 383, 391, 399, 411, 416, 423, 808, 811, 812, 822, 902, 903, 905, 996, 1034, 1036], "exhibit": [177, 225, 353, 360, 403, 420, 421, 423, 426, 1008], "exist": [47, 48, 52, 55, 57, 88, 238, 278, 316, 319, 353, 380, 385, 388, 389, 392, 398, 400, 401, 404, 410, 416, 420, 421, 423, 424, 431, 441, 445, 451, 452, 455, 457, 459, 461, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 507, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 593, 596, 597, 598, 599, 602, 605, 611, 618, 619, 640, 641, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 706, 708, 710, 770, 773, 777, 807, 809, 810, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 885, 886, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 984, 992, 997, 999, 1000, 1004, 1006, 1007, 1010, 1024, 1033, 1041, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "exist_ok": 47, "existing_credit": 272, "exit": [106, 299, 390, 394, 476], "exp": [2, 81, 89, 101, 134, 142, 152, 177, 204, 230, 304, 309, 312, 329, 330, 334, 353, 414, 416, 417, 422, 428, 460, 473, 529, 541, 544, 623, 624, 630, 649, 767, 774, 784, 869, 870, 888, 994, 996, 998, 1002, 1003, 1004, 1013, 1014, 1015, 1032], "exp10": 192, "exp_dirichlet_component_": 544, "exp_dist_embed": 309, "expand": [43, 84, 100, 249, 325, 329, 369, 378, 423, 452, 458, 507, 565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923, 1000, 1042, 1049, 1050, 1057], "expand_frame_repr": 238, "expans": [43, 187, 330, 458, 887, 1050], "expect": [43, 44, 49, 52, 61, 72, 79, 88, 118, 123, 130, 139, 142, 144, 146, 149, 152, 155, 171, 172, 176, 182, 189, 190, 194, 206, 211, 220, 221, 222, 224, 228, 238, 251, 254, 257, 258, 264, 265, 268, 269, 272, 285, 299, 324, 356, 360, 361, 369, 373, 374, 386, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 403, 407, 412, 414, 416, 417, 418, 420, 423, 424, 425, 439, 472, 473, 475, 476, 477, 490, 491, 492, 504, 531, 540, 544, 546, 549, 560, 562, 563, 564, 565, 566, 568, 570, 571, 572, 573, 574, 575, 576, 578, 580, 596, 597, 599, 603, 605, 614, 619, 635, 640, 641, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 682, 683, 686, 687, 703, 712, 713, 724, 743, 796, 802, 807, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 858, 862, 863, 864, 865, 870, 873, 878, 885, 886, 889, 892, 893, 902, 903, 910, 912, 913, 914, 915, 916, 917, 918, 921, 923, 963, 989, 996, 999, 1000, 1002, 1006, 1010, 1014, 1015, 1016, 1021, 1023, 1030, 1033, 1034, 1036, 1041, 1042, 1043, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "expected_anomaly_fract": 257, "expected_i": 152, "expected_n_anomali": 257, "expected_ri": 713, "expectedli": 360, "expens": [0, 91, 145, 160, 176, 191, 193, 248, 275, 287, 349, 353, 360, 361, 362, 375, 392, 400, 416, 417, 420, 423, 424, 457, 476, 516, 808, 811, 812, 822, 835, 910, 912, 997, 999, 1010, 1015, 1019, 1024, 1034, 1045], "experi": [30, 139, 179, 183, 191, 192, 193, 194, 197, 222, 272, 296, 324, 356, 361, 362, 374, 380, 386, 389, 401, 420, 523, 736, 793, 996, 1001, 1012, 1018, 1019, 1024, 1032, 1034], "experienc": 386, "experiment": [2, 152, 187, 188, 220, 289, 290, 330, 331, 336, 386, 388, 389, 396, 398, 400, 407, 420, 504, 557, 587, 588, 635, 704, 811, 812, 970, 989, 990, 996, 999, 1000, 1019, 1020, 1028, 1036, 1049, 1050, 1053, 1054, 1055, 1056, 1058, 1059, 1060], "expert_r": 417, "expertis": [385, 386, 398], "expit": [151, 210, 423, 569, 996, 1048], "explain": [2, 43, 44, 51, 64, 91, 107, 117, 118, 133, 152, 176, 181, 182, 193, 194, 220, 238, 247, 254, 269, 288, 291, 325, 336, 360, 361, 374, 384, 386, 390, 398, 410, 412, 419, 421, 426, 501, 529, 532, 542, 549, 552, 557, 633, 656, 664, 677, 688, 729, 730, 731, 732, 736, 793, 996, 1003, 1016, 1018, 1019, 1030, 1032, 1033, 1052, 1054, 1055], "explained_vari": [361, 1000], "explained_variance_": [118, 542, 549, 552, 1033, 1048], "explained_variance_ratio": 1047, "explained_variance_ratio_": [107, 133, 336, 361, 421, 542, 549, 552, 557, 1030, 1044, 1047], "explained_variance_scor": [2, 1000, 1044, 1048, 1055], "explan": [64, 118, 254, 373, 385, 386, 414, 424, 989, 999, 1001, 1016, 1024, 1044], "explic": 1012, "explicit": [43, 155, 189, 193, 197, 246, 254, 292, 353, 373, 374, 375, 385, 387, 398, 400, 401, 407, 417, 424, 430, 480, 507, 509, 510, 549, 559, 560, 639, 646, 647, 649, 684, 808, 809, 816, 856, 864, 872, 912, 917, 964, 992, 994, 996, 1000, 1010, 1016, 1019, 1021, 1041, 1045, 1050, 1051, 1054, 1058], "explicitli": [43, 81, 146, 176, 183, 187, 188, 221, 250, 254, 335, 353, 362, 369, 374, 380, 382, 386, 387, 388, 390, 398, 400, 407, 410, 412, 420, 424, 426, 543, 557, 558, 587, 588, 605, 635, 656, 666, 667, 677, 688, 717, 735, 790, 796, 797, 811, 812, 843, 846, 852, 853, 878, 902, 903, 989, 990, 992, 994, 996, 997, 1000, 1002, 1003, 1010, 1024, 1034, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1053, 1054, 1055, 1059], "explod": 325, "exploit": [62, 298, 410, 1001, 1020, 1044], "exploit_incremental_learn": [814, 836], "explor": [52, 72, 142, 143, 155, 195, 244, 245, 257, 272, 279, 280, 286, 287, 296, 326, 330, 349, 361, 369, 380, 383, 385, 392, 416, 423, 480, 808, 811, 819, 893, 989, 996, 997, 999, 1005, 1007, 1010, 1024, 1028, 1034, 1047], "exploratori": [192, 1024], "explos": [808, 822, 833, 834, 835], "expm1": 109, "expon": [426, 624, 684, 685, 686, 820, 869, 870, 887, 989], "exponenti": [2, 81, 109, 176, 181, 304, 309, 422, 423, 426, 457, 544, 562, 567, 622, 627, 630, 647, 651, 766, 767, 852, 853, 857, 869, 870, 887, 992, 996, 1000, 1015, 1032, 1048, 1054], "export": [2, 384, 387, 388, 404, 924, 925, 1016, 1019, 1050], "export_graphviz": [2, 1016, 1046, 1048, 1054, 1056, 1057], "export_text": [2, 1016, 1050, 1057], "expos": [2, 174, 254, 296, 331, 333, 374, 379, 383, 400, 407, 414, 417, 423, 425, 426, 445, 472, 561, 562, 569, 570, 575, 576, 577, 578, 601, 602, 610, 619, 807, 808, 811, 812, 822, 830, 841, 842, 843, 844, 845, 846, 927, 996, 1000, 1002, 1029, 1031, 1033, 1038, 1041, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "exposur": [220, 238, 996], "express": [43, 46, 51, 52, 139, 145, 176, 181, 192, 278, 279, 325, 330, 346, 353, 362, 380, 381, 386, 387, 392, 398, 410, 416, 421, 422, 423, 424, 458, 464, 465, 596, 597, 599, 724, 796, 808, 814, 822, 831, 833, 834, 835, 836, 839, 859, 992, 996, 1000, 1004, 1010, 1011, 1016, 1049], "expsinesquar": [2, 176, 181, 185, 426], "exstrac": 1000, "ext": 654, "extend": [31, 52, 90, 91, 102, 137, 221, 267, 272, 285, 349, 383, 384, 398, 400, 414, 416, 421, 423, 639, 728, 829, 841, 844, 845, 877, 879, 896, 912, 913, 927, 992, 1000, 1001, 1015, 1020, 1022, 1036, 1046, 1047, 1048, 1049, 1051, 1056], "extens": [285, 287, 304, 373, 374, 380, 381, 384, 387, 389, 390, 394, 395, 398, 410, 416, 421, 504, 511, 542, 749, 943, 951, 997, 999, 1000, 1018, 1019, 1024, 1041, 1047, 1054, 1055, 1057, 1058], "extent": [2, 48, 93, 178, 179, 180, 251, 357, 448, 543, 704, 805, 1000], "extercond": 149, "extern": [165, 176, 272, 375, 379, 383, 386, 388, 391, 398, 400, 413, 416, 424, 425, 426, 601, 618, 619, 725, 745, 803, 996, 999, 1000, 1003, 1016, 1020, 1026, 1032, 1036, 1049, 1053], "exterqu": [149, 160], "extmath": [2, 266, 360, 395, 461, 946, 947, 948, 949, 950, 951, 1041, 1042, 1047, 1048, 1051, 1055, 1056, 1058], "extr": 47, "extra": [2, 81, 148, 155, 256, 299, 335, 362, 384, 385, 387, 390, 400, 410, 423, 424, 446, 451, 455, 467, 472, 540, 565, 566, 574, 598, 599, 708, 709, 710, 833, 856, 922, 923, 939, 999, 1000, 1003, 1041, 1044, 1046, 1047, 1049, 1054, 1056], "extra_cflag": 392, "extra_tre": [922, 923], "extract": [2, 17, 42, 43, 45, 47, 50, 51, 55, 85, 90, 103, 104, 105, 106, 117, 125, 145, 170, 174, 189, 235, 270, 277, 278, 283, 286, 317, 342, 352, 360, 362, 369, 378, 381, 383, 388, 392, 395, 398, 416, 417, 420, 421, 458, 460, 463, 464, 470, 472, 496, 497, 501, 502, 511, 512, 539, 542, 543, 544, 545, 546, 547, 548, 549, 551, 553, 554, 555, 591, 592, 596, 597, 599, 601, 602, 605, 607, 639, 726, 796, 808, 822, 849, 871, 872, 917, 949, 957, 964, 989, 997, 1001, 1005, 1010, 1014, 1019, 1021, 1024, 1026, 1030, 1031, 1036, 1041, 1042, 1050, 1053], "extract_dbscan": 416, "extract_patches_2d": [2, 85, 128, 424, 595, 1049], "extract_scor": 281, "extractal": 47, "extractor": [220, 317, 375, 381, 400, 424, 511, 589, 590, 596, 597, 599, 989, 1041], "extran": 386, "extrapol": [43, 176, 199, 221, 250, 281, 891, 1000, 1010, 1016, 1054, 1056], "extratre": [148, 158, 373, 1044], "extratreeclassifi": [2, 565, 574, 923, 1001, 1045, 1050, 1051, 1052, 1054, 1055, 1056, 1058], "extratreeregressor": [2, 566, 571, 574, 922, 1001, 1006, 1050, 1051, 1052, 1054, 1055, 1056, 1058], "extratreesclassifi": [2, 148, 158, 423, 425, 566, 572, 574, 922, 923, 1001, 1044, 1045, 1049, 1050, 1051, 1054, 1055, 1056, 1057, 1058], "extratreesregressor": [2, 256, 423, 565, 573, 574, 922, 923, 1001, 1044, 1047, 1049, 1050, 1051, 1054, 1055, 1056, 1057, 1058], "extrem": [2, 152, 220, 222, 256, 257, 319, 326, 341, 361, 386, 389, 415, 416, 421, 565, 566, 572, 573, 574, 640, 641, 687, 732, 760, 922, 923, 924, 926, 1000, 1002], "extrema": 994, "exxon": 51, "ey": [113, 114, 265, 269, 349, 381, 542, 549, 558], "eyast": 1055, "ezebunandu": 1053, "ezeiza": 772, "ezri": 1054, "f": [0, 2, 43, 44, 46, 50, 51, 52, 54, 55, 58, 63, 66, 68, 72, 78, 82, 83, 84, 87, 88, 90, 93, 99, 102, 105, 109, 118, 128, 139, 142, 145, 146, 147, 149, 150, 152, 155, 160, 161, 166, 168, 170, 173, 174, 176, 182, 183, 185, 189, 191, 192, 193, 194, 195, 197, 204, 206, 209, 211, 220, 221, 222, 224, 230, 234, 238, 241, 251, 253, 254, 257, 261, 268, 272, 276, 278, 279, 280, 281, 284, 285, 287, 288, 290, 292, 299, 302, 314, 315, 316, 321, 324, 325, 328, 330, 332, 334, 335, 336, 338, 339, 348, 353, 356, 360, 361, 362, 369, 381, 386, 387, 388, 390, 392, 398, 410, 414, 417, 421, 423, 424, 425, 426, 495, 516, 517, 539, 540, 545, 546, 574, 589, 590, 591, 595, 600, 603, 604, 606, 607, 608, 612, 613, 614, 615, 616, 617, 625, 635, 640, 643, 666, 704, 721, 731, 734, 737, 738, 764, 791, 792, 795, 796, 809, 810, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829, 830, 836, 837, 839, 869, 870, 874, 883, 886, 887, 891, 892, 893, 919, 927, 932, 933, 984, 992, 995, 1004, 1007, 1008, 1010, 1014, 1021, 1043, 1049, 1050, 1051, 1053, 1055], "f0_c0": 893, "f0_c1": 893, "f0_c2": 893, "f0e442": 263, "f1": [2, 45, 62, 68, 104, 171, 276, 317, 338, 339, 342, 420, 721, 737, 738, 746, 791, 830, 1000, 1001, 1030, 1034, 1045, 1057], "f1_c0": 893, "f1_c1": 893, "f1_c2": 893, "f1_macro": [420, 1000, 1045], "f1_micro": [1000, 1045], "f1_sampl": 1000, "f1_score": [2, 62, 285, 342, 381, 415, 746, 1000, 1041, 1043, 1044, 1045, 1046, 1050, 1051, 1057, 1058], "f1_weight": [1000, 1045], "f2": [390, 1001], "f2001": 1000, "f2006": 1000, "f3": 1001, "f4": 506, "f401": [80, 102, 121, 131, 193, 217, 240, 242], "f781bf": [75, 79, 97, 98], "f7bd01": 75, "f_": [423, 643, 738, 1000], "f_0": 157, "f_1": [157, 285, 1000], "f_beta": 1000, "f_classif": [2, 170, 171, 352, 425, 600, 603, 604, 606, 607, 608, 612, 614, 617], "f_i": 414, "f_idx": 157, "f_j": [414, 1008], "f_m": 423, "f_n": 285, "f_p": 285, "f_regress": [2, 89, 169, 425, 600, 603, 604, 606, 607, 608, 612, 613, 617, 1044, 1048, 1055, 1058], "f_score": 285, "f_statist": [613, 614], "f_test": 169, "fa": [2, 124, 134, 135, 189, 392, 421, 481, 484, 540, 549, 808, 834, 1021], "fa_estim": 125, "fa_scor": 132, "fab": [1024, 1051, 1052], "fabia": [413, 727], "fabian": [0, 207, 225, 241, 311, 406, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1050, 1058], "fabiana": 1052, "fabio": 1047, "fabisch": [0, 406, 1043, 1044, 1045, 1047], "fabrizio": 1056, "face": [2, 42, 44, 54, 71, 86, 88, 124, 128, 130, 132, 134, 147, 189, 197, 246, 253, 379, 386, 390, 416, 421, 423, 425, 457, 480, 501, 502, 503, 529, 540, 541, 545, 547, 548, 549, 551, 566, 592, 665, 681, 705, 721, 822, 838, 855, 892, 917, 935, 1003, 1016, 1017, 1021, 1028, 1033, 1036, 1041, 1049], "face_compress": 1033, "face_id": 256, "facecolor": [51, 63, 70, 80, 95, 125, 131, 141, 167, 184, 240, 255, 278, 306, 321, 347, 350, 353, 354, 355], "faces_cent": 125, "facial": 381, "facil": 999, "facilit": [373, 400, 410, 1019, 1020, 1047, 1050], "fact": [43, 50, 57, 62, 114, 118, 139, 150, 152, 194, 251, 261, 296, 298, 360, 380, 393, 398, 400, 419, 421, 422, 423, 424, 657, 676, 678, 712, 994, 996, 1003, 1010, 1014, 1015, 1020, 1024, 1055], "facto": 1051, "factor": [2, 11, 42, 45, 48, 63, 67, 79, 81, 88, 90, 97, 124, 130, 134, 158, 189, 192, 234, 245, 247, 257, 272, 289, 290, 299, 300, 314, 315, 319, 321, 330, 332, 348, 373, 374, 386, 392, 395, 400, 413, 416, 423, 424, 426, 448, 450, 462, 477, 479, 480, 481, 482, 484, 486, 496, 512, 522, 523, 535, 540, 543, 544, 546, 548, 549, 552, 553, 554, 555, 557, 558, 569, 570, 571, 596, 599, 605, 621, 657, 658, 659, 662, 663, 664, 690, 691, 700, 727, 791, 808, 811, 812, 834, 858, 892, 906, 908, 916, 948, 949, 989, 996, 997, 1003, 1010, 1013, 1017, 1019, 1021, 1035, 1036, 1041, 1042, 1044, 1045, 1047, 1055, 1057], "factoranalysi": [2, 125, 132, 135, 421, 552, 1042, 1044, 1053, 1055], "factori": [2, 96, 272, 278, 424, 970, 1000], "facundo": [1052, 1055], "fagan": 1050, "fail": [43, 89, 101, 126, 132, 184, 185, 199, 204, 224, 254, 278, 328, 374, 384, 386, 388, 389, 394, 401, 404, 419, 420, 448, 480, 482, 684, 685, 686, 719, 869, 870, 931, 943, 989, 997, 1041, 1042, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1058, 1060], "failur": [189, 190, 192, 215, 386, 394, 404, 665, 793, 838, 932, 933, 1021, 1023, 1024, 1054, 1055, 1059], "fair": [51, 64, 423, 698, 702, 841, 1001, 1024], "fairer": 369, "fairli": [115, 151, 242, 294, 315, 394, 416, 567, 568, 707, 1001, 1032], "faith": [57, 182, 354], "fake": 424, "falak": 1050, "fall": [25, 30, 43, 52, 152, 155, 183, 277, 278, 386, 388, 416, 424, 441, 454, 455, 516, 517, 735, 736, 802, 889, 901, 999, 1000, 1010, 1025, 1033, 1050], "fallback": [401, 404, 840, 841, 1000], "fals": [2, 43, 44, 46, 47, 49, 50, 53, 54, 58, 59, 61, 63, 64, 68, 69, 70, 74, 77, 79, 81, 82, 89, 90, 99, 102, 104, 105, 106, 112, 114, 123, 129, 133, 134, 139, 145, 146, 149, 152, 153, 155, 163, 165, 176, 181, 182, 183, 184, 192, 193, 194, 195, 199, 200, 204, 206, 220, 221, 225, 226, 228, 236, 238, 240, 243, 254, 255, 257, 261, 263, 272, 275, 276, 278, 281, 282, 285, 286, 287, 288, 289, 290, 291, 293, 299, 303, 309, 312, 315, 316, 319, 320, 325, 326, 328, 330, 331, 332, 333, 335, 336, 340, 349, 351, 353, 356, 357, 360, 361, 380, 386, 387, 388, 391, 400, 407, 414, 415, 416, 417, 418, 420, 421, 423, 424, 425, 426, 428, 429, 441, 442, 443, 444, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 459, 460, 461, 462, 467, 469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 516, 517, 518, 520, 521, 523, 531, 532, 535, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 640, 643, 644, 645, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 698, 702, 703, 705, 706, 707, 708, 709, 710, 711, 716, 717, 719, 720, 721, 722, 723, 726, 727, 734, 735, 736, 737, 738, 739, 746, 750, 751, 758, 759, 762, 764, 769, 771, 775, 777, 782, 786, 790, 791, 792, 793, 795, 797, 802, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 819, 822, 826, 827, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 881, 882, 883, 884, 885, 887, 888, 889, 890, 891, 892, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 930, 931, 932, 933, 943, 950, 961, 962, 965, 966, 970, 971, 972, 974, 981, 986, 987, 989, 990, 996, 1000, 1003, 1010, 1014, 1015, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058, 1059], "false_discovery_r": 603, "famili": [2, 45, 272, 373, 375, 400, 416, 419, 421, 424, 425, 600, 603, 604, 606, 607, 608, 614, 869, 870, 888, 900, 996, 1010, 1014, 1030, 1032, 1045, 1055], "familiar": [386, 422, 1049], "famou": [381, 383, 423, 1015], "famous": 1002, "fan": [0, 374, 401, 405, 1015, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "fanci": 424, "fancybox": 355, "fanelli": [1056, 1057], "fang": [666, 1048, 1049], "fanni": 1051, "fantasi": 1005, "fantast": 1024, "faouzi": [1051, 1052], "faq": [0, 394, 420, 700, 997, 1010], "far": [62, 95, 115, 149, 177, 183, 192, 220, 238, 272, 349, 353, 360, 362, 386, 395, 426, 728, 892, 975, 1005, 1006, 1015, 1024, 1032], "farach": 992, "farahsae": 1049, "farawai": 1003, "fare": [105, 194, 261, 332, 333, 1045, 1046], "fargo": 51, "farhan": 1057, "farlei": [0, 406, 1041], "farouk": [1049, 1050], "farther": 733, "farthest": 416, "fashion": [2, 46, 144, 150, 228, 287, 374, 400, 413, 414, 416, 421, 423, 561, 565, 566, 567, 568, 572, 573, 574, 610, 635, 838, 861, 876, 879, 885, 896, 920, 921, 922, 923, 971, 990, 996, 1000, 1010, 1050], "fast": [2, 52, 64, 97, 197, 204, 209, 235, 236, 252, 253, 320, 362, 373, 381, 386, 395, 416, 418, 420, 421, 423, 424, 428, 454, 455, 477, 482, 516, 540, 541, 543, 546, 548, 552, 555, 572, 573, 574, 596, 597, 599, 640, 641, 648, 666, 667, 680, 682, 695, 707, 808, 822, 833, 834, 844, 845, 852, 853, 857, 868, 949, 969, 992, 996, 999, 1002, 1003, 1005, 1006, 1016, 1019, 1024, 1034, 1041, 1042, 1047, 1048, 1051, 1052], "fast_dict": 1051, "fast_dot": 1048, "fast_logdet": [2, 395], "fast_svd": 1041, "faster": [37, 46, 57, 74, 99, 107, 125, 144, 145, 149, 150, 152, 155, 174, 193, 197, 206, 220, 222, 235, 236, 238, 253, 257, 272, 299, 301, 316, 329, 331, 332, 336, 360, 361, 362, 373, 380, 386, 394, 395, 400, 410, 416, 421, 425, 426, 428, 451, 455, 457, 459, 460, 461, 470, 516, 539, 540, 541, 544, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 561, 567, 568, 569, 570, 651, 654, 655, 660, 661, 666, 667, 668, 669, 670, 671, 680, 682, 692, 695, 699, 703, 734, 764, 786, 787, 788, 852, 853, 857, 869, 870, 887, 889, 891, 901, 905, 949, 969, 989, 993, 996, 1001, 1003, 1004, 1007, 1012, 1014, 1015, 1016, 1019, 1030, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "fastest": [92, 276, 362, 455, 678, 680, 682, 695, 948, 949, 999], "fastest_top_recall_high_precision_index": 276, "fastfm": 1019, "fastica": [2, 124, 189, 219, 421, 540, 543, 549, 1021, 1033, 1041, 1043, 1049, 1055, 1056], "fastkmean": 457, "fastmcd": [418, 477, 482], "fastnc": 868, "fat": [529, 532], "fatima": [1055, 1058], "fato": 1054, "fauchereau": 1054, "fault": [394, 1049, 1051, 1053], "faulti": [223, 1041], "faust": 1059, "favor": [44, 115, 145, 263, 269, 398, 418, 423, 681, 683, 738, 816, 818, 871, 989, 1008, 1043, 1045, 1047, 1048, 1050, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "favorit": [386, 398, 1024], "favour": [800, 997, 999, 1050], "fawcett": [796, 797, 1000], "fazlul": 1043, "fbeta_scor": [2, 737, 750, 791, 1000, 1043, 1044, 1045, 1046, 1051, 1057], "fc": [48, 304, 381], "fc2009": 1000, "fcd116": 123, "fcharra": 1056, "fcluster": 195, "fcostin": 1041, "fd": 47, "fdr": 600, "fear": 1034, "feasibl": [386, 881, 882, 892], "feast": 417, "feat": [47, 49, 390, 424], "feat0": [249, 329], "feat1": [249, 329, 424], "feat2": [249, 329, 424], "feat3": [249, 329, 424], "feat_idx": 635, "featur": [2, 8, 16, 17, 18, 23, 25, 32, 42, 44, 45, 46, 47, 49, 50, 54, 57, 58, 62, 63, 64, 66, 67, 68, 69, 71, 77, 80, 82, 85, 93, 95, 98, 103, 104, 105, 106, 107, 113, 114, 117, 118, 120, 121, 122, 123, 125, 127, 129, 131, 132, 133, 135, 138, 140, 143, 145, 148, 152, 154, 159, 160, 161, 163, 165, 169, 171, 176, 177, 178, 181, 182, 184, 187, 188, 190, 191, 192, 193, 198, 200, 202, 203, 204, 206, 207, 209, 210, 216, 219, 220, 221, 222, 224, 225, 228, 229, 235, 236, 237, 241, 246, 249, 251, 255, 256, 257, 260, 261, 270, 272, 273, 275, 276, 277, 278, 281, 283, 284, 285, 286, 287, 288, 291, 292, 293, 298, 302, 303, 304, 307, 308, 310, 313, 314, 316, 318, 319, 322, 326, 327, 329, 332, 333, 334, 335, 336, 341, 342, 344, 345, 346, 349, 353, 356, 359, 362, 365, 367, 368, 369, 378, 379, 380, 381, 382, 383, 384, 388, 389, 391, 393, 394, 395, 398, 399, 400, 401, 403, 404, 410, 414, 416, 418, 419, 420, 421, 422, 426, 427, 428, 429, 430, 432, 437, 439, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 516, 517, 518, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 581, 587, 588, 589, 590, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 621, 622, 623, 626, 627, 628, 630, 631, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 693, 694, 695, 696, 697, 698, 699, 700, 705, 709, 710, 711, 721, 729, 730, 731, 732, 749, 750, 753, 754, 756, 766, 767, 771, 772, 774, 775, 776, 777, 778, 779, 781, 782, 783, 784, 785, 786, 789, 793, 796, 798, 800, 801, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 897, 898, 899, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 932, 933, 946, 965, 975, 976, 977, 981, 989, 992, 994, 995, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1011, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1030, 1031, 1032, 1036, 1038, 1039, 1040, 1041, 1042, 1043, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "feature_0": 925, "feature_1": [639, 925], "feature_2": 639, "feature_all_": 849, "feature_count_": [847, 849, 851], "feature_extract": [2, 47, 54, 57, 81, 82, 85, 86, 89, 101, 104, 128, 189, 279, 342, 359, 360, 361, 362, 375, 381, 416, 417, 424, 472, 552, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 885, 998, 1033, 1034, 1041, 1042, 1043, 1044, 1047, 1048], "feature_import": 153, "feature_importances_": [146, 147, 153, 174, 194, 195, 400, 423, 425, 561, 562, 565, 566, 567, 568, 572, 573, 574, 601, 602, 605, 920, 921, 922, 923, 1043, 1046, 1050], "feature_index": 424, "feature_indices_": 1049, "feature_log_prob_": [847, 848, 849, 851], "feature_map": [252, 319], "feature_map__n_compon": 252, "feature_map_fouri": 252, "feature_map_nystroem": [252, 647], "feature_nam": [54, 57, 121, 135, 146, 153, 157, 174, 192, 194, 229, 258, 292, 302, 319, 328, 329, 330, 335, 346, 360, 365, 379, 381, 391, 417, 498, 499, 500, 504, 508, 509, 510, 512, 513, 518, 590, 639, 640, 641, 893, 924, 925, 926, 1008, 1016, 1057], "feature_name_combin": [885, 1057], "feature_names_": 589, "feature_names_in": 1055, "feature_names_in_": [261, 326, 331, 400, 437, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 635, 636, 637, 638, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 1054, 1055, 1056, 1057, 1059], "feature_names_out": [432, 437, 450, 451, 453, 455, 457, 472, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 574, 575, 576, 577, 578, 589, 596, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 696, 697, 700, 856, 861, 864, 868, 871, 872, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 1055, 1058], "feature_rang": [317, 882, 898, 1010, 1043, 1053], "feature_select": [2, 89, 105, 106, 108, 168, 169, 170, 171, 172, 173, 174, 189, 261, 330, 332, 352, 369, 400, 407, 417, 425, 589, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 989, 1021, 1041, 1042, 1044, 1045, 1046, 1047, 1048], "feature_selector": 174, "feature_to_plot": 214, "feature_union": 1057, "featureagglomer": [2, 86, 89, 448, 449, 1017, 1033, 1044, 1050, 1051, 1054, 1055, 1057, 1058, 1059], "featureforg": 1024, "featurehash": [2, 57, 104, 189, 359, 360, 361, 375, 381, 424, 496, 589, 596, 597, 598, 599, 885, 1021, 1042, 1047, 1048, 1049, 1055, 1056], "featureheash": 362, "features_": [637, 990], "features__pca__n_compon": 108, "features__univ_select__k": 108, "features_idx": 319, "features_info": 193, "features_nam": [191, 1048], "features_samples_ratio": 69, "featureselector": 609, "featuresshould": 1027, "featuretool": 1019, "featureunion": [2, 7, 43, 108, 378, 400, 407, 472, 637, 874, 990, 1020, 1024, 1036, 1042, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1059], "featurewis": [2, 888], "feb": [73, 448, 462], "februari": [0, 418, 481, 1000, 1042, 1046, 1058], "fed": [47, 160, 369, 381, 424, 989, 1005, 1010, 1052], "feda": [1049, 1050], "feder": 1019, "federico": [1043, 1044, 1049, 1050, 1055], "federicopisanu": 1051, "federicov": 47, "feed": [47, 118, 221, 254, 362, 381, 384, 391, 398, 416, 424, 750, 885, 1001], "feedback": [275, 385, 386, 387, 401, 1019, 1023, 1049], "feedforward": [869, 870], "feedstock": 390, "feel": [64, 188, 319, 385, 386, 394, 416, 454, 1016], "feel_temp": [43, 193], "feghali": 1058, "fei": [571, 1006], "feld": [1045, 1057], "feldbauer": [1049, 1050, 1051, 1052, 1055], "feldman": [1043, 1048, 1049, 1050, 1051], "felip": [1054, 1055, 1056, 1057], "felix": [1043, 1048, 1049, 1051, 1053, 1054, 1055], "femal": [105, 192, 333, 391, 885, 886, 1010], "fenc": 391, "feng": [1051, 1053, 1054, 1055], "fenil": 1054, "fenx": 1049, "ferdman": 1058, "ferenc": 1024, "fernand": [1049, 1055, 1056], "fernandez": 1050, "fernando": [1046, 1053], "fern\u00e1ndez": 1055, "ferrando": 1051, "ferrari": 1049, "ferreira": [1049, 1054, 1055], "ferri": [425, 1000], "ferria": 1048, "ferrin": 1055, "ferriss": 1048, "ferr\u00e9": 1055, "ferr\u00edn": 1052, "fetal": 257, "fetch": [2, 51, 55, 160, 192, 238, 272, 292, 379, 380, 381, 386, 390, 391, 394, 421, 504, 563, 564, 565, 566, 571, 572, 573, 574, 596, 597, 599, 1049, 1057], "fetch_": 1048, "fetch_20newsgroup": [2, 54, 57, 104, 279, 342, 360, 361, 362, 381, 497, 1034, 1046, 1051, 1059], "fetch_20newsgroups_vector": [2, 46, 235, 251, 381, 1041, 1051, 1053, 1058, 1059], "fetch_california_h": [2, 145, 150, 187, 188, 319, 330, 381, 399, 417, 1050, 1052, 1059], "fetch_covtyp": [2, 197, 257, 330, 381, 1050, 1053, 1055, 1059], "fetch_data": 1034, "fetch_kddcup99": [2, 257, 381, 1048, 1049, 1050, 1053, 1054, 1059], "fetch_lfw_pair": [2, 381, 1046, 1056, 1059], "fetch_lfw_peopl": [2, 45, 381, 1030, 1056, 1059], "fetch_mldata": 1049, "fetch_olivetti_fac": [2, 85, 125, 147, 256, 381, 1049, 1050, 1051, 1059], "fetch_openml": [2, 43, 44, 52, 105, 109, 149, 155, 160, 181, 192, 193, 194, 220, 228, 236, 238, 248, 257, 261, 272, 292, 296, 298, 299, 316, 325, 328, 332, 335, 380, 390, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "fetch_rcv1": [2, 381, 1046, 1050, 1059], "fetch_species_distribut": [2, 50, 312, 1050, 1059], "fetcher": [379, 1046, 1048, 1057], "feth": 1041, "feurer": [1044, 1049], "fevott": [421, 546, 548, 555], "few": [0, 46, 54, 57, 74, 81, 87, 129, 149, 155, 179, 182, 183, 209, 218, 220, 222, 238, 253, 254, 263, 280, 281, 285, 316, 319, 323, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 356, 362, 373, 381, 382, 383, 386, 388, 399, 401, 407, 410, 413, 414, 416, 420, 421, 423, 425, 426, 445, 457, 569, 570, 663, 700, 703, 905, 949, 996, 997, 999, 1000, 1003, 1004, 1013, 1015, 1016, 1024, 1025, 1032, 1033, 1034, 1047, 1057], "fewer": [43, 53, 63, 90, 139, 148, 150, 220, 373, 387, 416, 425, 426, 456, 469, 549, 561, 602, 704, 842, 953, 996, 1001, 1003, 1046, 1047, 1048], "fewest": [277, 635], "ff": 394, "ff0000": [67, 307, 314], "ff3333": 123, "ff7216": 123, "ff7f00": [79, 97, 247], "ff9c34": [94, 99], "ffaaaa": 307, "ffc107": 323, "fft": 648, "fhaselbeck": 1053, "fhoang7": 1050, "fhr": 257, "fi": 883, "fibins": [1049, 1050], "fidel": 53, "fidor": 1057, "fiedler": 1047, "fiegel": [1053, 1054, 1056], "field": [174, 238, 383, 413, 416, 417, 424, 506, 509, 625, 996, 998, 1007, 1015, 1019, 1023, 1034, 1042], "fifth": [253, 993, 1025], "fig": [43, 44, 46, 47, 48, 49, 52, 54, 62, 64, 66, 70, 77, 78, 80, 88, 90, 92, 95, 99, 101, 107, 111, 113, 118, 121, 125, 130, 131, 135, 139, 145, 146, 149, 150, 152, 153, 155, 157, 158, 160, 162, 179, 185, 187, 193, 195, 197, 200, 208, 211, 214, 215, 217, 218, 220, 221, 224, 228, 233, 235, 238, 240, 241, 242, 243, 244, 245, 248, 250, 257, 258, 268, 272, 273, 274, 275, 278, 279, 280, 281, 284, 287, 288, 289, 292, 298, 299, 301, 303, 304, 312, 315, 316, 319, 320, 321, 323, 324, 325, 328, 332, 333, 346, 353, 355, 356, 357, 358, 360, 361, 362, 364, 393, 1030, 1033], "fig1": 102, "fig2": 102, "fig_num": 217, "figaspect": 323, "fight": [74, 224, 1024], "fighter": 104, "fignum": 354, "figsiz": [43, 44, 45, 49, 51, 52, 53, 54, 62, 63, 64, 66, 67, 68, 70, 74, 75, 77, 78, 79, 80, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 97, 99, 100, 101, 107, 109, 113, 115, 117, 118, 120, 121, 122, 123, 125, 128, 129, 130, 131, 134, 135, 139, 141, 142, 149, 150, 151, 152, 153, 155, 158, 160, 161, 169, 178, 180, 184, 185, 187, 188, 192, 193, 195, 197, 199, 200, 203, 204, 210, 214, 217, 218, 219, 220, 221, 222, 224, 226, 228, 231, 234, 236, 238, 240, 241, 242, 244, 245, 247, 248, 250, 252, 255, 256, 257, 258, 263, 265, 266, 269, 272, 273, 274, 275, 280, 281, 282, 285, 287, 288, 292, 293, 298, 299, 301, 302, 314, 315, 317, 319, 320, 321, 322, 323, 324, 325, 332, 333, 338, 340, 347, 349, 353, 354, 355, 356, 357, 358, 360, 361, 362, 926, 1030], "figur": [45, 46, 47, 49, 51, 53, 61, 62, 63, 64, 67, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 85, 86, 87, 89, 91, 93, 94, 96, 97, 98, 99, 100, 102, 111, 115, 117, 120, 121, 122, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 139, 140, 141, 142, 151, 152, 153, 154, 155, 158, 159, 163, 165, 167, 169, 170, 173, 177, 178, 179, 180, 183, 184, 188, 192, 193, 194, 195, 199, 204, 205, 210, 213, 214, 217, 219, 221, 222, 226, 231, 235, 236, 237, 242, 243, 244, 247, 251, 252, 253, 255, 256, 258, 263, 265, 266, 269, 271, 277, 282, 283, 293, 304, 308, 309, 312, 314, 317, 319, 321, 322, 326, 328, 330, 338, 339, 340, 347, 349, 354, 365, 366, 367, 386, 416, 422, 423, 424, 426, 446, 639, 640, 705, 706, 708, 709, 710, 814, 831, 926, 989, 993, 996, 999, 1000, 1003, 1004, 1007, 1008, 1014, 1015, 1016, 1029, 1030, 1032, 1033, 1054], "figure_": [68, 193, 258, 328, 330, 393, 446, 639, 640, 705, 706, 708, 709, 710, 814, 831], "figure_titl": 149, "filali": 1049, "file": [2, 47, 51, 68, 83, 360, 361, 373, 374, 375, 380, 381, 383, 384, 386, 390, 391, 392, 394, 398, 410, 417, 421, 495, 501, 502, 504, 511, 516, 517, 542, 587, 588, 596, 597, 599, 924, 1003, 1016, 1021, 1023, 1026, 1041, 1042, 1044, 1047, 1048, 1049, 1050, 1053, 1054, 1055, 1056, 1057], "file_1": 511, "file_2": 511, "file_42": 511, "file_43": 511, "file_44": 511, "file_id": 380, "filenam": [2, 47, 55, 342, 381, 392, 410, 496, 508, 511, 512, 515, 596, 597, 599, 1034, 1041, 1046, 1049, 1050], "filesystem": [394, 404, 1054], "filho": 414, "filip": [1058, 1059], "filipj8": [1048, 1049], "fill": [70, 148, 165, 194, 273, 304, 365, 400, 417, 421, 523, 535, 546, 548, 555, 595, 638, 924, 926, 990, 1003, 1016], "fill_between": [52, 152, 155, 165, 176, 181, 183, 185, 199, 200, 238, 278, 280, 281, 282, 288, 814, 831], "fill_between_": [814, 831], "fill_between_kw": [814, 831], "fill_betweenx": 95, "fill_diagon": [195, 243], "fill_legend": 238, "fill_valu": [188, 249, 259, 329, 430, 433, 439, 440, 635, 638, 1010, 1049, 1057, 1058], "fillna": [238, 257], "filo": [1041, 1044], "filter": [2, 18, 47, 54, 81, 82, 107, 226, 238, 276, 278, 301, 360, 374, 381, 392, 395, 416, 424, 456, 496, 497, 511, 596, 599, 603, 604, 605, 606, 607, 608, 782, 847, 941, 965, 1002, 1003, 1031, 1034, 1051], "filter_param": 782, "filtered_cv_result": 276, "filterwarn": [79, 97, 235, 315, 316, 386, 1010], "final": [2, 43, 52, 63, 64, 70, 75, 77, 90, 104, 105, 113, 115, 118, 122, 130, 139, 140, 142, 144, 149, 150, 153, 160, 163, 171, 181, 188, 191, 193, 195, 197, 199, 204, 208, 209, 217, 220, 222, 237, 238, 241, 247, 261, 267, 272, 276, 284, 296, 299, 325, 326, 328, 329, 349, 353, 373, 375, 381, 384, 386, 387, 388, 390, 399, 400, 413, 414, 416, 417, 420, 423, 424, 425, 445, 450, 455, 456, 460, 467, 470, 472, 544, 563, 564, 575, 576, 578, 602, 635, 655, 661, 667, 687, 698, 702, 727, 808, 840, 841, 872, 873, 909, 912, 989, 990, 992, 996, 997, 1000, 1003, 1006, 1007, 1010, 1013, 1024, 1032, 1046, 1049, 1050, 1051, 1052, 1054], "final_estim": [160, 328, 423, 575, 576], "final_estimator_": [575, 576], "final_lay": 423, "final_layer_gbr": 423, "final_layer_rfr": 423, "final_step": 77, "financ": [272, 1001], "financi": [0, 51, 416, 423, 996], "find": [2, 43, 44, 45, 51, 55, 64, 75, 81, 82, 83, 84, 87, 88, 90, 92, 100, 107, 113, 114, 125, 127, 129, 130, 135, 150, 160, 176, 180, 182, 184, 193, 204, 208, 209, 222, 228, 240, 242, 244, 245, 250, 257, 268, 272, 277, 278, 279, 289, 302, 307, 308, 309, 324, 328, 334, 336, 351, 352, 353, 356, 360, 361, 364, 374, 383, 384, 386, 387, 388, 391, 392, 395, 398, 399, 400, 401, 413, 415, 416, 418, 419, 421, 423, 424, 425, 427, 449, 452, 453, 454, 458, 459, 460, 461, 470, 539, 543, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 566, 573, 590, 597, 618, 619, 655, 658, 661, 662, 663, 664, 666, 667, 679, 696, 715, 737, 738, 746, 790, 791, 792, 795, 796, 802, 807, 808, 822, 830, 854, 855, 856, 858, 860, 862, 863, 864, 885, 886, 891, 904, 905, 906, 920, 921, 923, 929, 948, 949, 951, 989, 990, 992, 995, 996, 997, 999, 1000, 1001, 1004, 1006, 1010, 1014, 1015, 1016, 1018, 1020, 1023, 1024, 1025, 1027, 1029, 1030, 1032, 1033, 1034, 1041, 1048, 1049, 1050, 1051, 1053, 1055, 1056, 1059], "findal": 362, "fine": [43, 72, 148, 174, 224, 236, 269, 276, 353, 366, 367, 383, 390, 400, 424, 454, 949, 1003, 1006, 1015, 1020, 1051], "finer": [43, 52, 72, 301, 349, 374, 416, 420, 989, 1003, 1051], "finfo": [243, 479, 480, 486, 614, 658, 659, 662, 663, 664, 690, 691, 1056], "finish": [174, 266, 997], "finit": [64, 263, 269, 373, 381, 400, 476, 546, 559, 590, 614, 617, 618, 619, 666, 736, 786, 793, 805, 833, 910, 930, 931, 932, 933, 996, 999, 1000, 1024, 1025, 1032, 1048, 1049, 1053, 1055, 1056], "finn": [1049, 1050], "fire": 1034, "firefox": 1010, "fireplac": 149, "fireplacequ": 149, "firm": [51, 416], "first": [0, 2, 43, 44, 46, 47, 50, 52, 55, 58, 62, 63, 66, 67, 68, 70, 74, 90, 91, 93, 96, 99, 100, 101, 102, 104, 105, 106, 109, 113, 117, 118, 120, 121, 122, 130, 133, 139, 140, 144, 146, 147, 148, 149, 150, 151, 153, 155, 157, 160, 161, 162, 163, 170, 171, 174, 176, 177, 178, 181, 182, 183, 184, 188, 191, 192, 193, 195, 197, 199, 201, 203, 209, 216, 217, 218, 221, 222, 228, 229, 234, 241, 244, 251, 252, 254, 255, 256, 258, 260, 261, 265, 269, 272, 273, 278, 280, 281, 285, 287, 289, 290, 296, 298, 299, 301, 304, 308, 309, 310, 314, 316, 319, 321, 324, 325, 326, 329, 330, 339, 342, 345, 346, 349, 351, 360, 361, 362, 364, 365, 368, 369, 374, 375, 380, 381, 383, 384, 385, 386, 388, 390, 391, 392, 394, 398, 400, 410, 413, 414, 415, 416, 419, 420, 421, 423, 424, 425, 426, 428, 451, 454, 455, 458, 467, 468, 472, 480, 491, 495, 496, 498, 499, 500, 502, 505, 508, 510, 512, 516, 517, 518, 536, 541, 542, 546, 549, 561, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 590, 592, 596, 597, 598, 599, 601, 602, 609, 618, 619, 625, 629, 632, 639, 640, 641, 642, 654, 660, 667, 674, 676, 682, 684, 696, 703, 706, 707, 708, 710, 720, 724, 744, 750, 771, 772, 790, 802, 805, 806, 811, 812, 813, 814, 815, 820, 822, 829, 831, 840, 841, 843, 844, 846, 847, 848, 849, 850, 851, 852, 853, 857, 860, 861, 862, 863, 864, 865, 866, 869, 870, 871, 872, 877, 885, 889, 890, 891, 893, 894, 901, 902, 914, 917, 920, 921, 922, 923, 925, 927, 928, 932, 933, 934, 951, 953, 967, 971, 974, 986, 989, 990, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1007, 1010, 1011, 1014, 1015, 1016, 1024, 1025, 1031, 1032, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058], "first_img_data": 515, "first_pca_compon": 324, "first_quart": 134, "first_week": 155, "firstli": [128, 373, 398, 665, 1034], "fisach": 1047, "fiscal": 0, "fischer": [1046, 1047], "fischler": 996, "fischoff": 1053, "fish": 331, "fisher": [383, 423, 512, 644, 1019], "fisher1958": 423, "fisher_transform": 644, "fit": [2, 22, 25, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 59, 61, 62, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 93, 96, 97, 98, 99, 100, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 125, 127, 128, 129, 130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 182, 183, 184, 185, 189, 191, 192, 193, 194, 195, 197, 198, 202, 203, 204, 206, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 227, 228, 229, 232, 233, 234, 235, 236, 237, 238, 243, 247, 248, 250, 252, 253, 254, 255, 256, 257, 258, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 286, 287, 288, 289, 290, 291, 292, 293, 296, 299, 301, 302, 303, 304, 305, 307, 308, 309, 310, 312, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 353, 354, 356, 357, 358, 360, 361, 364, 365, 366, 367, 368, 373, 375, 378, 381, 383, 386, 389, 391, 392, 395, 398, 400, 410, 413, 414, 415, 416, 417, 418, 420, 421, 422, 424, 425, 426, 427, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 509, 517, 518, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 583, 585, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 695, 696, 697, 698, 699, 700, 702, 705, 706, 708, 709, 710, 718, 719, 731, 740, 743, 758, 796, 805, 806, 807, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 896, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 941, 957, 960, 984, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1003, 1004, 1005, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1021, 1022, 1024, 1029, 1030, 1031, 1032, 1033, 1034, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "fit_": 1054, "fit_algorithm": [125, 539, 545, 1056, 1057], "fit_and_evalu": 361, "fit_and_plot_model": 324, "fit_and_scor": 228, "fit_data": 59, "fit_dur": 299, "fit_ecoc": 1045, "fit_grid_point": 1052, "fit_intercept": [46, 199, 200, 206, 225, 234, 247, 286, 326, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 912, 913, 919, 996, 1014, 1045, 1049, 1050, 1051, 1053, 1054, 1055], "fit_inverse_transform": [44, 130, 543, 1050], "fit_ovo": 1045, "fit_ovr": 1045, "fit_param": [254, 400, 440, 445, 450, 453, 473, 540, 542, 544, 545, 547, 550, 551, 557, 563, 564, 575, 576, 577, 578, 590, 591, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 638, 643, 646, 647, 648, 649, 650, 673, 679, 814, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 856, 861, 864, 868, 871, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 889, 890, 891, 892, 904, 905, 960, 1048, 1051, 1052, 1053, 1055, 1057, 1058, 1059, 1060], "fit_path": [658, 662, 663, 664, 690, 691], "fit_predict": [57, 91, 92, 95, 247, 257, 306, 388, 400, 416, 434, 438, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 460, 477, 571, 685, 800, 801, 805, 806, 858, 864, 872, 916, 1006, 1046, 1049, 1050, 1054, 1056, 1058], "fit_prior": [381, 847, 848, 849, 851], "fit_status_": [914, 915, 916, 917, 918], "fit_tim": [52, 93, 149, 209, 228, 280, 420, 835, 836], "fit_timemapermsemaepinball_loss_05pinball_loss_50pinball_loss_95strstrstrstrstrstrstr": 52, "fit_times_nb": 280, "fit_times_svm": 280, "fit_transform": [43, 44, 45, 49, 51, 54, 57, 79, 84, 87, 88, 93, 97, 121, 126, 129, 135, 158, 197, 211, 236, 238, 240, 241, 242, 243, 244, 245, 250, 251, 254, 255, 261, 299, 303, 315, 319, 320, 324, 325, 326, 328, 331, 333, 334, 335, 336, 349, 360, 361, 362, 369, 378, 381, 388, 391, 392, 400, 412, 417, 421, 424, 425, 432, 440, 450, 451, 453, 455, 457, 472, 474, 476, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 696, 697, 698, 699, 700, 704, 856, 861, 864, 868, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 910, 990, 992, 996, 1001, 1003, 1010, 1011, 1012, 1025, 1030, 1033, 1034, 1045, 1046, 1047, 1049, 1050, 1051, 1053, 1055, 1057, 1058, 1059], "fitfailedwarn": [2, 808, 811, 812, 814, 822, 831, 834, 835, 836, 839], "fitted_transform": [388, 472], "fittedcolumntransform": [160, 193], "fittedgridsearchcv": 259, "fittedpipelin": [160, 249, 259, 279, 292, 325, 329], "fittedrandomforestclassifi": 335, "fittedrandomizedsearchcv": 105, "fittedstackingregressor": 160, "fitter": 1016, "fitting_weight": 407, "fitzgerald": 1049, "fitzk": 1024, "five": [147, 155, 264, 272, 339, 342, 381, 539, 547, 553, 997, 1003, 1015, 1024, 1041], "five_imag": 424, "fix": [2, 43, 47, 58, 62, 70, 81, 105, 134, 144, 145, 148, 155, 176, 177, 181, 184, 192, 204, 222, 238, 257, 269, 281, 314, 328, 329, 330, 331, 332, 333, 334, 335, 336, 361, 373, 374, 380, 382, 384, 385, 386, 388, 389, 394, 398, 400, 401, 407, 416, 417, 420, 421, 423, 424, 426, 460, 470, 480, 512, 520, 539, 545, 548, 550, 556, 557, 567, 568, 572, 573, 596, 599, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 638, 661, 671, 676, 678, 692, 695, 699, 703, 715, 793, 805, 822, 829, 854, 855, 857, 860, 862, 863, 879, 882, 896, 920, 921, 949, 967, 989, 996, 999, 1000, 1003, 1010, 1020, 1034, 1039, 1040, 1042, 1043, 1049, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1058, 1059, 1060], "fixed_classes_uniform_labelings_scor": 72, "fixed_vocabulary_": [596, 599], "fixedthresholdclassifi": [2, 272, 415, 830, 1059, 1060], "fixm": [390, 400], "fixtur": [374, 386], "fkaren27": 1055, "flach": [414, 1000], "flach2008": 1000, "flach2015": 1000, "flag": [181, 254, 257, 335, 384, 386, 387, 389, 407, 412, 472, 618, 619, 635, 681, 683, 736, 793, 1015, 1047, 1051, 1052, 1054, 1055, 1056, 1057], "flair": 1002, "flak": 1056, "flake8": 587, "flanagan": [1050, 1051], "flat": [2, 78, 125, 193, 240, 241, 242, 276, 416, 423, 424, 448, 454, 456, 469, 517, 1007, 1033, 1041, 1042, 1057], "flat_grid": 252, "flatnonzero": [134, 208, 277, 286, 287, 789], "flatten": [54, 68, 243, 252, 276, 323, 346, 357, 392, 510, 577, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 861], "flatten_transform": [577, 1048], "flatter": [43, 62], "flavanoid": [48, 383], "flaviomorelli": 1051, "flavor": [386, 1003], "flavour": 423, "flaw": [400, 423], "flaxman": [1043, 1045], "fledg": [375, 424], "fleet": 43, "fleme": 1056, "flennerhag": 1049, "fletcher": [996, 1041, 1045], "flexibl": [43, 62, 149, 187, 220, 320, 346, 362, 388, 393, 398, 410, 420, 426, 682, 912, 913, 989, 994, 996, 1000, 1004, 1010, 1019, 1020, 1024, 1050, 1054], "flier": 49, "flink": 104, "flip": [129, 590, 750, 949, 1002, 1045, 1054], "flip_i": 523, "flip_sign": 949, "float": [2, 46, 49, 51, 57, 76, 80, 81, 82, 83, 88, 95, 96, 100, 101, 102, 105, 128, 131, 167, 184, 192, 206, 210, 243, 272, 277, 278, 282, 286, 356, 362, 373, 380, 381, 386, 395, 400, 412, 415, 416, 417, 424, 425, 427, 428, 429, 433, 435, 439, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 460, 462, 463, 464, 465, 466, 467, 469, 470, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 532, 533, 535, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 591, 592, 596, 599, 600, 601, 602, 603, 604, 605, 606, 610, 611, 618, 619, 621, 622, 623, 624, 625, 627, 628, 630, 631, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 720, 721, 722, 724, 725, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 742, 743, 744, 745, 746, 747, 748, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765, 767, 774, 777, 783, 784, 785, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 801, 802, 803, 804, 805, 806, 807, 808, 810, 811, 812, 814, 822, 825, 828, 830, 833, 834, 835, 836, 837, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 872, 875, 878, 879, 885, 886, 888, 890, 892, 893, 894, 895, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 926, 929, 930, 932, 933, 936, 946, 947, 963, 975, 981, 986, 990, 1000, 1001, 1003, 1004, 1010, 1015, 1016, 1041, 1042, 1043, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "float16": 1050, "float32": [55, 151, 243, 317, 333, 374, 381, 386, 387, 388, 400, 410, 412, 565, 566, 567, 568, 571, 572, 573, 574, 601, 602, 648, 649, 666, 707, 771, 877, 920, 921, 922, 923, 930, 976, 977, 978, 1016, 1025, 1034, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "float64": [50, 52, 53, 83, 88, 105, 151, 153, 154, 192, 193, 272, 289, 332, 333, 374, 380, 386, 387, 388, 400, 424, 479, 480, 486, 504, 505, 516, 517, 550, 556, 589, 590, 597, 599, 649, 666, 681, 683, 707, 746, 877, 885, 886, 914, 915, 917, 918, 921, 923, 930, 932, 971, 974, 976, 977, 978, 1015, 1025, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058, 1059], "float_info": 57, "floch": 1058, "floor": 53, "floor_x": 53, "flore": 1054, "florian": [237, 1024, 1041, 1045, 1047, 1051, 1058], "florin": 1059, "flow": 388, "flowchart": [420, 1027], "flower": [121, 133, 287, 514, 515, 1000, 1019], "floyd": [381, 696, 997], "floydsoft": 1045, "fluctuat": [51, 95, 155, 220, 285, 1049], "flush": 228, "fly": [151, 391, 394, 516, 517, 590, 1041, 1043, 1050], "flyingdutchman23": 1054, "flyingimmidev": 1041, "flynn": [1054, 1056], "fmax": 238, "fmi": [416, 739], "fmin_l_bfgs_b": [618, 619], "fmt": [96, 231], "fn": [336, 416, 720, 726, 737, 738, 739, 790, 791, 792, 795, 1000, 1001], "fn_c": 287, "fna": [174, 383], "fnlwgt": [335, 504], "fnr": [275, 706, 735], "fo": 424, "focu": [43, 48, 125, 139, 176, 269, 309, 373, 391, 414, 423, 561, 562, 567, 569, 570, 686, 997, 1003, 1010, 1019, 1020, 1023], "focus": [62, 111, 209, 296, 381, 398, 997, 1010, 1019], "fokow": 1058, "fold": [2, 43, 102, 108, 111, 145, 148, 151, 165, 173, 192, 209, 265, 272, 273, 274, 276, 278, 279, 281, 288, 292, 326, 341, 356, 369, 381, 386, 389, 390, 399, 400, 407, 415, 416, 425, 445, 480, 501, 544, 575, 576, 602, 610, 655, 659, 661, 663, 667, 669, 671, 673, 681, 683, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 839, 843, 846, 893, 914, 917, 989, 996, 1000, 1010, 1015, 1029, 1041, 1043, 1045, 1046, 1047, 1049, 1050, 1052, 1053, 1058], "folder": [106, 381, 384, 386, 390, 394, 404, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 511, 1003, 1034], "folkman": 1048, "folloni": 1052, "follow": [0, 25, 43, 46, 57, 63, 64, 68, 72, 80, 89, 90, 92, 98, 102, 105, 106, 123, 125, 134, 139, 142, 152, 157, 169, 181, 187, 191, 192, 193, 194, 195, 199, 201, 204, 208, 209, 218, 220, 221, 235, 238, 248, 254, 255, 257, 269, 272, 278, 285, 287, 288, 292, 296, 319, 325, 326, 328, 329, 331, 332, 333, 336, 346, 356, 360, 361, 362, 364, 368, 369, 373, 374, 380, 381, 383, 384, 385, 386, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 431, 433, 435, 436, 437, 438, 439, 440, 449, 451, 453, 454, 455, 456, 457, 461, 469, 471, 472, 473, 476, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 523, 542, 546, 548, 549, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 578, 589, 596, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 639, 641, 642, 654, 660, 666, 667, 678, 679, 688, 700, 702, 707, 713, 717, 721, 726, 796, 827, 849, 854, 855, 856, 858, 860, 862, 863, 864, 871, 875, 876, 877, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 901, 910, 912, 913, 917, 920, 921, 922, 923, 927, 928, 948, 989, 990, 991, 992, 993, 994, 995, 996, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1023, 1025, 1027, 1034, 1038, 1041, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "folwarczn\u00fd": 1058, "fonari": [1053, 1054], "fond": [0, 1024], "fondat": 1024, "font": [152, 209, 234, 252, 924, 926], "font_manag": [114, 305, 348], "font_prop": 114, "font_siz": 323, "fontdict": [54, 74], "fontnam": [924, 1054], "fontproperti": [114, 305, 348], "fontsiz": [44, 47, 49, 54, 70, 85, 95, 122, 128, 148, 169, 179, 180, 182, 185, 193, 200, 210, 219, 231, 241, 242, 266, 273, 282, 283, 284, 289, 290, 317, 323, 355, 926], "fontweight": [95, 215], "foo": [388, 589, 1004], "food": 383, "foot": 1018, "footer": [54, 104, 279, 360, 361, 381, 496, 497], "footnot": [1007, 1019], "footprint": [330, 333, 373, 375, 416, 421, 549, 563, 564, 565, 566, 571, 572, 573, 574, 1043, 1046, 1047, 1052, 1053, 1056], "fopenmp": [384, 387], "foral": [416, 426, 621], "forbid": [416, 423], "forbidden": [193, 423], "forc": [139, 176, 205, 224, 299, 323, 360, 380, 384, 390, 411, 420, 423, 458, 465, 472, 475, 504, 614, 617, 654, 655, 660, 661, 665, 668, 669, 670, 671, 680, 681, 682, 689, 692, 695, 762, 786, 789, 830, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 914, 915, 916, 917, 918, 930, 932, 933, 1010, 1036, 1046, 1049, 1050, 1051, 1053, 1054, 1055, 1057], "force_all_finit": [786, 930, 932, 933, 1052, 1055], "force_alpha": [847, 848, 849, 851, 1056], "force_finit": [614, 617, 736, 793, 1000, 1055], "force_int_remainder_col": [472, 475], "ford": 51, "forecast": [42, 43, 152, 155, 175, 183, 189, 222, 238, 278, 414, 415, 426, 504, 570, 619, 623, 630, 631, 633, 709, 750, 753, 754, 756, 798, 829, 834, 835, 838, 1000, 1019, 1021], "foreground": [75, 101], "foreign_work": 272, "foreman": 1048, "forese": 398, "forest": [2, 14, 50, 64, 67, 138, 144, 148, 150, 151, 153, 154, 155, 156, 158, 160, 163, 187, 189, 190, 197, 247, 275, 277, 279, 312, 330, 360, 367, 369, 379, 399, 400, 414, 425, 471, 472, 498, 499, 503, 504, 506, 523, 563, 564, 565, 566, 568, 569, 570, 571, 572, 573, 574, 638, 642, 808, 813, 838, 845, 872, 886, 916, 920, 921, 922, 989, 990, 1001, 1008, 1020, 1021, 1022, 1036, 1038, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1050, 1058], "forest_import": 146, "forestclassifi": 1046, "forestcov": 257, "forg": [328, 329, 330, 331, 332, 333, 334, 335, 336, 374, 387, 389, 390, 394, 404], "forget": [193, 369, 374, 380, 390, 398, 421, 997], "forget_factor": [421, 546], "forgiv": 742, "forina": 383, "fork": [384, 386, 390, 394, 398], "forkserv": 398, "form": [2, 43, 48, 57, 68, 77, 95, 102, 125, 163, 183, 184, 189, 192, 253, 254, 269, 278, 338, 369, 380, 383, 386, 388, 390, 400, 401, 413, 416, 419, 420, 421, 422, 423, 424, 426, 428, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 464, 467, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 693, 695, 696, 697, 698, 699, 700, 701, 707, 805, 806, 807, 808, 811, 812, 813, 816, 818, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 938, 957, 960, 989, 991, 993, 994, 996, 997, 1000, 1001, 1004, 1005, 1006, 1010, 1015, 1019, 1025, 1032, 1047, 1051, 1053], "formal": [400, 401, 416, 423, 852, 853, 997, 1000, 1001, 1004], "format": [2, 47, 50, 51, 52, 57, 59, 83, 89, 93, 96, 104, 113, 125, 134, 142, 148, 151, 153, 165, 169, 170, 197, 200, 206, 220, 238, 273, 283, 285, 286, 289, 293, 303, 304, 307, 308, 323, 328, 336, 355, 364, 368, 373, 379, 385, 386, 388, 389, 394, 395, 399, 400, 410, 417, 420, 423, 424, 440, 450, 451, 453, 455, 457, 458, 460, 467, 472, 476, 490, 491, 492, 493, 495, 497, 504, 505, 506, 516, 517, 518, 531, 535, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 559, 565, 566, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 595, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 654, 660, 666, 667, 668, 670, 674, 675, 676, 684, 685, 686, 696, 697, 700, 705, 719, 721, 728, 747, 748, 759, 776, 799, 800, 841, 854, 855, 856, 858, 860, 861, 862, 863, 864, 865, 866, 867, 868, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 899, 904, 905, 910, 912, 924, 932, 933, 954, 962, 966, 971, 974, 976, 977, 978, 979, 980, 981, 986, 990, 1000, 1003, 1008, 1010, 1011, 1014, 1016, 1019, 1025, 1026, 1036, 1041, 1042, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1052, 1054, 1056, 1058, 1059], "format_func": 304, "formatter_result": 93, "former": [51, 362, 415, 423, 424, 573, 810, 817, 826, 1002, 1041, 1047, 1050], "formerli": [224, 1042, 1045, 1047, 1048], "formul": [139, 176, 185, 224, 287, 386, 416, 418, 421, 424, 426, 429, 483, 557, 558, 565, 572, 658, 659, 662, 663, 664, 666, 667, 673, 678, 771, 777, 806, 914, 917, 920, 922, 996, 1000, 1001, 1004, 1010, 1022, 1036, 1058], "formula": [111, 112, 285, 413, 416, 418, 429, 481, 483, 524, 525, 526, 598, 651, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 672, 684, 686, 712, 737, 738, 763, 772, 989, 994, 996, 1000, 1005, 1006, 1010, 1014, 1046, 1048, 1050], "forrest": [1052, 1053], "forsal": [57, 362, 381], "forsyth": 1049, "forth": 394, "fortin": [1041, 1043, 1044, 1045], "fortran": [428, 549, 654, 655, 660, 661, 668, 669, 670, 671, 673, 689, 692, 693, 694, 932, 933, 1041, 1044, 1045, 1049], "fortun": [392, 423, 1034, 1054, 1055], "forward": [46, 139, 174, 254, 330, 373, 386, 407, 410, 425, 516, 517, 547, 551, 561, 567, 568, 610, 676, 693, 694, 872, 876, 996, 1020, 1053], "foster": [0, 1049], "fouchet": 1047, "found": [0, 45, 57, 58, 59, 135, 146, 173, 176, 180, 182, 184, 224, 255, 272, 276, 279, 280, 281, 324, 328, 331, 333, 334, 349, 362, 373, 375, 380, 383, 385, 386, 388, 398, 400, 401, 410, 413, 415, 416, 419, 420, 421, 423, 424, 426, 441, 449, 452, 453, 467, 480, 565, 566, 567, 568, 572, 573, 596, 598, 618, 619, 636, 644, 655, 659, 661, 663, 669, 671, 673, 679, 680, 682, 684, 686, 695, 696, 720, 727, 808, 811, 812, 822, 830, 849, 854, 855, 861, 883, 885, 886, 920, 921, 922, 923, 927, 929, 984, 988, 989, 992, 996, 997, 999, 1001, 1002, 1003, 1004, 1010, 1014, 1015, 1016, 1020, 1025, 1030, 1034, 1041, 1044, 1045, 1048, 1049, 1051, 1055, 1058], "foundat": [0, 160, 272, 386, 414, 1003], "founder": 1024, "fouqu": 1041, "fouquet": [1057, 1058], "four": [64, 170, 184, 197, 202, 221, 265, 266, 272, 339, 346, 382, 386, 400, 565, 572, 727, 920, 922, 938, 996, 998, 999, 1000, 1010, 1018], "fourier": [2, 23, 252, 646, 647, 648, 649, 650, 766, 767, 992], "fourier_approx_svm": 252, "fourier_scor": 252, "fourier_tim": 252, "fournier": 1050, "fourth": [148, 1025], "fowkl": [416, 739], "fowlk": [739, 1047], "fowlkes_mallows_scor": [2, 416, 1000, 1047, 1049], "fox": [336, 424, 1057], "fp": [47, 272, 336, 416, 720, 726, 737, 738, 739, 790, 791, 792, 795, 1000], "fp_c": 287, "fpgawesom": 1055, "fpr": [2, 50, 248, 257, 272, 275, 287, 288, 393, 600, 604, 706, 710, 714, 735, 797, 1000, 1038, 1041, 1057], "fpr_a": 287, "fpr_b": 287, "fpr_grid": 287, "fpr_score": 272, "fr": [44, 46, 47, 48, 49, 61, 62, 66, 72, 77, 89, 92, 109, 115, 145, 155, 182, 199, 204, 205, 207, 211, 213, 214, 225, 241, 242, 247, 250, 257, 279, 281, 284, 291, 311, 324, 356, 360, 361, 362, 539, 545, 666, 672, 693, 694, 766, 767, 998, 1000], "fraa\u00df": 1058, "frac": [63, 113, 114, 139, 278, 285, 287, 331, 413, 414, 416, 418, 421, 422, 423, 424, 426, 439, 471, 473, 490, 491, 492, 562, 564, 566, 568, 570, 573, 576, 578, 619, 623, 627, 630, 631, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 677, 678, 680, 681, 686, 687, 688, 704, 737, 738, 763, 777, 845, 846, 855, 863, 870, 913, 915, 918, 921, 923, 992, 994, 995, 996, 997, 998, 1000, 1002, 1003, 1004, 1005, 1007, 1008, 1010, 1012, 1014, 1015, 1016, 1032], "frac12": [423, 992], "fractal": [174, 383], "fraction": [2, 43, 62, 64, 152, 155, 220, 228, 238, 272, 356, 361, 414, 420, 423, 446, 447, 457, 458, 464, 465, 523, 535, 565, 566, 567, 568, 572, 573, 574, 598, 601, 610, 674, 675, 676, 679, 684, 685, 686, 711, 729, 730, 731, 732, 742, 802, 804, 810, 814, 836, 837, 851, 879, 914, 915, 916, 920, 921, 922, 923, 966, 996, 1000, 1003, 1007, 1008, 1010, 1015, 1016, 1020, 1042, 1043, 1044, 1055], "fragil": 663, "fragment": [90, 128], "frame": [43, 52, 105, 155, 181, 192, 193, 220, 272, 325, 335, 381, 386, 398, 401, 497, 498, 499, 500, 504, 508, 509, 510, 512, 513, 518, 1019, 1030, 1053], "frameon": [46, 226], "framework": [278, 373, 388, 398, 400, 410, 416, 645, 696, 805, 996, 997, 1004, 1020, 1024, 1041, 1047], "fran": [1053, 1054, 1055], "franc": [325, 772], "francesco": [1053, 1056], "franci": [544, 666, 996, 1047], "francia": 1055, "francidona": 1051, "francisco": [424, 1012], "franck": [1056, 1058, 1059], "franco": 1051, "francoi": [1041, 1054], "francoisgoupil": 1055, "frank": [278, 843, 1001, 1046, 1050, 1051], "frankhui": 1049, "franki": 1054, "franz": 1049, "franziska": 1052, "fran\u00e7oi": [0, 370, 1044], "fraud": [272, 336, 996, 1024], "fraudul": [272, 996, 1024], "fraudulent_accept": 272, "fraudulent_refus": 272, "fred": [104, 1041, 1054], "freder": 1051, "frederick": 1054, "fredrik": 1049, "free": [0, 44, 64, 90, 181, 182, 188, 219, 268, 319, 380, 385, 386, 387, 394, 398, 404, 424, 460, 617, 679, 868, 918, 989, 992, 996, 1000, 1020, 1049], "freebsd": 389, "freedom": [43, 127, 181, 208, 209, 211, 278, 549, 664, 805, 996, 1044], "freeland": 1056, "freestand": 388, "freez": [390, 404, 410, 1020, 1024, 1049], "frei": [73, 448, 462, 1051], "freija": 1049, "freita": [1046, 1048, 1049], "frellwan": 1054, "fremtpl2": 238, "fremtpl2freq": 238, "fremtpl2sev": 238, "french": [0, 238, 325], "freq": [192, 204, 362], "frequenc": [57, 64, 176, 193, 204, 214, 220, 251, 329, 330, 360, 361, 362, 381, 398, 414, 420, 421, 423, 424, 425, 559, 565, 567, 568, 569, 572, 596, 597, 598, 599, 612, 666, 667, 672, 674, 676, 682, 683, 684, 693, 694, 841, 876, 885, 886, 912, 914, 917, 920, 922, 938, 996, 997, 1002, 1010, 1014, 1016, 1043, 1045, 1046, 1052, 1059], "frequent": [72, 139, 188, 281, 287, 288, 292, 361, 383, 386, 424, 559, 598, 638, 862, 885, 886, 889, 901, 990, 992, 1000, 1014, 1020, 1059], "frequentist": 536, "fresh": [546, 1020, 1051], "fresh_restart": 546, "fresh_restarts_max_it": 546, "freund": [423, 561, 562], "fri": [43, 155, 193, 381], "frid": [1024, 1044], "friedman": [2, 142, 143, 154, 277, 418, 420, 423, 486, 524, 525, 526, 528, 566, 567, 568, 573, 601, 602, 842, 920, 921, 923, 994, 996, 1001, 1007, 1016], "friedman2001": 423, "friedman2002": 423, "friedman_ms": [566, 567, 568, 573, 921, 923, 1016, 1057, 1058], "friend": [430, 1045], "friendli": [125, 374, 386, 394, 421, 905, 1012, 1013, 1019, 1020], "fring": [87, 416], "fritsch": [0, 48, 406, 1041, 1042, 1044], "fritzk": 1056, "fro": [421, 546, 548, 555, 701, 996], "fro_2": [669, 671], "frobeniu": [54, 128, 451, 455, 467, 477, 478, 479, 480, 481, 482, 483, 484, 539, 545, 546, 548, 553, 554, 555, 996, 1048], "frobenius_norm": 696, "from": [0, 2, 37, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 326, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 399, 400, 401, 403, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 583, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 959, 961, 962, 963, 964, 965, 967, 969, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 992, 994, 995, 996, 997, 998, 999, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1024, 1026, 1028, 1029, 1030, 1031, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "from_dtyp": [43, 149, 272, 335, 423, 569, 570, 1058], "from_estim": [45, 48, 62, 64, 66, 67, 70, 91, 141, 144, 155, 156, 157, 161, 193, 203, 212, 229, 234, 253, 258, 260, 271, 272, 275, 280, 281, 285, 288, 294, 302, 307, 310, 324, 328, 329, 330, 331, 333, 334, 335, 336, 345, 346, 347, 348, 350, 351, 353, 365, 393, 414, 446, 639, 640, 641, 705, 706, 708, 709, 710, 726, 735, 790, 792, 795, 796, 797, 814, 831, 995, 1000, 1007, 1030, 1038, 1054, 1055, 1056, 1057, 1058, 1059], "from_predict": [43, 52, 68, 109, 160, 192, 257, 274, 285, 287, 331, 338, 360, 393, 446, 639, 705, 706, 708, 709, 710, 726, 735, 790, 792, 795, 796, 797, 1000, 1038, 1054, 1055, 1056, 1057, 1058, 1059], "frombuffer_empti": 1048, "fromkei": [279, 927], "fromnumer": 392, "front": [390, 1048], "frontal": 381, "frontend": 392, "frontier": [48, 234, 305, 348, 1006, 1032], "frozen": 388, "frozentransform": 388, "frsi": 1049, "fruit": [386, 1001], "fr\u00e9minvil": [1058, 1059], "fs1995": 423, "ftfy": 424, "ftorres16": [1055, 1056], "ftp": [174, 383, 690, 691], "ftwo_scor": [750, 1000], "fu": [666, 1045], "fuck": [1053, 1054], "fuent": [1042, 1043], "fugled": 1058, "fujikawa": 1048, "fukatani": 1048, "fulfil": [386, 416, 423, 808, 811, 812, 822, 872, 876, 996], "full": [0, 2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 373, 374, 375, 379, 381, 384, 386, 388, 391, 394, 398, 400, 401, 404, 412, 416, 418, 420, 421, 424, 430, 433, 439, 440, 449, 453, 455, 457, 467, 496, 497, 500, 504, 505, 508, 509, 510, 511, 512, 513, 515, 518, 543, 545, 549, 567, 568, 575, 576, 640, 656, 658, 662, 677, 688, 729, 731, 736, 753, 754, 756, 758, 759, 761, 793, 798, 799, 805, 806, 819, 849, 938, 989, 996, 999, 1002, 1003, 1007, 1010, 1013, 1020, 1032, 1041, 1045, 1047, 1049, 1051, 1052, 1054, 1055, 1057, 1058, 1059], "full_data": 199, "full_lik": 100, "full_model": 301, "full_scor": 188, "fulli": [52, 79, 90, 146, 152, 373, 380, 381, 400, 416, 422, 423, 425, 451, 455, 565, 566, 572, 573, 920, 921, 922, 923, 924, 926, 989, 990, 996, 1005, 1013, 1019, 1054, 1055], "fullpap": 1013, "fultz": 1054, "fun": [428, 541, 1024], "fun_arg": [428, 541], "func": [50, 109, 144, 192, 200, 238, 312, 386, 417, 473, 707, 876, 1010, 1045, 1047, 1049, 1050, 1058, 1059], "func_min": [618, 619], "funcformatt": 304, "function": [2, 4, 27, 43, 44, 45, 46, 47, 52, 54, 58, 59, 64, 72, 81, 88, 89, 90, 92, 94, 101, 104, 105, 106, 109, 125, 128, 130, 134, 137, 144, 145, 149, 150, 151, 152, 153, 154, 155, 165, 170, 173, 174, 176, 179, 180, 181, 182, 183, 184, 188, 189, 191, 192, 193, 195, 198, 199, 202, 204, 207, 213, 215, 216, 217, 218, 220, 221, 226, 227, 228, 233, 236, 237, 238, 240, 248, 250, 253, 254, 257, 258, 260, 261, 268, 270, 272, 276, 278, 279, 280, 281, 286, 287, 293, 296, 299, 314, 317, 319, 326, 328, 329, 331, 332, 334, 336, 341, 343, 346, 347, 348, 349, 350, 351, 353, 356, 358, 360, 361, 365, 369, 373, 374, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 389, 390, 391, 392, 398, 399, 400, 404, 407, 410, 412, 414, 415, 416, 417, 418, 419, 421, 422, 424, 425, 427, 428, 431, 433, 435, 436, 438, 439, 440, 445, 448, 451, 452, 453, 455, 456, 458, 460, 462, 465, 466, 467, 468, 469, 472, 473, 476, 477, 479, 480, 482, 486, 496, 497, 499, 500, 503, 504, 505, 511, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 557, 558, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 580, 583, 589, 590, 596, 597, 599, 600, 601, 602, 603, 604, 606, 607, 608, 609, 610, 612, 615, 616, 617, 618, 619, 623, 627, 628, 630, 631, 635, 636, 639, 640, 641, 642, 643, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 695, 696, 697, 698, 699, 700, 701, 702, 706, 707, 708, 710, 711, 712, 714, 719, 720, 724, 727, 729, 730, 731, 732, 736, 740, 742, 743, 746, 748, 749, 750, 758, 763, 765, 769, 770, 771, 773, 776, 779, 782, 786, 787, 788, 789, 790, 791, 793, 797, 800, 801, 802, 804, 805, 806, 807, 808, 810, 811, 812, 813, 814, 819, 820, 822, 823, 824, 825, 826, 827, 828, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 846, 852, 853, 854, 855, 856, 857, 858, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 881, 882, 884, 888, 889, 890, 891, 892, 893, 896, 898, 901, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 927, 930, 939, 941, 942, 943, 948, 949, 959, 960, 966, 967, 970, 971, 974, 975, 984, 989, 990, 991, 993, 995, 997, 998, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1013, 1014, 1016, 1019, 1020, 1021, 1022, 1025, 1028, 1029, 1030, 1034, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059, 1060], "functiontransform": [2, 43, 104, 144, 220, 238, 342, 410, 472, 473, 1010, 1046, 1047, 1049, 1054, 1055, 1056, 1058], "functiontransformerfunctiontransform": 144, "functool": 238, "fundament": [72, 84, 114, 361, 398, 399, 419, 504, 546, 548, 555, 716, 996, 1000], "funder": 0, "fung": 420, "funki": 1019, "funnel": [45, 501, 502, 1030], "funni": 104, "furlanello": 751, "furrer": 1058, "further": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 62, 77, 105, 111, 118, 125, 142, 148, 150, 173, 176, 181, 192, 194, 199, 204, 240, 245, 254, 272, 275, 278, 279, 285, 333, 349, 361, 368, 373, 386, 398, 400, 410, 415, 416, 418, 421, 423, 424, 426, 452, 460, 470, 523, 540, 543, 590, 622, 630, 636, 666, 667, 674, 675, 676, 684, 685, 686, 699, 703, 745, 782, 786, 789, 800, 801, 848, 854, 855, 862, 863, 890, 892, 912, 914, 917, 949, 999, 1000, 1002, 1003, 1004, 1006, 1008, 1010, 1014, 1015, 1032, 1034, 1050, 1054], "furthermor": [43, 52, 72, 145, 182, 193, 194, 257, 258, 260, 299, 360, 361, 373, 375, 393, 416, 421, 423, 424, 570, 598, 614, 627, 712, 744, 754, 763, 765, 803, 912, 996, 1008, 1044, 1048], "fuse": [387, 1047, 1057], "fusion": 398, "futur": [52, 181, 221, 260, 331, 334, 386, 388, 390, 400, 401, 410, 420, 424, 504, 542, 643, 970, 1001, 1015, 1016, 1024, 1038, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "futurewarn": [386, 394, 1048, 1049, 1050, 1052, 1054, 1057, 1058], "fuxin": 650, "fw": 696, "fwe": 600, "f\u00e9lix": [1041, 1043, 1044, 1045, 1049], "g": [0, 25, 43, 46, 47, 49, 51, 61, 62, 63, 64, 68, 88, 90, 100, 104, 115, 118, 132, 139, 142, 143, 151, 152, 160, 176, 177, 178, 179, 181, 183, 184, 185, 188, 191, 192, 202, 205, 220, 221, 222, 224, 238, 241, 245, 253, 254, 263, 272, 278, 282, 283, 289, 298, 305, 319, 324, 336, 341, 355, 356, 362, 369, 373, 378, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 398, 400, 407, 410, 412, 414, 416, 418, 420, 421, 423, 424, 425, 426, 428, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 511, 536, 539, 541, 542, 545, 549, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 597, 598, 599, 601, 602, 605, 612, 618, 619, 625, 630, 631, 638, 641, 642, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 694, 698, 700, 705, 728, 736, 746, 748, 771, 786, 793, 796, 807, 809, 810, 811, 812, 814, 815, 817, 826, 830, 831, 833, 834, 835, 836, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 859, 861, 862, 863, 864, 868, 869, 870, 872, 875, 877, 878, 879, 882, 884, 885, 888, 890, 891, 892, 893, 895, 897, 898, 899, 900, 901, 902, 903, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 948, 949, 960, 989, 990, 994, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1014, 1015, 1016, 1020, 1023, 1024, 1029, 1034, 1041, 1045, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "g0g0gadget": 1051, "g2015": 1007, "g_": 416, "g_i": [423, 657], "g_j": [656, 677, 688], "ga": 0, "gaaca": 184, "gaatattaggccga": 398, "gabor": 1055, "gabriel": [317, 1049, 1050, 1051, 1054, 1055], "gael": [0, 51, 68, 74, 75, 81, 87, 88, 101, 102, 115, 127, 209, 210, 241, 252, 265, 405, 1018, 1020, 1024, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "gaido": 1050, "gaidon": 1041, "gain": [2, 88, 155, 242, 285, 299, 301, 335, 336, 339, 360, 361, 368, 385, 392, 394, 423, 504, 540, 565, 569, 570, 572, 734, 764, 805, 806, 841, 920, 922, 1001, 1005, 1013, 1016, 1044, 1048, 1051], "gain_matrix": 272, "galleri": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 381, 386, 388, 400, 404, 409, 1021, 1030, 1041, 1045, 1048], "galli": 1053, "gallopoulo": 421, "galvez": 1046, "gambl": 51, "gameiro": 1055, "gamma": [2, 43, 44, 45, 46, 48, 50, 67, 68, 130, 161, 167, 197, 234, 247, 252, 253, 276, 278, 280, 283, 289, 294, 330, 338, 339, 341, 343, 346, 348, 349, 352, 353, 355, 358, 419, 421, 423, 426, 460, 543, 570, 627, 628, 647, 648, 649, 651, 652, 653, 656, 688, 693, 699, 732, 755, 760, 767, 774, 783, 784, 785, 805, 819, 822, 907, 908, 909, 914, 915, 916, 917, 918, 989, 992, 995, 996, 998, 1013, 1015, 1025, 1029, 1030, 1032, 1041, 1042, 1044, 1045, 1046, 1048, 1049, 1051, 1052, 1055, 1056, 1057], "gamma_": [543, 1057], "gamma_0": [263, 269], "gamma_2d_rang": 349, "gamma_bound": 628, "gamma_k": 419, "gamma_rang": 349, "gammaregressor": [2, 238, 329, 332, 688, 996, 1052, 1055, 1056], "gandenberg": 1050, "ganesh": [1046, 1058], "ganevgv": 1051, "gangesh": 1053, "gangwar": 1048, "ganiev": [1046, 1047, 1048], "ganssl": 1048, "gap": [43, 52, 155, 360, 381, 420, 479, 480, 486, 596, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 829, 920, 921, 922, 923, 996, 997, 1049, 1053, 1055], "garagecar": [149, 160], "garagefinish": 149, "garagetyp": 160, "garageyrblt": 109, "garbag": 1053, "garcia": 1054, "garc\u00eda": [1050, 1051, 1056], "gardin": 380, "gardner": [1049, 1050], "garg": [1051, 1052], "gargsya": 1051, "gari": [381, 1048], "garret": 1045, "garreta": [1043, 1044], "garrett": 1045, "garri": 383, "garriga": [284, 420, 837], "gasmi": 1055, "gasquez": 1048, "gate": [383, 1054], "gather": [332, 334, 394, 401, 416, 1010, 1024], "gatsbi": 1013, "gaug": 192, "gaull": 772, "gaurav": [1049, 1050, 1051, 1052, 1053, 1055], "gauravahlawat": [1049, 1050], "gaussian": [2, 8, 19, 28, 43, 44, 46, 47, 48, 64, 66, 67, 70, 79, 81, 82, 90, 91, 92, 96, 100, 111, 112, 113, 114, 115, 122, 123, 126, 127, 128, 134, 137, 140, 141, 148, 152, 156, 158, 167, 188, 199, 202, 204, 208, 210, 230, 232, 233, 247, 251, 253, 254, 265, 266, 289, 304, 309, 312, 314, 321, 322, 323, 343, 346, 353, 354, 378, 382, 388, 391, 400, 416, 418, 421, 422, 428, 460, 477, 478, 479, 480, 481, 482, 483, 484, 504, 512, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 533, 538, 540, 552, 557, 558, 561, 571, 618, 619, 621, 622, 623, 625, 626, 627, 630, 631, 633, 635, 651, 652, 680, 685, 688, 711, 732, 749, 760, 784, 805, 806, 808, 822, 847, 848, 849, 850, 851, 852, 853, 857, 888, 892, 900, 904, 905, 906, 994, 996, 997, 998, 1006, 1021, 1022, 1024, 1033, 1035, 1036, 1041, 1042, 1044, 1045, 1047, 1048, 1049, 1051, 1053, 1055], "gaussian_filt": [53, 81, 82, 89, 1033], "gaussian_process": [2, 66, 67, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 189, 400, 426, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 651, 1001, 1021, 1044, 1047, 1048], "gaussianhmm": 1041, "gaussianmixtur": [2, 79, 92, 264, 265, 266, 267, 268, 269, 422, 805, 999, 1047, 1049, 1050, 1054, 1055, 1057, 1059], "gaussianmixturegaussianmixtur": 268, "gaussiannb": [2, 61, 62, 64, 67, 162, 280, 369, 414, 423, 445, 577, 847, 848, 849, 851, 873, 994, 1001, 1002, 1045, 1046, 1047, 1049, 1054, 1057], "gaussiannois": 388, "gaussianprocessclassifi": [2, 66, 67, 177, 178, 179, 180, 184, 400, 426, 619, 627, 628, 630, 631, 1001, 1047, 1049, 1051, 1055], "gaussianprocessregressor": [2, 176, 181, 182, 183, 184, 185, 426, 618, 621, 622, 623, 624, 625, 629, 632, 633, 651, 1001, 1044, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "gaussianprocessregressorifittedgaussianprocessregressor": 181, "gaussianrandomproject": [2, 905, 1012, 1042, 1055, 1057, 1058], "gauthier": 1055, "gauz": 1049, "gave": [64, 414, 808, 811, 812, 822, 879], "gavin": [636, 990], "gaynor": 410, "ga\u00ebl": [67, 80, 86, 107, 120, 121, 131, 203, 217, 218, 321, 353, 354, 401, 1024], "gb": [163, 423, 561, 641], "gbc": 369, "gbdt": [144, 193, 272, 328, 329, 334, 391, 423], "gbdt_appli": 144, "gbdt_cst": 329, "gbdt_leaves_yield": 144, "gbdt_model": 144, "gbdt_no_cst": [157, 329], "gbdt_pipelin": 160, "gbdt_with_monotonic_cst": 157, "gbdt_with_monotonic_cst_df": 157, "gbm": [151, 423, 1044], "gbm_early_stop": 150, "gbm_full": 150, "gbp": 1024, "gbr": 152, "gbr_l": 152, "gbrt": [43, 52, 220, 423], "gbrt_mean_poisson": 52, "gbrt_median": 52, "gbrt_percentile_5": 52, "gbrt_percentile_95": 52, "gbrt_predict": 43, "gbt": 373, "gc": 49, "gca": [47, 79, 97, 118, 179, 225, 229, 231, 247, 260, 282, 307, 309, 320, 345, 347, 350, 351, 1007, 1038], "gcc": [384, 387, 392, 398], "gcf": [47, 1007], "gcv": [681, 683], "gcv_mode": [681, 1043], "gd": [51, 163], "gdb": [387, 389, 1023], "gdex1": 1051, "ge": [51, 991, 1002, 1053], "ge0": 1016, "gear": 1018, "geb": 57, "gebremichael": [1056, 1057], "gedeck": 1048, "geevarghes": 1056, "gefel": 1000, "gegr": 424, "gei": 1043, "geiger": [1058, 1059], "geist": 383, "gelavizh": 1052, "gelder": 1052, "gemm": 1059, "gen": 789, "gen_batch": [2, 395, 953], "gen_cov": 113, "gen_even_slic": [2, 220, 395, 952], "gender": [259, 885, 1010], "gender_femal": 885, "gender_mal": 885, "gene": [184, 380, 413, 459, 521, 601, 602, 859, 892], "gener": [0, 2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 91, 93, 94, 95, 96, 97, 100, 104, 105, 106, 107, 108, 109, 112, 114, 117, 118, 119, 120, 121, 125, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 171, 172, 174, 177, 178, 179, 180, 181, 184, 187, 188, 191, 192, 193, 194, 195, 197, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 269, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 307, 308, 309, 310, 312, 314, 315, 316, 319, 320, 321, 322, 323, 324, 325, 326, 328, 330, 331, 332, 333, 334, 335, 336, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 373, 374, 378, 379, 381, 383, 387, 388, 389, 390, 391, 392, 394, 395, 398, 399, 410, 413, 414, 416, 420, 422, 424, 425, 426, 428, 432, 437, 439, 445, 448, 451, 454, 455, 457, 460, 462, 466, 467, 468, 470, 472, 473, 475, 477, 480, 482, 490, 491, 492, 496, 499, 500, 503, 504, 505, 511, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 544, 546, 548, 549, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 590, 591, 592, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 618, 619, 622, 623, 626, 627, 628, 630, 631, 635, 636, 637, 638, 640, 641, 642, 643, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 675, 677, 678, 679, 680, 681, 683, 685, 686, 687, 688, 693, 694, 697, 698, 699, 700, 701, 702, 703, 709, 712, 714, 725, 729, 731, 732, 745, 751, 765, 786, 789, 793, 801, 805, 806, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 839, 842, 843, 844, 845, 846, 852, 853, 855, 857, 858, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 897, 898, 900, 901, 902, 903, 904, 905, 912, 913, 914, 915, 917, 918, 921, 923, 924, 925, 926, 943, 944, 948, 949, 952, 953, 965, 969, 971, 974, 989, 990, 992, 994, 995, 997, 999, 1000, 1001, 1003, 1005, 1006, 1007, 1008, 1012, 1013, 1015, 1016, 1019, 1021, 1022, 1023, 1024, 1025, 1028, 1032, 1033, 1036, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1059], "generalis": [796, 1000, 1020], "generaliz": [353, 423], "generate_data": [46, 69], "generate_dataset": 49, "generate_missing_valu": 155, "generate_onli": [943, 1051], "generate_synthetic_data": 53, "generickernelmixin": [184, 1051], "genericunivariateselect": [2, 425, 603, 604, 606, 607, 608, 610, 1055, 1057, 1058], "generos": 386, "genesi": [1055, 1057], "genet": 1019, "genoa": 383, "genom": [58, 521], "genotyp": 380, "gensim": 1019, "gentil": [383, 1053], "gentli": 421, "genvalen": [1053, 1054, 1055, 1056, 1057], "geodes": [240, 696, 997], "geoff": [843, 1001], "geoffrei": [869, 870, 1004, 1052, 1053, 1054, 1055, 1057], "geograph": [43, 50, 312, 381, 506], "geometr": [127, 416, 696, 712, 739, 765, 997, 1049], "geometri": [74, 416, 997, 1003], "geomspac": 334, "georg": [45, 381, 416, 1047, 1053, 1054, 1055, 1056], "george_w_bush": 1030, "georgi": [1049, 1052], "georgiamaydai": 1056, "geospati": [312, 422], "geovan": [1054, 1055], "geq": [251, 414, 421, 423, 996, 1000, 1010, 1014, 1015], "ger": 424, "gerhard": [45, 381], "gerhard_schroed": 1030, "german_credit": 272, "germer": [1056, 1057], "geroldcsend": 1054, "geron": [1049, 1054, 1055], "gerstein": 521, "gertrud": 1048, "gertz": 458, "gervai": [1043, 1044], "gesa": 1053, "gesdd": 949, "gesvd": 949, "get": [2, 3, 43, 44, 48, 51, 52, 55, 57, 72, 83, 87, 91, 126, 130, 152, 155, 162, 171, 174, 176, 181, 182, 187, 192, 193, 194, 195, 213, 222, 235, 238, 240, 254, 255, 276, 279, 280, 282, 286, 289, 296, 299, 304, 312, 320, 328, 335, 339, 342, 346, 349, 351, 354, 358, 360, 362, 364, 374, 379, 380, 381, 384, 386, 387, 388, 391, 392, 393, 394, 400, 404, 410, 412, 414, 415, 416, 417, 418, 420, 421, 423, 424, 425, 426, 430, 431, 432, 437, 439, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 470, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 703, 707, 729, 730, 731, 732, 734, 740, 741, 750, 764, 771, 772, 777, 793, 796, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 833, 834, 835, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 927, 940, 941, 942, 948, 949, 959, 989, 995, 996, 997, 999, 1000, 1010, 1013, 1014, 1015, 1016, 1020, 1029, 1032, 1033, 1034, 1038, 1041, 1044, 1047, 1049, 1052, 1054, 1055, 1058], "get_adjacency_matrix": 55, "get_arrai": [852, 853], "get_bin_se": 456, "get_cmap": [62, 64, 354], "get_color": 46, "get_config": [2, 476, 789, 910, 967, 1056], "get_config_var": 384, "get_covari": [540, 542, 549], "get_data": [516, 517], "get_data_hom": [2, 47], "get_depth": [920, 921, 922, 923, 1050], "get_feature_nam": [331, 1049, 1050, 1052, 1053, 1054], "get_feature_names_out": [2, 54, 57, 192, 194, 331, 360, 361, 362, 381, 388, 400, 417, 424, 432, 437, 440, 450, 451, 453, 455, 457, 472, 475, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 574, 575, 576, 577, 578, 589, 596, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 696, 697, 700, 856, 861, 864, 868, 871, 872, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 1010, 1054, 1055, 1056, 1057, 1058, 1059], "get_figur": 139, "get_full_scor": 188, "get_height": [47, 150], "get_impute_it": 188, "get_impute_knn_scor": 188, "get_impute_mean": 188, "get_impute_zero_scor": 188, "get_indic": [57, 431, 459, 461], "get_initial_mean": 266, "get_legend_handles_label": [155, 253, 280, 285], "get_lin": 315, "get_metadata_rout": [254, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 956, 957, 958, 959, 960, 1000, 1058], "get_metr": 707, "get_minibatch": 47, "get_n_cal": [852, 853], "get_n_leav": [920, 921, 922, 923, 1050], "get_n_split": [400, 809, 810, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829], "get_nam": 321, "get_output_feature_nam": 1055, "get_param": [279, 389, 400, 426, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 989, 1051, 1052, 1053, 1055, 1056], "get_precis": [477, 478, 479, 480, 481, 482, 483, 484, 540, 542, 549], "get_redirect": 55, "get_routing_for_object": [2, 254, 957], "get_scor": [2, 335, 400, 741, 1048, 1057], "get_scorer_nam": [2, 415, 740, 1000, 1055, 1058], "get_scores_for_imput": 188, "get_shap": [57, 431, 459, 461], "get_stop_word": [596, 597, 599], "get_submatrix": [431, 459, 461], "get_subplotspec": 393, "get_support": [170, 174, 330, 589, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 1043], "get_tree_stat": [852, 853], "get_untrusted_typ": 410, "get_width": [47, 150], "get_x": [47, 150], "get_xaxi": [263, 309, 319], "get_xlim": [113, 215, 225, 319], "get_xticklabel": 289, "get_yaxi": [309, 319], "get_ybound": 88, "get_ylim": [215, 319, 320], "getattr": [43, 47, 272, 319, 388, 400, 1057], "getgaurav2": 1051, "getmoredataget": 1027, "gettempdir": 1003, "getter": [477, 478, 479, 480, 481, 482, 483, 484, 601, 602, 605], "geurt": [423, 563, 564, 565, 566, 573, 574, 922, 923], "gewili": [1056, 1057], "gh": 386, "ghahramani": 907, "gharibi": 1051, "ghg": 1047, "ghislain": 1053, "gholdman1": 1052, "ghorai": 1049, "ghosh": [0, 406, 416, 1041, 1042, 1058, 1059], "gia": 1052, "giancarlo": 1055, "gianr": 1056, "gibb": [868, 1005, 1019], "gideon": 1051, "giessel": 1047, "gif": 83, "gigant": [1049, 1051, 1056, 1057], "gijsber": 1055, "gil": [373, 374, 387, 1044, 1049, 1050, 1053, 1054, 1058], "gilad": 1024, "gilberto": 1049, "gilbertson": [1055, 1056], "gilch": 1048, "gile": [1044, 1045], "gill": [0, 142, 143, 406, 1041, 1042, 1043, 1044, 1045, 1046, 1047], "gilliam": 1048, "gilmor": 1045, "gim": 1053, "gini": [64, 195, 220, 238, 259, 290, 330, 561, 562, 565, 566, 567, 568, 572, 573, 574, 796, 920, 921, 922, 923, 989, 1008, 1016, 1049, 1050, 1057, 1058], "gionanidi": 1055, "giorgio": [1046, 1047, 1048], "giorgiop": 1046, "giotto": 1019, "giovanni": [1047, 1049], "gist": [386, 394, 1023], "git": [384, 388, 390, 392, 394, 1023, 1037, 1041, 1057], "github": [0, 46, 47, 51, 63, 105, 106, 144, 146, 147, 153, 156, 157, 160, 163, 171, 181, 188, 192, 193, 194, 201, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 299, 317, 325, 329, 330, 332, 333, 335, 340, 368, 384, 385, 389, 390, 391, 392, 394, 398, 400, 401, 410, 412, 700, 1018, 1019, 1023, 1034, 1051], "githubusercont": 51, "gitter": [1048, 1049], "giudic": 1053, "giusepp": [1049, 1050], "give": [2, 43, 51, 52, 53, 61, 62, 74, 79, 84, 95, 97, 99, 104, 105, 109, 127, 151, 176, 181, 185, 187, 192, 193, 209, 211, 217, 220, 221, 222, 247, 269, 272, 275, 280, 287, 301, 305, 308, 317, 331, 332, 336, 342, 373, 375, 381, 383, 385, 386, 388, 392, 394, 398, 399, 400, 401, 410, 413, 414, 416, 417, 418, 421, 423, 424, 426, 428, 441, 454, 455, 457, 459, 467, 480, 504, 507, 511, 541, 546, 557, 558, 559, 560, 565, 566, 572, 573, 574, 601, 602, 605, 615, 616, 646, 655, 669, 673, 684, 728, 738, 744, 747, 802, 808, 811, 812, 822, 833, 834, 835, 837, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 889, 890, 892, 893, 901, 996, 1000, 1003, 1004, 1005, 1007, 1008, 1010, 1014, 1015, 1016, 1019, 1024, 1025, 1027, 1032, 1033, 1034, 1041, 1045, 1048, 1049, 1051, 1052, 1053, 1055, 1057], "given": [2, 8, 30, 46, 49, 50, 52, 64, 66, 72, 84, 93, 95, 111, 117, 126, 130, 145, 155, 156, 158, 160, 176, 183, 192, 193, 204, 220, 221, 224, 238, 241, 247, 251, 252, 254, 256, 257, 258, 272, 274, 278, 279, 280, 281, 287, 292, 302, 305, 306, 307, 321, 325, 331, 336, 360, 361, 362, 367, 373, 375, 381, 385, 386, 388, 390, 392, 394, 395, 398, 400, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 429, 433, 442, 443, 444, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 464, 466, 467, 468, 469, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 486, 489, 490, 491, 492, 495, 504, 509, 511, 513, 531, 541, 542, 544, 546, 547, 548, 551, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 597, 598, 599, 601, 602, 609, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 639, 640, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 695, 696, 698, 699, 705, 706, 707, 708, 709, 710, 712, 713, 714, 720, 722, 725, 726, 728, 732, 734, 735, 742, 744, 745, 748, 760, 763, 764, 766, 767, 772, 782, 786, 789, 790, 792, 795, 796, 797, 802, 803, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 817, 820, 822, 826, 830, 831, 833, 834, 835, 836, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 869, 870, 871, 872, 873, 874, 875, 877, 878, 879, 882, 883, 884, 885, 886, 887, 888, 889, 891, 892, 898, 899, 901, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 927, 936, 937, 938, 956, 957, 959, 984, 988, 989, 992, 994, 996, 997, 998, 999, 1000, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1024, 1025, 1029, 1030, 1032, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1059, 1060], "gkevinyen5418": 1049, "gkf": 420, "gkiasta": 1054, "gl": [174, 383], "glad": 386, "glanc": [296, 385], "glaser": [1049, 1050], "glass": 381, "glasso": [418, 486], "glaxosmithklin": 51, "gleb": [1054, 1056, 1057, 1058], "glemaitr": [1050, 1051, 1053], "glemaitre58": 222, "glen": 1054, "glenn": 1047, "glennfrutiz": 1055, "glibc": 394, "glm": [220, 238, 329, 656, 677, 688, 996, 1041, 1052], "glm_freq": 238, "glm_pure_premium": 238, "glm_sev": 238, "glmnet": [654, 655, 1041], "glob": 47, "global": [2, 3, 47, 49, 77, 92, 125, 220, 240, 241, 261, 287, 316, 329, 369, 373, 374, 392, 398, 400, 416, 426, 450, 460, 470, 476, 598, 634, 640, 696, 699, 700, 703, 715, 737, 738, 746, 791, 792, 795, 796, 826, 893, 908, 910, 970, 989, 997, 1000, 1006, 1010, 1016, 1024, 1049, 1056], "global_dtyp": 374, "global_random_se": 374, "globular": [97, 416], "glorot": [869, 870], "glossari": [2, 369, 386, 388, 392, 427, 428, 445, 448, 451, 452, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 468, 469, 470, 472, 475, 477, 480, 482, 496, 499, 500, 503, 505, 511, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 591, 592, 602, 610, 615, 616, 618, 619, 635, 640, 642, 647, 648, 649, 650, 654, 655, 657, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 679, 680, 681, 682, 683, 684, 685, 686, 687, 695, 696, 697, 698, 699, 700, 701, 702, 703, 709, 782, 786, 789, 801, 805, 806, 808, 810, 811, 812, 813, 814, 820, 822, 823, 824, 825, 826, 827, 828, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 854, 855, 857, 858, 860, 861, 862, 863, 865, 866, 868, 869, 870, 871, 874, 877, 889, 893, 901, 904, 905, 907, 908, 912, 913, 914, 917, 920, 921, 922, 923, 948, 949, 971, 974, 989, 990, 996, 1025, 1049], "glu": [174, 383], "glushchenkov": 1055, "gl\u00f2ria": [1054, 1056], "gm": 806, "gmail": [46, 50, 54, 61, 77, 83, 92, 100, 104, 105, 137, 139, 140, 141, 142, 143, 144, 151, 153, 154, 159, 160, 176, 179, 181, 183, 185, 200, 222, 237, 241, 243, 250, 263, 265, 266, 279, 282, 319, 324, 360, 361], "gmil": 381, "gmm": [79, 94, 189, 262, 264, 267, 268, 269, 512, 520, 806, 827, 999, 1021, 1041, 1042, 1045, 1046, 1047], "gmm_": 1042, "gmm_bic_scor": 268, "gmmgmm": 1027, "gmmhmm": [1041, 1042], "gnb": [61, 62, 64, 162, 423, 577, 1002], "gnb_isoton": 62, "gnb_sigmoid": 62, "gnu": 384, "go": [0, 2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 381, 386, 388, 390, 391, 395, 401, 404, 417, 421, 423, 425, 451, 569, 570, 728, 891, 952, 953, 1010, 1016, 1019, 1020, 1025, 1034, 1052], "goadrich": 1000, "goal": [49, 55, 58, 64, 87, 92, 118, 155, 187, 193, 197, 220, 235, 238, 256, 257, 272, 275, 276, 360, 374, 375, 381, 388, 391, 392, 400, 401, 403, 407, 421, 425, 550, 556, 598, 601, 747, 1000, 1003, 1005, 1006, 1014, 1015, 1016, 1024, 1025, 1028, 1032, 1034, 1049], "god": [57, 360, 361, 1034], "godbol": 791, "goe": [43, 72, 144, 192, 368, 386, 423, 479, 480, 486, 565, 566, 572, 573, 574, 920, 921, 922, 923, 1010, 1014], "goetz": [1048, 1049], "goh": 1058, "gohlk": 1046, "goix": [0, 1045, 1047, 1048, 1049, 1050], "gold": [69, 214, 221, 223, 226, 230, 234, 237, 264, 269, 285, 305, 348, 392], "goldbaum": 1059, "goldberg": [861, 1003], "goldfarb": 996, "goldman": 51, "goldstein": [193, 1007], "goldszmidt": 1012, "gollonet": [0, 406], "goltermann": 1053, "golub": [542, 850, 892], "golubin": 1048, "gome": [1054, 1055, 1059], "gomez": [1049, 1056, 1058], "gommer": [1044, 1047, 1048, 1056, 1057, 1059], "goncalo": [1048, 1049], "gone": [1041, 1042], "gonthier": 1052, "goo": [174, 383], "good": [43, 48, 58, 62, 64, 75, 79, 81, 84, 87, 88, 90, 93, 108, 114, 118, 134, 145, 148, 151, 152, 155, 177, 181, 187, 192, 204, 209, 220, 221, 226, 235, 245, 247, 251, 254, 257, 264, 266, 271, 272, 278, 284, 294, 317, 324, 325, 330, 336, 338, 343, 349, 360, 361, 369, 373, 374, 375, 385, 387, 388, 389, 390, 392, 394, 398, 400, 413, 414, 416, 418, 420, 421, 423, 424, 425, 426, 445, 447, 452, 542, 567, 569, 570, 598, 638, 648, 655, 656, 664, 666, 667, 669, 677, 688, 698, 702, 731, 739, 750, 772, 837, 906, 949, 989, 995, 996, 997, 1000, 1001, 1003, 1004, 1005, 1007, 1008, 1010, 1014, 1015, 1016, 1020, 1024, 1025, 1029, 1032, 1034, 1047], "goodby": 386, "goodman": [1041, 1046], "googl": [0, 55, 398, 416, 450, 1018, 1030, 1041], "gool": 1000, "gorb": 1053, "gordon": [57, 266, 1047, 1051, 1053, 1055], "gorelli": [1049, 1050, 1054, 1056, 1059], "gorgolewski": [0, 406, 1041, 1044], "gorilla": 360, "gorinevski": 996, "gorodkin": 751, "gorro\u00f1o": [1052, 1054, 1055], "got": [254, 285, 369, 391, 559, 657, 673, 1054, 1056, 1058], "gotten": [996, 1010], "gou": 416, "gouillart": [53, 101, 1041], "goupil": [0, 370], "gov": [55, 383], "govern": [192, 369, 373, 386, 400, 1024], "govin": 1047, "go\u0144da": 1056, "gp": [179, 184, 426, 618, 619, 630, 1047], "gp_fix": 177, "gp_opt": 177, "gpapadok": [1051, 1055], "gpassino": 1045, "gpc": [2, 66, 122, 148, 158, 167, 175, 181, 182, 183, 189, 230, 232, 233, 253, 267, 314, 321, 322, 343, 354, 512, 618, 619, 621, 622, 627, 628, 630, 631, 711, 749, 1021, 1022, 1036, 1051], "gpc_rbf_anisotrop": 178, "gpc_rbf_isotrop": 178, "gperftool": 389, "gplearn": 1019, "gpr": [2, 175, 176, 177, 183, 185, 189, 504, 618, 619, 621, 622, 623, 624, 629, 630, 631, 632, 633, 1021, 1022, 1036, 1051], "gpr_model": 185, "gprof": 389, "gpu": [333, 336, 412, 1004, 1020, 1034, 1058], "gr": 905, "grab": 386, "gracefulli": [1044, 1045], "grad": [392, 1024], "gradd": 392, "grade": 1000, "gradi": 1051, "gradient": [2, 14, 46, 52, 81, 101, 105, 138, 139, 140, 143, 144, 146, 147, 157, 160, 163, 181, 182, 189, 195, 198, 200, 208, 222, 243, 247, 252, 277, 279, 305, 315, 319, 323, 325, 332, 335, 348, 400, 415, 416, 426, 460, 470, 474, 475, 496, 498, 504, 509, 511, 528, 561, 562, 567, 568, 569, 570, 572, 573, 594, 618, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 639, 640, 642, 643, 647, 656, 657, 666, 667, 676, 677, 680, 682, 684, 685, 686, 688, 695, 700, 702, 703, 749, 750, 756, 758, 798, 808, 811, 812, 813, 829, 835, 838, 868, 869, 870, 873, 885, 886, 916, 974, 997, 1000, 1003, 1004, 1005, 1006, 1019, 1021, 1022, 1036, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1050, 1051, 1054, 1056, 1058], "gradient_boost": [144, 1043, 1044, 1050], "gradientboost": 1046, "gradientboostingclassifi": [2, 144, 151, 154, 321, 369, 398, 561, 569, 640, 641, 1001, 1007, 1041, 1042, 1043, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "gradientboostingclassifier__learning_r": 321, "gradientboostingregressor": [2, 46, 150, 152, 153, 160, 163, 373, 391, 398, 562, 570, 640, 641, 996, 1000, 1001, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058], "gradientboostingregressorgradientboostingregressor": 163, "gradual": [224, 869, 870, 1014], "graduat": 383, "graham": [1046, 1047], "grai": [45, 53, 81, 82, 85, 86, 88, 125, 128, 154, 174, 218, 220, 238, 251, 255, 256, 285, 316, 383, 421, 501, 502, 510, 529, 1030, 1033, 1052], "grain": [43, 67, 72, 252, 269, 321, 392, 424, 454, 1020], "gram": [2, 189, 198, 388, 421, 424, 497, 532, 556, 596, 597, 598, 599, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 672, 673, 689, 690, 691, 692, 693, 694, 775, 989, 996, 1010, 1015, 1021, 1034, 1041, 1043, 1044, 1045, 1046, 1048, 1049, 1050, 1052, 1054, 1055], "gram_test": 1015, "gram_train": 1015, "gramfort": [0, 61, 62, 66, 77, 82, 89, 102, 125, 127, 132, 205, 207, 208, 209, 211, 213, 214, 247, 250, 284, 291, 311, 401, 405, 1024, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055], "grammar": 386, "granada": 0, "grant": [0, 257, 272, 386], "grape": 417, "graph": [2, 55, 62, 74, 79, 81, 101, 102, 184, 240, 275, 299, 301, 341, 373, 386, 389, 400, 413, 418, 427, 449, 452, 453, 460, 461, 465, 470, 471, 479, 480, 486, 519, 593, 594, 696, 699, 700, 703, 790, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 867, 908, 954, 997, 1000, 1003, 1005, 1013, 1016, 1019, 1024, 1030, 1033, 1041, 1048, 1049, 1051, 1054, 1056], "graph_laplacian": 1048, "graph_lasso": [486, 1049], "graph_model": 301, "graph_shortest_path": [395, 1054], "graphic": [8, 57, 114, 193, 342, 360, 361, 362, 381, 392, 416, 418, 421, 800, 801, 805, 842, 924, 1000, 1001, 1007, 1019, 1034], "graphical_lasso": [2, 395, 479, 480, 1049, 1057], "graphicallasso": [2, 115, 418, 477, 478, 480, 481, 482, 483, 484, 486, 1049, 1057], "graphicallassocv": [2, 51, 115, 407, 418, 479, 481, 482, 483, 484, 486, 1049, 1053, 1055, 1057, 1059], "graphicallassocvifittedgraphicallassocv": 51, "graphlasso": [479, 1046, 1049], "graphlassocv": [480, 1043, 1049], "graphviz": [924, 1016], "grasp": [292, 1015, 1020], "grassberg": [615, 616], "grate": 1024, "graviton": 394, "gray_r": [68, 120, 128, 179, 241, 317, 338, 339, 1031], "grayscal": 68, "greasemonkei": 394, "great": [90, 191, 192, 218, 369, 386, 398, 421, 772, 1020, 1024, 1041, 1048], "greater": [62, 123, 139, 141, 192, 237, 252, 257, 266, 272, 284, 298, 305, 306, 364, 373, 382, 391, 400, 414, 415, 416, 419, 423, 449, 453, 454, 457, 460, 471, 480, 544, 549, 565, 566, 567, 568, 569, 570, 572, 573, 574, 601, 602, 605, 618, 619, 636, 648, 650, 672, 674, 675, 679, 684, 685, 686, 700, 717, 720, 728, 743, 744, 747, 750, 796, 803, 805, 806, 842, 854, 855, 862, 863, 869, 870, 875, 890, 902, 906, 909, 912, 913, 920, 921, 922, 923, 949, 969, 989, 995, 996, 997, 1000, 1001, 1006, 1010, 1015, 1016, 1044, 1049, 1052, 1054, 1055, 1056, 1058], "greater_is_bett": [152, 336, 750, 1000], "greatest": [90, 404, 416, 879, 1049], "greatli": [218, 252, 333, 386, 394, 460, 1003, 1016, 1047, 1055], "greedi": [174, 423, 425, 455, 457, 468, 567, 568, 610, 996, 1016], "greedili": [118, 174, 416, 420, 425, 468], "greek": [51, 55, 59, 71, 83, 101, 189, 416, 470, 1021], "green": [63, 114, 123, 142, 157, 162, 176, 197, 245, 315, 320, 324, 329, 335, 400, 1001, 1049, 1050, 1052, 1053], "greenhal": 1049, "greg": [1024, 1047, 1048, 1050, 1051], "gregori": [1047, 1051, 1052, 1053, 1054], "gregorystrubel": 1054, "gregov": 1049, "grei": [44, 288, 319, 356, 381], "grep": 386, "greyscal": 317, "grid": [2, 45, 47, 49, 50, 58, 62, 63, 64, 77, 89, 96, 105, 106, 107, 108, 111, 115, 148, 158, 169, 171, 173, 180, 189, 191, 192, 193, 209, 238, 245, 252, 253, 254, 258, 263, 268, 270, 272, 275, 277, 279, 282, 283, 285, 290, 298, 301, 303, 304, 312, 317, 321, 322, 324, 346, 348, 349, 355, 360, 381, 388, 393, 398, 400, 411, 417, 420, 422, 423, 424, 456, 469, 472, 480, 506, 510, 523, 530, 639, 640, 641, 655, 658, 661, 662, 664, 667, 669, 671, 684, 721, 736, 750, 793, 796, 808, 811, 812, 819, 822, 824, 838, 839, 872, 917, 993, 995, 1000, 1003, 1007, 1020, 1021, 1025, 1026, 1028, 1030, 1032, 1036, 1041, 1044, 1045, 1046, 1048, 1049, 1055, 1057, 1058, 1059], "grid_encod": 322, "grid_model": 301, "grid_posit": [62, 64], "grid_resolut": [193, 330, 347, 639, 640, 641], "grid_scores_": [1047, 1053, 1054], "grid_search": [108, 145, 259, 268, 276, 286, 335, 417, 1043, 1044, 1045, 1046, 1047, 1048], "grid_siz": [50, 96, 312, 381, 506], "grid_to_graph": [2, 82, 86, 89, 416, 424, 1033, 1054], "grid_tograph": 1044, "grid_valu": [193, 641, 1007, 1057], "gridsearch": [89, 111, 289, 1019], "gridsearchcv": [2, 43, 89, 103, 105, 107, 108, 111, 132, 145, 189, 253, 259, 268, 270, 272, 276, 277, 278, 279, 283, 286, 289, 296, 301, 303, 317, 321, 330, 334, 335, 349, 353, 369, 374, 388, 398, 400, 407, 417, 420, 423, 426, 430, 510, 528, 548, 549, 583, 607, 615, 661, 711, 750, 819, 822, 872, 882, 912, 920, 989, 996, 1000, 1004, 1014, 1015, 1019, 1020, 1021, 1029, 1030, 1034, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1055, 1056, 1058, 1059], "gridsearchcvifittedgridsearchcv": [106, 268, 272, 276, 278], "gridsearchcvinot": 259, "gridsiz": 251, "gridspec": [62, 64, 100, 263, 393], "gridspecfromsubplotspec": 393, "griffith": [1049, 1050], "grigorev": 1046, "grigorio": 742, "grigsbi": 100, "grime": [697, 701, 997], "grinsztajn": 1058, "grisel": [0, 54, 55, 72, 83, 96, 209, 241, 279, 281, 360, 361, 362, 401, 405, 1018, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "griva": [1055, 1056], "grlivarea": 149, "grobler": [0, 67, 80, 86, 88, 107, 120, 121, 203, 216, 217, 218, 242, 354, 356, 406, 1041, 1042, 1043, 1044], "groceryheist": 1054, "groenen": [698, 702, 997], "grok": 495, "groothui": [635, 990], "grother": 383, "ground": [2, 27, 58, 68, 75, 80, 84, 92, 93, 96, 111, 115, 118, 128, 156, 184, 204, 214, 220, 221, 257, 269, 281, 361, 400, 416, 711, 712, 713, 716, 720, 721, 722, 723, 725, 726, 729, 731, 732, 734, 736, 737, 738, 742, 744, 745, 746, 747, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 791, 792, 793, 794, 795, 798, 799, 803, 804, 1000, 1013, 1025, 1033, 1049], "ground_truth": [90, 306], "group": [0, 2, 51, 72, 75, 90, 93, 95, 162, 193, 195, 220, 241, 254, 269, 273, 325, 335, 340, 361, 368, 381, 391, 400, 401, 407, 416, 422, 423, 424, 441, 454, 503, 596, 597, 599, 602, 726, 796, 808, 809, 810, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 833, 834, 835, 836, 837, 839, 885, 886, 922, 923, 996, 997, 999, 1000, 1001, 1010, 1016, 1017, 1019, 1025, 1028, 1029, 1047, 1048, 1049, 1050, 1053, 1054, 1055, 1057, 1058, 1059], "group_1": 885, "group_2": 885, "group_3": 885, "group_by_dynam": 181, "group_df": 228, "group_kfold": 809, "group_prior": 273, "groupbi": [43, 155, 193, 228, 238], "groupkfold": [2, 273, 283, 335, 407, 420, 602, 813, 814, 815, 816, 817, 826, 831, 833, 834, 835, 836, 839, 1029, 1047, 1054], "groupshufflesplit": [2, 273, 420, 1029, 1047], "grow": [43, 52, 74, 197, 204, 301, 356, 362, 373, 398, 412, 418, 423, 424, 565, 566, 567, 568, 572, 573, 574, 818, 852, 853, 920, 921, 922, 923, 989, 1000, 1003, 1016, 1024, 1028, 1032, 1044, 1045], "grower": [155, 423, 569, 570], "grown": [383, 423, 561, 562, 563, 564, 565, 566, 572, 573, 920, 921, 922, 923, 1016], "growth": [1000, 1046, 1047], "grumman": 51, "grusak": 1051, "gryllo": [1046, 1049], "gryze": [1043, 1046], "grzegorz": [1048, 1051], "gs_clf": 1034, "gs_time": 289, "gsh": 289, "gsh_time": 289, "gsiisg": 1056, "gsk": 51, "gss": [420, 810], "gt": [68, 105, 106, 144, 160, 192, 268, 276, 290, 384, 386, 390, 1027], "gu": [1052, 1053, 1055], "guan": 1051, "guangguo": 1047, "guarante": [46, 47, 64, 113, 114, 155, 192, 228, 251, 298, 299, 319, 361, 369, 375, 380, 394, 395, 410, 416, 420, 421, 424, 454, 544, 653, 666, 667, 676, 680, 682, 684, 686, 695, 702, 825, 828, 852, 853, 890, 892, 895, 897, 898, 899, 900, 901, 902, 903, 905, 906, 919, 992, 996, 997, 999, 1003, 1008, 1012, 1016, 1033, 1051], "gubri": [1049, 1050], "gudmalwar": 1053, "gued": 1059, "guerin": [1047, 1048], "guess": [55, 139, 148, 420, 423, 424, 540, 546, 548, 549, 555, 796, 1000, 1014], "guestrin": 423, "guha": 1056, "gui": [1042, 1052], "guid": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 52, 62, 64, 90, 103, 125, 145, 185, 189, 192, 193, 208, 240, 285, 305, 306, 309, 325, 328, 329, 330, 331, 332, 333, 334, 335, 336, 384, 385, 386, 391, 392, 393, 394, 399, 400, 401, 407, 417, 423, 427, 428, 429, 430, 433, 439, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 467, 469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 621, 622, 623, 624, 627, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 703, 705, 706, 708, 709, 710, 711, 712, 713, 715, 716, 717, 718, 720, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 765, 766, 767, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 945, 1000, 1001, 1027, 1034, 1041, 1042, 1043, 1044, 1046, 1048, 1050, 1051, 1058, 1059, 1060], "guidanc": [398, 426], "guidelin": [2, 25, 385, 389, 391, 392, 394, 416, 423], "guiel": 502, "guilherm": 1044, "guillaum": [0, 44, 46, 106, 109, 130, 160, 176, 181, 182, 183, 185, 208, 209, 222, 241, 319, 405, 1024, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "guillem": [1050, 1051, 1056], "guillemot": [0, 263, 265, 1047, 1048], "guillermo": 1055, "guiniol": 1048, "guitar": 1056, "guitton": 1053, "guiweb": 1054, "gulati": [1046, 1047, 1048], "gun": [57, 381], "gunduz": 1059, "gunesbayir": [1056, 1057], "gunnar": [543, 949], "guo": 1054, "guoci": 1048, "gupta": [906, 1012, 1048, 1049, 1052, 1053, 1054, 1055, 1057, 1058], "gustafson": [1056, 1057], "gustav": 1047, "gustavo": [1049, 1050, 1055], "gutierrez": 1051, "guttman": 702, "guyon": [523, 601, 602, 1000], "guyon2015": 1000, "gwulf": [1045, 1046], "gyeongja": 1059, "gz": [47, 390, 404, 516, 517], "gzip": 1041, "g\u00e9ron": 1049, "g\u00f3rski": [1052, 1053], "g\u00f6khan": [44, 421, 543], "g\u00f6n\u00fcl": 1059, "g\u00fcnther": [1054, 1058], "h": [44, 45, 52, 83, 93, 125, 126, 139, 140, 158, 174, 178, 192, 265, 304, 307, 314, 321, 332, 343, 345, 362, 383, 392, 414, 416, 418, 421, 422, 423, 424, 427, 452, 527, 540, 543, 546, 548, 555, 561, 575, 576, 590, 598, 615, 616, 697, 701, 712, 716, 765, 847, 851, 852, 853, 858, 868, 883, 892, 992, 994, 996, 997, 998, 1000, 1002, 1004, 1005, 1014, 1016, 1030, 1047, 1052, 1056, 1057, 1058], "h1998": 423, "h2009": 1007, "h4dr1en": 1051, "h5py": 380, "h_": 996, "h_i": [421, 1005], "h_init": 392, "h_j": 1005, "h_l": 994, "h_m": 423, "h_pad": [125, 148, 365], "h_samples_": 868, "ha": [0, 43, 44, 47, 50, 51, 52, 62, 66, 70, 72, 79, 85, 90, 91, 92, 95, 108, 113, 114, 118, 125, 137, 144, 148, 150, 152, 155, 157, 162, 172, 173, 176, 181, 182, 183, 188, 192, 193, 194, 195, 197, 213, 217, 220, 221, 222, 226, 237, 238, 240, 247, 251, 253, 254, 257, 258, 261, 263, 264, 266, 268, 269, 272, 273, 276, 277, 278, 281, 282, 284, 289, 290, 298, 302, 305, 306, 307, 309, 316, 319, 320, 322, 324, 328, 329, 330, 331, 332, 334, 336, 338, 341, 349, 353, 354, 355, 360, 368, 369, 373, 374, 375, 380, 381, 383, 384, 385, 386, 387, 388, 390, 391, 394, 395, 398, 399, 400, 401, 404, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 423, 424, 425, 426, 428, 441, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 469, 470, 471, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 501, 502, 505, 506, 516, 517, 524, 534, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 627, 635, 636, 637, 638, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 693, 695, 696, 697, 698, 699, 700, 703, 719, 721, 728, 730, 749, 771, 782, 786, 787, 788, 801, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 822, 826, 829, 830, 831, 836, 837, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 872, 875, 876, 877, 878, 879, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 927, 931, 932, 933, 951, 969, 985, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1020, 1023, 1024, 1025, 1029, 1032, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "haan": 1050, "haar": [53, 1058], "haas": 1051, "habchi": 1051, "haberland": [1056, 1057], "haberth\u00fcr": 1048, "hack": [47, 49], "had": [43, 48, 82, 152, 155, 181, 254, 319, 325, 331, 369, 386, 387, 407, 424, 427, 452, 990, 1000, 1024, 1025, 1041, 1042, 1048, 1049, 1050, 1051, 1052, 1056], "hadamard": 388, "haddad": 1048, "hadrien": [1048, 1051], "hadshirt": 1051, "haenel": 1044, "haesun": [1053, 1056, 1057], "hafner": 1054, "hagai": 805, "hagberg": 55, "hahn": [1048, 1049], "haiat": 1053, "haidar": [1054, 1055], "hail": 325, "hailei": [1051, 1052], "hain": 381, "haitz": [1052, 1054, 1055], "hakaa1": [1048, 1049], "hal": [555, 666, 766, 767, 998], "halchenko": [0, 405, 1041, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1057], "hale": [1043, 1055], "half": [2, 43, 61, 128, 155, 252, 256, 276, 278, 290, 381, 382, 421, 423, 471, 530, 570, 601, 605, 610, 778, 871, 879, 1000, 1003, 1016], "half_cal": 605, "half_selector": 605, "halfbath": 149, "halford": [1049, 1056, 1057], "halkidi": 416, "halko": [421, 543, 549, 552, 948, 949], "hall": [996, 1048, 1052], "hallock": 1047, "halpert": [700, 997], "halv": [2, 169, 189, 270, 282, 286, 355, 411, 523, 572, 587, 808, 811, 812, 917, 1021, 1036, 1053], "halvic": 1053, "halvinggridsearchcv": [2, 289, 290, 330, 407, 587, 812, 989, 1053, 1055, 1056, 1058, 1059], "halvingrandomsearchcv": [2, 152, 290, 330, 407, 587, 811, 989, 1053, 1055, 1056, 1057, 1058, 1059], "halvingrandomsearchcvifittedhalvingrandomsearchcv": 290, "halwai": 1047, "ham": [2, 46, 458, 465, 589, 707, 711, 717, 742, 749, 786, 787, 788, 804, 1003], "hamada": 1053, "hamdi": [1058, 1059], "hammerbach": 1045, "hamming_loss": [2, 46, 711, 804, 1000, 1043, 1047, 1050], "hammingdist": 707, "hammoudeh": 1050, "hamoumi": 1054, "hampton": 1034, "hampu": 1045, "hamzeh": [0, 1044, 1045], "han": [416, 450, 458, 465, 1041, 1049, 1050, 1054], "hancock": 1051, "hand": [44, 65, 86, 88, 118, 120, 127, 128, 130, 145, 152, 169, 172, 181, 189, 192, 193, 213, 224, 227, 244, 250, 251, 253, 254, 257, 271, 272, 275, 280, 287, 292, 303, 338, 339, 349, 373, 380, 381, 383, 386, 388, 392, 394, 399, 421, 422, 423, 425, 433, 439, 510, 651, 705, 721, 796, 838, 893, 917, 989, 993, 996, 1000, 1002, 1004, 1008, 1013, 1015, 1021, 1024, 1025, 1028, 1031, 1032], "handbook": [728, 748, 1000], "handi": [84, 105, 361, 362, 387, 1057], "handk": 1057, "handl": [0, 2, 43, 48, 105, 145, 149, 155, 156, 160, 197, 204, 253, 254, 272, 280, 285, 287, 296, 298, 299, 306, 325, 328, 335, 360, 362, 368, 373, 378, 380, 384, 386, 387, 388, 395, 398, 400, 423, 424, 426, 504, 552, 585, 589, 590, 596, 597, 599, 618, 643, 654, 655, 660, 666, 667, 668, 669, 670, 676, 683, 684, 686, 689, 728, 796, 876, 885, 886, 912, 913, 917, 924, 950, 957, 960, 997, 1000, 1001, 1002, 1003, 1006, 1008, 1015, 1016, 1019, 1020, 1024, 1036, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "handle_data": 47, "handle_endtag": 47, "handle_starttag": 47, "handle_unknown": [43, 105, 144, 149, 160, 193, 194, 249, 257, 259, 261, 325, 329, 332, 885, 886, 1010, 1045, 1049, 1053, 1054], "handler": 1052, "handler_map": 306, "handlerpathcollect": 306, "handletextpad": 365, "handpick": 247, "handprint": 383, "handwritten": [51, 71, 80, 83, 87, 94, 96, 144, 172, 189, 239, 240, 242, 244, 251, 266, 276, 309, 316, 317, 338, 339, 361, 379, 416, 423, 455, 510, 549, 552, 557, 574, 696, 697, 698, 699, 700, 712, 713, 725, 745, 801, 803, 861, 873, 882, 892, 905, 997, 1003, 1021, 1025, 1036], "hang": [386, 1051, 1052], "hank": 1044, "hanmin": [0, 320, 405, 1048, 1049, 1050, 1051, 1052], "hann": 1041, "hanna": [1045, 1046, 1052], "hannah": [1051, 1053, 1055], "hannel": [1049, 1050], "hansen": 1049, "hansin": [1055, 1056], "hanu\u0161": 1058, "hanxiang": [687, 996], "hao": [1052, 1053, 1055, 1056], "haoi": 1058, "haoran": 1049, "haoyin": [1052, 1054, 1055], "happen": [2, 44, 64, 144, 208, 272, 319, 325, 361, 369, 373, 374, 384, 385, 386, 390, 391, 392, 398, 400, 401, 404, 410, 416, 418, 420, 423, 445, 523, 580, 666, 793, 890, 892, 912, 996, 1000, 1001, 1015, 1020, 1034, 1049, 1053, 1054, 1056, 1057, 1058, 1059], "happi": [192, 272, 360, 398, 401, 826, 827], "haqu": [1043, 1044, 1045], "harabasz": [2, 718], "harabaz": 1047, "hard": [48, 220, 247, 251, 278, 280, 375, 385, 398, 400, 415, 416, 421, 424, 542, 549, 577, 684, 914, 915, 916, 917, 918, 996, 1013, 1015, 1016, 1020, 1032, 1033, 1034, 1050, 1051], "hardcod": [448, 462, 1049], "harder": [287, 288, 323, 381, 385, 388, 394, 398, 416, 523, 569, 570], "hardest": 1027, "hardin": 114, "hardli": [90, 615, 616], "hardwar": [57, 342, 362, 373, 374, 381, 384, 398, 404, 410, 412, 1019, 1055, 1056], "hare": 996, "harfouch": 1057, "harikrishnan": 1043, "harizo": [1047, 1048], "harm": [360, 388, 424, 803], "harmanan": [1058, 1059], "harmon": [43, 72, 285, 361, 416, 543, 549, 737, 738, 744, 791, 803, 1000], "haroldfox": [1049, 1050], "harper": 1048, "harri": [1045, 1047, 1053, 1054], "harsanyi": 1057, "harsh": [433, 445, 477, 557, 558, 559, 561, 563, 565, 567, 569, 572, 575, 577, 618, 666, 674, 676, 682, 683, 684, 807, 830, 840, 841, 842, 843, 847, 848, 849, 850, 851, 854, 859, 862, 869, 907, 908, 912, 914, 917, 920, 922, 1051, 1053, 1056], "harshit5674": 1056, "hart": [383, 994, 1049], "hartong": 1052, "harutaka": 1054, "harvest": 325, "harwar": 398, "has_fit_paramet": [2, 395], "hasan": 1056, "hasattr": [79, 91, 97, 115, 137, 148, 238, 251, 314, 321, 360, 400, 431, 435, 441, 961, 1051], "haseeb": [1054, 1055], "hash": [2, 47, 138, 189, 255, 361, 362, 373, 375, 378, 386, 389, 398, 423, 522, 552, 565, 574, 589, 590, 597, 648, 847, 965, 992, 1021, 1034, 1036, 1042, 1045, 1048], "hashabl": [400, 880, 883, 1011], "hashcode55": 1047, "hasher": [158, 362, 424], "hashingvector": [2, 47, 362, 375, 424, 497, 596, 598, 599, 1042, 1048, 1049, 1050, 1051, 1054], "hashlib": 47, "hasil": 1045, "haskel": 1019, "hasn": 407, "hassaan": [1049, 1050], "hassan": 1054, "hassen": 1041, "hassoun": 1056, "hasti": [2, 139, 142, 143, 154, 174, 208, 277, 383, 420, 423, 527, 528, 561, 567, 568, 636, 664, 729, 731, 732, 842, 859, 905, 920, 921, 990, 994, 996, 1001, 1007, 1012, 1014, 1016], "hat": [114, 134, 274, 278, 304, 331, 384, 414, 418, 422, 423, 991, 996, 997, 1000, 1002, 1004], "hathidara": 1053, "hatwar": [1049, 1050], "hauck": 1047, "hausamann": [1049, 1050], "haussler": 184, "hav": 1027, "have": [0, 2, 25, 43, 44, 46, 47, 48, 50, 51, 52, 53, 61, 62, 63, 64, 72, 74, 77, 78, 81, 82, 85, 88, 90, 92, 95, 97, 99, 100, 104, 105, 111, 113, 118, 120, 122, 123, 130, 131, 139, 146, 148, 149, 150, 152, 155, 170, 171, 174, 176, 177, 181, 182, 183, 188, 191, 192, 193, 194, 195, 197, 199, 204, 220, 221, 222, 224, 238, 244, 247, 249, 254, 255, 257, 258, 264, 265, 266, 268, 271, 272, 278, 279, 281, 284, 285, 292, 293, 296, 299, 301, 302, 305, 306, 319, 324, 325, 326, 328, 330, 331, 335, 339, 340, 341, 346, 352, 353, 354, 356, 360, 361, 368, 369, 373, 374, 375, 380, 381, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 441, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 500, 502, 503, 504, 516, 517, 522, 531, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 589, 590, 591, 592, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 640, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 693, 695, 696, 697, 698, 699, 700, 707, 712, 713, 719, 720, 723, 728, 734, 739, 744, 750, 764, 765, 766, 767, 790, 793, 794, 800, 803, 805, 806, 807, 808, 811, 812, 813, 814, 819, 822, 826, 830, 831, 833, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 897, 898, 900, 901, 902, 903, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 932, 934, 936, 938, 949, 975, 989, 990, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1017, 1019, 1020, 1023, 1024, 1025, 1026, 1029, 1030, 1032, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "havelabeleddatado": 1027, "haversin": [2, 312, 422, 707, 770, 772, 1003, 1050, 1053], "haversine_dist": [2, 770, 1050], "haversinedist": 707, "hawaii": 181, "haxbi": 0, "haya": 1055, "hayashi": 1049, "hbgt": 155, "hd": 51, "hdb": [90, 454], "hdbscan": [2, 71, 79, 84, 100, 189, 251, 452, 520, 892, 990, 1019, 1021, 1035, 1036, 1057, 1058, 1059], "hdbscan_min_cluster_s": 79, "hdbscan_min_sampl": 79, "hdf5": 380, "hdl": [174, 383], "hdmetor": 1047, "he": [386, 734, 764, 869, 870, 902, 903, 1000, 1034, 1048, 1055, 1056], "head": [0, 52, 63, 105, 144, 159, 181, 192, 208, 209, 238, 261, 268, 325, 328, 333, 386, 394, 405, 421, 1024, 1046, 1047, 1056, 1057, 1058, 1059], "head_width": 63, "header": [54, 104, 279, 360, 361, 381, 384, 424, 496, 497, 808, 811, 812, 822], "heali": 416, "health": 336, "heap": 458, "heapq": 471, "heard": 386, "heart": 257, "heat": [160, 349, 416, 460, 470, 703], "heatingqc": 160, "heatmap": [193, 195, 199, 204, 289, 333, 349, 640, 1007], "heatmap_kw": 640, "heatmaps_": 640, "heavei": 1049, "heavi": [222, 398, 413, 1020], "heavier": [134, 418, 996], "heavili": [209, 373, 374, 386, 394, 657, 663, 786, 1017], "heavy_rain": [43, 193], "hebei": 416, "hedlund": 1057, "hedyati": 1045, "hee": [1048, 1051], "heer": 1052, "hegd": 1058, "heidelberg": [181, 416, 421, 543, 704, 734, 764, 1000], "height": [47, 54, 88, 128, 149, 150, 174, 319, 325, 335, 360, 422, 454, 501, 502, 514, 594], "heightpet_catpet_dogf64f64f64": 335, "heikki": 1012, "heilman": [1045, 1046], "heitz": 325, "held": [43, 47, 105, 132, 153, 194, 228, 265, 281, 286, 298, 420, 423, 567, 568, 569, 570, 709, 808, 811, 812, 822, 869, 870, 882, 989, 990, 999, 1008, 1034], "helder": [1045, 1054, 1055], "heldout": 227, "heldout_scor": 151, "helen": 333, "heli": 1048, "hello": [386, 394, 961, 965], "helloifeven": 961, "helmu": 1045, "help": [0, 41, 43, 48, 50, 90, 104, 108, 130, 135, 193, 204, 238, 240, 272, 279, 281, 296, 317, 346, 349, 361, 362, 369, 373, 374, 384, 386, 387, 388, 389, 390, 391, 392, 394, 395, 400, 401, 403, 410, 416, 417, 420, 424, 426, 440, 544, 585, 635, 658, 662, 673, 693, 694, 700, 722, 848, 920, 921, 922, 923, 990, 994, 995, 997, 999, 1000, 1002, 1004, 1010, 1011, 1016, 1018, 1019, 1020, 1023, 1024, 1034, 1047, 1048, 1049, 1052, 1055, 1059], "helper": [44, 45, 128, 238, 289, 379, 388, 389, 399, 400, 420, 476, 583, 910, 1029, 1030, 1041, 1048, 1049, 1050, 1054], "helvetica": [924, 926], "heme": 1058, "hempstalk": 1048, "henc": [72, 95, 106, 192, 224, 251, 272, 287, 349, 360, 361, 373, 381, 388, 390, 392, 400, 404, 416, 420, 423, 424, 495, 516, 547, 549, 550, 551, 571, 598, 651, 654, 660, 668, 670, 680, 695, 712, 713, 717, 723, 739, 765, 794, 803, 827, 828, 847, 848, 849, 850, 851, 887, 957, 997, 999, 1000, 1001, 1006, 1007, 1010, 1020, 1048, 1049, 1052, 1053, 1055], "hendrik": [0, 61, 62, 63, 64, 176, 177, 179, 180, 181, 182, 183, 185, 253, 405, 1041, 1044, 1045, 1046, 1047], "henri": [1046, 1047, 1048, 1049, 1051, 1052, 1053, 1055, 1056], "henriqu": 1060, "henrymooresc": [1055, 1056], "hepe": [687, 996], "here": [43, 47, 48, 51, 52, 53, 55, 61, 64, 92, 93, 101, 111, 115, 120, 121, 123, 127, 128, 130, 131, 132, 133, 135, 139, 142, 145, 149, 153, 155, 160, 171, 174, 176, 184, 185, 192, 193, 194, 197, 199, 204, 209, 213, 220, 224, 226, 235, 236, 238, 240, 242, 247, 252, 254, 257, 258, 264, 265, 266, 271, 272, 275, 276, 278, 280, 281, 283, 287, 288, 290, 292, 296, 299, 301, 308, 315, 316, 317, 321, 324, 330, 332, 335, 338, 340, 349, 353, 356, 358, 362, 364, 369, 373, 374, 375, 380, 381, 384, 385, 386, 387, 388, 390, 391, 392, 394, 398, 399, 407, 410, 412, 413, 415, 416, 417, 419, 420, 421, 422, 423, 424, 427, 429, 445, 448, 449, 450, 451, 452, 453, 454, 455, 457, 460, 472, 480, 483, 544, 546, 547, 551, 552, 575, 576, 577, 578, 589, 590, 592, 596, 599, 602, 610, 636, 638, 655, 659, 661, 663, 669, 671, 673, 681, 683, 697, 699, 703, 707, 720, 734, 754, 764, 802, 807, 808, 811, 812, 814, 822, 830, 831, 832, 833, 834, 835, 836, 837, 839, 848, 852, 853, 876, 884, 887, 890, 893, 904, 905, 915, 966, 989, 992, 996, 997, 998, 999, 1000, 1003, 1006, 1010, 1012, 1013, 1014, 1015, 1019, 1020, 1023, 1024, 1025, 1026, 1032, 1041, 1049, 1054], "hereaft": 401, "hereund": 1006, "herilalaina": [1048, 1049, 1051], "hermano": [1056, 1057], "hermida": [1050, 1054], "hernandez": 1000, "hern\u00e1ndez": 1000, "hero": [418, 429, 483], "herrou": 1055, "hershei": 1000, "hertel": 1058, "herv": 1045, "hervieu": 1041, "herv\u00e9": 1045, "heryanto": 1048, "hesit": 386, "hessian": [240, 241, 242, 423, 569, 570, 656, 666, 667, 677, 688, 697, 701, 996, 1004, 1035, 1036, 1056], "hessian_tol": [697, 701], "heterogen": [43, 48, 61, 90, 103, 105, 189, 193, 220, 261, 324, 328, 378, 380, 398, 472, 496, 549, 589, 599, 721, 872, 876, 912, 997, 1007, 1010, 1019, 1021, 1036, 1045, 1049, 1051, 1052, 1059], "heteroscedast": [125, 132, 152, 222, 421, 888, 900], "heteroschedast": 1000, "heuer": 1044, "heurist": [51, 54, 151, 257, 360, 374, 416, 425, 457, 460, 469, 470, 516, 517, 545, 547, 554, 684, 685, 686, 699, 703, 811, 812, 914, 915, 916, 917, 918, 937, 997, 998, 1003, 1014, 1016, 1024, 1032, 1041, 1042, 1046, 1050, 1053, 1054], "hexbin": 251, "hexdigest": 47, "hgbdt": 145, "hgbdt_model": 193, "hgbdt_model_without_interact": 193, "hgbdt_preprocessor": 193, "hgbt": [145, 155, 423], "hgbt_cst": 155, "hgbt_no_cst": 155, "hgbt_quantil": 155, "hhu": [657, 1050], "hi": [0, 417, 1000, 1034], "hibon": 1048, "hida": [1056, 1057], "hidden": [43, 193, 316, 317, 386, 394, 413, 421, 868, 869, 870, 1004, 1005, 1019, 1041, 1052], "hidden_layer_s": [193, 258, 314, 316, 869, 870, 1004], "hide": [78, 386, 394, 847, 848, 849, 850, 851, 1044, 1049, 1057], "hideaki": 1055, "hierarch": [2, 53, 59, 71, 74, 75, 79, 81, 87, 88, 89, 92, 189, 195, 244, 332, 368, 400, 424, 449, 451, 453, 454, 512, 520, 522, 530, 538, 555, 739, 865, 892, 1017, 1020, 1021, 1035, 1036, 1041, 1044, 1045, 1057], "hierarchi": [76, 195, 386, 458, 464, 471, 1005, 1033], "higgin": [1058, 1059], "high": [0, 37, 43, 48, 50, 51, 62, 64, 67, 72, 75, 79, 84, 90, 92, 97, 100, 104, 108, 113, 114, 127, 128, 142, 144, 145, 146, 147, 152, 153, 155, 156, 158, 166, 167, 174, 176, 182, 188, 191, 193, 194, 195, 204, 215, 221, 222, 224, 234, 240, 241, 242, 247, 251, 263, 269, 276, 280, 284, 285, 294, 305, 306, 314, 316, 321, 323, 324, 325, 326, 334, 341, 346, 348, 349, 360, 361, 366, 367, 373, 381, 383, 386, 391, 394, 395, 398, 399, 413, 414, 415, 416, 420, 422, 423, 424, 425, 426, 452, 455, 457, 458, 460, 477, 490, 491, 492, 561, 562, 565, 566, 567, 568, 571, 572, 573, 574, 575, 576, 652, 678, 679, 687, 697, 700, 701, 734, 739, 750, 754, 764, 797, 800, 816, 818, 852, 853, 857, 886, 887, 891, 893, 914, 916, 917, 920, 921, 922, 923, 969, 989, 994, 995, 996, 997, 999, 1000, 1003, 1004, 1006, 1008, 1010, 1012, 1015, 1016, 1017, 1019, 1020, 1025, 1026, 1028, 1034, 1041, 1042, 1044, 1045, 1049, 1052, 1053, 1054, 1055, 1056], "high_cardin": 325, "high_cardinality_featur": 325, "high_cardinalityindex": 325, "high_i": 215, "high_precision_cv_result": 276, "high_recall_cv_result": 276, "high_x": 215, "higher": [43, 52, 92, 113, 128, 132, 139, 142, 144, 145, 152, 156, 172, 176, 178, 183, 184, 192, 193, 194, 197, 220, 221, 224, 238, 244, 245, 269, 271, 272, 276, 278, 281, 293, 304, 324, 349, 353, 360, 361, 362, 369, 373, 381, 384, 388, 413, 415, 416, 418, 423, 425, 426, 427, 452, 456, 457, 479, 486, 517, 540, 547, 551, 556, 561, 562, 565, 566, 567, 568, 569, 570, 572, 573, 574, 581, 596, 599, 615, 616, 627, 635, 639, 643, 645, 654, 655, 660, 661, 668, 669, 670, 671, 684, 686, 687, 712, 732, 736, 760, 793, 805, 808, 811, 812, 814, 822, 829, 831, 836, 839, 858, 861, 887, 904, 905, 906, 912, 913, 914, 915, 916, 917, 918, 925, 992, 996, 997, 999, 1000, 1003, 1007, 1010, 1014, 1015, 1032, 1034, 1042, 1047, 1049, 1056, 1058], "highest": [2, 55, 57, 63, 115, 170, 174, 224, 276, 278, 289, 330, 360, 386, 398, 414, 416, 420, 423, 425, 445, 563, 565, 572, 600, 603, 604, 606, 607, 608, 611, 612, 614, 643, 645, 734, 764, 802, 805, 808, 811, 812, 822, 909, 920, 951, 989, 996, 1000, 1001, 1004, 1014, 1016, 1053], "highest_protocol": 410, "highli": [43, 48, 64, 106, 113, 114, 127, 135, 156, 204, 215, 225, 272, 278, 281, 287, 315, 353, 361, 373, 374, 386, 388, 392, 398, 414, 416, 420, 423, 424, 460, 470, 504, 571, 679, 700, 820, 822, 868, 996, 1000, 1003, 1004, 1006, 1014, 1015, 1018, 1019], "highlight": [43, 54, 90, 105, 113, 123, 143, 144, 157, 174, 176, 177, 182, 187, 188, 193, 194, 197, 220, 221, 222, 238, 249, 259, 260, 261, 272, 273, 290, 292, 296, 301, 323, 325, 341, 360, 362, 368, 386, 390, 391, 394, 398, 426, 451, 454, 455, 472, 475, 498, 499, 504, 509, 510, 512, 520, 523, 529, 532, 546, 549, 569, 570, 572, 573, 575, 607, 610, 636, 638, 640, 642, 648, 654, 656, 660, 666, 677, 688, 696, 705, 709, 710, 725, 726, 740, 750, 756, 786, 796, 803, 807, 808, 809, 811, 812, 814, 822, 830, 831, 834, 835, 838, 854, 856, 873, 877, 882, 885, 886, 887, 891, 892, 893, 909, 910, 912, 917, 920, 921, 944, 997, 1000, 1008, 1010, 1015, 1021, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "highlight_min": [152, 209], "higuera": 380, "hila": 416, "hilbert": [225, 878, 992, 1010], "hilferti": 113, "hill": [416, 456, 469, 1051], "him": 424, "himanshu": [1052, 1055], "hind": 1055, "hinder": 1051, "hing": [2, 62, 227, 230, 232, 286, 346, 347, 351, 353, 400, 674, 684, 743, 912, 919, 996, 1014, 1015, 1034], "hinge_loss": [2, 353, 1000, 1045, 1053, 1054], "hinrich": 421, "hint": [192, 373, 387, 391, 407, 456, 1000, 1032], "hinton": [700, 861, 868, 869, 870, 997, 1003, 1004, 1005], "hintz": 1047, "hiramatsu": 1058, "hirofumi": [1052, 1053], "hirsch": 1049, "hirschberg": [416, 725, 745, 803], "hirzel": 1054, "hispan": 192, "hist": [43, 62, 64, 88, 109, 141, 145, 220, 222, 251, 257, 272, 284, 304, 319, 323, 325, 332, 335, 423], "hist_drop": 149, "hist_n": 149, "hist_nbin": 319, "hist_no_interact": 333, "hist_one_hot": 149, "hist_ordin": 149, "hist_quantil": 332, "hist_x0": 319, "hist_x1": 319, "histgradientboost": 1053, "histgradientboostingclassifi": [2, 144, 145, 272, 328, 329, 330, 331, 333, 335, 374, 410, 567, 572, 640, 641, 990, 1019, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "histgradientboostingclassifierhistgradientboostingclassifi": 272, "histgradientboostingclassifierifittedhistgradientboostingclassifi": 272, "histgradientboostingregressor": [2, 43, 46, 52, 140, 145, 149, 152, 153, 155, 157, 160, 187, 193, 220, 325, 328, 329, 330, 331, 333, 334, 335, 390, 423, 568, 573, 640, 641, 643, 990, 1007, 1019, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "histgradientboostingregressor__interaction_cst": 193, "histgradientboostingregressor__max_depth": 149, "histgradientboostingregressor__max_it": 149, "histgradientboostingregressorhistgradientboostingregressor": [160, 325], "histgradientboostingregressorifittedhistgradientboostingregressor": [157, 333], "histogram": [2, 52, 62, 64, 88, 138, 140, 144, 149, 150, 152, 153, 157, 189, 220, 228, 251, 277, 279, 284, 304, 319, 330, 332, 334, 335, 414, 498, 504, 567, 568, 569, 570, 572, 573, 640, 650, 750, 756, 766, 767, 798, 808, 813, 829, 835, 838, 992, 998, 1010, 1021, 1035, 1036, 1053, 1056, 1058], "histor": [51, 220, 272, 1020], "histori": [51, 567, 568, 1041], "hit": [222, 392], "hitesh": 1053, "hjortkj\u00e6r": 1055, "hkey_local_machin": 404, "hline": 127, "hlle": 997, "hmasdev": 1055, "hmc": 51, "hmm": [1041, 1042, 1043, 1044, 1046], "hmmlearn": 1019, "hn": 392, "hnyk": [1047, 1048], "ho": [143, 423, 563, 564, 1000, 1046, 1049, 1050, 1055], "hoang": [1050, 1051], "hobson": 1047, "hoc": [173, 174, 189, 270, 272, 281, 296, 336, 341, 400, 415, 504, 666, 824, 830, 835, 873, 892, 1021], "hochberg": [603, 1047, 1048], "hochreit": [413, 727], "hockei": [57, 381], "hoctor": 1053, "hoda1394": 1053, "hoenig": 1041, "hoesli": 423, "hoffman": [421, 544, 1046, 1053], "hogan": 1049, "hoh": 1049, "hold": [47, 52, 63, 64, 220, 224, 254, 272, 279, 368, 379, 386, 387, 388, 400, 414, 416, 420, 423, 424, 426, 511, 565, 569, 572, 597, 640, 641, 642, 744, 808, 811, 812, 822, 848, 879, 880, 885, 886, 893, 896, 920, 922, 990, 994, 1000, 1004, 1014, 1015, 1016, 1025, 1034, 1049, 1053, 1059], "holder": 1034, "holdgraf": 1049, "holdselig": 424, "hole": [189, 239, 240, 245, 538, 700, 701, 1021, 1055], "holger": 1048, "holidai": [43, 193], "holm": [843, 1001, 1058], "holman": 1056, "holmstr\u00f6m": 1043, "holohan": [1056, 1058], "holt": [0, 406, 1041], "holub": 542, "home": [0, 2, 7, 51, 141, 160, 180, 182, 184, 185, 264, 317, 333, 354, 381, 384, 394, 404, 494, 507, 687, 1024], "homebrew": [389, 404], "homepag": [381, 538, 1016], "homm": 1056, "homo": 93, "homogen": [2, 72, 73, 74, 79, 81, 84, 90, 93, 361, 381, 398, 400, 418, 423, 426, 454, 622, 712, 725, 739, 744, 745, 765, 803, 997, 998, 1000, 1050], "homogeneity_completeness_v_measur": [2, 416, 1050], "homogeneity_scor": [2, 73, 84, 93, 361, 416, 725, 744, 803, 1000], "homomorph": 1019, "homoscedast": [132, 250, 323, 1000, 1049], "homoschedast": 1000, "honda": 51, "honei": 994, "hong": [1047, 1049, 1053, 1054, 1055, 1057, 1059], "hongh": 1049, "hongkahjun": 1048, "honglu": 1051, "hongshaoyang": 1056, "honl": [1053, 1054], "honolulu": 1000, "honor": 325, "hood": [410, 996, 1015], "hoover": [1046, 1047, 1048, 1050], "hope": [30, 44, 238, 400, 1050], "hopefulli": [281, 394, 1041], "hopfensperg": [1058, 1059], "hopper": 1046, "horizont": [66, 125, 240, 252, 319, 322, 391, 400, 472, 523, 705, 709], "horizontal_distance_to_hydrologi": 499, "horizontalalign": [51, 63, 67, 75, 79, 80, 97, 131, 247, 263, 314, 321], "hornik": 643, "hornstein": 1056, "horrel": 1048, "hoshia": 1055, "hossein": [1049, 1050, 1051], "host": [0, 145, 334, 360, 381, 386, 390, 394, 395, 905, 1034, 1057], "hot": [2, 43, 105, 144, 147, 160, 192, 220, 287, 320, 321, 325, 330, 349, 400, 423, 424, 559, 574, 589, 656, 666, 667, 677, 688, 875, 877, 879, 880, 883, 885, 886, 893, 996, 1010, 1049, 1055, 1056], "hot_r": [51, 319], "hotel": 1024, "hotspot": 392, "hotter": 147, "hour": [43, 155, 192, 193, 335, 386, 392, 504, 997, 1018], "hour_co": 43, "hour_df": 43, "hour_sin": 43, "hour_workday_interact": 43, "hourli": [43, 155, 192], "hourly_wag": 191, "hous": [2, 109, 150, 160, 187, 188, 272, 319, 330, 379, 498, 1036], "house_pric": [109, 160], "houseag": [319, 330, 381, 498], "household": 381, "housestyl": [149, 160], "hover": 335, "hover_data": [145, 279], "how": [0, 43, 44, 46, 47, 48, 49, 52, 58, 59, 62, 63, 64, 68, 69, 72, 85, 86, 87, 88, 92, 95, 103, 104, 105, 108, 111, 113, 118, 134, 139, 140, 143, 147, 148, 149, 150, 152, 153, 155, 158, 160, 171, 172, 183, 189, 192, 193, 194, 195, 197, 201, 209, 210, 216, 221, 222, 223, 224, 227, 228, 234, 238, 244, 245, 249, 252, 254, 256, 257, 258, 260, 269, 272, 273, 274, 276, 278, 279, 280, 285, 287, 288, 290, 291, 292, 293, 298, 299, 301, 302, 303, 305, 306, 316, 324, 326, 329, 330, 331, 334, 335, 346, 347, 349, 352, 353, 356, 360, 361, 364, 368, 373, 374, 375, 381, 384, 385, 387, 388, 389, 391, 394, 399, 400, 401, 407, 410, 412, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 430, 440, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 474, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 512, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 630, 631, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 712, 728, 765, 800, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 835, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 984, 989, 990, 994, 995, 996, 997, 999, 1000, 1006, 1007, 1008, 1010, 1012, 1013, 1015, 1016, 1018, 1020, 1024, 1025, 1027, 1029, 1034, 1036, 1041, 1043, 1046, 1052, 1055, 1056, 1057], "howel": 1048, "howev": [0, 43, 44, 46, 52, 53, 61, 62, 64, 72, 82, 84, 88, 90, 95, 106, 109, 111, 115, 117, 130, 132, 142, 144, 145, 149, 152, 153, 160, 171, 174, 176, 181, 182, 193, 194, 201, 209, 220, 224, 241, 244, 245, 247, 253, 254, 257, 272, 278, 285, 292, 293, 296, 298, 299, 304, 315, 319, 330, 336, 353, 356, 360, 361, 369, 373, 374, 375, 380, 381, 383, 385, 386, 388, 392, 394, 398, 400, 407, 410, 412, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 448, 451, 455, 457, 459, 462, 467, 504, 516, 540, 549, 559, 575, 589, 590, 591, 597, 614, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 638, 640, 641, 646, 651, 663, 664, 680, 695, 700, 703, 708, 771, 773, 808, 811, 812, 822, 835, 839, 840, 851, 869, 870, 875, 884, 885, 890, 914, 915, 917, 928, 969, 989, 990, 993, 994, 995, 996, 997, 999, 1000, 1001, 1003, 1004, 1005, 1007, 1008, 1010, 1014, 1015, 1016, 1025, 1029, 1032, 1050, 1051, 1053, 1054, 1057], "hoyer": [421, 1044], "hp": [51, 1034], "hpq": 51, "hrishikesh": [1042, 1043], "hristo": [1049, 1056], "hsiang": [666, 1045], "hsieh": 1047, "hspace": [45, 53, 54, 79, 80, 97, 125, 238, 247, 263, 265, 266, 269, 304, 330, 339, 346, 1030], "hstack": [53, 69, 77, 162, 170, 245, 256, 273, 352, 420, 871], "hsuan": 1046, "ht2001": 1000, "htf": 423, "htm": [920, 921], "html": [2, 43, 47, 51, 63, 105, 106, 144, 146, 147, 156, 157, 160, 163, 171, 174, 181, 185, 192, 193, 194, 197, 201, 248, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 333, 335, 340, 368, 381, 383, 386, 387, 389, 390, 394, 417, 420, 424, 430, 495, 516, 517, 666, 847, 851, 945, 998, 1019, 1020, 1052, 1053, 1054, 1055, 1056, 1058, 1059], "htmledit": [847, 851, 998], "htmlparser": 47, "htsedebenham": 1056, "http": [43, 45, 46, 47, 51, 52, 55, 61, 105, 153, 160, 174, 185, 188, 197, 220, 228, 236, 238, 245, 248, 292, 296, 298, 299, 316, 380, 381, 383, 384, 386, 390, 391, 392, 394, 398, 400, 404, 416, 420, 425, 450, 457, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 510, 516, 517, 518, 538, 539, 542, 545, 549, 603, 644, 649, 652, 657, 666, 672, 674, 675, 676, 679, 684, 687, 690, 691, 693, 694, 700, 703, 713, 729, 731, 732, 766, 767, 777, 847, 849, 850, 851, 854, 855, 860, 861, 862, 863, 868, 890, 905, 906, 907, 920, 921, 996, 998, 1000, 1013, 1016, 1030, 1051], "hu": [1046, 1049, 1051], "hua": [571, 1006], "huang": [381, 666, 1047, 1052], "huangk10": 1052, "huard": 1041, "huber": [25, 202, 230, 423, 568, 657, 684, 686, 1014, 1041, 1043, 1044, 1053], "huberlossfunct": 1054, "huberregressor": [2, 89, 176, 189, 198, 218, 224, 225, 226, 326, 532, 678, 679, 680, 686, 687, 996, 1021, 1047, 1048, 1049, 1050], "hubert": [416, 713, 723, 794], "hubert1985": 713, "hudson": 333, "hue": [155, 268, 278, 324, 383], "huerta": 1051, "hug": [0, 174, 323, 405, 1049, 1050, 1051, 1052, 1053, 1054, 1055], "huge": [222, 225, 373, 392, 635, 1044], "hugh": [887, 1043, 1054], "hugo": [45, 381, 1047, 1052, 1053, 1054, 1055], "hugorichard": 1053, "hugu": 1045, "hui": [143, 208, 546, 548, 555, 664, 996], "huiginn": 1041, "huilgolkar": [1042, 1043], "hujiahong726": 1057, "hull": 1058, "humahn": 1056, "human": [125, 193, 360, 416, 421, 869, 870, 1000, 1007, 1050], "humid": [43, 193, 1007], "hunan": 1049, "hundr": [77, 151, 241, 323, 381, 420, 423, 569, 570, 997, 1052], "hungarian": [413, 727], "hunt": 1056, "hunter": 1050, "hurt": [373, 542, 1049], "husak": 1055, "huszar": 1024, "hut": [700, 997, 1046, 1048, 1051], "huynh": [1051, 1053], "hv": 424, "hvassard": 1055, "hwan": 1052, "hwang": 1047, "hybrid": [454, 657, 1019], "hye": 1052, "hyper": [2, 43, 64, 105, 145, 271, 272, 278, 283, 317, 349, 369, 388, 398, 399, 400, 411, 420, 423, 425, 476, 652, 653, 812, 820, 822, 868, 910, 995, 996, 1000, 1003, 1014, 1015, 1025, 1036, 1041, 1055], "hyperband": 989, "hyperbol": [353, 650, 869, 870, 998, 1004], "hypercub": [247, 523], "hyperlink": 1043, "hyperparamet": [2, 105, 107, 108, 155, 176, 177, 183, 184, 187, 189, 193, 199, 204, 209, 234, 238, 247, 257, 270, 272, 276, 281, 283, 289, 290, 301, 317, 360, 388, 400, 416, 420, 421, 423, 426, 510, 543, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 651, 661, 667, 673, 681, 684, 736, 793, 808, 822, 917, 989, 994, 995, 996, 999, 1000, 1002, 1004, 1006, 1014, 1020, 1021, 1034, 1043, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1057], "hyperparameter_baseline_similar": 184, "hyperparameter_grid": 335, "hyperparameter_length_scal": 623, "hyperplan": [122, 141, 179, 189, 198, 212, 229, 255, 281, 344, 345, 346, 347, 348, 349, 353, 354, 520, 639, 666, 667, 674, 676, 682, 683, 684, 685, 912, 914, 916, 917, 1014, 1015, 1021], "hyperspher": [382, 1019], "hypothes": 996, "hypothesi": [152, 278, 284, 420, 698, 702, 837, 997], "hypothet": 64, "hyunjin": 1041, "hyvarinen": [428, 541], "h\u00e9lion": 1052, "i": [0, 2, 8, 30, 37, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 308, 309, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 343, 347, 348, 349, 353, 354, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 374, 375, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 394, 395, 399, 400, 401, 403, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 433, 436, 437, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 516, 517, 518, 519, 520, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 581, 583, 584, 585, 586, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 781, 782, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 947, 948, 949, 951, 954, 955, 957, 958, 959, 960, 961, 962, 963, 965, 966, 967, 969, 970, 971, 972, 974, 975, 981, 984, 985, 986, 987, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1023, 1025, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1037, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "i_alpha_optim": 291, "i_ax": 299, "i_dataset": [79, 97, 247], "i_j": 1008, "iain": [174, 383, 996], "iampat": 1049, "ian": [1043, 1045, 1050, 1051, 1053, 1056, 1057, 1059], "iasoon": 1055, "ibay": 1041, "ibieta": 1054, "ibm": [51, 57, 342, 362, 381], "ibn": 1041, "ibnukhsein": 1058, "ibraheem": 1050, "ibrahima": 1051, "ibraim": [1046, 1047, 1048], "ib\u00e1\u00f1ez": [1049, 1050, 1053], "ic": [47, 296, 330, 380, 383, 403, 508, 510, 518, 640, 641, 1036, 1053, 1054], "ica": [11, 127, 428, 1016, 1035, 1036], "ica_estim": 125, "icann": 704, "icassp": 1000, "icdm": [571, 1006], "icdmw": 416, "ice_lines_kw": 640, "icml": [62, 64, 414, 416, 424, 445, 447, 847, 849, 868, 1000, 1002, 1014, 1018], "icml03": 849, "icml09": [539, 545], "icon": [335, 388], "icyblad": 1048, "id": [2, 45, 57, 238, 312, 368, 380, 381, 386, 394, 418, 420, 424, 430, 502, 503, 504, 924, 926, 944, 1030, 1034, 1049, 1050, 1053], "id3": [1022, 1036], "idea": [44, 88, 113, 114, 145, 174, 181, 192, 221, 240, 272, 304, 349, 364, 373, 374, 386, 391, 392, 418, 419, 420, 421, 422, 423, 425, 615, 616, 996, 997, 1000, 1003, 1006, 1018, 1024, 1034], "ideal": [220, 222, 238, 272, 275, 278, 285, 287, 288, 369, 385, 386, 387, 390, 391, 394, 398, 400, 414, 415, 734, 764, 989, 999, 1014, 1015, 1020, 1023], "idelberg": 1058, "ident": [52, 57, 99, 151, 215, 220, 238, 247, 251, 343, 360, 381, 388, 400, 413, 416, 417, 418, 420, 426, 429, 446, 447, 460, 472, 473, 481, 483, 484, 487, 488, 489, 496, 511, 559, 567, 568, 572, 573, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 651, 687, 688, 707, 712, 713, 744, 793, 803, 810, 813, 823, 824, 827, 828, 854, 855, 861, 869, 870, 876, 877, 889, 901, 920, 921, 993, 994, 997, 1000, 1003, 1004, 1015, 1045, 1049, 1050, 1051, 1055, 1059], "identif": [381, 386, 416, 505, 989, 1026], "identifi": [58, 121, 127, 133, 152, 153, 191, 192, 220, 223, 224, 266, 268, 276, 281, 287, 308, 326, 330, 353, 360, 361, 380, 381, 385, 386, 390, 391, 400, 415, 416, 417, 420, 423, 424, 454, 458, 465, 495, 504, 516, 517, 563, 564, 565, 566, 571, 572, 573, 574, 614, 651, 657, 707, 720, 782, 837, 858, 877, 907, 908, 989, 996, 1000, 1006, 1013, 1024, 1032, 1048, 1050, 1055, 1056], "idf": [2, 54, 57, 251, 360, 361, 362, 381, 421, 529, 552, 596, 597, 598, 599, 851, 859, 884, 989, 998, 1002, 1010, 1034, 1041], "idf_": [424, 598, 599, 1049], "idier": [421, 546, 548, 555], "idiom": 392, "idiosyncrat": 388, "idl": 1052, "ido": [1056, 1057], "idpol": [220, 238], "idx": [50, 57, 80, 90, 134, 141, 145, 148, 155, 161, 185, 193, 195, 204, 212, 219, 220, 229, 241, 272, 365, 417, 420], "idx_a": 287, "idx_b": 287, "idx_r": 219, "idx_sort": 220, "idxmax": 356, "idxmin": 276, "ie": [75, 101, 126, 448, 712, 996, 1010], "ieee": [98, 112, 114, 383, 416, 418, 425, 429, 456, 483, 542, 571, 672, 693, 694, 733, 777, 996, 1000, 1006], "ieeexplor": 777, "ieic": [546, 548, 555], "iem": 666, "if_binari": [192, 261, 885, 1010, 1052], "if_delegate_has_method": [1054, 1055], "iff": [600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 883], "iforest": 257, "iforest_kw": 257, "iglesi": 1056, "ignacio": 1044, "ignor": [2, 43, 45, 47, 55, 79, 84, 90, 97, 105, 139, 141, 144, 149, 157, 160, 193, 208, 220, 235, 249, 254, 259, 261, 269, 315, 316, 324, 325, 329, 332, 353, 354, 361, 374, 386, 388, 390, 392, 400, 404, 407, 416, 417, 423, 424, 434, 435, 438, 441, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 468, 469, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 496, 511, 516, 517, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 587, 589, 590, 591, 596, 597, 598, 599, 602, 605, 610, 611, 618, 619, 635, 636, 637, 638, 640, 641, 643, 647, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 715, 719, 721, 722, 734, 737, 738, 746, 763, 764, 771, 777, 782, 786, 791, 792, 795, 796, 805, 806, 807, 809, 810, 811, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 869, 870, 871, 872, 875, 876, 877, 878, 879, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 904, 905, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 975, 996, 997, 1000, 1002, 1006, 1010, 1015, 1030, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1058, 1059], "ignore_attribut": 380, "ignore_error": 89, "ignore_implicit_zero": [889, 901], "ignore_ti": [734, 764], "ignore_warn": [228, 321, 1047], "ignored_new_col": 417, "ignorerevsfil": 386, "igor": [1047, 1048, 1054], "ih": 304, "ii": [50, 126, 193, 227, 273, 383, 424, 590, 591, 597, 646, 674, 675, 875, 884, 996, 1010, 1018, 1058], "iid": 1049, "iii": [1034, 1055, 1058], "iijima": 1050, "iinfo": 1056, "ij": [278, 309, 413, 416, 421, 546, 548, 555, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 996, 997, 1000, 1002, 1005, 1010, 1015], "ijcnn": 1000, "ijcv": 1000, "ijet": 416, "ik": [996, 1000], "ikeda": 1053, "ikko": 1054, "il": [49, 672, 693, 694, 996, 1000], "ilambharathi": [1044, 1045], "ili": [1057, 1058], "ilic": 1054, "ilion": 1055, "iliya": 1056, "iljin": [1056, 1057], "ill": [75, 115, 225, 317, 479, 480, 486, 658, 659, 662, 663, 664, 690, 691, 996, 999, 1033, 1051], "illustr": [48, 60, 61, 63, 67, 69, 87, 91, 92, 104, 105, 108, 109, 111, 113, 118, 123, 127, 139, 142, 147, 154, 155, 157, 159, 160, 169, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 189, 191, 193, 194, 197, 209, 216, 217, 220, 222, 224, 228, 230, 233, 234, 237, 238, 240, 241, 243, 245, 247, 249, 250, 252, 253, 254, 256, 267, 272, 278, 285, 290, 291, 292, 300, 308, 322, 324, 327, 328, 330, 336, 341, 349, 350, 354, 356, 357, 361, 362, 367, 369, 373, 383, 386, 391, 394, 399, 415, 419, 421, 423, 424, 523, 618, 619, 621, 622, 623, 627, 630, 631, 861, 989, 996, 1000, 1003, 1006, 1012, 1013, 1014, 1015, 1021, 1024, 1025], "iloc": [43, 155, 160, 192, 193, 238, 278, 302], "ilya": 1048, "im": [125, 135, 289, 303], "im_": 705, "im_kw": [705, 1055], "imacul": 1047, "imag": [2, 42, 45, 53, 58, 59, 68, 71, 74, 75, 76, 79, 81, 83, 86, 89, 93, 97, 102, 104, 120, 124, 125, 130, 147, 172, 174, 180, 189, 211, 241, 249, 252, 256, 276, 308, 316, 317, 329, 338, 339, 360, 361, 378, 379, 381, 383, 386, 391, 394, 400, 404, 409, 415, 416, 421, 449, 453, 460, 470, 501, 502, 503, 504, 510, 511, 514, 515, 542, 543, 545, 549, 591, 592, 593, 594, 595, 615, 616, 699, 705, 746, 838, 882, 996, 1000, 1001, 1003, 1005, 1012, 1016, 1019, 1021, 1024, 1025, 1030, 1031, 1033, 1034, 1036, 1041, 1044, 1049, 1050, 1054, 1056, 1057], "image_arrai": 83, "image_array_sampl": 83, "image_height": [591, 592, 595], "image_index": [338, 339], "image_nam": 514, "image_patch": 595, "image_reconstruct": 595, "image_s": 595, "image_shap": [125, 256], "image_width": [591, 592, 595], "imagebox": 241, "imageio": 380, "imagenet": [869, 870], "images_approx": 1033, "images_restor": 86, "imagin": [126, 176, 254, 353, 420, 421, 424, 996], "imamura": 1055, "imbal": [271, 281, 292, 420, 715, 737, 738, 746, 791, 792, 795, 796, 1000], "imbalanc": [220, 272, 281, 285, 287, 292, 361, 398, 414, 420, 711, 716, 795, 809, 813, 849, 1000, 1002, 1008, 1019], "imbert": [1048, 1050, 1053, 1055, 1058, 1059], "img": [44, 85, 101, 514, 594], "img_height": 591, "img_shap": 147, "img_to_graph": [2, 81, 101, 424, 1044, 1054], "img_width": 591, "imit": 360, "immanuel": [0, 1041, 1042, 1046], "immedi": [90, 386, 398, 808, 822, 833, 834, 1049], "immens": 1024, "immensu": 1049, "immers": [698, 702], "immobil": 43, "immut": 410, "imp": 990, "imp_mean": [635, 638], "imp_reshap": 147, "impact": [51, 52, 62, 71, 72, 77, 78, 99, 109, 139, 170, 189, 191, 192, 193, 200, 222, 224, 238, 257, 271, 272, 296, 302, 324, 333, 356, 361, 369, 373, 374, 379, 398, 401, 414, 416, 421, 455, 457, 544, 548, 555, 598, 674, 675, 676, 680, 682, 684, 685, 686, 700, 802, 808, 811, 812, 822, 835, 852, 853, 854, 889, 901, 912, 913, 935, 949, 971, 974, 989, 999, 1007, 1015, 1021, 1048, 1051, 1054], "imped": 394, "imperfect": [736, 793, 1000, 1043], "imperfectli": [711, 742, 1000], "implant": 59, "implement": [2, 13, 30, 45, 46, 52, 53, 55, 81, 91, 114, 125, 145, 155, 188, 195, 197, 204, 205, 209, 234, 238, 240, 247, 253, 254, 272, 276, 278, 287, 296, 298, 299, 301, 304, 322, 328, 329, 330, 331, 332, 334, 360, 362, 373, 374, 375, 380, 381, 383, 384, 386, 387, 388, 391, 392, 394, 395, 400, 404, 407, 412, 413, 416, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 445, 450, 451, 452, 454, 455, 456, 457, 458, 483, 501, 504, 516, 540, 541, 542, 543, 544, 546, 549, 550, 551, 561, 562, 563, 565, 566, 569, 570, 571, 575, 580, 590, 596, 597, 599, 601, 605, 609, 618, 619, 640, 641, 648, 649, 653, 654, 661, 665, 666, 667, 671, 672, 676, 679, 680, 682, 683, 684, 685, 686, 692, 693, 694, 695, 696, 699, 700, 703, 715, 719, 728, 743, 746, 750, 786, 790, 796, 797, 805, 807, 808, 811, 812, 814, 822, 826, 827, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 847, 848, 849, 850, 851, 854, 855, 857, 860, 862, 863, 868, 869, 870, 872, 894, 902, 903, 909, 912, 913, 914, 915, 916, 917, 918, 948, 949, 957, 960, 965, 969, 971, 989, 990, 992, 994, 996, 997, 998, 999, 1001, 1002, 1004, 1005, 1006, 1010, 1012, 1013, 1016, 1017, 1019, 1020, 1022, 1024, 1025, 1030, 1031, 1032, 1033, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "impli": [43, 176, 192, 360, 361, 362, 421, 423, 426, 482, 581, 590, 618, 619, 630, 743, 936, 996, 997, 1034, 1052], "implic": [369, 386], "implicit": [2, 220, 400, 423, 424, 580, 690, 691, 994, 999, 1019, 1050], "implicitli": [362, 395, 423, 605, 640, 641, 891, 990, 992, 1007, 1010, 1015, 1059], "import": [2, 16, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 326, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 375, 380, 381, 384, 385, 386, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 403, 404, 407, 410, 412, 413, 416, 417, 418, 419, 420, 421, 422, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 585, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 961, 962, 963, 964, 965, 969, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 992, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1020, 1021, 1024, 1025, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1036, 1038, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056], "importance_gett": [425, 601, 602, 605, 1053], "importances_mean": [146, 153, 194, 195, 328, 642, 1008], "importances_std": [146, 642, 1008], "important_word": 57, "importantli": [43, 53, 126, 193, 197, 319, 416, 1059], "importerror": [50, 88, 128, 299, 312, 394], "importlib": 1054, "impos": [74, 92, 157, 214, 224, 325, 398, 416, 421, 423, 424, 535, 665, 996], "imposs": [152, 362, 1020], "impract": 917, "impress": 1024, "improp": [400, 1048], "improv": [0, 30, 43, 61, 62, 69, 111, 112, 115, 130, 135, 139, 140, 145, 148, 150, 151, 152, 154, 155, 160, 170, 188, 192, 197, 206, 220, 228, 238, 272, 279, 281, 296, 299, 302, 317, 324, 334, 352, 353, 361, 369, 374, 384, 389, 391, 392, 394, 395, 398, 400, 401, 410, 421, 423, 425, 457, 458, 539, 540, 542, 545, 546, 547, 549, 550, 551, 554, 562, 565, 566, 567, 568, 569, 570, 572, 573, 618, 619, 651, 660, 672, 674, 675, 676, 680, 681, 682, 683, 684, 686, 693, 695, 700, 737, 738, 792, 795, 796, 861, 869, 870, 886, 888, 900, 920, 921, 923, 949, 994, 996, 997, 1000, 1003, 1004, 1014, 1015, 1016, 1018, 1019, 1020, 1024, 1032, 1041, 1042, 1043, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "improvis": [50, 312], "impur": [153, 195, 368, 403, 423, 425, 561, 562, 565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923, 924, 926, 1016, 1036, 1046, 1047, 1048, 1049], "imput": [2, 105, 155, 160, 194, 249, 259, 261, 329, 332, 378, 390, 399, 400, 407, 417, 423, 498, 509, 573, 588, 635, 636, 637, 638, 647, 653, 680, 834, 855, 873, 931, 933, 1019, 1020, 1021, 1036, 1043, 1044], "imputation_const": 259, "imputation_mean": 259, "imputation_ord": [635, 1051], "imputation_sequence_": 635, "impute_estim": 187, "impute_scor": 188, "imran": [1043, 1044, 1045], "imread": 68, "imshow": [44, 45, 53, 68, 75, 81, 82, 83, 85, 86, 88, 89, 93, 115, 120, 125, 128, 135, 178, 179, 180, 184, 195, 211, 236, 241, 256, 289, 303, 317, 338, 339, 349, 357, 380, 640, 705, 1030, 1031, 1055], "in1d": 1048, "in_bodi": 47, "in_titl": 47, "in_top": 47, "in_topic_d": 47, "inaccess": 90, "inaccur": 1060, "inact": [362, 380, 386], "inadvert": [191, 400], "inadvis": 410, "inappropri": [381, 420, 426, 717, 829], "inbuilt": 420, "inc": [0, 104, 277, 990, 1012, 1024], "incap": 90, "incentiv": 390, "incept": 1020, "includ": [11, 18, 43, 68, 70, 90, 113, 145, 149, 150, 151, 191, 192, 194, 204, 220, 224, 238, 254, 279, 296, 299, 315, 319, 331, 332, 334, 349, 354, 360, 362, 369, 373, 374, 380, 382, 384, 386, 387, 388, 390, 391, 392, 394, 395, 400, 401, 404, 410, 413, 416, 417, 419, 420, 421, 423, 424, 425, 426, 427, 452, 454, 458, 464, 474, 477, 478, 479, 480, 481, 482, 483, 484, 497, 498, 499, 504, 508, 509, 510, 512, 513, 518, 542, 549, 565, 572, 582, 640, 646, 654, 655, 660, 668, 669, 670, 673, 689, 696, 697, 705, 721, 737, 738, 743, 745, 746, 779, 791, 792, 795, 803, 808, 810, 811, 812, 821, 822, 825, 828, 835, 838, 860, 862, 863, 864, 885, 886, 887, 891, 909, 912, 913, 920, 922, 924, 926, 932, 933, 936, 938, 941, 957, 989, 996, 999, 1000, 1001, 1003, 1004, 1010, 1014, 1015, 1016, 1019, 1020, 1023, 1024, 1032, 1034, 1041, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "include_bia": [43, 199, 293, 887, 891, 1055], "include_boundari": [936, 1055], "include_self": [74, 79, 102, 703, 865, 866, 1045], "include_valu": 705, "inclus": [386, 388, 394, 458, 464, 762, 794, 1000, 1001, 1041, 1055], "incom": [319, 381, 448], "incoming_count": 55, "incompat": [222, 390, 504, 990, 1049, 1050], "incomplet": [386, 404, 412, 416, 713, 803, 990, 997, 1034, 1045, 1047], "inconsist": [2, 400, 410, 424, 516, 517, 584, 914, 917, 936, 1006, 1015, 1036, 1041, 1046, 1047, 1048, 1049, 1051, 1054, 1056, 1057, 1058], "inconsistentversionwarn": [2, 410, 1057], "incorpor": [334, 386, 417, 423, 999, 1019, 1024], "incorrect": [139, 191, 285, 341, 369, 386, 416, 615, 616, 640, 641, 742, 1041, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054], "incorrectli": [201, 423, 424, 561, 567, 569, 742, 748, 1000, 1042, 1047, 1049, 1050, 1052, 1057], "incr_mean_variance_axi": [2, 1047, 1053], "increas": [2, 43, 46, 54, 63, 72, 78, 90, 92, 93, 96, 109, 128, 139, 140, 142, 145, 148, 150, 155, 157, 170, 174, 176, 180, 181, 182, 185, 192, 193, 197, 200, 202, 211, 220, 221, 222, 224, 238, 245, 251, 264, 265, 272, 278, 279, 280, 285, 291, 292, 314, 320, 321, 324, 330, 336, 339, 349, 356, 361, 362, 364, 373, 374, 375, 385, 394, 395, 400, 414, 416, 418, 421, 423, 424, 427, 448, 452, 454, 460, 471, 479, 480, 486, 540, 544, 561, 562, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 635, 643, 644, 645, 653, 658, 659, 662, 663, 664, 666, 667, 674, 675, 676, 684, 685, 686, 690, 691, 693, 694, 700, 714, 715, 720, 786, 790, 797, 811, 812, 841, 860, 862, 863, 864, 867, 869, 870, 886, 912, 920, 921, 922, 923, 949, 989, 991, 995, 996, 997, 999, 1000, 1003, 1010, 1014, 1015, 1016, 1024, 1041, 1043, 1046, 1050, 1052, 1053, 1056], "increasing_": 643, "increasing_bool": 644, "increment": [2, 106, 124, 130, 131, 132, 133, 189, 281, 390, 392, 450, 455, 471, 512, 541, 542, 543, 544, 547, 549, 552, 610, 654, 666, 674, 814, 836, 844, 845, 847, 848, 849, 850, 851, 881, 882, 892, 912, 913, 975, 996, 1002, 1021, 1044, 1045], "incrementalpca": [2, 129, 375, 421, 541, 543, 547, 549, 552, 1045, 1048, 1049, 1051, 1052, 1055], "incur": [63, 627, 912, 1015, 1049], "ind": [53, 77, 151, 162, 361, 852, 853], "inde": [44, 46, 62, 64, 70, 74, 75, 88, 90, 93, 115, 118, 130, 139, 142, 173, 174, 176, 192, 194, 199, 204, 208, 209, 220, 222, 280, 281, 285, 287, 296, 299, 319, 324, 356, 361, 369, 373, 385, 391, 399, 400, 401, 416, 418, 423, 575, 576, 996, 1010, 1014, 1055], "indecisiveus": [1052, 1053], "indefinit": 390, "indent": [388, 966], "independ": [2, 32, 52, 62, 64, 72, 81, 126, 127, 129, 144, 148, 183, 193, 256, 257, 278, 281, 283, 287, 298, 319, 326, 328, 361, 369, 373, 374, 382, 388, 390, 399, 400, 404, 413, 414, 416, 417, 418, 419, 420, 424, 428, 457, 472, 496, 511, 523, 524, 525, 526, 528, 540, 541, 543, 545, 547, 548, 554, 555, 559, 560, 612, 615, 616, 633, 648, 652, 653, 654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 680, 681, 682, 683, 712, 713, 725, 744, 745, 763, 765, 803, 810, 837, 841, 843, 845, 846, 884, 888, 889, 890, 892, 896, 897, 898, 899, 901, 902, 903, 906, 914, 915, 916, 917, 918, 943, 989, 992, 994, 996, 997, 1000, 1001, 1002, 1005, 1007, 1010, 1015, 1016, 1035, 1036, 1041, 1042, 1047, 1049, 1051, 1056], "inder128": 1051, "inderjeet": 1052, "inderjit": [413, 461], "indeterminaci": 552, "index": [2, 51, 54, 55, 72, 73, 74, 75, 76, 84, 85, 93, 105, 106, 139, 144, 146, 155, 171, 174, 187, 191, 192, 193, 194, 195, 220, 224, 238, 258, 261, 264, 265, 269, 273, 276, 277, 278, 279, 281, 289, 290, 292, 299, 319, 324, 325, 326, 332, 336, 338, 339, 361, 362, 381, 383, 384, 386, 388, 390, 395, 398, 400, 413, 417, 420, 421, 423, 424, 431, 451, 455, 456, 457, 458, 459, 461, 462, 465, 467, 468, 472, 475, 511, 517, 565, 566, 567, 568, 572, 573, 574, 595, 596, 597, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 625, 640, 641, 648, 705, 712, 713, 720, 724, 726, 739, 746, 765, 787, 788, 794, 796, 802, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 838, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 885, 920, 921, 922, 923, 953, 971, 974, 979, 980, 1000, 1002, 1003, 1004, 1014, 1016, 1019, 1032, 1034, 1041, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "index_alpha_path_a": 208, "index_alpha_path_b": 208, "index_map": 55, "indexerror": [1049, 1050], "indexhash": 648, "indexhash_": 648, "indian": 381, "indic": [2, 51, 57, 58, 62, 63, 83, 94, 95, 101, 109, 118, 121, 125, 139, 144, 150, 181, 184, 188, 191, 193, 217, 242, 251, 254, 271, 272, 280, 281, 284, 285, 299, 312, 338, 339, 342, 360, 361, 362, 368, 374, 381, 386, 387, 388, 390, 394, 395, 398, 400, 412, 413, 414, 416, 418, 420, 421, 423, 424, 427, 431, 445, 448, 452, 458, 459, 460, 461, 463, 464, 465, 468, 472, 475, 480, 495, 516, 517, 519, 520, 521, 531, 540, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 589, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 628, 635, 636, 637, 638, 640, 641, 647, 654, 655, 658, 659, 660, 661, 662, 663, 669, 671, 673, 681, 683, 690, 691, 698, 700, 702, 704, 711, 715, 720, 721, 726, 727, 728, 730, 733, 736, 737, 738, 739, 742, 746, 747, 748, 749, 762, 779, 786, 787, 788, 789, 791, 792, 793, 795, 796, 800, 801, 802, 804, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 843, 845, 846, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 876, 879, 883, 885, 893, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 928, 932, 933, 938, 953, 963, 964, 975, 976, 977, 978, 979, 980, 981, 990, 995, 996, 997, 1000, 1001, 1002, 1003, 1004, 1007, 1010, 1011, 1014, 1015, 1020, 1025, 1029, 1032, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1049, 1051, 1052, 1054, 1056, 1057, 1058, 1059], "indicator_": [635, 636, 638], "indicator_matrix_": 1046, "indigo": 237, "indirect": [281, 387, 400], "indirectli": [238, 353], "indispens": 1024, "indistinguish": 319, "individu": [2, 43, 81, 95, 113, 138, 140, 142, 160, 169, 172, 185, 189, 190, 192, 195, 220, 238, 248, 257, 258, 272, 281, 283, 298, 328, 335, 336, 353, 356, 374, 387, 390, 393, 395, 400, 403, 407, 413, 417, 420, 423, 424, 445, 460, 470, 472, 504, 509, 511, 517, 563, 564, 567, 568, 570, 571, 573, 575, 576, 577, 578, 611, 617, 618, 640, 641, 651, 653, 665, 666, 667, 676, 679, 680, 681, 682, 683, 684, 685, 686, 695, 720, 727, 736, 742, 758, 759, 793, 798, 799, 808, 822, 840, 844, 845, 847, 848, 849, 850, 851, 870, 873, 881, 882, 884, 885, 886, 889, 891, 892, 897, 898, 899, 912, 913, 1000, 1001, 1010, 1015, 1021, 1029, 1034, 1036, 1042, 1045, 1047, 1053, 1055, 1057], "indptr": [55, 299, 368, 975, 976, 977, 978, 979, 980, 981, 1049, 1057], "induc": [25, 63, 91, 192, 204, 211, 213, 218, 221, 235, 253, 257, 356, 362, 413, 421, 423, 454, 457, 547, 551, 561, 565, 566, 567, 568, 572, 573, 574, 651, 734, 764, 885, 920, 921, 922, 923, 993, 1000, 1014, 1032], "induct": [43, 47, 64, 71, 137, 152, 184, 189, 254, 299, 400, 416, 423, 430, 449, 520, 572, 635, 639, 907, 908, 961, 984, 996, 1013, 1021, 1043], "inductive_learn": 91, "inductivecluster": 91, "industri": [416, 1019], "ineffect": [323, 1010, 1049, 1050], "ineffici": [2, 423, 451, 582, 840, 841, 1003, 1005], "inequ": [368, 400, 416, 451, 455, 467, 707, 997, 998, 1003], "inertia": [92, 93, 96, 361, 416, 451, 455, 457, 460, 467, 468, 470, 471, 1052], "inertia_": [93, 96, 99, 451, 455, 457, 1052], "inf": [109, 179, 309, 395, 416, 426, 454, 458, 463, 464, 465, 469, 479, 480, 486, 561, 562, 567, 568, 601, 602, 605, 614, 615, 616, 627, 635, 643, 645, 656, 657, 658, 660, 677, 679, 680, 684, 685, 686, 688, 695, 736, 738, 754, 786, 793, 797, 868, 877, 884, 930, 931, 932, 933, 947, 1000, 1010, 1048, 1050, 1051, 1052, 1053, 1055, 1056, 1057], "infant": 1010, "infeas": [996, 1003, 1005], "infer": [25, 189, 190, 192, 215, 264, 268, 269, 278, 365, 380, 388, 398, 410, 420, 421, 504, 516, 517, 523, 542, 544, 546, 548, 555, 557, 558, 561, 567, 568, 640, 643, 665, 717, 730, 731, 749, 793, 805, 806, 814, 831, 838, 848, 886, 893, 907, 908, 920, 921, 922, 923, 963, 990, 996, 999, 1000, 1005, 1010, 1013, 1016, 1019, 1020, 1021, 1028, 1042, 1046, 1047, 1052, 1055, 1058], "inferencesess": 410, "inferenti": 91, "inferior": [449, 453, 1052], "infin": [2, 278, 356, 549, 690, 691, 720, 833, 919, 931, 1003], "infinit": [64, 221, 263, 281, 353, 373, 426, 454, 630, 631, 786, 805, 930, 932, 933, 992, 999, 1010, 1015, 1049, 1051, 1054, 1055, 1056, 1058, 1059], "inflammatori": 381, "inflat": [92, 191, 192, 194, 416, 420, 1000, 1010], "inflect": 280, "influenc": [42, 48, 52, 113, 114, 139, 189, 192, 202, 263, 286, 319, 326, 349, 353, 356, 369, 375, 418, 421, 423, 439, 448, 462, 473, 490, 491, 492, 497, 509, 562, 564, 566, 568, 570, 573, 576, 578, 619, 636, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 684, 686, 687, 742, 758, 838, 845, 846, 854, 855, 862, 863, 870, 889, 890, 901, 913, 915, 918, 921, 923, 932, 989, 994, 995, 996, 1003, 1006, 1010, 1014, 1015, 1021, 1024, 1044, 1049, 1050], "influenti": [224, 361, 1024], "info": [2, 45, 77, 105, 125, 192, 193, 254, 272, 276, 383, 385, 390, 400, 424, 504, 956, 1030], "inform": [2, 3, 43, 44, 47, 50, 51, 52, 53, 62, 64, 69, 70, 72, 73, 84, 88, 93, 101, 102, 104, 105, 118, 120, 121, 122, 131, 145, 146, 147, 168, 170, 171, 173, 174, 176, 181, 189, 192, 193, 195, 197, 198, 199, 200, 204, 221, 224, 235, 237, 238, 254, 258, 265, 266, 268, 272, 273, 275, 278, 279, 280, 283, 285, 287, 302, 305, 306, 309, 326, 331, 335, 352, 356, 360, 361, 362, 365, 368, 369, 373, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 391, 392, 394, 398, 399, 400, 401, 407, 410, 413, 415, 420, 421, 423, 424, 425, 426, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 470, 472, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 500, 502, 503, 504, 505, 508, 509, 510, 511, 512, 513, 518, 523, 532, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 611, 614, 615, 616, 617, 618, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 696, 697, 698, 699, 700, 703, 705, 709, 712, 713, 723, 734, 738, 751, 763, 764, 765, 794, 796, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 835, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 897, 898, 900, 901, 902, 903, 904, 905, 907, 908, 911, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 957, 990, 992, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1011, 1014, 1016, 1020, 1021, 1023, 1024, 1031, 1032, 1033, 1034, 1041, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "informatik": [61, 62, 63, 64, 176, 177, 179, 180, 181, 182, 183, 185, 253, 1000], "informed": 1000, "infrastructur": [316, 334, 1019, 1020], "infrequ": [885, 886, 893, 1000, 1041, 1055, 1056, 1057], "infrequent_categories_": [332, 334, 885, 886, 893, 1010], "infrequent_if_exist": [885, 1010], "infrequent_sklearn": [885, 1010], "infti": [238, 426, 627, 996, 1010, 1048], "ing": 424, "ingela": 1055, "ingest": 424, "ingredi": 426, "ingrid": 1051, "inher": [135, 215, 369, 416, 421, 990, 992, 994, 995, 997, 1001], "inherit": [254, 386, 388, 399, 400, 430, 585, 684, 941, 943, 996, 1041, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1056, 1057, 1058], "inhibit": [427, 452], "inhomogen": [426, 622], "ini": 266, "init": [2, 54, 77, 80, 93, 94, 96, 99, 193, 200, 240, 241, 243, 244, 245, 264, 266, 299, 361, 389, 394, 416, 421, 423, 451, 455, 457, 459, 461, 467, 468, 546, 548, 555, 556, 567, 568, 640, 641, 698, 700, 702, 861, 997, 1041, 1050, 1053, 1055, 1056, 1057], "init_": [567, 568], "init_param": [263, 266, 269, 805, 806], "init_s": [96, 361, 457], "init_size_": 1053, "init_tim": 266, "initi": [0, 46, 51, 55, 71, 77, 78, 80, 92, 93, 95, 98, 99, 114, 153, 161, 162, 163, 177, 182, 189, 192, 200, 213, 235, 240, 241, 245, 262, 264, 265, 278, 299, 330, 340, 349, 361, 369, 374, 381, 386, 388, 394, 395, 398, 400, 416, 421, 423, 425, 426, 428, 450, 451, 455, 456, 457, 458, 459, 460, 461, 467, 468, 469, 470, 520, 523, 539, 540, 541, 545, 546, 548, 551, 553, 554, 555, 556, 561, 562, 567, 568, 601, 615, 616, 618, 619, 627, 628, 635, 648, 653, 654, 655, 656, 660, 661, 666, 668, 669, 670, 671, 674, 675, 676, 677, 679, 684, 685, 686, 688, 689, 692, 698, 699, 700, 702, 703, 805, 806, 842, 861, 868, 869, 870, 908, 935, 948, 949, 969, 974, 975, 992, 996, 997, 999, 1004, 1005, 1006, 1014, 1016, 1019, 1021, 1031, 1033, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "initial_imputer_": 635, "initial_strategi": 635, "initial_theta": [618, 619], "initialis": [125, 546, 548, 555, 1041, 1049, 1050], "initializedcheck": 387, "inject": [257, 381, 423], "inki": 1047, "inli": [247, 996, 1006], "inlier": [113, 156, 223, 247, 257, 319, 400, 418, 438, 477, 571, 679, 685, 858, 889, 901, 915, 916, 918, 996, 1006, 1048, 1049, 1054], "inlier_mask": 223, "inlier_mask_": [223, 679], "inlier_plot": 113, "inliers_mask": 114, "inlin": [231, 386, 387, 1016], "inner": [64, 130, 152, 155, 279, 283, 298, 340, 373, 424, 451, 522, 590, 597, 626, 656, 677, 688, 783, 785, 992, 1000, 1010, 1015, 1042, 1045, 1055, 1058], "inner_clf": 1000, "inner_cv": [283, 335], "inner_it": 392, "inner_numb": 340, "inner_stat": 1055, "inner_stats_": 1055, "inpaint": 421, "inplac": [2, 238, 257, 290, 462, 490, 491, 492, 493, 867, 875, 878, 881, 882, 884, 888, 889, 890, 892, 973, 976, 977, 978, 982, 983, 1050], "inplace_column_scal": 2, "inplace_csr_column_scal": [2, 395], "inplace_csr_row_normalize_l1": [2, 395], "inplace_csr_row_normalize_l2": [2, 395], "inplace_row_scal": 2, "inplace_swap_column": 2, "inplace_swap_row": 2, "inproceed": 0, "input": [2, 43, 45, 49, 64, 67, 69, 107, 125, 129, 148, 152, 153, 182, 183, 184, 192, 197, 199, 220, 223, 224, 228, 235, 238, 250, 251, 253, 254, 261, 273, 296, 303, 304, 316, 320, 321, 322, 323, 328, 331, 333, 336, 349, 353, 357, 362, 380, 383, 386, 389, 391, 395, 396, 398, 399, 400, 410, 413, 414, 417, 420, 421, 422, 423, 424, 425, 426, 428, 434, 437, 438, 439, 440, 441, 445, 446, 447, 448, 449, 450, 453, 456, 457, 458, 462, 465, 466, 469, 472, 473, 475, 476, 477, 479, 480, 490, 491, 492, 497, 511, 517, 524, 525, 526, 528, 532, 536, 540, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 556, 557, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 619, 628, 630, 635, 636, 637, 638, 639, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 689, 690, 693, 694, 695, 696, 697, 698, 700, 701, 704, 705, 706, 707, 708, 709, 710, 729, 730, 731, 732, 736, 753, 754, 756, 758, 759, 761, 762, 769, 775, 779, 780, 782, 786, 787, 788, 789, 793, 798, 799, 805, 806, 807, 808, 811, 812, 814, 822, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 858, 860, 861, 862, 863, 864, 867, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 899, 900, 904, 905, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 929, 930, 931, 932, 933, 934, 938, 943, 946, 948, 957, 959, 960, 964, 973, 975, 981, 982, 983, 986, 987, 990, 992, 994, 996, 997, 998, 999, 1000, 1002, 1003, 1004, 1005, 1007, 1008, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1024, 1025, 1029, 1030, 1036, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "input_featur": [199, 388, 400, 432, 437, 450, 451, 453, 455, 457, 472, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 574, 575, 576, 577, 578, 589, 596, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 696, 697, 700, 856, 861, 864, 868, 871, 872, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 1057], "input_nam": [931, 933, 963, 1055], "input_typ": [362, 424, 590], "inria": [0, 44, 48, 66, 72, 87, 89, 92, 109, 115, 145, 155, 182, 199, 204, 205, 207, 211, 213, 214, 225, 241, 242, 247, 250, 257, 279, 281, 284, 291, 311, 324, 356, 360, 361, 362, 666, 1041], "insensit": [253, 651, 684, 686, 796, 913, 993, 1014, 1015, 1041], "insepar": [174, 383], "insert": [95, 192, 220, 398, 416, 495, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 927], "insid": [2, 55, 57, 63, 193, 222, 254, 278, 340, 349, 375, 380, 381, 388, 392, 407, 416, 424, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 597, 598, 599, 602, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 807, 809, 810, 815, 817, 826, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 957, 960, 1007, 1024, 1058], "insight": [43, 46, 192, 193, 221, 222, 238, 272, 316, 319, 360, 368, 414, 415, 808, 811, 812, 822, 835, 1007, 1016, 1024], "insist": 104, "inspect": [2, 43, 48, 66, 67, 70, 91, 96, 141, 146, 153, 155, 156, 157, 161, 171, 176, 181, 182, 192, 193, 194, 195, 203, 212, 229, 234, 258, 272, 278, 281, 290, 302, 307, 310, 324, 328, 329, 330, 331, 333, 335, 345, 346, 347, 348, 350, 351, 353, 360, 365, 374, 388, 400, 416, 417, 423, 424, 472, 561, 562, 565, 566, 567, 568, 572, 573, 574, 639, 640, 641, 642, 841, 872, 873, 920, 921, 922, 923, 988, 1000, 1001, 1004, 1007, 1008, 1015, 1019, 1021, 1034, 1036, 1044], "inspir": [112, 157, 193, 238, 386, 398, 423, 569, 570, 937, 990, 1019, 1050], "instabl": [74, 192, 309, 426, 460, 543, 547, 551, 703, 1048, 1051, 1054], "instal": [88, 261, 299, 328, 329, 330, 331, 332, 333, 334, 335, 336, 373, 374, 386, 387, 389, 390, 392, 394, 398, 399, 409, 410, 412, 416, 424, 460, 470, 504, 699, 703, 1016, 1034, 1048, 1049, 1050, 1054, 1055], "installment_commit": 272, "instanc": [2, 43, 47, 49, 52, 61, 63, 64, 88, 91, 93, 142, 155, 171, 174, 188, 193, 194, 203, 204, 249, 254, 257, 272, 274, 276, 287, 289, 290, 310, 328, 335, 343, 345, 346, 352, 353, 360, 361, 362, 372, 373, 374, 380, 381, 383, 384, 385, 386, 388, 390, 391, 392, 394, 395, 398, 400, 404, 407, 410, 412, 413, 414, 415, 416, 417, 420, 421, 423, 424, 425, 426, 427, 428, 430, 440, 441, 444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 468, 470, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 496, 499, 500, 503, 504, 505, 511, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 585, 589, 590, 591, 592, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 618, 619, 628, 635, 636, 637, 638, 640, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 693, 695, 696, 697, 698, 699, 700, 701, 702, 703, 705, 706, 707, 708, 709, 710, 715, 728, 737, 738, 746, 779, 782, 786, 787, 788, 789, 791, 792, 795, 796, 797, 800, 801, 805, 806, 807, 808, 810, 811, 812, 813, 814, 815, 817, 820, 822, 823, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 901, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 925, 932, 933, 935, 943, 944, 948, 949, 956, 957, 958, 959, 969, 970, 971, 974, 984, 985, 989, 990, 996, 997, 1000, 1002, 1003, 1006, 1008, 1010, 1014, 1015, 1016, 1020, 1025, 1032, 1033, 1034, 1036, 1041, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "instanci": 1050, "instant": 214, "instantan": 516, "instanti": [106, 179, 331, 389, 407, 423, 458, 575, 576, 610, 638, 808, 811, 812, 814, 822, 831, 833, 834, 835, 836, 837, 839, 939, 1006, 1031, 1041, 1049, 1053, 1057], "instead": [0, 43, 44, 45, 52, 58, 83, 88, 90, 91, 92, 105, 130, 142, 147, 157, 171, 174, 176, 220, 222, 235, 238, 244, 257, 269, 274, 275, 279, 280, 298, 304, 319, 328, 329, 330, 331, 332, 349, 351, 353, 360, 362, 368, 369, 373, 374, 380, 381, 384, 385, 386, 387, 388, 390, 391, 394, 395, 398, 399, 400, 407, 410, 412, 416, 417, 419, 420, 421, 422, 423, 424, 425, 427, 439, 445, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 464, 467, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 517, 518, 541, 542, 543, 545, 546, 547, 548, 549, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 602, 615, 616, 618, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 635, 638, 640, 643, 646, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 698, 700, 702, 715, 717, 750, 754, 758, 759, 782, 786, 787, 788, 790, 791, 805, 806, 807, 808, 809, 810, 811, 812, 815, 817, 820, 822, 826, 827, 828, 830, 833, 834, 835, 836, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 873, 874, 875, 877, 878, 879, 884, 885, 890, 891, 892, 902, 903, 906, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 925, 926, 938, 944, 949, 957, 975, 989, 990, 992, 996, 997, 999, 1000, 1001, 1004, 1005, 1010, 1014, 1015, 1016, 1019, 1030, 1032, 1034, 1038, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "instinct": 360, "institut": [0, 272, 383, 1003], "instruct": [373, 386, 387, 388, 389, 390, 391, 394, 398, 399, 400, 511, 596, 597, 599, 1023, 1025, 1034, 1041], "instrument": [51, 104, 126, 191], "insuffici": [403, 999, 1033], "insur": [189, 198, 220, 415, 472, 504, 560, 656, 677, 688, 714, 753, 758, 760, 838, 873, 876, 877, 885, 892, 996, 1021], "int": [47, 49, 52, 53, 55, 57, 72, 79, 97, 114, 142, 151, 155, 156, 166, 167, 177, 178, 179, 185, 188, 191, 201, 211, 213, 220, 238, 245, 247, 253, 257, 263, 272, 273, 276, 277, 278, 299, 304, 306, 312, 326, 339, 362, 381, 386, 388, 398, 400, 414, 417, 420, 424, 427, 428, 431, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 510, 511, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 593, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 615, 616, 618, 619, 625, 635, 636, 637, 638, 639, 640, 641, 642, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 706, 708, 709, 710, 711, 712, 713, 715, 717, 721, 734, 735, 737, 738, 739, 742, 746, 764, 765, 777, 782, 786, 787, 788, 789, 790, 791, 792, 795, 797, 801, 802, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 874, 875, 876, 877, 878, 879, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 928, 932, 933, 935, 936, 948, 949, 951, 952, 953, 954, 965, 969, 971, 974, 979, 980, 996, 1007, 1041, 1047, 1051, 1052], "int32": [257, 299, 326, 386, 400, 451, 455, 457, 459, 461, 467, 914, 915, 916, 917, 918, 965, 1015, 1050, 1056, 1057, 1058], "int64": [43, 53, 89, 105, 192, 193, 272, 292, 296, 325, 335, 368, 400, 424, 434, 450, 456, 458, 504, 596, 648, 654, 655, 660, 661, 722, 723, 848, 877, 930, 986, 1049, 1052, 1054, 1056, 1057, 1058], "int64dtyp": 1058, "intact": [885, 1034], "integ": [2, 43, 55, 83, 88, 105, 192, 220, 238, 329, 330, 369, 373, 380, 381, 383, 388, 391, 395, 399, 400, 416, 417, 420, 421, 423, 424, 441, 445, 470, 472, 475, 480, 495, 504, 506, 509, 510, 511, 513, 516, 517, 520, 522, 523, 527, 530, 558, 567, 568, 569, 570, 571, 575, 576, 580, 590, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 640, 641, 652, 659, 663, 667, 673, 681, 683, 684, 686, 707, 722, 743, 808, 810, 811, 812, 813, 815, 817, 822, 823, 824, 827, 828, 830, 832, 835, 843, 846, 848, 851, 852, 853, 877, 885, 886, 891, 892, 893, 896, 906, 908, 920, 921, 922, 923, 928, 963, 964, 965, 969, 990, 996, 1001, 1003, 1010, 1013, 1015, 1016, 1025, 1032, 1034, 1041, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058], "integr": [0, 77, 105, 171, 184, 209, 316, 330, 374, 384, 388, 389, 390, 392, 394, 400, 404, 421, 426, 454, 723, 763, 794, 975, 999, 1007, 1024, 1028, 1042, 1044, 1045, 1053, 1054, 1058, 1060], "intel": [1000, 1019], "intelex": [404, 1019], "intellectu": 191, "intellig": [98, 174, 272, 360, 383, 416, 423, 456, 563, 564, 646, 704, 733, 842, 869, 870, 1001, 1012, 1020, 1024], "intend": [92, 93, 129, 221, 353, 360, 386, 387, 388, 393, 398, 400, 420, 476, 590, 681, 707, 881, 882, 892, 910, 995, 996, 1000, 1004, 1011], "intens": [101, 128, 299, 383, 387, 398, 400, 421, 451, 455, 467, 615, 616, 640, 641, 810, 989, 1007, 1024, 1049], "intention": 64, "inter": [2, 75, 146, 369, 423, 724], "interact": [2, 42, 153, 155, 189, 220, 245, 249, 279, 329, 385, 387, 388, 390, 392, 398, 400, 401, 410, 417, 567, 568, 569, 570, 640, 641, 887, 891, 989, 992, 996, 997, 998, 1005, 1007, 1010, 1018, 1020, 1043, 1048, 1055, 1056], "interaction_cst": [193, 333, 423, 569, 570, 1056], "interaction_onli": [43, 887, 996, 1010], "interactiveshellapp": 392, "intercept": [128, 212, 229, 237, 357, 400, 490, 491, 492, 557, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 887, 891, 894, 912, 913, 919, 996, 998, 1000, 1005, 1014, 1015, 1044, 1046, 1050, 1051], "intercept_": [202, 210, 212, 229, 255, 347, 354, 357, 388, 400, 490, 491, 492, 557, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 912, 913, 914, 915, 916, 917, 918, 994, 996, 1014, 1015, 1041, 1048, 1053, 1055, 1058], "intercept_hidden_": 868, "intercept_init": [674, 675, 676, 684, 686], "intercept_sc": [213, 666, 667, 912, 913, 919, 996, 1015], "intercept_visible_": 868, "intercepts_": [869, 870, 1004], "interchang": [1019, 1058], "interclass": 75, "interdepend": 523, "interest": [0, 43, 45, 52, 77, 79, 85, 90, 97, 101, 106, 139, 147, 152, 160, 171, 174, 181, 187, 192, 193, 194, 209, 220, 221, 222, 238, 241, 252, 271, 272, 275, 278, 279, 281, 287, 292, 296, 336, 349, 356, 361, 368, 373, 381, 383, 386, 391, 392, 394, 398, 401, 415, 416, 418, 421, 424, 426, 501, 502, 508, 512, 518, 654, 655, 912, 990, 996, 997, 1000, 1005, 1006, 1007, 1020, 1024, 1030, 1032, 1033, 1041, 1058], "interestingli": [111, 174, 1010], "interfac": [2, 42, 139, 189, 379, 380, 387, 388, 395, 398, 400, 420, 426, 427, 449, 453, 458, 504, 561, 707, 808, 811, 812, 822, 872, 873, 898, 985, 989, 1003, 1015, 1019, 1020, 1024, 1041, 1043, 1046, 1047, 1049, 1050, 1055, 1057], "interfer": [335, 1051], "interim": 1048, "interior": [222, 678, 996, 1056], "interleav": [2, 382, 398, 530], "intermedi": [43, 46, 87, 90, 144, 152, 257, 349, 398, 424, 567, 568, 627, 872, 1000, 1053, 1059], "intern": [0, 43, 63, 105, 115, 130, 145, 150, 153, 155, 165, 174, 177, 187, 189, 220, 254, 272, 292, 299, 301, 318, 325, 340, 362, 369, 374, 381, 383, 388, 392, 395, 398, 400, 407, 412, 413, 416, 420, 421, 423, 424, 425, 426, 427, 445, 447, 452, 473, 476, 519, 542, 543, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 601, 602, 618, 619, 648, 651, 654, 660, 676, 680, 684, 686, 704, 716, 739, 742, 766, 767, 791, 838, 852, 853, 868, 869, 870, 872, 873, 877, 891, 893, 907, 908, 910, 912, 913, 914, 917, 920, 921, 922, 923, 996, 997, 998, 1000, 1003, 1006, 1010, 1012, 1015, 1016, 1021, 1024, 1041, 1044, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "internet": [381, 391, 1010, 1032], "interoper": [410, 426, 1020], "interp": [287, 288, 349], "interp1d": [661, 671, 692], "interp_tpr": 288, "interpol": [43, 53, 68, 75, 85, 86, 89, 93, 115, 120, 125, 128, 180, 183, 189, 198, 199, 211, 236, 250, 256, 287, 293, 303, 304, 311, 317, 339, 349, 426, 643, 653, 661, 671, 680, 692, 708, 715, 855, 863, 873, 887, 891, 991, 996, 1000, 1010, 1021, 1048, 1053], "interpret": [43, 64, 155, 174, 183, 189, 190, 191, 193, 216, 220, 221, 225, 236, 238, 271, 278, 280, 281, 292, 317, 320, 323, 330, 360, 362, 373, 384, 386, 387, 392, 394, 395, 400, 403, 414, 416, 417, 422, 424, 460, 472, 473, 475, 504, 549, 580, 619, 647, 651, 661, 680, 681, 699, 700, 703, 709, 737, 761, 766, 767, 791, 800, 801, 814, 823, 835, 836, 838, 841, 873, 885, 892, 994, 996, 1000, 1001, 1007, 1008, 1010, 1016, 1019, 1021, 1025, 1033, 1041, 1042, 1046, 1049, 1054, 1055, 1056], "interquartil": [257, 890, 902], "interquartile_rang": 890, "interrog": 424, "interrupt": 996, "intersect": [279, 346, 413, 416, 746], "interv": [2, 52, 64, 138, 155, 183, 189, 204, 220, 221, 222, 238, 278, 381, 400, 414, 420, 423, 426, 446, 447, 524, 525, 526, 565, 566, 568, 570, 572, 573, 643, 644, 646, 685, 750, 756, 758, 812, 829, 838, 875, 877, 891, 914, 915, 916, 936, 992, 996, 1000, 1010, 1016, 1021, 1048, 1052], "intervent": [90, 192], "intl": [64, 420], "intp": [431, 459, 461], "intra": [43, 596, 599, 800, 801], "intract": [91, 421, 997, 1005], "intric": [224, 520], "intricaci": 386, "intrins": [199, 400, 421, 423, 1003, 1008, 1014, 1053], "introduc": [43, 111, 113, 114, 130, 155, 173, 189, 194, 199, 204, 224, 246, 251, 254, 257, 259, 285, 333, 334, 362, 379, 382, 384, 386, 388, 390, 391, 394, 398, 400, 407, 414, 416, 418, 420, 421, 423, 424, 440, 449, 450, 451, 453, 455, 457, 467, 472, 476, 490, 491, 492, 493, 504, 512, 523, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 563, 564, 574, 575, 576, 577, 578, 589, 590, 591, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 666, 672, 693, 694, 696, 697, 700, 838, 856, 861, 864, 868, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 906, 910, 994, 996, 999, 1002, 1003, 1006, 1010, 1012, 1014, 1015, 1021, 1025, 1032, 1041, 1042, 1047, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1059], "introduct": [173, 238, 276, 386, 415, 420, 421, 424, 598, 796, 797, 847, 851, 996, 998, 1000, 1002, 1018, 1026, 1032, 1035, 1036], "introductori": [152, 175, 176, 181, 182, 185, 189, 246, 426, 619, 630, 1021, 1024], "introspect": [43, 45, 105, 392, 567, 568, 597, 1010, 1030], "intrus": 381, "intuit": [43, 52, 67, 79, 87, 97, 130, 139, 142, 149, 169, 176, 192, 193, 221, 222, 242, 247, 279, 296, 304, 321, 324, 346, 349, 353, 361, 386, 400, 414, 416, 418, 420, 422, 653, 790, 791, 792, 795, 883, 912, 914, 915, 917, 918, 992, 996, 997, 1000, 1001, 1007, 1010, 1011, 1015, 1024, 1032, 1034, 1041], "inv": [111, 115, 315], "inv_kw_arg": 876, "invalid": [2, 47, 220, 400, 454, 586, 679, 720, 782, 996, 1000, 1047, 1049, 1051, 1052, 1054, 1055, 1057], "invalidparametererror": 1000, "invalu": 1024, "invari": [75, 383, 400, 416, 426, 622, 697, 755, 826, 827, 996, 997, 1000, 1015, 1020, 1049, 1052, 1053, 1054], "invent": 1003, "inventor": 1002, "inventori": 1024, "invers": [2, 8, 51, 89, 110, 111, 112, 139, 189, 268, 285, 287, 294, 302, 349, 361, 362, 378, 400, 417, 419, 420, 421, 423, 424, 428, 453, 473, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 535, 541, 542, 543, 547, 549, 551, 565, 569, 572, 597, 598, 599, 636, 652, 653, 666, 667, 674, 676, 682, 683, 684, 685, 686, 688, 732, 751, 760, 805, 806, 854, 855, 862, 863, 869, 870, 872, 876, 879, 885, 886, 888, 904, 905, 912, 913, 914, 917, 918, 920, 922, 938, 994, 996, 1000, 1003, 1004, 1010, 1014, 1015, 1021, 1032, 1034, 1035, 1036, 1041, 1044, 1049, 1052, 1053, 1055, 1059], "inverse_components_": [904, 905, 1012, 1055], "inverse_func": [109, 192, 417, 473, 876, 1010, 1049, 1059], "inverse_transform": [44, 86, 89, 130, 171, 303, 361, 407, 421, 424, 453, 473, 490, 491, 492, 541, 542, 543, 546, 547, 548, 549, 551, 552, 589, 596, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 638, 808, 811, 812, 822, 872, 876, 877, 879, 880, 881, 882, 883, 885, 886, 888, 889, 890, 892, 904, 905, 1010, 1011, 1012, 1043, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "invert": [115, 130, 171, 241, 361, 362, 398, 418, 424, 638, 697, 701, 1010, 1050], "invert_yaxi": [188, 362], "invest": [392, 1024], "investig": [130, 135, 139, 188, 356, 386, 410, 996], "invit": 390, "invok": [388, 539, 545, 547, 553, 554, 575, 577, 578, 807, 830, 833, 909, 1053, 1058], "involv": [324, 326, 328, 336, 349, 353, 373, 375, 381, 386, 390, 400, 401, 410, 419, 426, 707, 840, 841, 997, 1001, 1003, 1007, 1008, 1015, 1019, 1024, 1032, 1049], "invscal": [315, 684, 685, 686, 869, 870, 1014], "io": [380, 383, 386, 390, 392, 394, 400, 700, 1019, 1036, 1039], "ioangatop": 1058, "ioanni": 742, "ioerror": 1057, "iofal": 1055, "ion": 1056, "ionescu": [650, 992, 1051], "iowa": [149, 160, 257], "ipca": [2, 129, 541, 542], "ipdb": [394, 1034], "ipm": 678, "ipynb": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368], "ipython": [388, 391, 392, 394, 1026, 1034], "ipython_config": 392, "iq": 191, "iqbal": 1053, "iqr": [257, 890, 902], "ir": [250, 421, 598, 734, 764, 847, 851, 998, 1000], "iren": [1056, 1057], "iri": [2, 50, 55, 66, 67, 69, 76, 80, 108, 119, 124, 127, 129, 135, 138, 139, 140, 141, 143, 158, 161, 167, 170, 175, 177, 180, 189, 197, 198, 203, 212, 213, 217, 252, 261, 265, 271, 283, 284, 287, 288, 294, 302, 308, 310, 314, 315, 321, 330, 337, 342, 344, 345, 347, 349, 351, 352, 353, 363, 364, 366, 367, 368, 379, 380, 399, 410, 416, 417, 420, 421, 423, 455, 504, 512, 549, 557, 561, 565, 572, 618, 630, 639, 684, 808, 822, 907, 908, 909, 912, 917, 920, 924, 925, 926, 989, 990, 994, 999, 1000, 1003, 1007, 1010, 1013, 1014, 1015, 1016, 1021, 1025, 1032, 1033, 1036, 1054], "iris": [121, 284, 285, 1031], "iris_61": 380, "iris_969": 380, "iris_i": 1032, "iris_version_3": 380, "iris_x": 1032, "iris_x_test": 1032, "iris_x_train": 1032, "iris_y_test": 1032, "iris_y_train": 1032, "irreduc": [142, 1000], "irregular": [181, 353, 416, 1003], "irregularities_kernel": 181, "irrelev": [169, 204, 369, 392, 418, 423, 425, 612, 748, 1000], "irrespect": [220, 251, 272, 287, 299, 614], "irvin": 383, "is_categor": 640, "is_categorical_": [569, 570], "is_classifi": [2, 388, 400], "is_cluster": [2, 1060], "is_data_valid": [679, 996], "is_fit": [2, 984], "is_fitted_": [430, 433, 435, 438, 439], "is_inli": [477, 571, 858], "is_leav": 368, "is_max_test_scor": 107, "is_model_valid": [679, 996], "is_multilabel": [2, 395, 1058], "is_paramet": 988, "is_pypi": 1059, "is_regressor": [2, 400], "is_scalar_nan": 1054, "is_sh": 289, "is_split_nod": 368, "is_stationari": [184, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633], "isa": 57, "isaac": [1047, 1048, 1050, 1051, 1058], "isaack": 1054, "isaactrost": 1058, "isakov": 1053, "isbn": [383, 416, 996], "isclos": 55, "isdigit": [57, 424], "ish": 69, "ishaan": 1054, "ishan": [1054, 1055], "ishank": [1046, 1047, 1048], "ishikawa": [1053, 1054], "isin": [294, 339], "isinst": [70, 148, 238, 400], "islic": [47, 79, 97], "ism": 1045, "isn": [174, 328, 360, 362, 369, 374, 386, 394, 523, 569, 570, 602, 802, 811, 812, 885, 1003, 1015, 1051], "iso": [122, 175, 189, 232, 242, 618, 621, 622, 1021], "iso_reg": 643, "isoformat": 55, "isol": [2, 149, 156, 247, 257, 361, 384, 392, 404, 571, 858, 916, 1050, 1051], "isolationforest": [2, 138, 189, 223, 247, 257, 294, 639, 838, 916, 1006, 1021, 1047, 1048, 1049, 1050, 1052, 1054, 1055, 1056, 1057, 1058], "isolationforestifittedisolationforest": 156, "isomap": [2, 51, 87, 144, 189, 239, 242, 244, 251, 309, 328, 332, 423, 510, 552, 557, 574, 697, 698, 699, 700, 861, 873, 882, 905, 1003, 1021, 1035, 1036, 1049, 1051, 1054, 1055, 1056, 1057, 1058], "isomap__n_neighbor": 328, "isometr": [240, 696, 698, 699, 700, 997], "isoton": [2, 61, 62, 109, 189, 246, 445, 643, 644, 645, 665, 935, 1021, 1022, 1036, 1042, 1043, 1044, 1045, 1047, 1054, 1057], "isotonic_regress": [2, 643, 1054], "isotonicregress": [2, 250, 991, 1042, 1043, 1044, 1045, 1047, 1049, 1050, 1051, 1053, 1055, 1056, 1057], "isotonicregression0": 643, "isotrop": [2, 70, 90, 92, 96, 130, 178, 180, 240, 242, 416, 418, 426, 520, 527, 540, 623, 627, 628, 630, 631], "isotropi": 421, "isr": 425, "issam": [0, 314, 1047], "issu": [0, 2, 43, 62, 112, 118, 220, 238, 283, 326, 374, 380, 389, 390, 391, 394, 395, 398, 400, 401, 403, 404, 407, 410, 412, 416, 418, 419, 424, 457, 460, 470, 481, 490, 491, 492, 542, 547, 551, 581, 596, 597, 599, 619, 635, 699, 703, 777, 883, 888, 900, 939, 989, 990, 997, 1008, 1010, 1015, 1019, 1020, 1023, 1033, 1034, 1041, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1056, 1058, 1059], "issuenumb": 394, "ist": 425, "isupp": 424, "isuru": 1053, "itakura": [421, 546, 548, 555, 1048], "itali": 383, "item": [2, 47, 48, 49, 50, 51, 52, 55, 57, 66, 78, 90, 109, 143, 145, 149, 152, 160, 192, 218, 222, 228, 241, 253, 254, 256, 265, 275, 281, 332, 339, 361, 379, 386, 387, 388, 395, 417, 472, 534, 569, 570, 596, 597, 599, 640, 820, 885, 907, 908, 927, 928, 954, 992, 1013, 1020, 1025], "item_idx": 319, "itemgett": 57, "iter": [2, 47, 54, 55, 67, 81, 106, 115, 125, 128, 139, 142, 145, 148, 150, 151, 153, 154, 155, 174, 185, 187, 189, 199, 200, 228, 235, 265, 266, 270, 273, 286, 289, 314, 316, 317, 321, 330, 339, 341, 342, 349, 386, 388, 392, 394, 395, 399, 400, 411, 416, 419, 421, 423, 425, 428, 445, 448, 449, 451, 453, 455, 456, 457, 460, 462, 467, 469, 470, 471, 479, 480, 486, 490, 491, 492, 523, 539, 540, 541, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 561, 562, 567, 568, 569, 570, 572, 575, 576, 589, 590, 596, 597, 599, 601, 602, 610, 618, 635, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 700, 701, 702, 805, 806, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 843, 846, 861, 868, 869, 870, 871, 872, 876, 883, 885, 887, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 927, 948, 949, 955, 956, 957, 958, 966, 990, 996, 997, 999, 1000, 1003, 1004, 1005, 1013, 1014, 1015, 1016, 1020, 1021, 1024, 1029, 1033, 1034, 1036, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "iter_minibatch": 47, "iter_offset": 1055, "iter_offset_": 1055, "iterated_pow": [106, 540, 543, 549, 1047], "iterative_impute_scor": 188, "iterativeimput": [2, 186, 188, 189, 407, 498, 573, 588, 636, 637, 638, 647, 653, 680, 834, 855, 873, 1021, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1058, 1059], "itergrid": 1043, "itertool": [47, 77, 79, 97, 161, 193, 205, 264, 269, 278, 285, 287, 423], "ith": [504, 782, 786, 848, 869, 870, 885, 886], "ith_cluster_silhouette_valu": 95, "itk": [1051, 1052, 1053], "its": [0, 2, 7, 25, 43, 48, 51, 52, 53, 57, 63, 64, 70, 72, 90, 100, 101, 111, 113, 115, 118, 121, 122, 123, 130, 137, 139, 145, 148, 150, 152, 155, 165, 174, 176, 181, 183, 192, 193, 195, 197, 199, 209, 233, 237, 238, 242, 247, 254, 256, 257, 259, 261, 263, 268, 269, 272, 277, 281, 283, 285, 287, 292, 299, 301, 305, 306, 321, 331, 341, 346, 353, 358, 360, 361, 364, 368, 369, 374, 375, 379, 380, 381, 382, 386, 387, 388, 390, 391, 394, 398, 399, 400, 401, 404, 407, 410, 413, 414, 416, 417, 418, 419, 420, 421, 422, 423, 424, 426, 427, 428, 432, 448, 450, 452, 454, 458, 462, 464, 468, 471, 472, 473, 475, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 505, 511, 531, 539, 541, 542, 543, 545, 546, 548, 549, 550, 552, 558, 561, 563, 564, 565, 566, 567, 568, 572, 573, 574, 591, 595, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 635, 652, 653, 679, 680, 682, 693, 694, 695, 696, 700, 704, 707, 716, 733, 737, 738, 744, 745, 749, 786, 789, 791, 805, 806, 808, 833, 840, 841, 843, 854, 855, 856, 858, 859, 860, 862, 863, 864, 871, 872, 876, 881, 884, 885, 887, 904, 905, 908, 912, 913, 920, 922, 932, 933, 938, 944, 970, 989, 992, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1006, 1007, 1008, 1013, 1014, 1015, 1016, 1019, 1024, 1025, 1027, 1029, 1032, 1033, 1034, 1043, 1044, 1045, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059, 1060], "itsaphel": 1059, "itself": [27, 61, 64, 84, 90, 139, 152, 156, 193, 204, 218, 254, 260, 272, 287, 299, 326, 349, 361, 373, 375, 385, 386, 388, 390, 400, 407, 410, 414, 416, 427, 448, 449, 452, 453, 454, 477, 478, 479, 480, 481, 482, 483, 484, 535, 539, 541, 542, 543, 545, 546, 547, 548, 549, 550, 551, 559, 574, 577, 591, 600, 603, 604, 606, 607, 608, 610, 611, 647, 648, 649, 650, 651, 653, 663, 697, 699, 800, 801, 847, 848, 849, 850, 851, 852, 853, 857, 865, 866, 877, 878, 879, 907, 908, 957, 992, 996, 997, 999, 1003, 1004, 1008, 1019, 1045, 1056], "iv": [191, 1000], "ivan": [1049, 1050, 1053, 1056, 1059], "ivanllt": 1056, "iver": 1047, "iverson": 996, "ivicajov": 1044, "ivl": 195, "ivt": 542, "iv\u00e1n": [1048, 1054], "iwhalv": 1054, "iwona": 1058, "ix": [50, 287, 355], "iy_j": 1010, "iyer": 1052, "izadifar": 1059, "j": [0, 50, 55, 72, 73, 75, 78, 96, 104, 112, 113, 114, 139, 142, 143, 154, 172, 177, 188, 193, 232, 243, 256, 263, 277, 278, 283, 289, 303, 309, 312, 323, 333, 368, 374, 380, 381, 383, 390, 392, 398, 405, 413, 414, 416, 418, 420, 421, 423, 424, 426, 427, 445, 448, 452, 454, 461, 462, 477, 482, 506, 521, 524, 525, 526, 528, 536, 539, 542, 544, 545, 546, 548, 549, 555, 561, 567, 568, 601, 602, 640, 641, 645, 652, 653, 656, 657, 674, 675, 677, 688, 696, 697, 698, 700, 701, 702, 704, 713, 716, 718, 722, 724, 726, 729, 731, 732, 734, 763, 764, 766, 767, 782, 786, 796, 797, 800, 801, 841, 842, 849, 854, 855, 856, 858, 860, 861, 862, 863, 864, 865, 866, 883, 892, 893, 920, 921, 989, 990, 994, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1012, 1014, 1015, 1016, 1034, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "j0rd1smit": 1053, "ja": [419, 1048], "jaccard": [2, 298, 413, 458, 465, 707, 711, 727, 737, 742, 746, 786, 787, 788, 804, 1003, 1049, 1050], "jaccard_scor": [2, 298, 711, 737, 742, 804, 1000, 1050, 1053], "jaccard_similarity_scor": [1043, 1045, 1050], "jaccarddist": 707, "jack": [1043, 1046, 1054, 1055, 1056, 1057, 1059], "jacklangerman": [1049, 1050], "jackman": 1042, "jackmartin": 1047, "jackson": [1047, 1048, 1050], "jacob": [0, 406, 1046, 1047, 1048], "jacobi": 1056, "jacobsen": 1044, "jacopo": [1049, 1050], "jacqu": [1042, 1044], "jaehong": 1051, "jaehyun": 1053, "jaewon": 1049, "jai": [1051, 1055], "jaidev": 1046, "jaim": 1051, "jain": [1047, 1048, 1049, 1053, 1055, 1056], "jair": 1048, "jake": [0, 50, 183, 221, 240, 266, 304, 312, 406, 1018, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1055], "jakemick": 1043, "jakevdp": [304, 312], "jakhar": 1053, "jakirkham": [1048, 1049, 1050, 1056, 1057], "jakub": 1058, "jakubek": [1054, 1055], "jalali": [0, 100, 357, 401, 405, 410, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "jalexand3r": 1055, "jamaoui": [1049, 1050, 1053], "jame": [0, 383, 420, 842, 1001, 1041, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1057, 1058], "jamestwebb": [1043, 1044], "jami": 1049, "jamieson": 989, "jan": [0, 61, 62, 63, 64, 176, 177, 179, 180, 181, 182, 183, 185, 221, 253, 296, 405, 891, 1041, 1044, 1045, 1046, 1047, 1049, 1050, 1053, 1057], "jana": 1051, "janet": 383, "jane\u017e": [1042, 1043], "janfidor": [1056, 1057], "janhang": 1051, "janin": 1048, "janna": 1047, "jannik": 1054, "janso": 1041, "jansson": [1044, 1056], "januari": [384, 386, 1041, 1042, 1051, 1053, 1056, 1058], "janvanrijn": [1049, 1050], "jaqu": [0, 67, 80, 86, 88, 107, 120, 121, 203, 216, 217, 218, 242, 354, 356, 406, 1041, 1042, 1043, 1044], "jardim": 1054, "jare": 1056, "jarfa": 1047, "jarir": 1054, "jarkko": 704, "jarosch": 1043, "jaroslaw": 1048, "jarrod": [0, 406, 1050, 1057, 1058], "jarvelin": [734, 764, 1000], "jaskowiak": 454, "jason": [44, 421, 543, 908, 1047, 1049, 1053, 1056], "jatin": [1045, 1047], "jauhar": 1055, "jauvin": 1042, "java": [416, 450, 1019], "javascript": 1019, "javier": [1045, 1059], "jawahar": 992, "jax": 1058, "jay": 1048, "jaya": 1055, "jayaratn": [1052, 1053, 1056, 1057], "jayratn": 1053, "jayzed82": 1048, "jb": [1057, 1058], "jbdelafoss": 1048, "jbirch": [416, 450], "jblackburn": 1047, "jc": [1048, 1049], "jdcaballero": 1045, "jdethuren": [1049, 1050], "je": 1055, "jean": [1041, 1044, 1045, 1046, 1047, 1048, 1054], "jeann": 1055, "jeanselm": 1051, "jeb": 1049, "jeevan": 1053, "jeff": [1045, 1047, 1054, 1055], "jeffrei": [1044, 1047], "jeffrey04": [1046, 1047], "jelfner": 1055, "jell": 1044, "jen": [666, 1049], "jen09": 421, "jenatton": 421, "jenni": 1055, "jennif": 1054, "jensen": [1047, 1053], "jeong": 1051, "jeremi": [1024, 1046, 1047, 1048, 1049, 1052, 1053], "jeremiedbb": [1049, 1050, 1051], "jeremynixon": 1047, "jeroen": 1047, "jeroenpeterbo": 1053, "jeroko": 1048, "jeromedock": 1051, "jerphanion": [0, 405, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "jerryzhu": 907, "jesper": 1051, "jess": [843, 1001, 1054], "jess010": 1044, "jessica": 1047, "jessicakk0711": 1057, "jesu": [57, 360, 361], "jet": 102, "jevnik": 1046, "jewalikar": 1047, "jf": 1050, "jfraj": 1046, "jha": [1045, 1051, 1055], "jhay": 1053, "jhm": [61, 62, 63, 64, 176, 177, 179, 180, 181, 182, 183, 185, 253], "jhun": 482, "jia": 1047, "jiacheng": 1048, "jiali": 1046, "jian": 416, "jianbo": [416, 460, 470, 699], "jiang": [414, 1045, 1052], "jianzhu": 1054, "jiawei": [1057, 1058, 1059], "jiaxiang": 1053, "jie": [1049, 1050, 1053], "jiefangxuanyan": 1054, "jigna": 1053, "jihan": 1055, "jill": 1047, "jim": 1043, "jim0421": 1053, "jimenez": [1054, 1055], "jimmi": [869, 870, 1004, 1047, 1049], "jim\u00e9nez": [0, 376, 1049, 1052, 1053, 1054, 1055, 1056], "jin": [647, 1052, 1053], "jindal": 1053, "jinkun": 1049, "jiongyan": 1049, "jiquan": 1004, "jirka": 1055, "jiten": 1056, "jitendra": [416, 460, 470, 699], "jitter": [139, 658, 662, 1052], "jiyuan": 1047, "jjabl": 1049, "jjmistri": 1052, "jk": 997, "jkarolczak": 1056, "jkleint": [1048, 1049], "jl": [251, 905], "jmlr": [0, 416, 674, 675, 684, 712, 996, 1015], "jmlr_2014": 700, "jmontoyam": 1048, "jnboehm": 1054, "jnt": 420, "joaak": [1049, 1050], "joan": [1048, 1049, 1050, 1051], "joanna": 1051, "joaquin": 1053, "job": [147, 155, 192, 266, 272, 386, 390, 394, 423, 427, 445, 452, 454, 456, 458, 460, 465, 466, 469, 472, 475, 476, 480, 539, 543, 544, 545, 547, 550, 551, 553, 554, 556, 563, 564, 565, 566, 571, 572, 573, 574, 575, 576, 577, 578, 610, 615, 616, 618, 642, 647, 665, 696, 697, 698, 699, 700, 701, 702, 782, 786, 789, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 844, 845, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 871, 874, 907, 908, 910, 966, 1024, 1027], "joblib": [2, 41, 77, 89, 106, 145, 299, 329, 381, 384, 386, 389, 395, 398, 400, 404, 409, 417, 427, 445, 449, 452, 453, 454, 456, 458, 460, 465, 466, 469, 472, 475, 480, 516, 517, 539, 543, 544, 545, 547, 550, 551, 553, 554, 556, 563, 564, 565, 566, 571, 572, 573, 574, 575, 576, 577, 578, 602, 610, 615, 616, 618, 640, 642, 647, 655, 659, 661, 663, 665, 666, 667, 669, 671, 673, 674, 676, 684, 687, 696, 697, 698, 699, 700, 701, 702, 782, 786, 789, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 844, 845, 854, 855, 858, 860, 862, 863, 865, 866, 871, 872, 873, 874, 907, 908, 966, 967, 970, 985, 1000, 1020, 1036, 1041, 1042, 1044, 1046, 1048, 1049, 1050, 1052, 1053, 1056, 1058, 1059], "joblib_start_method": 398, "jochen": 1043, "jock": 104, "joe": 1046, "joei": 1057, "joel": [0, 106, 401, 405, 424, 543, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059], "johann": [1043, 1044, 1049, 1051, 1052, 1055], "johanna": [114, 1059], "johannah": 1047, "johanwork": 1054, "john": [383, 424, 544, 716, 743, 777, 887, 914, 915, 917, 918, 990, 996, 1000, 1041, 1042, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1054, 1056, 1057, 1058, 1059], "johnathanpi": [1056, 1057], "johnson": [37, 90, 189, 246, 319, 323, 378, 497, 510, 888, 900, 904, 905, 906, 1010, 1017, 1021, 1036, 1049, 1055, 1057], "johnson_lindenstrauss_min_dim": [2, 251, 1012, 1042], "johnston": [174, 383, 996, 1050], "johnstott": 1049, "johnthagen": 1056, "johnwon": 323, "join": [50, 51, 57, 90, 187, 238, 278, 321, 381, 401, 471, 1023, 1034, 1041, 1049], "joint": [152, 189, 193, 198, 204, 206, 207, 209, 219, 240, 272, 417, 619, 660, 670, 700, 847, 848, 849, 850, 851, 912, 996, 997, 1001, 1005, 1007, 1011, 1021, 1041], "jointli": [25, 214, 285, 416, 421, 996], "joli": [0, 406, 1042, 1043, 1044, 1045, 1046, 1047], "jon": [360, 1048, 1051, 1052, 1054, 1055, 1058], "jona": [135, 1053, 1058], "jonatan": 1049, "jonathan": [381, 1045, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1057], "joncral": 1047, "jone": [0, 381, 406, 1041], "jong": 1048, "joona": 1041, "jordal": 1047, "jordan": [416, 421, 699, 805, 1051, 1052, 1055, 1056], "jordi": 1047, "jorg": [666, 1044, 1053, 1055], "jori": [0, 405, 1048, 1049, 1050, 1053, 1054], "jose": [174, 383, 666, 1000, 1049, 1051], "joseph": [1044, 1045, 1046, 1047, 1053, 1055, 1056], "josephsalmon": [1048, 1049, 1050], "josh": [424, 1048], "joshi": [1047, 1049, 1055, 1058, 1059], "joshua": [333, 381, 1043, 1044, 1046, 1047, 1053, 1056, 1057], "joshuakennethjon": 1050, "jos\u00e9": [731, 1044, 1054, 1059], "jotasi": 1049, "joudet": [1048, 1049], "journal": [0, 114, 193, 278, 284, 296, 380, 381, 383, 414, 416, 418, 423, 460, 470, 481, 542, 549, 635, 643, 653, 697, 700, 701, 713, 723, 739, 742, 743, 766, 767, 794, 837, 842, 888, 900, 989, 990, 994, 996, 997, 998, 1001, 1007, 1012, 1014, 1015], "jovan": [1055, 1056], "joydeep": 416, "jo\u00e3o": 1056, "jo\u00ebl": 1049, "jpcar": 1059, "jpeg": [380, 381, 501, 502], "jpfrancoia": [1047, 1048], "jpg": [83, 514, 592, 595], "jpienaar": 1059, "jpm": 51, "jpmml": 1019, "jpmorgan": [51, 1024], "jr": 996, "jrenni": 849, "jrfiedler": 1047, "jschendel": [1048, 1049], "jschuerz": 1055, "json": [380, 386, 404], "jth": [782, 786], "juan": [0, 376, 1041, 1052, 1053, 1054, 1055, 1056], "juanfe88": 1056, "judg": [93, 226, 416, 1029], "judgment": [269, 1000], "judithabk6": 1052, "juergen": [1051, 1056], "jul": 287, "juli": [174, 383, 425, 742, 893, 1010, 1044, 1048, 1049, 1050], "julia": [416, 725, 745, 803], "julian": [1048, 1049, 1059], "juliankahnert": 1047, "juliaschoepp": [1056, 1057], "juliathebrav": 1047, "julien": [0, 405, 666, 996, 1024, 1041, 1044, 1048, 1049, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "juliet": 1049, "julietcl": 1049, "julio": 1054, "julyrashchenko": 1054, "jumon": 1052, "jump": [43, 221, 319, 383, 386, 424, 891], "jumpi": 424, "june": [416, 997, 1047, 1057], "jung": [1048, 1052, 1056], "jungkook": 1046, "jungl": 997, "jupyt": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 387, 388, 417, 476, 910, 1016, 1019, 1020, 1052, 1055], "jupyterlit": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368], "jurgen": 1024, "juri": 574, "jurman": 751, "just": [43, 52, 67, 104, 118, 125, 145, 149, 155, 174, 210, 217, 241, 252, 272, 278, 285, 289, 299, 314, 349, 360, 361, 368, 369, 381, 385, 386, 387, 388, 390, 391, 394, 398, 399, 400, 413, 415, 416, 417, 420, 423, 425, 428, 476, 541, 543, 550, 554, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 587, 592, 618, 619, 654, 660, 665, 666, 668, 670, 674, 675, 676, 684, 685, 686, 814, 831, 861, 869, 870, 989, 996, 999, 1000, 1001, 1004, 1008, 1010, 1014, 1020, 1032, 1041, 1045, 1047, 1049, 1053, 1057], "justglow": 1050, "justif": 684, "justifi": [386, 392, 414, 573], "justin": [1043, 1049, 1053], "jvm": 1054, "jygerardi": [1056, 1057], "j\u00e9r\u00e9mie": [0, 405, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "j\u00e9r\u00f4me": [1050, 1051, 1052, 1058, 1059], "j\u00eann": 1047, "j\u00f6rg": [416, 458, 465, 1049], "j\u00f6rn": 1048, "j\u00f8rgensen": [996, 1058], "k": [2, 33, 45, 50, 51, 54, 55, 57, 61, 63, 66, 67, 71, 72, 73, 75, 77, 81, 84, 85, 88, 90, 91, 95, 98, 100, 108, 109, 113, 121, 122, 123, 125, 128, 131, 132, 139, 141, 148, 152, 156, 158, 159, 161, 162, 165, 167, 170, 171, 174, 177, 179, 180, 184, 185, 188, 189, 192, 193, 194, 195, 200, 202, 203, 205, 214, 217, 222, 224, 232, 234, 251, 253, 255, 256, 257, 263, 266, 274, 278, 281, 282, 287, 288, 291, 292, 299, 301, 304, 305, 306, 307, 308, 310, 311, 312, 320, 321, 322, 323, 326, 328, 332, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 359, 360, 362, 368, 369, 374, 380, 381, 383, 386, 394, 395, 398, 400, 407, 412, 413, 414, 417, 418, 419, 421, 422, 423, 424, 425, 426, 428, 448, 451, 454, 455, 456, 457, 458, 459, 460, 461, 467, 468, 470, 477, 480, 496, 510, 512, 514, 520, 531, 539, 545, 549, 552, 553, 554, 557, 558, 561, 563, 565, 566, 567, 589, 597, 598, 599, 600, 602, 603, 604, 606, 607, 608, 614, 615, 616, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 639, 647, 648, 656, 658, 659, 661, 662, 663, 664, 666, 667, 671, 672, 673, 674, 675, 677, 687, 688, 690, 691, 692, 693, 694, 696, 699, 703, 704, 712, 713, 716, 725, 734, 745, 751, 764, 766, 767, 769, 774, 777, 782, 783, 784, 785, 787, 801, 802, 803, 805, 806, 809, 813, 815, 816, 817, 820, 823, 824, 826, 827, 829, 830, 836, 847, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 865, 866, 873, 877, 878, 879, 883, 884, 885, 887, 888, 892, 900, 905, 919, 927, 935, 944, 949, 974, 989, 990, 992, 993, 994, 996, 997, 998, 999, 1002, 1004, 1005, 1006, 1008, 1013, 1014, 1015, 1016, 1019, 1021, 1029, 1035, 1036, 1041, 1042, 1043, 1044, 1047, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1058, 1059], "k0": 994, "k1": [426, 629, 632], "k1__": 426, "k1__constant_valu": 180, "k1__k1": 426, "k1__k1__constant_valu": 426, "k1__k1__constant_value_bound": 426, "k1__k2": 426, "k1__k2__length_scal": [182, 426], "k1__k2__length_scale_bound": 426, "k2": [426, 629, 632], "k2__": 426, "k2__length_scal": 426, "k2__length_scale_bound": 426, "k_": [413, 426, 624, 627, 629, 632, 782, 992, 1010], "k_1": [2, 426, 629, 632], "k_2": [2, 426, 629, 632], "k_best": [600, 909, 1013, 1058], "k_diag": [620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633], "k_fit_all_": 878, "k_fit_rows_": 878, "k_fold": [165, 1029], "k_gradient": [620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633], "k_init": [451, 467], "k_mean": [2, 99, 395, 400, 1033, 1049, 1057], "k_means_cluster_cent": 99, "k_means_elkan": 1049, "k_means_iris_3": 80, "k_means_iris_8": 80, "k_means_iris_bad_init": 80, "k_means_label": 99, "k_new": 878, "k_ret": [852, 853], "k_true": [852, 853], "ka00ri": [1056, 1057], "kachaiev": 1058, "kaczmarzyk": 1058, "kadatatlu": 1054, "kadota": 1055, "kaggl": [160, 399], "kahni": 1053, "kai": [383, 571, 1006, 1048], "kaicheng": 1045, "kaichogami": 1047, "kailasa": [1055, 1056], "kaim": [869, 870], "kaiser": [421, 540], "kakati": 1056, "kalli": [1049, 1050], "kalyan": 1047, "kamalakerdadi": [1046, 1047], "kamar": 1049, "kamchyev": 1058, "kamel": 1041, "kamishima": [1047, 1048], "kamm": 1000, "kanai": [1047, 1048, 1049], "kanazu": [1056, 1057], "kanchimo": 1059, "kang": [1049, 1051], "kania": [1056, 1057], "kanika": 1051, "kanishk": 1056, "kanissh": 1056, "kanji": 1054, "kanniah": [1044, 1045], "kansal": 1047, "kapadni": 1056, "kapeln": [193, 1007], "kapoor": [1049, 1050], "kappa": [2, 544, 724], "kapur": 1048, "kar": 1047, "karan": [1048, 1049, 1050], "karayev": 1043, "karbownik": 1054, "karen": 1054, "karger": [849, 1002], "karhunen": 542, "karin": [635, 990], "karl": 1049, "karlo": [1058, 1059], "karnofski": 1048, "karnowski": 1053, "karol": 1044, "kartik": 1053, "karypi": 416, "kaseorg": 1051, "kashif": 1046, "kasim": 1045, "kaski": 704, "kasper": 1049, "kassa": [1056, 1057], "kastner": [0, 129, 406, 1043, 1044, 1045, 1052, 1053], "kat": 1048, "kataev": [1049, 1050], "kataki": [728, 742, 748, 1000], "katarina": [1051, 1053], "katheleen": 380, "kathi": [1048, 1051], "kathleen": 1048, "kathryn": 1052, "kati": 1048, "katotten": 1055, "katrin": [1049, 1050], "katrina": [153, 1052], "katriopla": 1049, "katyal": 1051, "katz": [1046, 1053, 1054], "kaufmann": [1012, 1016, 1053], "kaushik": [1048, 1055, 1056, 1057, 1059], "kaushik94": 1044, "kawamura": 1054, "kawwa": 1054, "kayawari": 1054, "kaylani2": 1053, "kaynak": 383, "kazmar": 1045, "kb": [105, 192, 193, 272], "kbest": [106, 600], "kbin": [326, 333], "kbinsdiscret": [2, 43, 88, 123, 189, 200, 220, 238, 258, 318, 321, 326, 333, 520, 665, 875, 891, 921, 1010, 1021, 1049, 1053, 1054, 1055, 1057, 1059], "kbinsdiscretizer__n_bin": 321, "kcachegrind": 389, "kd": [304, 416, 422, 1003, 1049, 1050, 1051], "kd_tree": [427, 452, 454, 458, 465, 696, 697, 854, 855, 856, 857, 858, 860, 862, 863, 864, 1003, 1054, 1058], "kdd": [197, 381, 414, 445, 1012], "kdd06_rp": 905, "kddcup": [257, 379, 500, 1036], "kddcup99": [2, 381, 500], "kde": [191, 192, 292, 296, 303, 304, 312, 422, 857], "kdt": 1003, "kdtree": [2, 454, 458, 465, 696, 697, 852, 854, 855, 856, 857, 858, 860, 862, 863, 864, 1043, 1045, 1049, 1053, 1054, 1057, 1058], "ke": [423, 1052, 1053], "kearn": 1044, "keat": [1056, 1057], "keep": [0, 45, 52, 64, 77, 109, 128, 130, 145, 155, 173, 187, 191, 192, 193, 194, 195, 204, 220, 221, 222, 228, 238, 268, 273, 276, 323, 324, 331, 339, 349, 360, 361, 364, 369, 373, 374, 378, 386, 390, 399, 400, 414, 416, 417, 418, 419, 420, 421, 439, 458, 473, 490, 491, 492, 493, 501, 502, 542, 548, 549, 552, 555, 562, 564, 566, 568, 570, 573, 576, 578, 603, 606, 608, 611, 619, 642, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 684, 685, 686, 687, 716, 826, 845, 846, 855, 863, 869, 870, 908, 913, 915, 918, 921, 923, 996, 1001, 1005, 1008, 1010, 1020, 1023, 1024, 1025, 1030, 1032, 1034, 1036, 1041, 1046, 1049, 1050, 1054, 1055, 1057, 1059], "keep_empty_featur": [635, 636, 638, 990, 1056], "keerti": 1056, "kegl": [61, 1045], "kei": [2, 47, 49, 52, 55, 57, 77, 145, 149, 160, 187, 191, 238, 254, 257, 260, 279, 281, 282, 329, 330, 331, 332, 333, 334, 335, 336, 375, 379, 388, 391, 392, 393, 398, 400, 401, 404, 407, 416, 417, 420, 426, 472, 480, 569, 570, 575, 576, 577, 578, 596, 599, 602, 625, 634, 640, 642, 667, 719, 808, 811, 812, 820, 822, 830, 835, 871, 872, 927, 937, 965, 1008, 1020, 1034, 1036, 1038, 1047, 1053, 1054, 1056, 1057, 1059], "keith": [360, 1041, 1046], "kekalainen": [734, 764, 1000], "kelkar": [1048, 1049, 1051], "kelleh": [716, 1000], "kelleher2015": 1000, "kellei": [381, 1043, 1044], "keller": 1053, "kellogg": 51, "kellycarmodi": 1051, "kemal": [0, 58, 59, 1043, 1044], "kemaleren": [58, 59], "kemenad": 1052, "kemk": 1052, "ken": [383, 1034, 1043, 1050], "ken4git": 1055, "kendal": 1056, "kendrick": 1053, "kennedi": [1048, 1051, 1058], "kennel": 1052, "kenneth": [1012, 1041, 1042, 1047, 1048, 1055, 1056], "kenni": 1053, "kensuk": 1051, "kent": 57, "kenta": 1044, "kento": [1056, 1057], "kept": [64, 268, 299, 356, 380, 390, 410, 426, 504, 543, 546, 548, 549, 555, 605, 618, 619, 627, 628, 652, 703, 805, 806, 933, 1010, 1049, 1050], "kera": [398, 1019], "kerimov": [1048, 1049], "kernal": 130, "kernc": [1041, 1055, 1056], "kernel": [2, 23, 24, 27, 42, 45, 48, 49, 50, 66, 67, 86, 92, 108, 118, 124, 126, 134, 161, 167, 172, 175, 177, 178, 179, 180, 183, 187, 202, 203, 221, 234, 246, 247, 255, 259, 271, 276, 278, 280, 283, 284, 288, 293, 294, 300, 305, 310, 324, 331, 340, 343, 344, 346, 347, 349, 350, 351, 352, 354, 357, 369, 373, 378, 388, 398, 400, 414, 416, 417, 420, 423, 424, 439, 448, 456, 460, 469, 470, 473, 490, 491, 492, 499, 504, 506, 510, 512, 522, 541, 542, 543, 549, 552, 562, 564, 566, 568, 570, 573, 576, 578, 601, 602, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 639, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 684, 685, 686, 687, 696, 698, 699, 700, 703, 743, 766, 767, 769, 774, 775, 782, 783, 784, 785, 808, 814, 819, 822, 838, 840, 845, 846, 852, 853, 855, 857, 863, 870, 872, 873, 878, 882, 884, 885, 887, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 921, 923, 989, 995, 996, 997, 1000, 1001, 1003, 1006, 1013, 1014, 1021, 1022, 1025, 1027, 1029, 1030, 1035, 1036, 1041, 1042, 1043, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "kernel_": [176, 177, 178, 179, 180, 181, 182, 183, 185, 618, 619], "kernel__length_scal": 176, "kernel__period": 176, "kernel_approxim": [2, 43, 187, 189, 196, 197, 234, 247, 252, 330, 646, 647, 648, 649, 650, 685, 766, 767, 878, 992, 1021, 1025, 1042, 1048, 1058], "kernel_dens": [852, 853], "kernel_label": 355, "kernel_metr": [2, 647, 648, 649, 650], "kernel_param": [460, 543, 647, 651], "kernel_pca": [44, 130, 417], "kernel_pca_": 696, "kernel_pca_back_proj_ax": 130, "kernel_pca_proj_ax": 130, "kernel_ridg": [2, 176, 253, 651, 1001, 1045], "kernel_ridge_tun": 176, "kernel_svm": 252, "kernel_svm_scor": 252, "kernel_svm_tim": 252, "kernelapproximationkernel": 1027, "kernelcenter": [2, 412, 1010, 1051, 1055, 1057, 1058], "kerneldens": [2, 303, 304, 312, 422, 1043, 1049, 1050, 1054, 1055, 1056], "kernelpca": [2, 44, 417, 421, 541, 542, 549, 552, 696, 698, 700, 878, 1010, 1042, 1043, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "kernelridg": [2, 130, 176, 253, 680, 993, 1001, 1045, 1058], "kertesz": 1055, "keshat": [674, 675, 996], "keshavan": 1051, "kesshi": [1051, 1052], "kevad": 1051, "kevin": [651, 1043, 1045, 1047, 1048, 1051, 1052, 1053, 1055, 1056, 1058], "kevlani": 1049, "keyber": 1059, "keyerror": [927, 1051], "keyword": [360, 380, 386, 388, 391, 393, 400, 416, 427, 430, 446, 452, 453, 458, 460, 465, 472, 475, 504, 511, 543, 546, 548, 567, 568, 575, 576, 577, 578, 628, 636, 639, 640, 647, 651, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 696, 700, 705, 706, 707, 708, 709, 710, 782, 786, 787, 788, 789, 800, 801, 814, 831, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 872, 876, 944, 967, 989, 997, 1000, 1003, 1013, 1041, 1045, 1047, 1048, 1049, 1051, 1053, 1055, 1056, 1057, 1058, 1059], "kf": [420, 813], "kfold": [2, 89, 145, 151, 165, 273, 283, 369, 420, 445, 480, 575, 576, 602, 610, 655, 659, 661, 663, 669, 671, 673, 681, 808, 811, 812, 814, 816, 818, 822, 827, 829, 831, 832, 833, 834, 835, 836, 837, 839, 843, 846, 893, 1029, 1042, 1043, 1044, 1046, 1047, 1049, 1051], "khaja": 1056, "khan": [1056, 1057], "khandelw": 1053, "khanduja": 1044, "khant": 1056, "kharsa": 1055, "khedkar": 1055, "khine": 1055, "kho": 1056, "khoo": 1053, "khosasi": 1054, "khosrow": 1000, "khoual": 1054, "khwaja": 1056, "ki": 1000, "kian": [143, 1046, 1056, 1057, 1058], "kid": 1010, "kieker": [1049, 1050], "kielczewski": [224, 1047], "kie\u00dfl": 1052, "kilian": [424, 1056, 1057], "kill": [360, 398], "killer": [386, 1024], "kilobyt": 88, "kilomet": 772, "kim": [996, 1049, 1050, 1051, 1055], "kimayoung": 1055, "kimberli": 51, "kimbinyi": 1053, "kind": [43, 48, 51, 52, 61, 62, 109, 133, 145, 160, 169, 192, 193, 268, 271, 272, 274, 287, 326, 330, 333, 346, 349, 360, 374, 375, 379, 381, 386, 388, 392, 398, 399, 414, 416, 419, 420, 421, 423, 424, 425, 496, 497, 511, 516, 517, 529, 532, 596, 640, 641, 709, 941, 996, 1002, 1007, 1016, 1044, 1053, 1055, 1056, 1057], "kindli": 0, "king": 937, "kingjr": 1047, "kingma": [869, 870, 1004], "kink": 209, "kiragu": 1053, "kiran": 1053, "kirandevraj": 1056, "kiril": [1048, 1049, 1051, 1053], "kirkbi": [1048, 1049], "kirkham": [1046, 1047, 1049], "kirthi": 1051, "kishan": 1058, "kishimoto": 1053, "kishor": 1054, "kislovskii": 1058, "kit": 398, "kitchen": [649, 992], "kj": [380, 1002], "kjell": 1047, "kk": 1000, "kl": [421, 997, 1049], "kl_divergence_": [700, 1048], "klarup": 1048, "klass": 100, "klau": [421, 543, 878], "kleczewski": [298, 1048, 1049], "kleiber": 1055, "klevebr": 1049, "klima": 1056, "klopfer": 1050, "kluge": [1056, 1057], "kluger": [2, 413, 459, 521], "klusacek": 1000, "km": [96, 332, 361], "kmatt10": 1054, "kmb": 51, "kmean": [2, 57, 58, 71, 78, 80, 81, 83, 85, 88, 92, 93, 96, 189, 266, 269, 322, 332, 361, 395, 407, 416, 442, 443, 444, 448, 451, 456, 457, 460, 470, 520, 718, 800, 801, 805, 806, 877, 1003, 1010, 1020, 1021, 1033, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "kmeans_estim": 125, "kmeans_model": 416, "kmeans_plusplu": [2, 94, 416, 1053, 1058], "kmitl": 257, "kmode": 1019, "kms15": [1049, 1050], "knee": 416, "kneighbor": [324, 332, 854, 855, 856, 858, 860, 1003, 1045, 1050, 1054, 1055, 1056, 1057], "kneighbors_graph": [2, 74, 79, 97, 102, 299, 400, 416, 449, 453, 703, 854, 855, 856, 858, 860, 862, 863, 864, 866, 1003, 1041, 1045, 1050], "kneighborsclassifi": [2, 67, 161, 166, 301, 302, 307, 308, 324, 330, 332, 360, 423, 610, 855, 859, 860, 861, 862, 863, 1001, 1003, 1032, 1041, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "kneighborsclassifierkneighbor": 1027, "kneighborsregressor": [2, 187, 256, 311, 332, 423, 578, 854, 860, 862, 863, 1001, 1003, 1041, 1043, 1045, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "kneighborstransform": [2, 299, 301, 328, 700, 864, 1003, 1051, 1055, 1056], "knew": 1033, "knight": 325, "knit": 1028, "knn": [142, 161, 166, 187, 302, 307, 308, 311, 324, 330, 340, 360, 423, 610, 861, 907, 908, 1003, 1013, 1032, 1047], "knn__weight": 302, "knn_graph": 74, "knn_impute_scor": 188, "knnimput": [2, 188, 328, 635, 638, 990, 1051, 1052, 1055, 1056, 1057, 1058], "knnquerybatch": 299, "knot": [43, 221, 331, 891, 1010, 1054], "know": [88, 101, 171, 174, 176, 185, 192, 238, 254, 255, 272, 278, 296, 298, 332, 338, 356, 361, 373, 386, 398, 407, 410, 416, 419, 420, 421, 424, 508, 512, 518, 654, 660, 666, 667, 734, 764, 808, 822, 897, 898, 900, 901, 902, 903, 920, 921, 922, 923, 989, 999, 1000, 1001, 1003, 1012, 1047, 1048, 1051, 1053], "knowledg": [92, 147, 155, 192, 237, 257, 272, 278, 292, 381, 386, 389, 392, 399, 400, 416, 420, 423, 427, 452, 519, 563, 564, 571, 728, 744, 748, 791, 841, 1000, 1001, 1012, 1034, 1059], "known": [2, 50, 55, 62, 64, 74, 84, 92, 93, 114, 133, 134, 160, 181, 183, 188, 204, 220, 221, 238, 247, 272, 278, 280, 287, 308, 312, 320, 331, 336, 338, 346, 353, 361, 375, 381, 383, 384, 386, 389, 394, 398, 400, 412, 413, 414, 416, 417, 418, 419, 420, 421, 423, 424, 426, 446, 471, 490, 492, 506, 516, 517, 552, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 596, 597, 599, 602, 617, 630, 641, 666, 667, 680, 690, 691, 702, 712, 718, 721, 726, 737, 751, 763, 765, 803, 841, 847, 848, 849, 850, 851, 854, 859, 862, 868, 896, 920, 921, 922, 923, 990, 992, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1010, 1015, 1016, 1025, 1030, 1032, 1033], "known_val": 635, "knox": 1053, "knp": 635, "knr": 423, "knyazev": [81, 416, 460, 470, 703, 1051, 1054, 1055], "ko": [51, 63, 177], "kobak": [700, 1054], "kobaski": 1054, "kobayashi": [1053, 1054], "kober": 1049, "kobi": 743, "koch": [1043, 1049, 1050, 1052, 1053], "kocot": 1052, "koehler": 1045, "koen": [1049, 1050], "koenker": [731, 996], "koh": [996, 1024], "kohavi": 420, "kohli": [1058, 1059], "koi8": 424, "koivunen": 114, "kokhlikyan": [245, 1048, 1049], "koki": 1053, "koko": [1049, 1055, 1056], "kolawol": 1054, "kolganov": 1046, "kolh": 1043, "kolstad": 57, "komey": [1055, 1056], "kommireddi": 1055, "kondratyev": 1055, "kong": 1054, "konstantin": [1046, 1047, 1048], "konstantino": [1049, 1058], "konwar": 1052, "koonc": 1049, "korba": 381, "korean": 1019, "kornel": [224, 1047], "kornev": 1056, "korobko": 1058, "korobov": [1042, 1043, 1044, 1047, 1048], "korolev": 1051, "kosic": 1053, "kosobrodov": 1049, "kossaifi": [1041, 1045, 1046], "kossen": [1056, 1057], "kossori": [1049, 1050], "kostelac": [1056, 1057], "kot271828": 1054, "kothari": 1052, "kotwalia": [1049, 1050], "koumenti": 1056, "koushik": 1055, "koustav": [1058, 1059], "kovalevskyi": 1047, "kowalski87": 1044, "koyama": 1055, "kozachenko": [615, 616], "kozynet": [1053, 1055], "kpca": [2, 541, 542, 543, 1035, 1036, 1041], "kr": [253, 278, 1055], "kr_fit": 253, "kr_predict": 253, "kraig": 1056, "kraktu": 1059, "kranthi": 1055, "kranz": 1024, "kraskov": [615, 616], "krasouli": [1048, 1049, 1050, 1051, 1053, 1054], "kratzwald": 1047, "krawczyk": 1055, "krawutschk": [1056, 1057], "krell": [1045, 1047], "kriegel": [416, 427, 452, 458, 465, 858, 1006], "krinitsyn": 1049, "krishna": [1047, 1048, 1049, 1050, 1051, 1052, 1055, 1056], "krishnachaitanya9": 1052, "krishnakalyan3": 1047, "krishnan": 1051, "krivich": [1047, 1048, 1050], "kronovet": 1046, "krr": [253, 651, 993], "krsto": 1059, "krum": [1053, 1055], "krumetoft": 1055, "krump": 1046, "kruskal": [643, 698, 702, 997], "krzeminski": 1048, "krzysztof": 380, "ksemb": 1049, "kshitij": [1056, 1057, 1059], "ksvd": [672, 693, 694, 996], "ksvm": 197, "ksvm_score": 197, "ksvm_time": 197, "kth": [57, 829], "ku": [1045, 1046], "kuai": [1049, 1050], "kubin": 1052, "kuhlmann": [1048, 1049], "kulbear": 1050, "kulkarni": 1049, "kull": [414, 1000], "kullback": [54, 240, 421, 546, 548, 555, 700, 997, 1048], "kulsinski": [458, 465, 707, 786, 787, 788], "kulsinskidist": [707, 1057], "kumar": [0, 77, 174, 202, 381, 406, 416, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "kumaresshan": [1049, 1050, 1053], "kumawat": 1055, "kund": [1057, 1058], "kunj": 1054, "kuno": 1059, "kuo": 1045, "kurumeyuta": 1054, "kurz": [1055, 1056], "kusanagi": [1052, 1054], "kusanagi2": 1053, "kushal": [1049, 1050], "kushan": [137, 1058], "kushansharma1": 137, "kushwah": [1057, 1058], "kushwaha": 1053, "kusterl": 1051, "kuth": 1047, "kvam": [1042, 1044], "kvle": 1047, "kw_arg": [144, 876, 1010, 1047], "kwarg": [76, 128, 254, 388, 393, 430, 434, 438, 446, 450, 456, 458, 472, 477, 543, 546, 548, 571, 639, 654, 655, 660, 661, 668, 669, 670, 671, 685, 689, 692, 706, 707, 708, 710, 750, 871, 872, 876, 916, 927, 960, 966, 968, 1048, 1052, 1054, 1058], "kwd": [636, 779, 782, 786, 789, 800, 801], "kwei": [54, 1044, 1045, 1046, 1047, 1048], "kxytim": 1054, "kybernetika": 383, "kye": 1049, "kyeongpil": 1049, "kyle": [0, 129, 406, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1052, 1053], "kyledrogo": 1049, "kyler": 1046, "k\u00e4rkk\u00e4inen": 996, "l": [0, 46, 53, 55, 75, 81, 82, 101, 102, 114, 142, 174, 194, 212, 215, 224, 229, 230, 283, 284, 285, 296, 315, 323, 356, 383, 384, 392, 394, 413, 414, 416, 420, 421, 423, 426, 482, 524, 525, 526, 546, 548, 555, 563, 564, 565, 566, 573, 574, 598, 615, 616, 618, 619, 623, 627, 630, 631, 642, 656, 657, 666, 677, 680, 682, 688, 695, 697, 700, 701, 713, 723, 733, 734, 739, 764, 794, 849, 883, 920, 921, 922, 923, 989, 994, 996, 997, 1000, 1002, 1003, 1004, 1008, 1012, 1014, 1016, 1033, 1044, 1049, 1053, 1054, 1055, 1056, 1058], "l1": [2, 25, 42, 46, 55, 66, 75, 101, 115, 117, 189, 191, 198, 199, 205, 206, 207, 208, 209, 214, 215, 224, 231, 235, 249, 279, 299, 316, 331, 395, 398, 416, 418, 421, 449, 453, 458, 465, 472, 477, 478, 479, 480, 481, 482, 483, 484, 486, 504, 510, 512, 539, 545, 546, 547, 548, 550, 551, 555, 556, 566, 573, 597, 598, 599, 605, 652, 653, 654, 655, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 675, 676, 678, 680, 684, 685, 686, 687, 689, 696, 743, 770, 776, 781, 786, 787, 788, 793, 822, 829, 838, 854, 855, 856, 858, 859, 860, 862, 863, 864, 865, 866, 884, 892, 899, 912, 913, 919, 921, 923, 935, 982, 996, 998, 1000, 1003, 1010, 1014, 1015, 1016, 1021, 1032, 1046, 1048, 1054, 1057], "l1_color": 231, "l1_contour": 231, "l1_distanc": 1041, "l1_min_c": [2, 213, 996, 1015, 1041], "l1_plot": 236, "l1_ratio": [46, 49, 54, 204, 205, 211, 286, 291, 373, 398, 421, 546, 548, 555, 654, 655, 660, 666, 667, 668, 669, 670, 671, 676, 684, 686, 689, 996, 1014, 1042, 1044, 1046, 1053, 1055], "l1_ratio_": [655, 667, 669], "l1_ratios_": 667, "l2": [2, 53, 66, 75, 115, 117, 189, 191, 192, 198, 199, 204, 205, 211, 213, 216, 220, 225, 231, 235, 236, 238, 279, 291, 299, 319, 326, 342, 360, 361, 388, 395, 398, 416, 418, 421, 423, 424, 449, 453, 458, 465, 532, 546, 548, 555, 566, 569, 570, 573, 597, 598, 599, 651, 654, 655, 656, 657, 660, 665, 666, 667, 668, 669, 670, 671, 676, 677, 680, 684, 686, 688, 689, 694, 695, 696, 743, 758, 769, 770, 786, 787, 788, 822, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 869, 870, 884, 892, 899, 912, 913, 917, 918, 919, 921, 923, 983, 989, 993, 996, 998, 1003, 1004, 1010, 1014, 1016, 1021, 1032, 1034, 1043, 1045, 1046, 1048, 1050], "l2014": 423, "l2_color": 231, "l2_contour": 231, "l2_regular": [331, 423, 569, 570], "l_": [413, 619, 660, 749, 1000], "l_i": 1010, "l_inf": 55, "l_m": 423, "l_p": [458, 465, 696, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866], "l_x": 53, "la": [0, 212, 228, 299, 301, 321, 322, 325, 383, 405, 1024, 1042, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "lab": [0, 381, 476, 544, 910, 1024, 1052], "labb\u00e9": 1059, "label": [2, 30, 38, 43, 45, 46, 48, 50, 51, 52, 53, 58, 61, 62, 63, 64, 66, 68, 69, 73, 75, 77, 78, 80, 81, 82, 83, 84, 86, 87, 90, 91, 93, 95, 98, 99, 100, 101, 102, 107, 109, 111, 112, 113, 114, 117, 118, 120, 122, 123, 127, 129, 131, 132, 133, 134, 139, 140, 141, 142, 143, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 163, 170, 176, 177, 181, 182, 183, 184, 185, 187, 189, 192, 195, 197, 199, 200, 202, 203, 204, 208, 209, 210, 214, 220, 221, 222, 223, 226, 227, 228, 229, 230, 234, 235, 237, 238, 241, 242, 243, 247, 252, 253, 255, 257, 258, 265, 271, 272, 273, 276, 277, 279, 280, 281, 282, 284, 287, 288, 289, 290, 291, 292, 293, 298, 304, 306, 308, 311, 315, 317, 319, 320, 324, 328, 329, 332, 335, 337, 341, 342, 343, 351, 353, 355, 356, 360, 361, 364, 365, 366, 367, 375, 378, 379, 380, 385, 386, 388, 391, 395, 400, 401, 413, 414, 415, 426, 427, 433, 434, 438, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 467, 469, 470, 473, 477, 495, 496, 497, 501, 502, 503, 504, 510, 511, 516, 517, 520, 522, 523, 527, 530, 531, 557, 558, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 571, 572, 573, 575, 577, 578, 600, 601, 602, 603, 604, 606, 607, 608, 612, 613, 614, 617, 618, 639, 666, 667, 674, 675, 676, 681, 682, 683, 684, 685, 686, 705, 706, 708, 710, 711, 712, 713, 715, 717, 718, 720, 721, 722, 723, 724, 725, 726, 728, 730, 733, 734, 735, 737, 738, 739, 742, 743, 744, 745, 746, 747, 748, 749, 751, 762, 763, 764, 765, 790, 791, 792, 794, 795, 796, 797, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 817, 822, 823, 824, 826, 827, 828, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 858, 859, 861, 862, 869, 870, 872, 876, 879, 880, 883, 885, 886, 893, 896, 907, 908, 909, 912, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 932, 937, 938, 963, 964, 971, 989, 996, 997, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1014, 1015, 1016, 1019, 1021, 1022, 1025, 1029, 1030, 1032, 1033, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "label1": 400, "label2": 400, "label_a": 287, "label_b": 287, "label_binar": [2, 285, 287, 879, 1045], "label_binarizer_": 841, "label_distributions_": [338, 339, 907, 908, 1052], "label_im": 101, "label_out": 78, "label_pr": [725, 744, 745, 763, 765, 803], "label_prop_model": [907, 908], "label_propag": 1042, "label_ranking_average_precision_scor": [2, 1000, 1045, 1049, 1050, 1056], "label_ranking_loss": [2, 1000, 1046], "label_spread": 340, "label_tru": [712, 725, 745, 763, 765, 803], "labelbinar": [2, 287, 400, 730, 749, 841, 876, 885, 893, 896, 1001, 1025, 1044, 1045, 1046, 1050, 1055], "labelbottom": [163, 278], "labeled_iter_": [341, 909], "labelencod": [2, 400, 577, 886, 1011, 1041, 1049, 1056, 1057, 1060], "labelkfold": [1046, 1047], "labelleft": 263, "labelpad": 278, "labelpropag": [2, 332, 340, 908, 909, 1001, 1013, 1042, 1047, 1048, 1051, 1052, 1053, 1055, 1056, 1057], "labels": [54, 323], "labels_": [73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 86, 87, 90, 93, 96, 97, 98, 100, 102, 332, 334, 361, 386, 400, 416, 434, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 460, 463, 718, 1033, 1046], "labels_050": 100, "labels_200": 100, "labels_a": 72, "labels_b": 72, "labels_pr": [416, 712, 713, 722, 723, 725, 739, 744, 745, 763, 765, 794, 803], "labels_random": 83, "labels_tru": [73, 84, 90, 99, 416, 712, 713, 722, 723, 725, 739, 744, 745, 763, 765, 794, 803], "labels_uniqu": 98, "labelshufflesplit": [1046, 1047], "labelspread": [2, 332, 338, 339, 340, 342, 343, 907, 909, 1001, 1013, 1042, 1047, 1048, 1051, 1052, 1055, 1056, 1057], "labelspreadingifittedlabelspread": 340, "labex": 0, "labl": 155, "laboratori": [381, 1019], "lacchia": 1048, "lack": [43, 64, 353, 386, 388, 398, 420, 837, 927, 1015, 1055], "lacost": [666, 996], "lacouth": 1054, "lacrosse91": 1054, "lad": 1054, "lag": [42, 43, 152, 155, 189, 222, 238, 504, 570, 709, 750, 753, 754, 756, 798, 829, 834, 835, 838, 1021], "lagacheri": 1045, "lagard": 1044, "lagat": 1051, "lagged_count_": 52, "lagged_count_1d": 52, "lagged_count_1d_1h": 52, "lagged_count_7d": 52, "lagged_count_7d_1h": 52, "lagged_df": 52, "lagged_max_24h": 52, "lagged_max_7d": 52, "lagged_mean_24h": 52, "lagged_mean_7d": 52, "lagged_min_24h": 52, "lagged_min_7d": 52, "lai": [51, 324, 353, 1006], "laid": [0, 191, 386], "lakhotia": [1051, 1052], "lakshmi": 1051, "lakshmikanth": 1048, "lakshya": [1049, 1050, 1051], "lal": 908, "lalliacqua": [1051, 1054], "lam": [329, 330, 1052, 1059], "lama": 502, "lamb": [1046, 1054], "lambda": [43, 46, 47, 49, 57, 91, 151, 200, 238, 278, 279, 323, 342, 410, 412, 416, 421, 423, 424, 652, 653, 654, 655, 876, 888, 992, 996, 1010, 1029, 1049, 1055], "lambda_": [200, 652, 653, 888, 996, 1048], "lambda_1": [652, 653, 996], "lambda_2": [652, 653, 996], "lambda_i": [996, 1010], "lambda_init": [199, 200, 653, 996, 1051], "lambdas_": [323, 888, 1054, 1057], "lami": 1049, "lamond": 1045, "lamp": 1024, "lamu": 1047, "lan": [666, 1056, 1057], "land": [50, 312, 401, 423], "land_mask": 312, "land_refer": [50, 312], "landeau": 1058, "landmark": [889, 901, 1010], "landscap": 177, "lane": 1047, "lang": 1034, "langford": [424, 696, 997], "langl": [992, 1000, 1014, 1015], "languag": [0, 362, 391, 421, 424, 1014, 1019, 1020, 1024, 1026], "language_level": 387, "lanigan": [324, 1048], "lanl": 55, "lannuzel": 1053, "lanterni": 1055, "lanzani": 1047, "lapack": [373, 374, 384, 540, 543, 549, 696, 1056], "lapack_lit": 392, "lapack_svd_driv": 1056, "laplac": [2, 177, 426, 618, 619, 847, 848, 849, 851, 1002], "laplacian": [2, 240, 378, 413, 448, 460, 470, 628, 647, 651, 699, 703, 773, 774, 782, 908, 996, 997, 1013, 1036, 1042, 1047], "laplacian_kernel": [2, 773, 998, 1046], "laptop": [52, 394, 476, 910, 1055, 1056, 1057], "lar": [0, 2, 54, 128, 174, 189, 198, 205, 206, 209, 213, 214, 225, 360, 361, 362, 383, 406, 479, 480, 486, 509, 539, 545, 547, 550, 551, 553, 554, 556, 659, 660, 661, 662, 663, 664, 671, 672, 673, 686, 690, 691, 692, 693, 694, 1001, 1021, 1022, 1032, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1054], "laradji": [0, 314, 1047], "larg": [0, 2, 38, 43, 51, 52, 53, 59, 63, 64, 72, 74, 78, 82, 84, 85, 87, 88, 90, 107, 109, 125, 129, 142, 144, 145, 152, 155, 156, 158, 170, 181, 182, 194, 195, 199, 200, 209, 211, 220, 222, 224, 225, 226, 238, 252, 257, 272, 275, 281, 284, 287, 301, 308, 316, 319, 321, 331, 332, 335, 349, 354, 356, 361, 362, 373, 381, 386, 392, 395, 398, 399, 400, 404, 410, 416, 418, 420, 421, 422, 423, 425, 427, 429, 450, 452, 454, 455, 458, 459, 460, 461, 466, 470, 481, 483, 507, 522, 542, 544, 546, 548, 549, 552, 555, 557, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 590, 597, 642, 649, 651, 654, 655, 658, 660, 661, 662, 665, 666, 667, 672, 679, 680, 682, 685, 687, 693, 695, 697, 699, 700, 701, 703, 754, 787, 788, 808, 816, 818, 822, 826, 837, 847, 848, 849, 850, 851, 852, 853, 858, 869, 870, 877, 881, 882, 890, 892, 904, 905, 912, 913, 917, 918, 920, 921, 922, 923, 948, 949, 989, 992, 994, 996, 997, 999, 1002, 1003, 1004, 1008, 1010, 1013, 1014, 1015, 1016, 1019, 1020, 1024, 1030, 1032, 1033, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "larger": [43, 46, 64, 72, 74, 77, 82, 90, 113, 115, 123, 134, 142, 153, 155, 177, 182, 183, 188, 192, 193, 197, 200, 204, 235, 236, 237, 245, 251, 253, 263, 269, 272, 279, 281, 287, 288, 296, 299, 301, 314, 315, 317, 319, 349, 353, 361, 362, 379, 381, 386, 392, 400, 413, 414, 416, 417, 418, 420, 421, 423, 424, 426, 448, 451, 457, 458, 460, 462, 464, 523, 535, 549, 552, 569, 570, 571, 575, 576, 590, 597, 651, 660, 680, 681, 682, 683, 687, 695, 700, 712, 727, 744, 805, 857, 858, 889, 891, 892, 893, 901, 906, 948, 949, 971, 974, 992, 993, 996, 997, 999, 1000, 1003, 1004, 1008, 1010, 1014, 1015, 1032, 1034, 1045, 1046, 1049, 1050, 1051, 1054, 1055, 1058, 1059], "largest": [115, 127, 145, 174, 222, 383, 416, 418, 421, 451, 535, 549, 565, 566, 567, 568, 572, 573, 596, 717, 805, 806, 827, 850, 882, 920, 921, 922, 923, 949, 997, 1000, 1010, 1015, 1016], "largest_clust": [416, 451], "largest_coef": [115, 535], "larrald": 1058, "lars_path": [2, 207, 395, 539, 545, 547, 550, 551, 553, 554, 556, 658, 659, 660, 661, 662, 663, 664, 671, 672, 673, 691, 692, 693, 694, 996, 1041, 1043, 1046, 1050, 1052], "lars_path_gram": [2, 690, 996, 1050], "larscv": [2, 407, 658, 673, 690, 691, 1048, 1054, 1058], "larson": [1046, 1050, 1051, 1053, 1055], "larsson": [1053, 1054, 1055], "lasagna": 1047, "laserjet": 1034, "laska": 1047, "lasso": [2, 42, 55, 101, 134, 160, 165, 189, 192, 198, 201, 211, 213, 219, 225, 228, 231, 251, 268, 331, 335, 356, 373, 398, 418, 419, 421, 423, 424, 425, 479, 480, 486, 509, 532, 539, 545, 547, 550, 551, 553, 554, 556, 605, 654, 655, 657, 658, 659, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 678, 680, 686, 689, 690, 691, 692, 693, 694, 729, 731, 732, 833, 834, 835, 873, 892, 989, 1000, 1001, 1014, 1021, 1022, 1029, 1032, 1036, 1041, 1045, 1046, 1047, 1049, 1050, 1052, 1054, 1055, 1059], "lasso_cd": [539, 545, 550, 556], "lasso_cv": 165, "lasso_lar": [134, 539, 545, 550, 556, 1051], "lasso_lars_": [208, 209], "lasso_path": [2, 205, 659, 660, 661, 662, 663, 664, 671, 690, 691, 996, 1041, 1043, 1045, 1054], "lasso_pipelin": 160, "lassocv": [2, 53, 160, 165, 192, 204, 209, 407, 423, 425, 659, 660, 662, 663, 664, 671, 692, 996, 1029, 1041, 1044, 1048, 1051, 1052, 1054, 1055, 1058, 1059], "lassocvlassocv": 160, "lassolar": [2, 659, 660, 661, 663, 664, 671, 672, 673, 690, 691, 692, 996, 1001, 1032, 1041, 1042, 1044, 1048, 1051, 1052, 1054], "lassolars": [2, 208, 209, 425, 659, 662, 663, 996, 1041, 1048, 1050, 1054, 1055], "lassolarscv": [2, 209, 407, 425, 660, 661, 662, 664, 671, 673, 690, 691, 692, 996, 1041, 1048, 1054, 1058], "lassolarsic__criterion": [208, 209], "last": [43, 58, 79, 93, 120, 152, 192, 199, 220, 221, 228, 233, 247, 269, 281, 289, 290, 324, 330, 332, 341, 364, 373, 381, 384, 388, 390, 391, 394, 400, 404, 410, 416, 417, 424, 428, 446, 450, 455, 467, 472, 475, 476, 523, 541, 567, 568, 569, 570, 591, 592, 595, 601, 602, 605, 618, 690, 691, 693, 694, 705, 706, 708, 709, 710, 715, 790, 805, 806, 811, 812, 827, 852, 853, 857, 872, 873, 877, 885, 891, 927, 952, 975, 989, 995, 996, 997, 999, 1001, 1004, 1014, 1020, 1025, 1032, 1041, 1047, 1048, 1049, 1050, 1055, 1057, 1058], "last_hour": [43, 52], "last_mean": 975, "last_n": 975, "last_var": 975, "lat": [50, 312, 506, 772], "late": [325, 375], "latenc": [42, 46, 189, 372, 532, 573, 680, 686, 838, 892, 918, 965, 974, 1019, 1021, 1036, 1044], "latent": [2, 42, 45, 55, 135, 189, 317, 361, 419, 424, 426, 496, 540, 544, 546, 547, 548, 551, 552, 596, 599, 868, 999, 1019, 1021, 1034, 1035, 1036, 1043, 1046], "latentdirichletalloc": [2, 54, 375, 391, 421, 1019, 1046, 1048, 1055, 1056], "later": [0, 50, 88, 139, 144, 153, 176, 193, 197, 199, 257, 272, 296, 312, 362, 369, 384, 392, 398, 399, 410, 858, 881, 882, 890, 892, 992, 1010, 1029, 1034, 1044, 1047, 1049, 1053], "latest": [328, 329, 330, 331, 332, 333, 334, 335, 336, 384, 386, 390, 392, 394, 1016, 1055], "latestst": 390, "latex": 1041, "latexpdf": 386, "latin": [47, 424], "latitud": [312, 319, 381, 506, 707, 772], "lattarini": 1043, "latter": [43, 54, 268, 278, 287, 288, 307, 324, 356, 375, 383, 400, 415, 420, 423, 424, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 750, 805, 806, 807, 808, 811, 812, 817, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 967, 1003, 1008, 1050], "laughlin": 1048, "launch": [360, 361, 404, 1024], "laur": 1041, "lauren": [0, 370, 700, 704, 997, 1053, 1056], "laurent": [1044, 1045, 1048, 1049, 1056, 1057], "laurenz": 1053, "lauritzen": 1049, "laveen": 1054, "law": 1024, "lawrenc": 272, "lawson": [1048, 1049, 1050], "lawton": 1049, "layer": [2, 43, 67, 148, 158, 167, 178, 180, 189, 227, 236, 258, 313, 316, 317, 321, 322, 343, 354, 358, 373, 394, 423, 522, 523, 530, 575, 838, 868, 869, 870, 873, 892, 1005, 1021, 1022, 1036, 1047], "layout": [139, 319, 398, 912, 913, 914, 917, 933, 1015, 1044, 1046, 1058], "layton": [0, 83, 406, 1041, 1042, 1043, 1044, 1046], "lazaru": 1059, "lazebnik": [766, 767, 998], "lazi": [52, 401, 424, 1014, 1045], "lazyfram": 107, "lazz": 1056, "lb": [879, 1011], "lbfg": [185, 314, 388, 656, 657, 666, 667, 677, 680, 682, 688, 695, 843, 846, 869, 870, 996, 1004, 1045, 1046, 1048, 1049, 1054, 1055, 1056, 1058], "lbfgsb": 666, "lbfin": 1051, "lc": [51, 243, 250], "lceil": [413, 1006], "lda": [54, 69, 121, 124, 127, 129, 135, 189, 308, 369, 383, 412, 512, 544, 549, 557, 558, 861, 1019, 1021, 1022, 1035, 1036, 1046], "lda_featur": 391, "lda_model": 391, "lda_np": 412, "ldavid": 1047, "ldflag": 384, "ldirer": 1048, "ldl": [174, 383], "ldot": [996, 1000, 1002, 1004, 1014], "ldwy4": [1058, 1059], "le": [666, 880, 991, 996, 1003, 1011, 1013, 1049, 1053, 1054, 1058], "le_": 577, "lead": [0, 46, 62, 64, 67, 72, 87, 90, 96, 106, 145, 149, 150, 152, 173, 174, 192, 193, 194, 199, 204, 209, 211, 220, 224, 252, 254, 257, 272, 278, 279, 281, 285, 304, 305, 316, 319, 321, 324, 325, 330, 349, 356, 361, 364, 369, 373, 374, 380, 385, 394, 395, 399, 400, 413, 414, 415, 416, 418, 420, 421, 422, 423, 425, 460, 470, 473, 476, 504, 523, 535, 543, 546, 547, 548, 551, 555, 559, 565, 566, 567, 568, 571, 572, 573, 574, 614, 638, 654, 655, 658, 660, 661, 662, 668, 669, 670, 671, 687, 699, 703, 754, 805, 811, 812, 840, 852, 853, 857, 876, 883, 893, 904, 905, 910, 912, 920, 921, 922, 923, 989, 994, 996, 997, 999, 1000, 1001, 1003, 1004, 1006, 1008, 1010, 1013, 1014, 1016, 1024, 1025, 1044, 1046, 1048, 1049, 1050, 1051, 1053, 1054, 1056, 1057, 1058, 1059, 1060], "leader": [386, 1024], "leadership": 0, "leaf": [76, 144, 156, 158, 364, 368, 416, 423, 427, 449, 450, 451, 452, 453, 454, 458, 465, 471, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 920, 921, 922, 923, 924, 925, 1003, 1016, 1044, 1046, 1048, 1052, 1055], "leaf_id": 368, "leaf_rot": 195, "leaf_siz": [427, 452, 454, 458, 463, 464, 465, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 1003], "leagu": 381, "leak": [144, 283, 360, 369, 417, 420, 872, 897, 898, 900, 901, 902, 903, 1010, 1041, 1048, 1051, 1057, 1058, 1059], "leakag": [399, 400, 417, 1036], "lean": 410, "leandro": [1050, 1054], "lear": 1024, "learn": [2, 15, 26, 29, 30, 32, 38, 43, 45, 46, 47, 48, 49, 52, 54, 55, 58, 62, 63, 64, 67, 68, 70, 71, 72, 83, 84, 86, 87, 88, 90, 91, 102, 104, 105, 109, 114, 115, 124, 130, 134, 137, 139, 142, 143, 144, 145, 147, 148, 154, 155, 157, 158, 159, 160, 165, 166, 167, 171, 174, 176, 179, 181, 185, 187, 188, 190, 194, 195, 196, 206, 208, 209, 215, 220, 221, 222, 224, 234, 238, 243, 244, 245, 246, 247, 248, 249, 251, 252, 255, 256, 257, 259, 260, 261, 270, 275, 277, 278, 281, 282, 283, 284, 285, 286, 290, 292, 293, 296, 299, 301, 303, 304, 305, 306, 307, 312, 313, 316, 317, 319, 320, 324, 325, 326, 327, 337, 341, 343, 348, 353, 356, 360, 361, 362, 364, 365, 366, 367, 368, 369, 374, 378, 379, 380, 381, 383, 385, 389, 392, 393, 394, 395, 399, 400, 403, 407, 410, 411, 412, 413, 414, 415, 416, 417, 418, 420, 422, 424, 425, 426, 430, 431, 433, 434, 435, 436, 438, 439, 440, 445, 446, 447, 450, 451, 454, 455, 457, 458, 465, 472, 473, 475, 476, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511, 512, 516, 517, 518, 520, 522, 523, 524, 525, 526, 528, 529, 530, 532, 533, 538, 539, 540, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 557, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 584, 589, 590, 591, 592, 595, 596, 597, 598, 599, 601, 602, 607, 610, 611, 618, 619, 622, 627, 630, 634, 636, 638, 640, 642, 646, 648, 649, 651, 652, 653, 654, 656, 660, 665, 666, 676, 677, 684, 685, 686, 688, 696, 697, 698, 699, 700, 704, 705, 708, 709, 710, 716, 721, 725, 726, 729, 731, 732, 734, 740, 743, 749, 750, 751, 756, 764, 786, 787, 788, 792, 793, 795, 796, 803, 805, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 846, 847, 848, 849, 850, 851, 854, 856, 861, 868, 869, 870, 871, 872, 873, 875, 877, 879, 882, 884, 885, 886, 887, 890, 891, 892, 893, 896, 904, 905, 907, 908, 909, 910, 912, 913, 914, 917, 920, 921, 922, 923, 935, 943, 944, 966, 967, 989, 990, 992, 993, 994, 996, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1011, 1014, 1015, 1016, 1017, 1018, 1021, 1023, 1027, 1029, 1030, 1036, 1038, 1039, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "learn_rat": 1042, "learnalgorithm": 1027, "learner": [2, 47, 140, 150, 160, 375, 562, 567, 568, 569, 570, 590, 597, 638, 854, 855, 860, 862, 863, 1002, 1005, 1016, 1019, 1020, 1034, 1057], "learning_curv": [2, 280, 333, 407, 814, 995, 1044, 1047, 1048, 1049, 1050, 1051, 1053, 1055, 1056, 1058, 1060], "learning_decai": 544, "learning_method": [54, 391, 544], "learning_offset": [54, 544], "learning_r": [46, 139, 150, 151, 152, 153, 154, 155, 245, 299, 315, 317, 329, 331, 423, 561, 562, 567, 568, 569, 570, 676, 684, 685, 686, 700, 868, 869, 870, 997, 1007, 1014, 1042, 1050, 1054], "learning_rate_": [700, 870], "learning_rate_init": [193, 315, 316, 869, 870], "learningcurvedisplai": [2, 253, 280, 333, 995, 1056, 1057], "learnt": [155, 192, 326, 369, 400, 420, 893, 989, 1010], "least": [2, 37, 44, 52, 54, 113, 114, 116, 117, 127, 128, 153, 172, 174, 184, 189, 191, 198, 199, 202, 204, 210, 213, 216, 220, 222, 224, 225, 228, 237, 238, 251, 257, 278, 296, 298, 324, 330, 331, 349, 361, 362, 373, 379, 381, 383, 385, 386, 390, 392, 394, 398, 400, 401, 407, 416, 418, 419, 420, 421, 423, 424, 425, 426, 427, 452, 456, 458, 464, 465, 466, 469, 482, 489, 490, 491, 492, 493, 502, 524, 539, 545, 547, 549, 550, 551, 553, 554, 555, 556, 557, 565, 566, 567, 568, 570, 572, 573, 574, 601, 602, 610, 643, 651, 654, 656, 658, 659, 660, 661, 662, 663, 664, 665, 671, 672, 673, 674, 675, 676, 677, 679, 680, 682, 684, 686, 687, 688, 690, 691, 692, 693, 694, 695, 700, 705, 720, 724, 726, 793, 809, 813, 814, 820, 822, 823, 824, 826, 827, 829, 833, 836, 837, 838, 869, 870, 873, 884, 892, 917, 920, 921, 922, 923, 941, 963, 990, 993, 997, 1000, 1003, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1024, 1032, 1036, 1041, 1043, 1044, 1047, 1048, 1052], "least_absolute_devi": [1051, 1053, 1054], "least_angl": 395, "least_squar": 1054, "leastangle_2002": [174, 383], "leastsquareserror": 1050, "leav": [2, 88, 139, 144, 153, 193, 195, 238, 285, 324, 368, 369, 373, 383, 385, 391, 400, 416, 423, 449, 450, 453, 454, 471, 511, 565, 566, 567, 568, 569, 570, 572, 573, 574, 681, 683, 810, 815, 816, 817, 818, 826, 827, 852, 853, 920, 921, 922, 923, 989, 997, 1003, 1007, 1016, 1029, 1032, 1041, 1048, 1050, 1052, 1053, 1057], "leaveonegroupout": [2, 283, 420, 809, 816, 817, 1029, 1047], "leaveonelabelout": 1047, "leaveoneout": [2, 283, 420, 1029], "leavepgroupsout": [2, 420, 810, 1029, 1047], "leaveplabelout": 1047, "leaveplabelsout": 1047, "leavepout": [2, 420, 816, 1029], "leaves_parallel": 924, "lebedev": [1047, 1048], "lebel": 1056, "lebourgeoi": 1024, "lectur": [416, 652, 992, 1018], "lecture2": 652, "lecun": [1004, 1014], "led": 1041, "ledoit": [2, 49, 65, 70, 110, 111, 114, 115, 189, 308, 481, 483, 487, 488, 520, 557, 994, 1021], "ledoit_wolf": [2, 115, 418, 1054], "ledoit_wolf_shrinkag": [2, 1054], "ledoitwolf": [2, 69, 110, 112, 115, 132, 154, 189, 310, 418, 477, 478, 482, 483, 484, 485, 808, 1021, 1045], "lee": [421, 1041, 1042, 1045, 1047, 1048, 1049, 1050, 1052, 1053, 1056], "leepei": 1045, "leereev": 1048, "leeuw": 643, "lefebvr": [1054, 1055], "lefevr": [421, 546], "left": [45, 46, 51, 53, 54, 61, 69, 70, 74, 77, 79, 80, 86, 90, 97, 99, 106, 109, 114, 115, 122, 123, 127, 128, 139, 142, 144, 145, 146, 149, 152, 155, 160, 162, 179, 185, 188, 192, 195, 205, 213, 220, 221, 222, 224, 231, 233, 234, 237, 238, 247, 251, 255, 257, 258, 263, 265, 266, 269, 274, 275, 276, 277, 279, 287, 288, 290, 302, 304, 305, 312, 314, 317, 319, 332, 334, 335, 339, 348, 349, 353, 368, 381, 386, 388, 390, 413, 416, 419, 420, 422, 423, 424, 426, 433, 439, 454, 480, 490, 491, 492, 493, 501, 506, 557, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 595, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 643, 647, 651, 659, 663, 805, 806, 808, 811, 812, 815, 822, 885, 892, 920, 921, 922, 923, 924, 936, 949, 971, 974, 989, 992, 994, 996, 998, 1000, 1002, 1007, 1012, 1014, 1016, 1029, 1030, 1032, 1033, 1048, 1050, 1055], "left_h": 319, "left_impur": [565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923], "leftarrow": [416, 1004, 1014], "leftmost": 1004, "legaci": [380, 390, 400, 1041, 1048, 1053], "legarreta": [1052, 1054, 1055], "legend": [43, 46, 47, 48, 50, 52, 61, 63, 69, 72, 75, 96, 106, 107, 109, 111, 112, 113, 114, 117, 118, 121, 127, 129, 132, 133, 134, 139, 140, 141, 142, 143, 145, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 162, 163, 170, 176, 177, 181, 182, 183, 184, 185, 192, 193, 197, 199, 200, 202, 205, 208, 209, 210, 214, 220, 221, 222, 223, 226, 227, 228, 229, 230, 233, 234, 235, 237, 238, 243, 250, 251, 252, 253, 255, 258, 265, 272, 273, 275, 277, 278, 280, 281, 282, 283, 285, 288, 290, 291, 292, 293, 296, 302, 304, 305, 306, 311, 315, 320, 324, 329, 332, 335, 340, 348, 351, 353, 355, 360, 364, 365, 366, 367, 708, 1030, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "legend_el": [121, 156, 233, 281, 302, 353], "legend_handl": 306, "legend_lin": 48, "legend_titl": 226, "legitim": [272, 997], "legitimate_accept": 272, "legitimate_refus": 272, "lego": 1019, "lehoucq": 421, "leibler": [54, 240, 421, 546, 548, 555, 700, 997, 1048], "leibniz": 1000, "leig": 1047, "leightonzhang": 1047, "leinweb": [1049, 1050], "leisur": 43, "lejeun": 1048, "lekhwani": 1050, "leland": [1047, 1048, 1049, 1051, 1052, 1057], "lemaitr": [0, 44, 46, 106, 109, 130, 160, 176, 181, 182, 183, 185, 208, 209, 222, 241, 319, 405, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "lemaitre58": [46, 160, 176, 181, 183, 185, 241, 319], "lemir": 1052, "lemma": [37, 251, 378, 542, 549, 557, 904, 905, 906, 994, 1036, 1044], "lemmat": 424, "lemmatoken": 424, "lemo": [1057, 1058], "len": [46, 47, 49, 50, 55, 57, 66, 67, 68, 72, 73, 76, 78, 79, 84, 85, 86, 90, 95, 96, 97, 98, 99, 100, 104, 106, 128, 134, 135, 137, 142, 145, 148, 149, 155, 166, 167, 172, 176, 184, 188, 193, 195, 219, 220, 238, 243, 247, 250, 251, 252, 254, 256, 257, 263, 265, 266, 273, 276, 278, 279, 286, 287, 289, 293, 298, 299, 306, 308, 309, 314, 320, 321, 322, 325, 334, 336, 338, 339, 342, 349, 355, 358, 360, 361, 362, 368, 398, 400, 423, 426, 434, 438, 440, 445, 453, 458, 464, 472, 515, 523, 558, 577, 578, 590, 605, 640, 641, 790, 808, 822, 834, 838, 840, 842, 843, 893, 907, 908, 1032, 1033, 1034, 1050, 1053], "lenail": [1049, 1053], "lend": 1024, "lene": 1057, "length": [2, 80, 104, 120, 121, 123, 133, 135, 148, 174, 176, 177, 178, 181, 182, 184, 197, 203, 254, 255, 258, 261, 302, 330, 333, 346, 362, 379, 383, 386, 394, 395, 400, 417, 421, 423, 424, 426, 453, 498, 516, 517, 520, 523, 531, 559, 571, 589, 590, 597, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 640, 654, 655, 658, 659, 660, 661, 662, 664, 665, 668, 669, 670, 671, 689, 692, 789, 808, 811, 812, 822, 838, 840, 843, 844, 846, 854, 855, 856, 858, 860, 899, 925, 932, 934, 938, 954, 955, 971, 974, 999, 1006, 1010, 1025, 1031, 1032, 1041, 1044, 1045, 1047, 1048, 1049, 1050, 1052, 1053, 1057], "length_scal": [176, 177, 180, 181, 182, 183, 185, 426, 620, 623, 626, 627, 629, 630, 631, 632], "length_scale_bound": [176, 182, 183, 185, 426, 619, 623, 627, 630, 631], "length_scale_grid": 182, "lengthi": [386, 398], "lenient": [886, 1020, 1058], "lenz": [1052, 1056], "leo": 1058, "leogrin": 1059, "leon": [684, 685, 686, 1041, 1059], "leonardo": 1054, "leonenko": [615, 616], "leonieborn": 1047, "leopoldo": 1054, "leq": [179, 421, 423, 996, 1000, 1003, 1014, 1015, 1016], "lera": 1048, "leriqu": [1047, 1049], "lernen": 458, "lesne": 1055, "less": [43, 44, 47, 64, 87, 88, 95, 123, 125, 128, 135, 139, 146, 152, 153, 155, 176, 183, 192, 202, 204, 220, 222, 224, 253, 257, 264, 266, 272, 278, 279, 287, 289, 292, 293, 320, 323, 324, 325, 330, 332, 336, 353, 360, 361, 369, 373, 375, 381, 386, 388, 398, 400, 410, 416, 420, 421, 423, 424, 428, 447, 449, 451, 453, 456, 458, 460, 465, 468, 470, 471, 490, 491, 492, 504, 523, 539, 543, 545, 546, 548, 549, 550, 551, 552, 553, 554, 555, 556, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 598, 604, 627, 635, 642, 655, 669, 684, 686, 700, 709, 729, 730, 731, 732, 733, 744, 760, 772, 787, 788, 793, 803, 805, 806, 810, 811, 812, 818, 836, 847, 848, 849, 851, 852, 853, 854, 855, 856, 858, 860, 861, 862, 863, 864, 875, 887, 889, 890, 892, 895, 901, 902, 912, 913, 920, 921, 922, 923, 938, 952, 989, 990, 992, 993, 994, 997, 999, 1000, 1003, 1005, 1010, 1014, 1015, 1016, 1019, 1032, 1034, 1041, 1042, 1044, 1045, 1047, 1048, 1049, 1051, 1055, 1056, 1058], "lessen": [226, 666, 667], "lesser": [314, 400, 450, 549, 996], "let": [43, 44, 52, 88, 90, 99, 105, 109, 121, 125, 130, 146, 149, 152, 153, 155, 157, 176, 182, 183, 188, 192, 193, 194, 201, 209, 220, 222, 238, 240, 244, 254, 261, 272, 273, 278, 281, 285, 292, 336, 360, 362, 368, 369, 381, 386, 388, 392, 398, 410, 413, 415, 416, 420, 423, 424, 449, 453, 499, 508, 512, 518, 542, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 689, 692, 878, 885, 886, 996, 997, 998, 999, 1000, 1007, 1008, 1010, 1015, 1016, 1024, 1032, 1033, 1034, 1051], "letelli": 1047, "letter": [174, 184, 381, 383, 390, 424, 796, 797, 814, 831, 1000], "leu": 1055, "leung": 1052, "lev_metr": 398, "levarag": 335, "level": [43, 48, 50, 51, 64, 70, 76, 88, 125, 144, 148, 167, 174, 175, 176, 177, 180, 183, 185, 189, 192, 193, 231, 232, 233, 234, 235, 238, 247, 251, 252, 267, 272, 278, 281, 287, 288, 305, 312, 347, 348, 350, 351, 353, 356, 361, 368, 373, 381, 383, 386, 388, 392, 398, 400, 403, 404, 407, 414, 421, 424, 426, 430, 462, 476, 501, 502, 504, 511, 529, 539, 544, 545, 553, 554, 555, 569, 570, 575, 576, 619, 623, 630, 631, 633, 674, 675, 676, 684, 685, 686, 695, 698, 700, 702, 708, 710, 724, 731, 736, 793, 833, 834, 835, 837, 840, 841, 868, 869, 870, 910, 925, 989, 996, 1000, 1001, 1003, 1008, 1014, 1016, 1019, 1020, 1021, 1034, 1044, 1052, 1055, 1056, 1057], "levelnam": 125, "leven": 398, "levenshtein": [336, 398], "levenshtein_dist": 336, "levequ": [850, 892], "leverag": [43, 47, 72, 84, 118, 238, 336, 360, 361, 373, 374, 384, 400, 420, 423, 887, 989, 996, 1025, 1044, 1056, 1059], "levesqu": 1047, "levi": [542, 1048], "levinson": [1049, 1050], "levitski": [1056, 1057, 1058], "levitskii": 1054, "lewi": [381, 1048, 1052], "lex": [416, 460, 470], "lexicograph": [400, 575, 796, 802, 854, 862], "lexicon": 1010, "lexsort": 61, "lf": 394, "lfw": [2, 45, 381, 501, 502, 1030, 1041], "lfw_": 1030, "lfw_home": 381, "lfw_pairs_train": [381, 501], "lfw_peopl": [45, 381, 502, 1030], "lg2012": 423, "lgtm": 1048, "li": [0, 341, 381, 406, 647, 650, 704, 734, 764, 905, 989, 992, 1000, 1003, 1010, 1012, 1015, 1041, 1042, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "liabil": 238, "liac": [333, 380, 386, 504, 1056, 1057], "liam": [1049, 1050], "liang": [1047, 1052, 1053, 1058, 1059], "liau": 1044, "lib": [374, 384, 404, 1019], "liberti": 269, "libisel": 1059, "liblinear": [213, 347, 392, 666, 667, 796, 912, 913, 914, 917, 918, 996, 1000, 1015, 1041, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1057], "libomp": [384, 1053], "librari": [45, 272, 278, 331, 333, 366, 369, 378, 380, 381, 384, 385, 386, 387, 392, 398, 399, 400, 404, 410, 412, 666, 912, 913, 914, 915, 917, 918, 996, 1000, 1015, 1016, 1019, 1020, 1024, 1030, 1034, 1039, 1044, 1048, 1049, 1050, 1051, 1052, 1054, 1058], "libsvm": [2, 197, 347, 379, 392, 495, 516, 571, 912, 913, 914, 915, 916, 917, 918, 1015, 1036, 1041, 1043, 1049, 1052, 1055], "libsvmtool": [197, 380, 495, 516, 517], "licenc": [44, 380], "licens": [46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 61, 62, 63, 64, 66, 67, 68, 72, 74, 75, 77, 80, 81, 82, 83, 86, 87, 88, 89, 92, 96, 100, 101, 102, 104, 105, 107, 108, 109, 115, 120, 121, 125, 127, 129, 130, 131, 132, 135, 137, 139, 140, 141, 142, 143, 144, 145, 150, 151, 153, 154, 155, 159, 160, 174, 176, 177, 179, 180, 181, 182, 183, 185, 188, 197, 202, 203, 205, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 221, 222, 225, 227, 228, 236, 237, 241, 242, 243, 245, 247, 250, 252, 253, 255, 257, 263, 265, 279, 282, 284, 291, 298, 299, 301, 307, 308, 309, 311, 312, 314, 317, 319, 320, 321, 322, 323, 324, 338, 339, 340, 341, 343, 353, 354, 356, 357, 360, 361, 362, 380, 398, 400, 1016, 1024], "lichman": 383, "liddel": 1049, "lidston": [847, 848, 849, 851, 1002], "lie": [52, 95, 117, 173, 192, 252, 319, 340, 347, 349, 421, 423, 614, 860, 862, 863, 864, 912, 913, 994, 997, 1000, 1010, 1015], "lieg": 423, "lieret": 1056, "lieu": [1047, 1048], "life": [52, 155, 271, 336, 394, 997], "lifecycl": [1019, 1020], "lifo": 927, "lift": 404, "light": [142, 381], "lighter": [373, 708, 710, 790, 797, 1057], "lightfm": 1019, "lightgbm": [155, 423, 569, 570, 1019, 1050, 1057], "lightgreen": [162, 226, 237], "lightgrei": 49, "lightn": 1019, "lightweight": [387, 808, 822, 833, 834, 1019], "ligo": 1048, "lihaitao": 1059, "lik_max": 111, "lik_min": 111, "like": [0, 2, 43, 51, 52, 57, 87, 90, 93, 95, 104, 120, 123, 128, 132, 134, 137, 139, 141, 146, 152, 155, 156, 176, 182, 192, 200, 220, 254, 269, 272, 278, 281, 282, 285, 286, 293, 308, 317, 319, 324, 325, 328, 341, 349, 353, 360, 361, 369, 373, 375, 378, 380, 381, 385, 386, 388, 390, 393, 394, 395, 398, 399, 400, 407, 410, 412, 414, 415, 416, 417, 419, 420, 421, 423, 424, 425, 427, 428, 429, 431, 432, 433, 434, 435, 437, 438, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 466, 467, 468, 469, 470, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 520, 521, 523, 527, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 587, 589, 590, 591, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 742, 743, 744, 745, 746, 747, 748, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 875, 876, 877, 878, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 937, 938, 951, 954, 963, 964, 971, 972, 973, 985, 987, 989, 992, 994, 995, 996, 997, 1000, 1002, 1003, 1004, 1006, 1007, 1010, 1015, 1016, 1019, 1020, 1024, 1025, 1032, 1034, 1038, 1041, 1044, 1045, 1048, 1049, 1051, 1052, 1053, 1055, 1056, 1057, 1058, 1059], "likelihood": [2, 69, 92, 110, 112, 113, 114, 115, 132, 154, 176, 177, 178, 180, 181, 182, 183, 185, 189, 208, 238, 267, 270, 278, 284, 310, 317, 319, 388, 400, 414, 418, 421, 423, 426, 445, 477, 478, 479, 480, 481, 482, 483, 484, 485, 523, 540, 544, 549, 557, 558, 559, 618, 619, 639, 653, 666, 720, 749, 805, 806, 808, 835, 838, 857, 868, 888, 900, 914, 915, 917, 918, 996, 999, 1002, 1010, 1015, 1021, 1044, 1045, 1050, 1056], "likewis": [255, 416, 531], "lil": [400, 561, 562, 879, 928, 954, 1003], "lil_matrix": 55, "lili": [1049, 1050], "lilian": [1046, 1047, 1058], "lim": [179, 542], "lima": [1054, 1055], "limit": [43, 47, 55, 64, 72, 77, 92, 101, 115, 139, 146, 147, 153, 160, 187, 192, 193, 194, 199, 220, 221, 237, 251, 285, 321, 325, 331, 356, 362, 369, 374, 387, 388, 391, 398, 400, 401, 414, 415, 416, 419, 421, 425, 454, 471, 476, 567, 568, 569, 570, 640, 658, 687, 690, 691, 696, 786, 829, 860, 862, 863, 864, 885, 886, 910, 914, 915, 916, 917, 918, 989, 996, 997, 999, 1000, 1007, 1008, 1010, 1020, 1025, 1036, 1049, 1051, 1054, 1055, 1058, 1060], "limits_": 1003, "lin": [0, 542, 666, 1015, 1046, 1047, 1048, 1049], "lin_clf": 1015, "linalg": [70, 89, 111, 112, 115, 132, 134, 206, 263, 264, 265, 268, 269, 335, 386, 392, 421, 459, 460, 461, 470, 529, 540, 543, 549, 552, 665, 680, 682, 695, 699, 703, 947], "linalgerror": 1051, "lincoln": 381, "lindenbaum": 542, "lindenstrauss": [37, 90, 189, 246, 378, 497, 510, 904, 905, 906, 1017, 1021, 1036], "lindgren": 1059, "lindquist": 1056, "line": [48, 50, 52, 55, 75, 78, 95, 104, 113, 122, 125, 130, 139, 145, 151, 175, 187, 188, 189, 192, 193, 208, 209, 210, 212, 215, 216, 218, 221, 222, 223, 228, 229, 231, 232, 234, 247, 251, 252, 255, 257, 275, 282, 284, 285, 305, 309, 312, 320, 330, 348, 351, 353, 354, 357, 358, 360, 380, 381, 384, 386, 387, 388, 390, 391, 392, 393, 394, 398, 421, 422, 423, 446, 495, 496, 497, 516, 517, 550, 561, 562, 563, 564, 618, 621, 622, 640, 678, 694, 708, 709, 710, 814, 831, 994, 1000, 1004, 1007, 1014, 1019, 1021, 1023, 1032, 1034, 1043, 1052, 1054, 1057, 1058], "line0": [51, 243], "line1": [46, 51, 243], "line2": [46, 51, 243, 357], "line2d": [48, 113, 234, 305, 348, 351, 814, 831], "line_": [393, 446, 706, 708, 709, 710, 814, 831], "line_bin": 320, "line_fig": 145, "line_i": 223, "line_kw": [155, 157, 258, 280, 329, 335, 640, 814, 831], "line_kwarg": [160, 709], "line_profil": 392, "line_trac": 145, "line_x": [223, 237], "line_y_ransac": 223, "linea": 1027, "linear": [2, 12, 44, 48, 49, 51, 52, 53, 64, 65, 66, 67, 72, 87, 92, 108, 109, 111, 112, 113, 114, 115, 118, 121, 125, 130, 133, 142, 144, 158, 160, 163, 165, 167, 169, 174, 180, 182, 187, 188, 190, 191, 193, 197, 200, 202, 204, 206, 208, 209, 210, 215, 217, 218, 221, 222, 224, 225, 228, 232, 234, 236, 237, 238, 239, 242, 244, 250, 251, 253, 255, 256, 259, 268, 271, 274, 275, 276, 278, 281, 283, 284, 285, 286, 287, 288, 293, 304, 305, 307, 308, 309, 317, 319, 320, 321, 324, 326, 330, 331, 344, 346, 349, 350, 351, 354, 356, 357, 360, 366, 367, 374, 378, 382, 383, 384, 388, 389, 391, 400, 403, 414, 416, 419, 420, 421, 422, 423, 424, 425, 426, 428, 450, 452, 463, 473, 475, 483, 490, 491, 492, 504, 509, 510, 520, 523, 529, 532, 540, 541, 542, 543, 544, 547, 549, 551, 552, 556, 557, 558, 562, 574, 590, 597, 601, 602, 614, 617, 622, 628, 639, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 692, 695, 696, 697, 698, 699, 700, 701, 709, 715, 724, 758, 761, 773, 775, 782, 793, 808, 819, 823, 835, 838, 852, 853, 857, 861, 868, 869, 870, 873, 877, 878, 879, 882, 885, 887, 889, 890, 891, 892, 901, 905, 912, 913, 914, 915, 916, 917, 918, 989, 991, 992, 993, 995, 1000, 1003, 1004, 1005, 1006, 1007, 1008, 1014, 1015, 1019, 1021, 1022, 1024, 1025, 1027, 1028, 1029, 1034, 1035, 1036, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1054, 1055], "linear_baselin": 330, "linear_kernel": [2, 769, 773, 998, 1049], "linear_model": [2, 43, 46, 47, 49, 53, 62, 64, 66, 89, 105, 107, 109, 118, 144, 160, 162, 163, 165, 166, 172, 173, 174, 176, 187, 189, 191, 192, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 232, 233, 234, 235, 236, 237, 238, 247, 248, 249, 250, 254, 256, 259, 261, 272, 274, 281, 286, 287, 291, 292, 293, 298, 317, 320, 321, 324, 326, 328, 329, 330, 331, 332, 334, 335, 336, 342, 360, 369, 373, 375, 385, 386, 388, 392, 394, 395, 399, 400, 407, 412, 415, 417, 423, 436, 441, 446, 473, 545, 547, 550, 551, 553, 554, 556, 575, 576, 577, 578, 605, 639, 640, 642, 643, 646, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 708, 709, 796, 807, 822, 831, 833, 834, 835, 837, 839, 843, 844, 845, 846, 870, 887, 891, 912, 913, 916, 919, 941, 943, 944, 945, 984, 992, 996, 1000, 1001, 1006, 1008, 1010, 1014, 1021, 1029, 1030, 1032, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048], "linear_model_preprocessor": 220, "linear_pca": 417, "linear_preprocessor": 160, "linear_regress": [222, 293], "linear_svc": 1015, "linear_svm": 252, "linear_svm_scor": 252, "linear_svm_tim": 252, "lineardiscriminantanalysi": [2, 69, 70, 133, 241, 308, 369, 412, 544, 558, 861, 994, 1001, 1003, 1041, 1044, 1045, 1046, 1047, 1048, 1050, 1053, 1055, 1056, 1057], "linearli": [67, 130, 141, 174, 192, 199, 234, 241, 247, 287, 288, 321, 324, 353, 360, 373, 383, 398, 421, 423, 523, 561, 650, 715, 881, 882, 1000, 1003, 1006, 1015, 1032, 1048, 1057], "linearly_separ": [67, 314], "linearmodel": 1054, "linearoper": [335, 695], "linearregress": [2, 118, 163, 191, 199, 210, 215, 216, 217, 218, 223, 226, 237, 250, 254, 256, 274, 293, 320, 369, 386, 398, 399, 417, 423, 473, 578, 640, 643, 654, 657, 660, 662, 679, 680, 695, 996, 1000, 1001, 1010, 1032, 1045, 1046, 1050, 1053, 1054, 1055, 1057], "linearregressionifittedlinearregress": 250, "linearregressionlinearregress": 163, "linearsvc": [2, 62, 64, 104, 106, 170, 171, 189, 197, 252, 275, 277, 285, 321, 328, 344, 346, 350, 351, 356, 360, 373, 388, 392, 414, 424, 425, 445, 520, 575, 585, 639, 647, 651, 660, 680, 681, 682, 683, 684, 695, 743, 750, 835, 840, 913, 914, 917, 919, 996, 1000, 1001, 1015, 1021, 1041, 1042, 1043, 1047, 1049, 1052, 1057], "linearsvc__c": 321, "linearsvclinearsvc": [106, 171, 285], "linearsvr": [2, 576, 918, 1015, 1045, 1047, 1052, 1057], "linecollect": [51, 243, 250, 640], "linen": [51, 243], "lineno": 392, "lineplot": [155, 278], "liner": [388, 838], "lines_": [393, 640, 814, 831], "linestyl": [49, 50, 69, 95, 107, 113, 132, 134, 139, 151, 162, 165, 167, 176, 179, 181, 183, 185, 194, 195, 205, 207, 208, 209, 220, 221, 222, 226, 230, 232, 233, 238, 255, 257, 272, 275, 277, 281, 282, 287, 292, 304, 312, 315, 320, 347, 350, 351, 353, 354, 356, 1030], "linewidth": [61, 69, 70, 72, 75, 93, 107, 111, 118, 123, 140, 152, 155, 157, 176, 180, 184, 209, 210, 214, 215, 216, 218, 221, 223, 226, 234, 237, 247, 255, 257, 287, 291, 305, 309, 320, 329, 335, 347, 348, 350, 366, 1030], "linger": 222, "linguist": [724, 909, 1013], "lingyi1110": 1056, "link": [51, 55, 139, 192, 193, 199, 220, 224, 238, 263, 272, 281, 309, 364, 374, 380, 385, 386, 387, 388, 390, 394, 400, 414, 416, 418, 421, 423, 426, 569, 570, 618, 656, 677, 688, 696, 713, 931, 933, 996, 1003, 1016, 1017, 1019, 1023, 1028, 1032, 1034, 1039, 1041, 1044, 1045, 1048, 1049, 1052, 1058], "link_thickness_i": 309, "linkag": [71, 74, 75, 76, 79, 82, 87, 90, 91, 92, 102, 189, 195, 448, 449, 453, 454, 471, 520, 522, 530, 892, 1019, 1021, 1033, 1044, 1049, 1052], "linkage_matrix": 76, "linkage_tre": 1045, "linkedin": 390, "linker": [384, 387], "linnerrud": [379, 1036], "linnerud": [2, 383, 513], "linprog": [678, 996], "linspac": [43, 47, 49, 50, 53, 61, 63, 72, 73, 75, 77, 84, 90, 113, 114, 126, 134, 140, 152, 176, 177, 179, 180, 181, 182, 183, 185, 193, 199, 200, 202, 204, 210, 214, 220, 221, 222, 226, 230, 231, 232, 233, 234, 238, 245, 247, 250, 251, 253, 255, 267, 278, 280, 281, 285, 286, 287, 288, 293, 304, 305, 311, 312, 320, 322, 332, 333, 348, 349, 352, 353, 354, 356, 357, 358, 639, 640, 814, 836, 852, 853, 1033], "lint": [386, 394], "linter": 587, "linthresh": [199, 204], "linu": [1057, 1058, 1059], "linux": [386, 388, 389, 394, 1019, 1041], "lipoprotein": [174, 383], "lippert": 996, "lippmann": 381, "lipschitz": [37, 1012], "lisa": [1049, 1050, 1052, 1053, 1055, 1056], "lise": 1055, "list": [0, 2, 43, 47, 49, 51, 52, 53, 55, 57, 58, 62, 68, 75, 79, 84, 97, 104, 134, 135, 143, 145, 151, 160, 195, 224, 257, 258, 273, 276, 278, 279, 281, 282, 287, 291, 308, 321, 325, 328, 329, 330, 331, 332, 333, 334, 335, 336, 342, 352, 361, 362, 375, 380, 381, 384, 385, 386, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 404, 407, 414, 416, 417, 420, 422, 423, 424, 439, 441, 445, 458, 464, 465, 472, 473, 474, 475, 479, 480, 486, 490, 491, 492, 496, 497, 498, 499, 500, 501, 504, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 522, 523, 524, 525, 526, 527, 528, 531, 540, 558, 559, 561, 562, 563, 564, 565, 566, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 597, 599, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 640, 642, 643, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 689, 692, 694, 695, 700, 704, 705, 707, 718, 719, 720, 721, 724, 726, 733, 741, 750, 754, 762, 786, 789, 791, 796, 802, 805, 806, 808, 811, 812, 814, 819, 820, 822, 831, 833, 834, 835, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 865, 866, 869, 870, 871, 872, 873, 874, 876, 880, 883, 885, 886, 891, 893, 909, 913, 915, 918, 920, 921, 922, 923, 926, 928, 932, 933, 934, 938, 940, 941, 942, 944, 952, 953, 955, 966, 971, 974, 984, 989, 990, 996, 1000, 1002, 1003, 1004, 1007, 1008, 1011, 1016, 1019, 1020, 1024, 1025, 1029, 1031, 1034, 1037, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "list_param": 386, "listedcolormap": [67, 70, 148, 307, 310, 314, 321], "listen": 360, "listinfo": 394, "lite": 1041, "liter": [386, 390, 1024], "literatur": [83, 181, 278, 296, 361, 383, 386, 392, 394, 398, 399, 416, 419, 421, 423, 451, 455, 457, 509, 544, 546, 548, 555, 563, 564, 596, 599, 716, 805, 989, 992, 996, 1000, 1051], "litsidi": [1056, 1057], "littl": [192, 193, 194, 195, 247, 381, 424, 470, 652, 808, 822, 949, 990, 997, 999, 1015, 1016, 1032, 1042, 1053, 1058], "lituiev": 1054, "liu": [0, 284, 376, 397, 571, 734, 764, 1000, 1006, 1044, 1047, 1048, 1049, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "liutong": 1049, "live": [50, 104, 192, 272, 312, 381, 386, 416, 506, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 1023], "livesei": 360, "livni": [416, 450], "lizao": 1049, "lizsz": 1047, "lj2017": 416, "lk": 1044, "lkjcalc": 1049, "lkubin": 1052, "ll": [50, 90, 147, 273, 312, 386, 398, 540, 549, 992, 1003, 1016, 1025], "llcrnrlat": [50, 312], "llcrnrlon": [50, 312], "lle": [240, 241, 242, 244, 538, 697, 701, 997, 1053], "lle_hessian": 240, "lle_ltsa": 240, "lle_method": 240, "lle_mod": 240, "lle_standard": 240, "lloyd": [416, 451, 455, 457, 467, 1055, 1056], "llvm": 384, "lm": 201, "lmbda": 323, "lmbda_bc": 323, "lmbda_yj": 323, "lml": [177, 178, 182, 426], "ln": [390, 996, 1004, 1010], "loa": [175, 183, 189, 426, 504, 619, 623, 630, 631, 633, 1021], "load": [2, 10, 43, 45, 50, 51, 52, 54, 63, 68, 81, 83, 88, 105, 106, 120, 125, 135, 144, 146, 148, 150, 156, 157, 160, 161, 163, 171, 172, 181, 192, 193, 197, 201, 216, 217, 220, 228, 236, 249, 250, 254, 256, 257, 258, 259, 261, 268, 272, 274, 276, 278, 283, 285, 290, 292, 296, 299, 303, 308, 315, 316, 317, 329, 330, 332, 333, 335, 340, 341, 342, 365, 368, 373, 378, 381, 383, 389, 392, 399, 410, 419, 420, 421, 423, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 540, 542, 551, 852, 853, 949, 1010, 1020, 1026, 1028, 1030, 1036, 1041, 1046, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "load_ames_h": 160, "load_boston": [1047, 1049, 1054], "load_breast_canc": [2, 174, 195, 341, 364, 391, 600, 603, 604, 606, 682, 683, 796, 1000, 1046, 1047, 1052], "load_cont": 511, "load_dataset": 360, "load_diabet": [2, 46, 153, 163, 165, 174, 188, 205, 207, 208, 209, 216, 217, 258, 274, 333, 423, 566, 570, 576, 681, 709, 833, 834, 835, 921, 923, 1008, 1029, 1032, 1047, 1052, 1055], "load_digit": [2, 68, 86, 87, 93, 106, 107, 120, 166, 172, 211, 227, 241, 251, 252, 276, 277, 280, 286, 294, 301, 303, 308, 315, 317, 334, 338, 339, 392, 417, 428, 453, 454, 540, 541, 542, 543, 607, 608, 646, 647, 676, 696, 697, 698, 699, 701, 703, 1025, 1029, 1030, 1031, 1032, 1033, 1047, 1052], "load_fil": [2, 380, 381, 1034, 1043, 1055], "load_iri": [2, 66, 76, 80, 108, 121, 129, 131, 133, 135, 148, 161, 167, 170, 178, 203, 213, 229, 261, 265, 271, 283, 284, 285, 287, 288, 302, 307, 310, 315, 328, 330, 333, 343, 345, 346, 349, 352, 365, 368, 399, 410, 416, 417, 420, 423, 425, 436, 569, 575, 609, 610, 618, 627, 628, 630, 631, 639, 666, 667, 719, 796, 808, 811, 812, 814, 822, 840, 861, 907, 908, 909, 920, 922, 924, 925, 926, 990, 995, 1000, 1001, 1002, 1003, 1007, 1010, 1016, 1025, 1031, 1032, 1033, 1047, 1049, 1052], "load_lfw_pair": 1046, "load_linnerud": [2, 845, 1047, 1052], "load_mnist": [228, 299], "load_mtpl2": 238, "load_sample_imag": [2, 83, 591, 592, 595, 1050], "load_svmlight_fil": [2, 380, 1041, 1042, 1047, 1048, 1049, 1056], "load_win": [2, 48, 260, 324, 856, 864, 1038, 1052], "loader": [2, 279, 342, 360, 379, 380, 381, 506, 507, 516, 1020, 1034, 1041, 1046, 1048, 1049, 1052], "loan": [423, 542, 996, 1024], "loayza": 1055, "lobpcg": [81, 460, 470, 696, 699, 703, 1051, 1054, 1055, 1056], "loc": [43, 46, 47, 48, 61, 63, 69, 75, 106, 109, 112, 113, 114, 117, 121, 127, 129, 132, 133, 134, 139, 141, 142, 143, 151, 152, 153, 154, 155, 157, 160, 162, 163, 170, 176, 177, 183, 185, 192, 193, 202, 205, 210, 214, 220, 221, 222, 223, 226, 227, 230, 233, 234, 237, 238, 243, 250, 251, 252, 253, 255, 257, 265, 266, 273, 276, 277, 278, 281, 282, 285, 288, 291, 292, 293, 302, 304, 305, 315, 320, 323, 324, 329, 332, 335, 340, 348, 351, 353, 355, 356, 360, 365, 367, 822, 889, 901, 1029], "loc_a": 323, "loc_b": 323, "local": [2, 43, 48, 51, 58, 74, 87, 92, 96, 125, 128, 144, 145, 157, 174, 181, 182, 189, 193, 221, 234, 239, 242, 244, 247, 251, 257, 300, 309, 348, 366, 367, 374, 383, 384, 386, 390, 392, 394, 404, 416, 421, 423, 424, 426, 455, 460, 470, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 510, 546, 548, 552, 555, 557, 567, 568, 571, 574, 618, 619, 696, 697, 698, 699, 700, 701, 703, 704, 766, 767, 855, 858, 861, 863, 873, 882, 905, 908, 916, 966, 998, 999, 1003, 1004, 1016, 1021, 1023, 1033, 1035, 1036, 1045, 1049, 1053, 1056, 1059], "localcach": 404, "locally_linear_embed": [2, 244, 997], "locallylinearembed": [2, 51, 240, 241, 242, 332, 696, 698, 700, 997, 1003, 1046, 1047, 1055, 1056, 1057], "localoutlierfactor": [2, 247, 257, 305, 306, 332, 400, 571, 916, 1006, 1048, 1049, 1051, 1055, 1056, 1057, 1058, 1060], "localoutlierfactor__n_neighbor": 257, "locat": [48, 62, 88, 89, 106, 113, 114, 214, 312, 330, 349, 379, 381, 384, 386, 390, 391, 394, 395, 404, 416, 418, 422, 456, 468, 469, 477, 478, 479, 480, 481, 482, 483, 484, 496, 508, 509, 512, 513, 520, 523, 985, 990, 996, 1001, 1006, 1010, 1016, 1049], "location_": [113, 114, 477, 478, 479, 480, 481, 482, 483, 484], "location_reweight": [477, 482], "lock": [404, 409, 410, 966, 1059], "loev": 542, "lof": [2, 48, 189, 234, 247, 257, 300, 348, 571, 858, 916, 1006, 1021], "lof_kw": 257, "lofti": [1051, 1052], "log": [2, 43, 58, 62, 63, 64, 111, 125, 139, 150, 152, 160, 170, 174, 177, 178, 180, 181, 182, 185, 205, 208, 209, 213, 220, 225, 230, 238, 251, 253, 267, 272, 309, 324, 360, 381, 383, 384, 386, 390, 394, 395, 400, 413, 414, 416, 417, 418, 421, 423, 424, 426, 456, 459, 468, 473, 478, 479, 480, 481, 482, 483, 484, 540, 544, 549, 557, 558, 559, 561, 563, 565, 567, 570, 572, 598, 599, 601, 602, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 650, 653, 656, 666, 667, 677, 679, 684, 688, 730, 749, 759, 763, 805, 806, 808, 811, 812, 822, 847, 848, 849, 850, 851, 852, 853, 857, 868, 869, 876, 877, 906, 909, 914, 917, 919, 920, 922, 947, 989, 992, 994, 996, 997, 1002, 1003, 1005, 1008, 1010, 1014, 1016, 1019, 1020, 1032, 1043, 1044, 1045, 1050, 1051, 1052, 1055, 1058, 1059], "log10": [170, 182, 192, 205, 213, 279, 349], "log1p": [109, 250, 876, 1000, 1010], "log2": [143, 230, 259, 565, 566, 567, 568, 572, 573, 920, 921, 922, 923, 1001], "log_": 1000, "log_2": [413, 571, 1006], "log_bas": 734, "log_den": 304, "log_dens": 857, "log_likelihood": [111, 618, 619, 805, 806], "log_likelihood_gradi": [618, 619], "log_logist": 1058, "log_loss": [2, 62, 63, 151, 154, 177, 324, 342, 360, 400, 414, 423, 565, 567, 569, 572, 654, 666, 684, 920, 922, 989, 996, 1000, 1014, 1016, 1043, 1045, 1047, 1055, 1056, 1057, 1058], "log_marginal_likelihood": [177, 178, 180, 182, 185, 426, 618, 619, 1051], "log_marginal_likelihood_value_": [618, 619], "log_prob": [805, 806, 807, 830], "log_reg": [261, 332], "log_reg_input_featur": 332, "log_scal": 1057, "log_scale_transform": [220, 238], "log_scaled_numer": [220, 238], "log_y_prob": 869, "logaddexp": 1058, "logan": [1055, 1056, 1057], "logarithm": [2, 109, 160, 192, 224, 251, 279, 349, 400, 425, 468, 598, 666, 667, 684, 712, 734, 749, 759, 763, 764, 765, 799, 807, 830, 843, 852, 853, 947, 1016, 1029, 1048], "logcosh": [428, 541], "logdet": 947, "logged_in": 381, "logger": 1052, "logic": [137, 374, 387, 388, 393, 412, 423, 1016, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "logical_and": [53, 152], "logical_not": [57, 99, 134, 223], "logical_or": [222, 228, 287, 392], "logical_xor": [53, 180, 353], "loginov": 1047, "logist": [2, 62, 64, 66, 103, 105, 109, 121, 135, 144, 166, 172, 189, 198, 205, 207, 215, 217, 218, 224, 226, 229, 231, 237, 248, 250, 261, 272, 286, 289, 292, 298, 316, 317, 324, 332, 345, 356, 357, 360, 400, 401, 414, 417, 423, 425, 426, 445, 497, 504, 510, 512, 520, 549, 567, 569, 618, 639, 654, 665, 666, 667, 674, 676, 684, 749, 808, 822, 838, 841, 868, 869, 870, 872, 892, 919, 935, 937, 1000, 1004, 1005, 1014, 1015, 1021, 1022, 1024, 1030, 1036, 1045, 1048, 1049, 1051, 1052], "logistic__c": [107, 1030], "logistic_regress": [272, 831, 839], "logistic_regression_path": [1049, 1050], "logisticregress": [2, 62, 66, 105, 107, 144, 162, 166, 172, 173, 174, 203, 210, 211, 212, 213, 227, 235, 236, 248, 249, 259, 261, 272, 281, 287, 292, 317, 321, 328, 329, 330, 331, 332, 334, 336, 360, 373, 386, 388, 392, 394, 399, 407, 414, 415, 417, 423, 425, 436, 441, 446, 575, 577, 605, 639, 642, 651, 660, 667, 680, 681, 682, 683, 684, 695, 708, 796, 807, 822, 831, 837, 839, 843, 844, 846, 897, 898, 900, 901, 902, 903, 919, 943, 944, 945, 984, 996, 1000, 1001, 1010, 1014, 1015, 1030, 1032, 1041, 1042, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "logisticregression__c": [272, 321], "logisticregressioncv": [2, 64, 324, 400, 407, 666, 996, 1001, 1045, 1046, 1047, 1049, 1050, 1051, 1055, 1056, 1058, 1059], "logisticregressionifittedlogisticregress": 317, "logisticregressionlogisticregress": [105, 144, 248, 249, 259, 261, 272, 292, 329, 332], "logit": [2, 414, 426, 666, 667, 996], "loglik_lw": 111, "loglik_oa": 111, "loglik_r": 111, "loglike_": 540, "loglog": [111, 251], "logloss": 1052, "lognorm": [152, 182, 201, 267, 323, 1010], "logo": [0, 420, 815], "logprob": 857, "logreg": [203, 846], "logspac": [43, 51, 64, 107, 111, 132, 165, 174, 177, 182, 192, 213, 224, 225, 251, 253, 267, 272, 279, 291, 294, 303, 314, 321, 324, 349, 356, 831, 839, 995, 996, 1029, 1030, 1032], "logsumexp": [309, 1048], "loguniform": [45, 176, 286, 989, 1030, 1051], "logx": [224, 356], "lohit": 1058, "loic": [1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058, 1059], "loki": [374, 1000, 1049, 1052], "lomp": 384, "lon": 772, "london": [417, 424, 474], "londschien": [221, 1054, 1058], "lone": [1056, 1057], "long": [30, 43, 50, 51, 79, 97, 152, 181, 188, 192, 194, 220, 254, 255, 257, 281, 312, 319, 329, 360, 361, 369, 374, 384, 386, 394, 398, 400, 401, 410, 416, 461, 506, 546, 684, 685, 686, 811, 812, 847, 848, 849, 850, 851, 869, 870, 880, 1000, 1006, 1010, 1011, 1013, 1014, 1018, 1043, 1047, 1053, 1055], "long_term_trend_kernel": 181, "long_titl": 353, "longer": [0, 43, 70, 88, 142, 192, 193, 205, 316, 331, 386, 388, 416, 420, 423, 424, 457, 544, 571, 995, 999, 1000, 1002, 1005, 1015, 1023, 1024, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "longest": 299, "longitud": [312, 319, 381, 506, 707, 772], "longpathsen": 404, "longstand": [1042, 1048], "loo": [400, 816, 1052], "look": [43, 44, 64, 88, 90, 125, 128, 130, 152, 153, 176, 181, 182, 188, 192, 193, 222, 240, 244, 247, 254, 269, 272, 273, 278, 280, 292, 316, 335, 360, 361, 369, 374, 375, 380, 381, 386, 387, 388, 390, 392, 394, 398, 399, 416, 419, 421, 422, 423, 424, 456, 496, 497, 565, 566, 567, 568, 572, 573, 610, 611, 639, 667, 700, 892, 920, 921, 922, 923, 996, 997, 1010, 1014, 1015, 1017, 1033, 1034, 1041, 1049, 1051], "lookup": [395, 965, 1050], "loop": [46, 47, 142, 152, 192, 273, 283, 360, 368, 373, 386, 387, 392, 416, 420, 425, 654, 655, 660, 661, 667, 668, 669, 670, 671, 989, 1013, 1014, 1029, 1044, 1045, 1048, 1053, 1054, 1057, 1058], "loopym": 1051, "loos": [269, 275, 1015, 1049], "looser": 213, "lope": 197, "lopez": 197, "lopusz": 1052, "lorain": 333, "lorek": 1048, "lorentzen": [0, 221, 222, 405, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "lorenz": [220, 238, 1046, 1058], "lorenz_curv": [220, 238], "lose": [224, 237, 362, 381, 400, 419, 424, 426, 948, 949, 990, 996, 1034], "losi": [0, 406, 1041], "loss": [2, 25, 46, 52, 61, 62, 63, 64, 134, 145, 151, 152, 153, 154, 176, 177, 189, 198, 202, 210, 213, 222, 224, 225, 227, 228, 232, 238, 253, 272, 286, 315, 316, 324, 331, 335, 336, 342, 346, 347, 351, 353, 356, 360, 398, 400, 414, 421, 426, 472, 473, 504, 516, 517, 540, 546, 547, 548, 551, 555, 560, 561, 562, 566, 567, 568, 569, 570, 573, 651, 654, 657, 666, 667, 674, 675, 676, 677, 678, 679, 680, 684, 685, 686, 687, 711, 714, 717, 730, 731, 742, 743, 748, 749, 750, 753, 754, 755, 756, 757, 758, 759, 760, 761, 798, 799, 804, 808, 811, 812, 822, 834, 835, 838, 869, 870, 872, 873, 876, 877, 885, 886, 887, 892, 912, 913, 918, 919, 921, 923, 949, 953, 993, 996, 1004, 1008, 1013, 1014, 1015, 1016, 1021, 1034, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "loss_": [315, 869, 870, 1004, 1055], "loss_curve_": [315, 869, 870], "loss_func": 52, "loss_funct": 52, "loss_function_": [674, 676, 684, 685, 1058], "lossfit_timemapermsemaepinball_loss_05pinball_loss_50pinball_loss_95strstrstrstrstrstrstrstr": 52, "lossfunct": [676, 684, 685, 1050], "lossi": 416, "lossili": 400, "lost": [58, 92, 115, 381, 387, 398, 997, 1000], "lostanlen": 1051, "lostcoast": 1051, "lot": [43, 115, 155, 192, 224, 381, 386, 387, 388, 394, 421, 423, 811, 812, 904, 905, 989, 1012, 1014, 1015, 1019, 1020, 1024, 1033, 1034, 1041, 1046, 1048, 1049, 1050, 1051, 1053], "lot_area": 257, "lotan": 1024, "lotconfig": 149, "lotfrontag": 109, "loui": [333, 1046, 1047, 1051, 1053, 1055, 1057, 1058], "louib": [1049, 1050], "loupp": [0, 142, 143, 406, 423, 563, 564, 1041, 1042, 1043, 1044, 1045, 1046, 1047], "lourida": 1047, "love": 1034, "low": [2, 37, 43, 50, 51, 72, 85, 114, 118, 127, 129, 132, 139, 142, 156, 174, 194, 213, 215, 220, 222, 224, 234, 240, 242, 247, 251, 257, 263, 264, 266, 269, 271, 272, 278, 280, 284, 285, 294, 305, 306, 316, 323, 325, 326, 334, 341, 348, 349, 360, 368, 382, 383, 386, 391, 394, 398, 400, 404, 413, 414, 415, 420, 421, 424, 450, 452, 457, 476, 529, 532, 543, 590, 597, 611, 687, 700, 704, 713, 734, 750, 797, 857, 886, 893, 910, 949, 965, 989, 995, 996, 997, 999, 1000, 1003, 1005, 1006, 1007, 1008, 1010, 1012, 1015, 1016, 1022, 1036, 1042, 1045, 1046, 1047, 1049, 1050, 1055, 1056], "low_cardin": 325, "low_cardinality_featur": 325, "low_cardinalityindex": 325, "low_i": 215, "low_x": 215, "lower": [37, 44, 52, 63, 64, 67, 69, 93, 112, 118, 121, 125, 127, 132, 139, 142, 145, 148, 152, 155, 156, 172, 176, 178, 180, 182, 184, 192, 193, 194, 204, 205, 206, 210, 220, 221, 222, 223, 233, 240, 244, 250, 251, 256, 265, 269, 272, 277, 278, 280, 281, 285, 286, 288, 291, 292, 302, 303, 305, 306, 321, 324, 332, 336, 341, 349, 360, 361, 362, 365, 381, 386, 400, 414, 415, 416, 419, 420, 421, 422, 423, 424, 427, 452, 456, 472, 475, 506, 517, 540, 542, 549, 552, 561, 567, 568, 569, 570, 571, 596, 597, 599, 611, 619, 621, 622, 623, 625, 627, 628, 630, 631, 633, 640, 641, 643, 645, 685, 687, 720, 724, 733, 736, 742, 747, 805, 806, 858, 860, 862, 863, 864, 866, 893, 912, 913, 914, 915, 916, 919, 936, 995, 996, 997, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1012, 1014, 1015, 1016, 1032, 1043, 1044, 1049, 1056, 1058], "lower_bound": 277, "lower_bound_": [805, 806, 1049], "lowercas": [424, 432, 450, 451, 453, 455, 457, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 596, 597, 599, 647, 648, 649, 650, 696, 697, 700, 856, 861, 864, 868, 873, 878, 904, 905, 1054], "lowest": [2, 109, 118, 193, 204, 268, 380, 416, 420, 643, 645, 811, 812, 815, 919, 920, 997, 1000, 1016, 1056], "loyal": 1046, "loyola": [0, 376, 1054, 1055], "lo\u00efc": [0, 405, 1049, 1052, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "lp_model": [338, 339], "lpgo": [420, 817], "lpo": 818, "lprun": 392, "lr": [62, 64, 144, 162, 163, 223, 249, 250, 274, 281, 399, 407, 423, 576, 577, 578, 720, 984], "lr_": 1000, "lr__c": 423, "lr_base": 281, "lrap": [747, 1000], "lrjball": [1051, 1052], "ls100": 343, "ls2010": 992, "ls30": 343, "ls50": 343, "ls_pipelin": 342, "lsa": [2, 421, 552, 1043], "lsa_vector": 361, "lshforest": [1045, 1048], "lsi": 421, "lsqr": [69, 326, 557, 680, 682, 695, 994, 1042, 1048, 1055], "lstrip": [67, 79, 97, 247, 314, 321], "lstsq": [134, 386, 665, 678], "lsturtew": 1054, "lsvc": 425, "lsvm": 197, "lsvm_score": 197, "lsvm_time": 197, "lt": [105, 106, 144, 160, 192, 268, 276, 290, 384, 386, 1027], "ltd": [272, 381], "ltg": [174, 383, 509], "ltorgo": 381, "ltsa": [240, 241, 242, 697, 701, 997], "lu": [549, 552, 948, 949, 1047, 1048, 1049, 1050, 1057, 1058, 1059], "luangkot": 1048, "luca": [1041, 1051, 1052, 1053, 1054], "lucca": 1054, "luce": 1044, "lucen": 424, "lucgiffon": 1052, "luci": [0, 284, 376, 397, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "luciano": [1049, 1056], "lucieclair": 1055, "lucija": 1049, "lucio": 1050, "lucki": 369, "lucyleeow": 1052, "ludwig": 1041, "luessi": 1043, "lui": [666, 1042, 1044, 1045, 1049, 1058], "luiz": 1055, "luk": 1050, "luka": [1045, 1052, 1058, 1059], "luke": 1049, "lukowski": 1056, "luk\u00e1\u0161": 1058, "luna": 1055, "lunt": 1044, "luo": 1045, "lupo": 1053, "luqi": 1050, "luqu": 1051, "lurk": 1041, "lustig": 996, "lutz": [1047, 1051, 1054, 1058], "luxburg": [416, 460, 470, 699], "luzgin": 1051, "lv_ep": 252, "lvdmaaten": [700, 1048], "lw": [95, 111, 112, 114, 129, 133, 134, 214, 221, 223, 226, 230, 237, 243, 266, 273, 288, 304, 319, 340, 355], "lw_cov_": 115, "lw_mse": 112, "lw_prec_": 115, "lw_score": 132, "lw_shrinkag": 112, "lwda": 458, "lx": 1003, "ly": [252, 860, 862, 863, 864, 1045], "ly648499246": 1054, "lynch": [1042, 1048], "lyon": [1047, 1048], "lyra": [1042, 1045, 1046], "lyrl2004": [381, 505], "l\u00e9o": 1049, "l\u00e9on": [1014, 1055, 1056, 1057], "l\u00e9onard": [1051, 1056], "l\u00e9one": 1047, "l\u00e9oni": 1047, "l\u00f3pez": [1045, 1049, 1050, 1053], "l\u00f6fstedt": 1048, "l\u00f6ning": 1053, "m": [0, 43, 47, 50, 57, 63, 64, 79, 93, 94, 98, 99, 100, 113, 114, 125, 139, 163, 202, 220, 238, 278, 282, 312, 335, 342, 345, 355, 360, 373, 374, 380, 381, 383, 384, 386, 390, 392, 400, 404, 413, 414, 416, 418, 421, 423, 425, 427, 452, 453, 454, 458, 465, 481, 482, 508, 521, 536, 540, 542, 544, 549, 647, 653, 657, 672, 679, 693, 694, 697, 701, 716, 724, 734, 749, 764, 766, 767, 805, 806, 858, 883, 949, 979, 980, 990, 992, 994, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1008, 1010, 1014, 1016, 1024, 1049, 1050, 1051, 1052, 1055, 1056, 1057, 1058], "m1": [384, 412], "m11": 381, "m2": 412, "m2012": 993, "m2019": 1007, "m2cgen": 1019, "m4x": [212, 236], "m_max": 178, "ma": [115, 325, 349, 996, 1047, 1052], "maascha": 1056, "maaten": [700, 704, 997], "mabel": [1049, 1053], "mabu": 1054, "mac": [57, 325, 342, 381, 386, 716, 1000], "macaulei": 325, "macbook": 1049, "macdonald": [1051, 1052], "mach": [283, 414, 420, 601, 602], "machado": [414, 731], "machin": [0, 2, 39, 43, 45, 47, 48, 52, 64, 98, 107, 117, 145, 170, 171, 174, 176, 181, 190, 194, 210, 215, 232, 260, 272, 278, 281, 284, 296, 313, 319, 324, 326, 330, 333, 336, 345, 350, 353, 356, 360, 362, 373, 374, 379, 380, 381, 383, 386, 389, 392, 393, 398, 399, 400, 403, 410, 414, 416, 420, 421, 423, 424, 426, 445, 447, 456, 479, 480, 486, 510, 512, 518, 524, 525, 526, 538, 540, 542, 549, 552, 563, 564, 565, 566, 567, 568, 572, 573, 574, 601, 602, 618, 619, 622, 627, 630, 642, 646, 647, 649, 651, 652, 653, 658, 659, 662, 663, 664, 665, 666, 667, 684, 690, 691, 700, 716, 721, 733, 743, 749, 751, 793, 796, 805, 837, 838, 852, 853, 858, 861, 868, 869, 870, 872, 890, 892, 898, 912, 913, 914, 915, 917, 918, 922, 923, 989, 990, 992, 993, 996, 997, 998, 1000, 1001, 1003, 1006, 1007, 1008, 1010, 1014, 1016, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1026, 1027, 1028, 1030, 1034, 1035, 1036, 1038, 1041, 1043, 1053, 1054, 1055, 1056, 1058], "maciej": 1052, "maci\u00e0": [1000, 1054, 1056], "mackai": [652, 653, 996], "mackenbach": 1052, "maco": [387, 389, 404, 412, 1049, 1053, 1055], "macosx": 1041, "macro": [45, 68, 104, 171, 276, 317, 328, 338, 339, 381, 420, 715, 721, 737, 738, 746, 791, 792, 795, 796, 830, 1000, 1034, 1041, 1049, 1057], "macro_roc_auc_ovo": 287, "macro_roc_auc_ovr": 287, "macroscop": 416, "macsween": [1050, 1051], "mad": [679, 1047], "madan": 1053, "made": [0, 52, 64, 104, 114, 120, 130, 139, 145, 163, 183, 192, 193, 220, 238, 257, 269, 282, 325, 329, 349, 365, 373, 381, 383, 386, 390, 400, 401, 407, 416, 423, 424, 428, 451, 454, 455, 457, 467, 504, 511, 596, 597, 599, 638, 639, 664, 673, 687, 693, 694, 743, 791, 808, 811, 812, 822, 826, 827, 828, 849, 852, 853, 1001, 1006, 1016, 1019, 1024, 1031, 1033, 1041, 1042, 1043, 1044, 1045, 1048, 1050, 1051, 1054, 1055], "madelon": 523, "madhura": [1050, 1052, 1053, 1056, 1057], "madinak": 1056, "madsen": [1047, 1049], "mae": [43, 52, 160, 220, 222, 566, 573, 753, 921, 923, 1000, 1016, 1048, 1049, 1053, 1054], "mae_test": 192, "mae_train": 192, "maennel": 1056, "magali": 1055, "magazin": [114, 425], "magda": 1052, "magenta": [111, 154], "maggi": 1055, "maggiecheg": [1051, 1055], "maggio": [1052, 1053, 1054], "magic": [254, 387, 392, 426, 624, 629, 632], "magnesium": 383, "magnitud": [43, 134, 141, 177, 188, 192, 237, 257, 283, 319, 324, 331, 336, 373, 381, 392, 416, 423, 426, 621, 660, 712, 892, 996, 1000, 1004, 1010, 1014, 1016, 1043, 1050, 1059], "mahajan": [1049, 1051, 1058], "mahal": 113, "mahal_emp_cov": 113, "mahal_robust_cov": 113, "mahalanobi": [110, 114, 189, 223, 416, 418, 458, 465, 477, 478, 479, 480, 481, 482, 483, 484, 707, 786, 787, 788, 994, 1003, 1006, 1021, 1049, 1052, 1053], "mahalanobisdist": 707, "mahapatra": 1048, "mahdavi": 647, "maheshakya": [0, 1044, 1045, 1046], "mahieux": 1024, "mahimkar": 1059, "mahmood": 1059, "mahout": 849, "mai": [0, 2, 25, 47, 57, 62, 74, 79, 81, 91, 105, 118, 125, 149, 150, 155, 174, 180, 182, 184, 192, 195, 197, 200, 204, 209, 224, 226, 245, 254, 257, 281, 283, 285, 286, 292, 314, 324, 339, 349, 353, 356, 360, 361, 362, 369, 373, 374, 375, 378, 380, 381, 382, 383, 385, 386, 388, 390, 391, 394, 398, 400, 401, 404, 407, 410, 413, 415, 416, 417, 418, 419, 420, 421, 423, 424, 425, 426, 427, 439, 447, 448, 449, 451, 452, 453, 454, 455, 457, 459, 460, 461, 462, 467, 470, 473, 477, 480, 490, 491, 492, 495, 496, 497, 504, 516, 517, 523, 542, 543, 546, 548, 549, 552, 555, 556, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 580, 582, 589, 602, 605, 610, 618, 619, 625, 628, 642, 643, 645, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 678, 680, 681, 682, 684, 685, 686, 687, 689, 692, 694, 696, 697, 699, 700, 701, 703, 705, 713, 719, 720, 723, 724, 726, 727, 729, 730, 731, 732, 734, 746, 764, 771, 793, 794, 808, 810, 811, 812, 813, 822, 823, 824, 827, 828, 833, 837, 840, 845, 846, 847, 848, 849, 851, 854, 855, 856, 858, 860, 862, 863, 864, 870, 871, 872, 875, 877, 887, 889, 890, 891, 892, 893, 895, 901, 904, 905, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 925, 930, 952, 953, 989, 990, 992, 994, 996, 997, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1020, 1025, 1031, 1032, 1041, 1043, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "maikia": [46, 153, 160, 188, 1049, 1050, 1052, 1053], "mail": [222, 324, 381, 386, 390, 394, 398, 401, 1049, 1050], "mailhot": 1041, "mailman": 394, "main": [2, 37, 48, 68, 97, 118, 129, 149, 189, 247, 287, 298, 327, 356, 360, 373, 374, 375, 379, 384, 386, 388, 390, 392, 394, 398, 399, 400, 403, 404, 414, 416, 421, 423, 424, 426, 511, 533, 538, 557, 558, 633, 721, 842, 912, 913, 989, 997, 999, 1000, 1007, 1012, 1020, 1023, 1031, 1034, 1041, 1044, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "mainak": 1048, "maingret": 1052, "mainli": [64, 88, 139, 142, 176, 287, 296, 373, 388, 414, 619, 1002, 1007], "maint": 390, "maint_tool": 390, "maintain": [90, 225, 238, 240, 254, 278, 374, 385, 389, 392, 393, 394, 398, 400, 401, 404, 416, 423, 448, 450, 881, 882, 888, 889, 892, 897, 900, 901, 903, 996, 997, 1010, 1019, 1020, 1025, 1036, 1056, 1060], "mainten": [0, 386, 394, 398, 404, 409, 996, 1020, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "mainy": 1053, "mair": 643, "mairal": [421, 539, 545], "maisonneuv": 1053, "maithreyi": 1051, "maj": 577, "major": [2, 49, 54, 70, 145, 272, 285, 319, 323, 328, 329, 330, 331, 332, 333, 334, 335, 353, 362, 373, 381, 385, 386, 389, 392, 398, 401, 410, 416, 420, 422, 424, 559, 577, 578, 702, 924, 926, 1000, 1003, 1014, 1020, 1024, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "make": [0, 2, 43, 46, 47, 50, 52, 54, 55, 58, 59, 62, 63, 64, 74, 75, 78, 79, 91, 96, 97, 102, 107, 130, 139, 145, 149, 152, 155, 158, 171, 174, 176, 181, 184, 191, 192, 193, 194, 199, 204, 206, 209, 212, 213, 214, 216, 220, 221, 222, 224, 226, 238, 241, 249, 251, 253, 254, 255, 257, 263, 265, 268, 269, 272, 273, 278, 280, 281, 287, 288, 289, 292, 298, 308, 316, 319, 320, 325, 332, 334, 336, 349, 358, 360, 361, 362, 369, 373, 374, 375, 380, 381, 384, 385, 387, 388, 389, 391, 392, 394, 398, 400, 404, 407, 410, 413, 414, 416, 417, 418, 420, 421, 423, 424, 425, 428, 448, 449, 450, 451, 453, 455, 457, 459, 460, 461, 466, 467, 468, 470, 496, 511, 522, 523, 530, 531, 535, 540, 542, 549, 559, 560, 563, 564, 569, 570, 591, 592, 615, 616, 639, 657, 663, 664, 679, 699, 703, 738, 745, 750, 776, 777, 789, 805, 806, 808, 810, 813, 819, 823, 824, 827, 828, 834, 835, 842, 843, 846, 879, 888, 891, 892, 896, 900, 902, 903, 904, 905, 918, 926, 932, 933, 943, 949, 955, 961, 986, 989, 990, 992, 994, 996, 997, 999, 1000, 1001, 1002, 1003, 1005, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1024, 1025, 1030, 1032, 1034, 1038, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "make_": 1050, "make_biclust": [2, 59, 521, 1043], "make_blob": [2, 61, 63, 69, 73, 77, 78, 79, 84, 90, 91, 92, 94, 95, 97, 98, 99, 122, 212, 232, 247, 266, 322, 329, 332, 347, 350, 351, 357, 382, 388, 389, 423, 523, 704, 718, 800, 801, 1049, 1052, 1055], "make_cbar": 289, "make_checkerboard": [2, 58, 519, 1043], "make_circl": [2, 67, 79, 97, 130, 158, 245, 314, 315, 321, 340, 382, 1042, 1049, 1052], "make_classif": [2, 62, 64, 67, 122, 143, 144, 146, 171, 173, 275, 281, 289, 290, 309, 314, 321, 328, 330, 334, 336, 356, 369, 382, 389, 412, 415, 423, 445, 446, 495, 520, 561, 563, 565, 572, 613, 615, 674, 705, 706, 708, 710, 807, 830, 831, 836, 837, 839, 842, 869, 872, 912, 919, 989, 1000, 1001, 1010, 1015, 1047, 1048, 1049, 1051], "make_column_selector": [2, 105, 149, 160, 257, 417, 472, 475, 1051], "make_column_transform": [2, 149, 160, 192, 249, 329, 417, 472, 474, 1049], "make_data": [70, 96], "make_dataset": 1050, "make_default": 970, "make_ellips": 265, "make_estim": 257, "make_friedman1": [2, 382, 423, 547, 551, 601, 602, 640], "make_friedman2": [2, 382, 619, 621, 622, 623, 624, 625, 629, 632, 633], "make_friedman3": [2, 382], "make_gaussian_quantil": [2, 122, 139, 141, 382, 478, 482, 483, 484, 489, 528], "make_hastie_10_2": [2, 154, 282, 382, 423, 567, 1007], "make_heatmap": 289, "make_low_rank_matrix": [2, 334, 336, 532], "make_ml_clf": 123, "make_moon": [2, 67, 79, 97, 247, 278, 314, 315, 321, 382, 989, 1048, 1052], "make_multilabel_classif": [2, 123, 255, 382, 523, 544, 796, 843, 844, 1000, 1043, 1044, 1046, 1052], "make_pipelin": [2, 43, 67, 93, 118, 144, 149, 160, 170, 171, 174, 187, 188, 192, 193, 197, 199, 208, 209, 220, 221, 226, 234, 238, 241, 247, 248, 249, 257, 258, 259, 261, 272, 275, 285, 292, 299, 308, 314, 321, 324, 325, 326, 328, 329, 330, 331, 332, 333, 361, 369, 399, 407, 417, 420, 575, 684, 686, 864, 872, 897, 898, 900, 901, 902, 903, 912, 913, 914, 915, 917, 918, 990, 1003, 1010, 1014, 1015, 1044, 1051, 1054], "make_plot": 319, "make_regress": [2, 49, 109, 199, 201, 202, 206, 223, 224, 291, 329, 335, 369, 382, 388, 389, 399, 562, 564, 568, 573, 614, 616, 617, 643, 654, 655, 657, 659, 660, 661, 663, 668, 669, 670, 671, 672, 673, 675, 679, 687, 689, 690, 691, 693, 694, 695, 870, 913, 1000, 1001, 1003], "make_s_curv": [2, 240, 245], "make_scor": [2, 52, 152, 155, 272, 282, 336, 407, 415, 420, 719, 808, 830, 834, 835, 1000, 1050, 1058], "make_sparse_coded_sign": [2, 219, 539, 545, 553, 554, 1055, 1057], "make_sparse_spd_matrix": [2, 115, 486, 537, 1058], "make_sparse_uncorrel": [2, 382], "make_spd_matrix": [2, 535], "make_subplot": 145, "make_swiss_rol": [2, 102, 244, 1055], "make_union": [2, 417, 871, 1044, 1048], "makedir": 1048, "maker": [191, 192], "makhija": 1056, "makoeppel": 1054, "maksym": 1056, "maladier": 1056, "maladi\u00e8r": [1056, 1057], "malcolm": 1049, "maldonado": [1051, 1054], "male": [105, 192, 333, 391, 885, 886, 1010], "malem": 1058, "malet": 1041, "malform": [55, 1045], "malic": [324, 383], "malic_acid": 48, "malici": 410, "malign": [174, 383, 508], "malik": [416, 460, 470, 699], "mallat": [672, 693, 694, 996], "mallatpursuit93": [672, 693, 694], "mallow": [739, 1047], "maloo": [1049, 1050], "malt": [221, 1054, 1055, 1056, 1058], "maltimor": 1051, "malu": 238, "malzer": 454, "mal\u00e9zieux": 1054, "mamba": 410, "mame": 1058, "mammal": 50, "mammalian": 421, "man": [421, 598, 777, 847, 851, 998, 1000, 1002], "manag": [0, 2, 118, 261, 372, 380, 384, 387, 388, 390, 394, 398, 400, 401, 410, 423, 458, 476, 634, 910, 994, 1016, 1019, 1020, 1024, 1034, 1036, 1054, 1057], "manaileng": 1054, "manasimj": 1059, "mandal": 1051, "mandatori": [386, 424, 436, 639], "mandatorili": 1048, "mandera": 1044, "mandi": [1052, 1055], "mandjev": 1055, "mandyam": 1051, "mangasarian": [174, 383], "mangipudi": 1047, "manh": 1049, "manhattan": [416, 449, 453, 458, 465, 707, 770, 779, 786, 787, 788, 859, 998, 1003, 1045, 1050, 1057], "manhattan_dist": [2, 458, 465, 696, 770, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 1041, 1051, 1056, 1057], "manhattandist": 707, "mani": [43, 46, 49, 57, 90, 91, 108, 111, 115, 139, 145, 146, 147, 148, 153, 170, 174, 194, 220, 240, 251, 264, 271, 272, 278, 285, 286, 290, 299, 319, 324, 325, 328, 329, 330, 331, 332, 334, 335, 336, 360, 369, 373, 375, 381, 383, 385, 386, 399, 400, 401, 404, 410, 413, 414, 416, 417, 418, 421, 423, 424, 425, 426, 428, 511, 549, 561, 562, 565, 566, 567, 568, 572, 573, 574, 614, 617, 635, 647, 658, 662, 666, 667, 674, 675, 676, 684, 685, 686, 700, 703, 782, 786, 808, 812, 822, 869, 870, 885, 890, 892, 912, 920, 921, 922, 923, 989, 990, 992, 996, 997, 999, 1000, 1001, 1002, 1003, 1006, 1007, 1010, 1013, 1015, 1017, 1018, 1019, 1020, 1024, 1032, 1034, 1041, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1055, 1056, 1057], "manideep": 1059, "manifest": [394, 997, 1003], "manifold": [2, 51, 74, 87, 102, 144, 243, 244, 245, 251, 299, 309, 328, 332, 333, 340, 379, 400, 416, 421, 423, 510, 533, 538, 552, 557, 574, 696, 697, 698, 699, 700, 701, 702, 703, 704, 861, 873, 882, 905, 935, 1003, 1021, 1035, 1036, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1058], "manimaran": [1050, 1052, 1053, 1054, 1055], "manipul": [2, 380, 412, 515, 1019, 1047], "manish": 1052, "maniteja": [1047, 1048, 1049], "mankoo": 1056, "mann": 1051, "mannbi": 1049, "manner": [43, 109, 125, 171, 193, 197, 265, 332, 333, 374, 386, 392, 416, 421, 423, 424, 717, 852, 853, 989, 1000, 1016, 1044, 1051], "mannila": 1012, "manning2008": 1000, "manoharan": [1048, 1049], "manoj": [0, 77, 174, 202, 406, 1044, 1045, 1046, 1047, 1048], "manojkumarsivaraj334": 77, "manraj": 1048, "mansi": 1056, "mansingh": 1055, "mansouri": 1057, "mantovani": 1056, "manu": 381, "manual": [2, 43, 81, 90, 192, 193, 195, 221, 231, 280, 299, 341, 347, 360, 362, 373, 374, 381, 386, 390, 391, 398, 399, 404, 410, 416, 420, 421, 422, 445, 457, 575, 807, 830, 862, 885, 891, 989, 994, 995, 996, 999, 1000, 1003, 1010, 1020, 1025, 1026, 1034, 1049, 1051, 1057, 1059], "manuel": [1041, 1045, 1049, 1050, 1053, 1054, 1059], "manufactur": [192, 423], "manvendra": [1047, 1048], "maocx": 1051, "map": [2, 23, 37, 43, 44, 49, 50, 55, 57, 63, 88, 118, 130, 143, 151, 154, 158, 176, 189, 197, 220, 238, 240, 242, 246, 254, 257, 279, 282, 287, 307, 310, 312, 318, 319, 342, 349, 353, 361, 362, 380, 381, 387, 398, 400, 407, 410, 414, 416, 417, 420, 421, 423, 424, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 504, 506, 510, 517, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 770, 773, 805, 806, 807, 808, 811, 812, 819, 820, 822, 830, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 900, 901, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 954, 957, 958, 989, 992, 997, 1000, 1002, 1012, 1015, 1016, 1021, 1029, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1058], "mapd": 1000, "mape": [2, 52, 754, 1000], "mape_cv_mean": 149, "mape_cv_std": 149, "mapi": 52, "mar": 51, "marc": [1048, 1050, 1051, 1057], "march": [181, 734, 764, 1000, 1041, 1045, 1049, 1051, 1056], "marchand": 1055, "marchman": [1042, 1043], "marco": [1047, 1049, 1050, 1054, 1055, 1056, 1059], "marcofalk": 1048, "marcogorelli": [1049, 1050], "marcolini": 1054, "marcom": 1055, "marcu": [1049, 1058], "mare": 1058, "marek": [1041, 1058], "maren": [0, 376, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "margeta": 1049, "margin": [30, 43, 51, 62, 64, 122, 141, 177, 178, 179, 180, 181, 182, 189, 192, 193, 198, 230, 231, 233, 255, 257, 278, 296, 319, 322, 325, 344, 345, 347, 348, 349, 351, 353, 357, 358, 383, 414, 421, 423, 426, 520, 618, 619, 639, 653, 684, 743, 841, 889, 901, 914, 917, 996, 1000, 1002, 1006, 1007, 1010, 1014, 1015, 1021, 1032, 1048, 1050], "marguli": 1051, "mari": [104, 1049, 1050, 1051, 1052, 1055], "maria": [46, 153, 160, 174, 188, 416, 1052, 1053, 1054, 1055, 1056], "mariam": 1053, "mariana": 1052, "mariangela": 1054, "mariano": 278, "mariel": 1052, "marielaraj": 1054, "marija": [1052, 1053, 1059], "marijn": 1053, "marin": [536, 1059], "marina": 416, "marinelm": 1050, "mario": [414, 1045, 1047, 1055, 1056, 1057], "marit": [335, 504], "mari\u00e9": [0, 376, 1050, 1051, 1052, 1053, 1054, 1055], "mark": [2, 70, 93, 123, 169, 188, 282, 289, 378, 386, 388, 390, 394, 395, 400, 416, 543, 615, 616, 619, 640, 666, 865, 866, 907, 908, 925, 939, 944, 949, 996, 1024, 1036, 1041, 1042, 1047, 1049, 1050, 1057, 1058, 1059], "markdown": 389, "marker": [49, 50, 55, 64, 66, 70, 72, 73, 77, 87, 90, 93, 94, 95, 98, 99, 117, 122, 123, 127, 145, 159, 183, 184, 197, 208, 213, 215, 217, 218, 220, 222, 223, 235, 237, 241, 263, 265, 266, 272, 273, 278, 280, 281, 282, 306, 319, 324, 340, 364, 386, 390, 424, 1049, 1051, 1052, 1057], "markeredgecolor": [84, 90, 96, 98, 99], "markeredgewidth": [113, 282], "markerfacecolor": [84, 90, 96, 98, 99], "markers": [84, 90, 93, 96, 98, 99, 152, 179, 183, 250, 272, 332], "markerstyl": 272, "market": [42, 81, 155, 189, 240, 241, 416, 418, 462, 480, 697, 1021, 1024, 1028], "marketplac": 1024, "markham": [1045, 1052, 1053], "markiwanchyshyn": 1049, "marko": [1041, 1050, 1051, 1057], "markou": 1054, "markov": [426, 619, 1005, 1019, 1041], "markovtsev": 1049, "marktab": 1046, "marku": [416, 458, 465, 1049, 1051, 1052, 1053], "marmo": [0, 377, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "maron": [416, 450], "marr": 192, "marr_unmarri": 192, "marreddi": 1055, "marri": 192, "marriott": 51, "marsgui": 1049, "marsh": 1052, "marshal": 383, "marsi": 1044, "marsland": 538, "marslast": 538, "marszalek": [766, 767, 998], "mart": [51, 1051], "martel": 1055, "martha": 325, "martian": 1051, "martin": [0, 376, 729, 731, 732, 996, 1000, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1058], "martin1997": 1000, "martina": [1051, 1053], "martinbpr": [1046, 1047], "martinez": 1048, "martino": 1046, "martinosorb": 1046, "martinsson": [55, 543, 549, 949], "martynov": 1054, "mart\u00edn": [1054, 1055], "marufo": 1056, "marufur": 1048, "marvin": [1056, 1057], "marwaha": 1049, "marx": 1010, "maryanmorel": [1046, 1047], "marzinotto": [1049, 1050], "mar\u00eda": [1055, 1056, 1057], "mas_vnr_typ": 257, "masafumi": 1046, "masanori": [1056, 1057], "masashi": [1051, 1053], "masecchia": 1041, "mash": 424, "mask": [2, 53, 77, 101, 147, 220, 228, 257, 276, 277, 342, 395, 400, 417, 423, 472, 477, 482, 569, 570, 589, 593, 594, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 637, 638, 640, 641, 657, 679, 808, 811, 812, 822, 972, 990, 1007, 1041, 1044, 1046, 1047, 1049, 1051, 1059], "mask_al": 990, "mask_false_neg": 272, "mask_false_posit": 272, "mask_missing_values_onli": 990, "mask_out": 53, "mask_test": 238, "mask_train": [193, 238], "mask_true_neg": 272, "mask_true_posit": 272, "mask_y_pr": 66, "maskani": [1049, 1051, 1052, 1053], "masked_arrai": [349, 808, 822], "masked_equ": 115, "maskedarrai": [282, 1047], "mason": 1045, "mass": [174, 258, 383, 454, 805, 996, 1007], "massachusett": 381, "massia": [0, 1052, 1054, 1055], "massich": [1048, 1049, 1050, 1051], "massil": 1047, "masstran": 1050, "master": [51, 299, 333, 386, 390, 1024], "masurel": 1042, "masvnrarea": [109, 160], "masvnrtyp": [149, 160], "mat": [380, 424], "match": [2, 43, 58, 72, 125, 126, 128, 131, 134, 145, 189, 197, 198, 220, 242, 250, 257, 291, 353, 362, 381, 384, 388, 390, 416, 421, 423, 424, 437, 457, 472, 474, 516, 517, 523, 534, 539, 545, 550, 556, 559, 575, 576, 580, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 666, 672, 673, 693, 694, 707, 711, 712, 713, 721, 723, 727, 742, 786, 787, 788, 794, 852, 853, 857, 861, 875, 876, 877, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 912, 919, 925, 936, 997, 999, 1000, 1002, 1003, 1021, 1022, 1025, 1034, 1036, 1041, 1047, 1048, 1049, 1051, 1053, 1054, 1057], "matchingdist": 707, "matchmak": 1024, "matcovici": 1051, "mate": 360, "matem\u00e1tica": 996, "mateo": 1054, "materi": [53, 192, 335, 401, 549, 589, 902, 903, 1018], "matern": [2, 185, 426, 1052, 1056], "mateusz": [1045, 1052, 1053, 1058, 1059], "math": [84, 104, 155, 174, 257, 278, 279, 383, 404, 772], "mathbb": [125, 142, 179, 419, 1000, 1007, 1015], "mathbf": [179, 353, 421, 996, 1000, 1004, 1005, 1014], "mathcal": [224, 356, 421, 423, 635, 704, 992, 994, 996, 1000, 1014, 1054], "mathemat": [37, 139, 192, 208, 237, 281, 378, 383, 386, 400, 403, 416, 418, 421, 422, 426, 557, 558, 565, 572, 643, 654, 664, 800, 801, 806, 870, 914, 917, 920, 922, 996, 1000, 1004, 1010, 1012, 1022, 1024, 1032, 1036, 1055], "matheu": 1047, "mathew": 1056, "mathi": 1054, "mathia": 1055, "mathieu": [0, 61, 83, 130, 211, 221, 241, 255, 279, 360, 406, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1054], "mathrm": [416, 418, 421, 425, 996, 1016], "mathschi": 1053, "mathur": [1048, 1050, 1051, 1056, 1057, 1059], "mathurin": [0, 1052, 1054, 1055], "mathurinm": [1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "matjansen": 1055, "mato": 1053, "matplotlib": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 106, 107, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 195, 197, 199, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 250, 251, 252, 253, 255, 256, 257, 258, 260, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 277, 278, 280, 281, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 332, 333, 335, 338, 339, 340, 341, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 380, 386, 393, 404, 409, 446, 510, 639, 640, 705, 706, 708, 709, 710, 814, 831, 926, 995, 1019, 1028, 1029, 1030, 1031, 1032, 1033, 1038, 1050, 1053, 1054, 1055, 1056, 1059], "matric": [2, 37, 70, 74, 75, 113, 115, 125, 225, 264, 265, 267, 268, 269, 299, 312, 329, 335, 342, 360, 361, 378, 380, 388, 389, 398, 399, 400, 416, 417, 418, 419, 421, 424, 425, 431, 458, 459, 461, 472, 481, 489, 490, 491, 492, 534, 542, 543, 546, 548, 549, 552, 555, 557, 558, 563, 564, 571, 574, 589, 590, 597, 651, 654, 655, 660, 661, 666, 672, 680, 682, 695, 762, 768, 776, 782, 786, 787, 788, 789, 800, 805, 806, 838, 856, 859, 864, 875, 879, 881, 884, 887, 889, 890, 892, 895, 897, 899, 901, 902, 903, 904, 905, 914, 915, 917, 918, 928, 949, 955, 964, 971, 973, 974, 990, 992, 994, 997, 998, 999, 1001, 1003, 1004, 1012, 1014, 1015, 1019, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "matrix": [2, 8, 11, 42, 45, 46, 48, 52, 53, 57, 58, 59, 68, 70, 74, 76, 79, 89, 97, 104, 112, 113, 114, 115, 117, 125, 126, 127, 135, 183, 189, 195, 198, 206, 221, 225, 248, 251, 252, 268, 270, 272, 285, 316, 332, 335, 338, 339, 353, 360, 361, 362, 368, 373, 381, 382, 383, 386, 388, 392, 395, 398, 399, 400, 413, 417, 418, 419, 424, 425, 426, 427, 428, 438, 439, 446, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 460, 462, 465, 467, 468, 470, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 500, 504, 505, 508, 509, 510, 511, 512, 513, 516, 517, 518, 527, 529, 531, 532, 534, 535, 537, 539, 540, 541, 542, 543, 544, 545, 546, 548, 549, 552, 553, 554, 555, 556, 557, 558, 561, 562, 563, 564, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 593, 594, 596, 597, 598, 599, 601, 602, 611, 612, 613, 614, 615, 616, 617, 619, 628, 637, 638, 639, 641, 643, 646, 647, 648, 649, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 708, 709, 710, 711, 715, 720, 721, 722, 723, 724, 726, 730, 737, 738, 739, 742, 746, 747, 748, 749, 762, 763, 766, 767, 768, 769, 771, 772, 774, 775, 776, 778, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 791, 792, 795, 796, 800, 801, 804, 805, 806, 807, 808, 811, 812, 822, 830, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 851, 854, 855, 856, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 875, 876, 877, 878, 879, 881, 883, 884, 885, 887, 889, 890, 891, 892, 894, 895, 896, 897, 899, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 928, 930, 931, 932, 933, 938, 946, 947, 948, 949, 950, 953, 954, 955, 963, 964, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 986, 990, 992, 994, 996, 997, 1001, 1002, 1003, 1004, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1021, 1033, 1034, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "matrixorz": 1044, "matshow": [58, 59, 101, 147, 172, 316, 510], "matsubara": 1000, "matt": [104, 1044, 1045, 1046, 1051, 1052, 1056, 1057], "matteo": [1045, 1047, 1055], "matter": [134, 269, 353, 369, 416, 417, 423, 575, 676, 684, 686, 996, 1045], "matthew": [2, 385, 391, 544, 751, 1041, 1044, 1048, 1050, 1054, 1055], "matthews_corrcoef": [2, 1000, 1041, 1047, 1048, 1055], "matthia": [1041, 1043, 1044, 1047, 1048, 1049, 1053, 1056], "matthieu": [0, 406, 1041, 1045, 1056], "matti": [1042, 1045, 1046], "matur": [386, 1019, 1020], "mat\u00e9rn": 627, "mat\u00eda": 1055, "maud": 1044, "mauna": 181, "maura": 1052, "mauroantonioserrano": 1056, "mav": 1059, "mavani": 1049, "mavroforaki": [1045, 1047], "max": [43, 47, 49, 50, 51, 52, 55, 57, 62, 64, 67, 69, 75, 79, 87, 93, 97, 102, 106, 107, 110, 112, 115, 125, 128, 132, 135, 139, 141, 148, 154, 158, 165, 166, 167, 169, 170, 174, 178, 180, 181, 188, 189, 192, 202, 207, 208, 209, 213, 215, 222, 223, 226, 234, 236, 238, 243, 251, 255, 276, 277, 278, 289, 291, 298, 299, 301, 305, 306, 310, 312, 314, 316, 319, 321, 322, 324, 331, 336, 341, 343, 357, 373, 416, 418, 421, 477, 478, 479, 480, 481, 482, 483, 484, 485, 520, 544, 563, 564, 565, 566, 567, 568, 571, 572, 573, 614, 635, 639, 640, 656, 657, 677, 680, 682, 688, 699, 700, 704, 707, 712, 713, 765, 800, 801, 808, 869, 870, 881, 882, 884, 891, 898, 899, 920, 921, 922, 923, 996, 998, 1003, 1010, 1014, 1015, 1021, 1032, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "max_": [416, 1000], "max_abs_": 881, "max_abs_scal": 1010, "max_bin": [331, 332, 423, 569, 570, 1058], "max_categori": [325, 332, 334, 885, 886, 1010, 1055, 1057], "max_cluster_s": 454, "max_column": 238, "max_degre": [887, 1054], "max_depth": [46, 67, 140, 141, 144, 148, 149, 150, 151, 152, 153, 154, 158, 159, 161, 187, 241, 275, 290, 296, 330, 331, 364, 366, 367, 368, 399, 400, 415, 423, 561, 562, 565, 566, 567, 568, 569, 570, 572, 573, 574, 719, 811, 812, 836, 920, 921, 922, 923, 924, 925, 926, 989, 1007, 1016, 1050, 1052], "max_df": [54, 279, 342, 360, 361, 596, 599, 1052, 1059], "max_dist": 251, "max_doc_update_it": 544, "max_ep": [416, 458, 463, 464, 465], "max_error": [2, 1000, 1050], "max_estim": 143, "max_featur": [54, 67, 143, 154, 256, 275, 290, 330, 423, 425, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 596, 599, 605, 920, 921, 922, 923, 989, 996, 1041, 1043, 1044, 1048, 1049, 1052, 1055, 1058], "max_features_": [567, 568, 605, 920, 921, 922, 923, 1055], "max_fpr": [796, 1000, 1049], "max_fun": [869, 870, 1051], "max_i": [255, 1002], "max_idf": 1054, "max_it": [43, 47, 52, 54, 55, 62, 64, 66, 67, 106, 107, 125, 128, 144, 145, 149, 155, 162, 165, 166, 185, 187, 188, 192, 193, 199, 206, 212, 213, 227, 228, 229, 232, 233, 235, 240, 241, 242, 243, 245, 258, 259, 263, 264, 265, 266, 269, 291, 309, 314, 315, 316, 325, 330, 331, 332, 338, 339, 346, 360, 361, 392, 400, 423, 428, 448, 451, 455, 456, 457, 462, 467, 469, 479, 480, 486, 490, 491, 492, 539, 540, 541, 543, 544, 545, 546, 547, 548, 551, 553, 554, 555, 556, 569, 570, 635, 646, 648, 649, 650, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 677, 680, 682, 684, 685, 686, 687, 688, 690, 691, 695, 696, 697, 698, 700, 701, 702, 805, 806, 822, 861, 869, 870, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 990, 992, 996, 1003, 1004, 1013, 1014, 1030, 1034, 1042, 1045, 1048, 1049, 1050, 1051, 1053, 1055, 1056, 1057, 1058, 1059], "max_iter": 339, "max_iter_list": 155, "max_iter_predict": 618, "max_j": [654, 660], "max_leaf_nod": [139, 145, 154, 220, 331, 368, 423, 565, 566, 567, 568, 569, 570, 572, 573, 574, 920, 921, 922, 923, 1044, 1050, 1052], "max_n": [596, 597, 599, 1041], "max_n_alpha": [659, 663], "max_nbyt": 966, "max_no_improv": [77, 96, 99, 457, 545, 546, 547, 554, 1055, 1056], "max_patch": [85, 424, 591, 592, 1049], "max_resourc": [152, 811, 812, 989], "max_resources_": [811, 812], "max_sampl": [156, 187, 423, 563, 564, 565, 566, 571, 572, 573, 642, 1051, 1054, 1057], "max_samples_": 571, "max_skip": 679, "max_subpopul": [237, 687, 1055], "max_thread": [374, 387], "max_train_s": [43, 52, 420, 829, 1048], "max_trial": [679, 996], "max_val": 936, "max_valu": [635, 1052, 1053], "max_x": 255, "maxabs_scal": [2, 400, 881, 1049], "maxabsscal": [2, 375, 412, 876, 897, 990, 1010, 1046, 1049, 1050, 1051, 1052, 1057, 1058], "maxent": [2, 666, 667, 996], "maxent_du": 666, "maxi": 1056, "maxim": [117, 118, 121, 125, 135, 152, 199, 268, 269, 272, 279, 283, 287, 288, 292, 309, 324, 330, 349, 353, 364, 368, 383, 400, 413, 415, 416, 419, 421, 423, 425, 426, 557, 602, 618, 619, 652, 653, 656, 677, 687, 688, 728, 808, 811, 812, 822, 881, 887, 897, 994, 996, 999, 1000, 1003, 1005, 1015, 1029, 1032, 1044, 1046, 1051, 1054, 1056, 1059], "maxima": 416, "maximesaur": [1056, 1057], "maximis": [165, 264, 307, 994, 1003], "maximum": [2, 43, 47, 50, 64, 69, 72, 92, 111, 112, 113, 114, 115, 122, 127, 139, 141, 144, 145, 148, 155, 177, 179, 183, 189, 198, 208, 257, 272, 288, 301, 305, 306, 312, 319, 344, 345, 347, 348, 351, 353, 361, 364, 366, 367, 373, 381, 391, 392, 399, 400, 413, 414, 416, 418, 419, 421, 423, 424, 426, 427, 428, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 462, 465, 467, 469, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 490, 491, 492, 506, 517, 519, 520, 521, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 553, 554, 555, 556, 560, 561, 562, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 591, 592, 605, 618, 635, 639, 640, 643, 645, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 679, 680, 682, 684, 685, 686, 687, 690, 691, 693, 694, 695, 696, 697, 698, 700, 701, 702, 724, 752, 789, 805, 808, 811, 812, 814, 822, 829, 836, 861, 868, 869, 870, 876, 877, 881, 882, 884, 887, 888, 889, 891, 900, 901, 906, 907, 908, 909, 912, 913, 917, 920, 921, 922, 923, 924, 926, 929, 936, 989, 995, 996, 997, 999, 1000, 1002, 1003, 1004, 1006, 1010, 1014, 1015, 1016, 1021, 1033, 1048, 1049, 1051, 1052, 1055, 1056, 1058], "maxin": [1051, 1052], "maxsiz": 625, "maxval": [519, 521], "maxwel": [0, 376, 1051, 1054, 1055, 1056, 1057], "maxwelllzh": 1056, "may_share_memori": 1058, "mayb": [108, 316, 400, 424, 1015, 1020], "mayer": [423, 1053, 1055, 1058, 1059], "mayer2022": 423, "mayilvahanan": 416, "mayorov": [1044, 1045, 1046, 1047], "mayur": 1049, "mazari": 1049, "mb": [47, 251, 272, 360, 362, 381, 392, 504, 914, 915, 916, 917, 918, 1015, 1021, 1037], "mbilling": 1046, "mbillingr": 1051, "mbk": [77, 99], "mbk_means_cluster_cent": 99, "mbk_means_label": 99, "mbk_means_labels_uniqu": 77, "mblondel": [61, 83, 211, 241, 279, 360, 380, 516], "mbnmf": 54, "mc4229": 1052, "mc_clf": 1007, "mcar": 155, "mcc": [2, 751, 1000, 1055], "mccall": 104, "mccallum": [847, 1002], "mccarthi": [1041, 1049], "mcclish": [287, 796], "mcconaghi": 1024, "mccullagh": 996, "mcculloh": [1046, 1047], "mcd": [2, 51, 113, 114, 418, 477, 482], "mcdermott": [1043, 1058], "mcdonald": 51, "mcdowel": 1049, "mcfadden": 1000, "mcfee": [1046, 1047], "mcgibbon": [106, 1043, 1044, 1047], "mcgushion": 1050, "mcinn": [416, 1047, 1048, 1049, 1051, 1052, 1057], "mcivor": [1056, 1057], "mcm": [762, 1000], "mcm_": 762, "mcmahon": 1058, "mcsherri": [734, 764, 1000], "mctiernan": [1055, 1056], "mcve": [391, 398], "md": [2, 240, 241, 242, 243, 390, 696, 700, 702, 1035, 1036, 1041, 1053, 1056], "md5": 1053, "md5_checksum": 380, "md_scale": 240, "mdarii": 1057, "mdbecker": 1024, "mdi": [146, 153, 189, 190, 195, 423, 472, 504, 572, 638, 642, 838, 872, 886, 1008, 1021], "mdi_import": [194, 195], "mds_result": 702, "me": 360, "me1": 296, "me2": 296, "me3": 296, "mea": 93, "mean": [2, 43, 44, 45, 47, 50, 52, 53, 54, 57, 61, 62, 64, 70, 71, 72, 73, 75, 77, 79, 81, 84, 85, 88, 89, 90, 95, 105, 112, 113, 114, 115, 118, 121, 123, 125, 128, 129, 130, 131, 132, 139, 141, 142, 145, 148, 149, 152, 153, 155, 160, 161, 162, 173, 174, 176, 181, 183, 185, 187, 189, 192, 193, 200, 202, 209, 211, 213, 216, 217, 220, 222, 226, 227, 229, 235, 236, 237, 238, 243, 245, 247, 250, 251, 252, 253, 254, 255, 257, 258, 259, 261, 263, 264, 265, 266, 268, 269, 272, 274, 275, 278, 279, 280, 281, 283, 285, 286, 287, 288, 289, 290, 292, 293, 294, 296, 298, 299, 310, 319, 322, 324, 325, 326, 328, 331, 334, 336, 341, 349, 352, 353, 356, 358, 359, 360, 362, 369, 373, 378, 380, 381, 383, 384, 386, 387, 388, 390, 391, 392, 394, 395, 398, 399, 400, 407, 413, 414, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 433, 439, 445, 446, 447, 448, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 466, 467, 468, 469, 470, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 496, 509, 510, 512, 514, 520, 527, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 591, 596, 597, 598, 599, 602, 605, 610, 614, 615, 616, 617, 618, 619, 621, 630, 635, 636, 638, 640, 641, 642, 643, 647, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 687, 688, 689, 692, 696, 697, 698, 699, 700, 701, 702, 703, 712, 713, 715, 717, 720, 721, 724, 725, 732, 734, 737, 738, 739, 744, 745, 746, 749, 750, 753, 754, 755, 756, 757, 758, 759, 760, 761, 765, 782, 786, 787, 789, 791, 792, 793, 795, 796, 798, 799, 800, 801, 803, 805, 806, 807, 808, 811, 812, 814, 822, 826, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 858, 859, 860, 862, 863, 865, 866, 868, 869, 870, 871, 873, 874, 876, 877, 881, 882, 884, 888, 890, 892, 893, 898, 900, 901, 903, 905, 907, 908, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 928, 932, 933, 935, 974, 975, 981, 985, 989, 990, 991, 994, 996, 997, 999, 1002, 1003, 1004, 1005, 1007, 1008, 1013, 1014, 1015, 1016, 1019, 1021, 1024, 1029, 1032, 1034, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "mean_": [126, 282, 540, 541, 542, 547, 549, 551, 892, 1010, 1033, 1049], "mean_absolute_error": [2, 52, 220, 222, 238, 412, 1000, 1042, 1044, 1060], "mean_absolute_percentage_error": [2, 52, 149, 1000, 1053, 1055], "mean_auc": 288, "mean_change_tol": 544, "mean_fit_tim": [145, 301, 808, 822], "mean_fpr": 288, "mean_gamma_devi": [2, 1000, 1051], "mean_impute_scor": 188, "mean_l1_ratio": 1044, "mean_pinball_loss": [2, 52, 152, 155, 331, 996, 1000, 1054], "mean_pinball_loss_95p": 1000, "mean_poisson_devi": [2, 220, 1000, 1051], "mean_precis": 276, "mean_precision_": 805, "mean_precision_prior": [263, 269, 805], "mean_precision_prior_": 805, "mean_predict": [52, 183], "mean_predictions_gpr": 176, "mean_prior": 805, "mean_prior_": 805, "mean_recal": 276, "mean_scor": [106, 287, 290, 361, 1054], "mean_score_tim": [145, 276, 279, 808, 822], "mean_shift": [2, 1046, 1049], "mean_square_error": 1042, "mean_squared_error": [2, 46, 150, 152, 153, 216, 220, 222, 224, 226, 238, 369, 423, 760, 1000, 1042, 1044, 1051, 1052, 1058], "mean_squared_log_error": [2, 719, 1000, 1048, 1054, 1058], "mean_test_": 282, "mean_test_precis": [276, 282], "mean_test_recal": 276, "mean_test_scor": [105, 106, 107, 115, 145, 165, 173, 268, 277, 278, 279, 286, 289, 290, 301, 349, 480, 602, 808, 822, 989, 1047, 1054], "mean_tim": 1047, "mean_tpr": [287, 288], "mean_train_precis": [808, 822], "mean_train_scor": [808, 822, 1047], "mean_tweedie_devi": [2, 238, 412, 1000, 1051, 1060], "mean_variance_axi": [2, 395, 1047, 1054], "mean_y_pr": 181, "meaning": [72, 195, 245, 308, 336, 362, 413, 415, 420, 424, 425, 556, 737, 738, 746, 791, 792, 795, 861, 1004, 1014, 1015, 1041, 1057], "meaningfulli": [220, 1000], "meaningless": [193, 424, 914, 917, 1044], "means_": [70, 263, 264, 265, 266, 268, 269, 557, 558, 805, 806], "means_init": [265, 266, 806], "meanshift": [2, 79, 332, 416, 448, 1044, 1045, 1046, 1049, 1051, 1052, 1055, 1056, 1057, 1059], "meant": [92, 155, 174, 257, 336, 381, 388, 395, 482, 501, 685, 858, 966, 967, 990, 1004, 1006, 1010, 1042], "meanwhil": [398, 1015], "measur": [2, 27, 43, 46, 47, 49, 50, 52, 57, 62, 72, 73, 84, 93, 95, 96, 126, 142, 143, 152, 156, 163, 174, 176, 181, 189, 191, 192, 193, 197, 209, 214, 219, 220, 224, 226, 238, 270, 276, 278, 284, 285, 291, 324, 353, 360, 361, 373, 381, 383, 388, 392, 400, 413, 418, 420, 421, 422, 423, 424, 457, 460, 470, 506, 523, 546, 548, 555, 559, 565, 566, 567, 568, 571, 572, 573, 612, 615, 616, 619, 635, 639, 666, 698, 700, 706, 710, 712, 713, 715, 717, 720, 721, 724, 725, 728, 733, 734, 735, 737, 739, 744, 745, 747, 748, 751, 755, 763, 764, 765, 790, 791, 792, 794, 795, 796, 797, 800, 803, 833, 835, 838, 858, 889, 901, 920, 921, 922, 923, 990, 996, 998, 1003, 1005, 1006, 1008, 1014, 1016, 1021, 1029, 1032, 1041, 1044, 1046, 1047, 1049, 1051], "mechan": [74, 254, 357, 360, 374, 386, 388, 410, 414, 416, 424, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 602, 603, 604, 605, 606, 607, 608, 611, 618, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 998, 1016, 1024], "mecopur": 1058, "med": [57, 104, 287, 381, 1010, 1034], "meda": [109, 192, 1000], "media": [416, 1024], "median": [2, 43, 52, 72, 105, 109, 113, 114, 152, 187, 188, 192, 222, 226, 237, 249, 257, 319, 329, 331, 332, 381, 418, 423, 425, 448, 462, 466, 469, 482, 560, 562, 566, 573, 605, 635, 638, 643, 678, 679, 687, 729, 761, 859, 890, 902, 921, 923, 990, 1010, 1016, 1044, 1045], "median_absolute_error": [2, 109, 192, 1000, 1045, 1051, 1053], "median_predict": 52, "medic": [281, 420, 720, 996, 1024], "medicin": [281, 720, 1000], "medina": [1041, 1043], "medinc": [319, 330, 381, 498], "medium": [42, 189, 253, 294, 326, 349, 416, 651, 886, 993, 996], "medoid": 454, "medoids_": 454, "medri": 1044, "meekail": [0, 405, 1055, 1056, 1057, 1058], "meer": [98, 416, 456], "meet": [386, 398, 401, 425, 580, 611, 869, 870, 909, 1000, 1013, 1024, 1049, 1050, 1051], "megabyt": 1055, "megasari": 1053, "meghann": [1049, 1051], "mehak": 1048, "mehdi": [1045, 1054], "mehgarg": 1056, "mehmet": [1048, 1054], "mehmetcanakbai": 1056, "mehrdad": 1055, "mehta": [1045, 1046, 1047, 1049, 1050, 1051, 1052, 1056, 1057], "mehul": 1048, "mei": [1046, 1051], "meier": 1048, "meila": 416, "mein": 424, "meinshausen": 204, "meirel": 1052, "meketon": 1048, "melani": [1024, 1048, 1049], "melderi": 1049, "melemo2": 1055, "meli": [1054, 1055, 1056], "melissa": 1049, "mellon": 907, "melnik": 1056, "melsyt": [1049, 1050], "mem": [89, 392, 516, 517, 1021], "member": [0, 360, 361, 381, 386, 389, 401, 416, 431, 450, 454, 456, 459, 461, 500, 563, 564, 565, 566, 571, 572, 573, 574, 589, 666, 667, 674, 675, 676, 684, 685, 686, 712, 713, 723, 725, 739, 744, 745, 765, 794, 803, 808, 912, 996, 1003, 1025, 1041, 1053, 1056], "membership": [30, 91, 401, 413, 416, 519, 520, 521, 522, 523, 527, 530, 1015], "memit": 392, "memmap": [374, 381, 400, 421, 516, 542, 1049, 1058], "memoiz": [106, 381, 400], "memor": 194, "memori": [2, 47, 89, 105, 106, 129, 192, 193, 272, 301, 325, 328, 330, 332, 333, 336, 360, 361, 362, 374, 375, 380, 386, 389, 395, 398, 400, 410, 416, 417, 420, 421, 424, 427, 428, 449, 450, 451, 452, 453, 454, 455, 457, 458, 462, 465, 467, 476, 481, 487, 504, 511, 516, 517, 541, 542, 543, 546, 549, 563, 564, 565, 566, 571, 572, 573, 574, 589, 590, 596, 597, 599, 654, 655, 656, 660, 661, 666, 667, 668, 669, 670, 671, 674, 675, 676, 677, 684, 685, 686, 687, 688, 689, 692, 786, 787, 788, 789, 808, 814, 822, 831, 833, 834, 835, 836, 839, 840, 841, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 872, 873, 890, 892, 902, 903, 905, 910, 912, 913, 920, 921, 922, 923, 933, 969, 985, 996, 1002, 1003, 1010, 1012, 1013, 1015, 1016, 1020, 1024, 1025, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "memory_profil": [392, 404, 409], "memoryerror": [1049, 1053], "memoryview": 387, "memorywis": 410, "men": 383, "menes": 1056, "meng": [1041, 1042, 1045, 1047, 1048], "menoci": 1059, "menon": 414, "mensch": [235, 236, 1046, 1047, 1048, 1049], "mention": [90, 118, 139, 238, 292, 329, 369, 373, 386, 390, 391, 398, 416, 704, 904, 905, 989, 994, 996, 1020, 1023, 1024, 1034, 1048, 1049, 1050], "menu": 404, "menuet": 1050, "mercer": 992, "mere": [43, 278, 400, 839, 1014], "merg": [74, 76, 81, 86, 331, 384, 386, 389, 394, 398, 401, 416, 448, 449, 450, 453, 454, 471, 828, 1033, 1041, 1048], "merit": [386, 390, 401], "meritocrat": 401, "merritt": 1047, "mersenn": 1052, "merz": 414, "mesfer": 1054, "mesh": [93, 148, 158, 178, 252, 307, 314, 321, 343, 345], "meshgrid": [50, 63, 77, 93, 113, 148, 158, 177, 178, 179, 180, 182, 193, 231, 232, 233, 234, 245, 247, 267, 305, 312, 314, 321, 322, 343, 348, 349, 353, 354, 357, 358, 639], "meshulam": 1044, "meson": [384, 389, 404, 409], "mess": 1055, "messag": [73, 79, 97, 104, 125, 254, 360, 361, 381, 384, 385, 386, 390, 391, 394, 395, 416, 448, 462, 476, 547, 551, 556, 582, 635, 720, 808, 811, 812, 814, 822, 831, 836, 839, 841, 861, 869, 870, 910, 931, 932, 933, 936, 939, 963, 984, 1000, 1010, 1041, 1045, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "met": [147, 254, 388, 425, 542, 549, 635, 679, 996, 1000, 1049], "meta": [2, 7, 30, 31, 91, 104, 138, 163, 189, 220, 283, 287, 292, 295, 298, 334, 335, 367, 369, 380, 384, 388, 390, 398, 400, 407, 412, 414, 425, 426, 436, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 504, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 583, 589, 590, 596, 598, 599, 602, 605, 611, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 807, 808, 809, 810, 815, 817, 824, 826, 830, 835, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 960, 989, 1001, 1020, 1021, 1022, 1036, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1055, 1056, 1058], "meta_clf_sample_weight": 254, "meta_est": 254, "meta_meta_est": 254, "metaclassifi": [254, 255], "metaclassifierifittedmetaclassifi": 254, "metadata": [2, 47, 91, 137, 184, 189, 201, 246, 272, 336, 361, 380, 381, 410, 430, 433, 436, 439, 440, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 496, 497, 504, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 833, 834, 835, 836, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 956, 957, 958, 959, 960, 984, 1000, 1019, 1020, 1021, 1025, 1036, 1057], "metadata_rout": [2, 254, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 598, 599, 602, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 807, 809, 810, 815, 817, 826, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 956, 957, 958, 959, 960], "metadatarequest": [2, 254, 430, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 477, 478, 479, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 565, 566, 567, 568, 569, 570, 572, 573, 574, 589, 590, 591, 596, 597, 598, 599, 600, 603, 604, 606, 607, 608, 611, 618, 619, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 656, 657, 658, 660, 662, 664, 665, 666, 668, 670, 672, 674, 675, 676, 677, 678, 680, 682, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 809, 810, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 957, 959, 1058], "metadatarout": [2, 254, 445, 472, 480, 563, 564, 571, 575, 576, 577, 578, 605, 635, 655, 659, 661, 663, 667, 669, 671, 673, 679, 681, 683, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 871, 872, 959, 1058], "metaestim": [2, 91, 388, 400, 909, 961, 1045, 1054, 1055, 1058], "metaestimatormixin": [2, 254], "metaireau": [1041, 1044], "metal": 412, "metaregressor": 254, "metatransfom": 1046, "meteorologi": 414, "meth_nam": 323, "method": [2, 5, 8, 14, 18, 30, 32, 36, 43, 47, 51, 52, 55, 57, 58, 61, 62, 63, 64, 71, 72, 74, 75, 76, 79, 82, 84, 85, 87, 88, 89, 91, 92, 93, 94, 96, 100, 103, 106, 112, 113, 116, 118, 123, 125, 128, 130, 133, 134, 135, 137, 139, 144, 146, 147, 153, 160, 169, 170, 174, 187, 197, 207, 209, 221, 228, 237, 239, 241, 243, 244, 245, 247, 251, 253, 254, 255, 257, 261, 262, 265, 272, 280, 283, 285, 286, 287, 292, 296, 299, 305, 306, 308, 319, 323, 326, 328, 330, 331, 352, 360, 361, 362, 368, 369, 373, 374, 375, 378, 383, 384, 386, 387, 388, 392, 393, 395, 398, 399, 403, 407, 410, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 430, 431, 433, 434, 435, 438, 439, 440, 441, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 464, 465, 467, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 512, 520, 522, 530, 533, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 615, 616, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 692, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 707, 713, 718, 719, 730, 739, 740, 743, 744, 749, 750, 771, 776, 777, 782, 786, 791, 796, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 822, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 900, 901, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 927, 935, 939, 949, 956, 957, 958, 959, 960, 961, 966, 969, 984, 985, 988, 989, 990, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1017, 1019, 1021, 1024, 1025, 1029, 1031, 1032, 1034, 1035, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "method_map": [254, 957], "method_max_it": [553, 554, 1051], "method_nam": [254, 957, 960], "methodmap": [2, 254, 957], "methodmetadatarequest": 956, "methodol": 1010, "methodolog": [420, 1023], "methodologi": [549, 885, 990, 1000, 1024], "methodpair": 958, "metric": [2, 13, 43, 45, 46, 50, 52, 57, 58, 59, 61, 62, 63, 66, 68, 71, 73, 77, 79, 82, 83, 84, 87, 93, 95, 99, 104, 109, 115, 139, 144, 150, 151, 153, 154, 155, 160, 171, 174, 177, 187, 189, 191, 192, 194, 204, 209, 215, 216, 220, 222, 224, 226, 238, 243, 248, 251, 252, 257, 260, 270, 271, 274, 275, 276, 278, 279, 281, 285, 287, 288, 292, 298, 299, 301, 309, 312, 317, 319, 324, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 341, 342, 360, 361, 369, 373, 378, 381, 386, 388, 398, 399, 400, 403, 407, 411, 414, 415, 421, 422, 423, 426, 427, 433, 445, 449, 452, 453, 454, 458, 462, 463, 464, 465, 470, 477, 528, 543, 557, 558, 559, 561, 563, 565, 566, 567, 569, 570, 572, 573, 575, 577, 586, 610, 618, 628, 636, 639, 642, 646, 647, 648, 649, 650, 651, 666, 667, 671, 674, 676, 682, 683, 684, 696, 698, 700, 702, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 807, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 837, 840, 841, 842, 843, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 869, 878, 884, 907, 908, 912, 914, 917, 920, 922, 990, 992, 995, 997, 1001, 1003, 1006, 1008, 1019, 1020, 1021, 1029, 1030, 1034, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048], "metric_kwarg": [787, 788], "metric_obj": 707, "metric_param": [427, 452, 454, 458, 463, 464, 465, 696, 700, 854, 855, 856, 857, 858, 860, 862, 863, 864, 865, 866, 1045, 1048, 1055], "metsi": [847, 1002], "metzen": [0, 61, 62, 63, 64, 176, 177, 179, 180, 181, 182, 183, 185, 253, 405, 1041, 1044, 1045, 1046, 1047], "mexican": 134, "meyer89": 1052, "mferrari3": [1049, 1050], "mgrid": [53, 167], "mhg": 1046, "mi": [64, 72, 169, 416, 615, 616, 712, 763, 765, 990, 1000, 1014], "mia": 1056, "miao": 1054, "mib": [373, 476, 910], "mic": [893, 1010], "micah": 1051, "micci": [893, 1010], "mice": [380, 635, 990], "miceprotein": 380, "michael": [383, 414, 416, 458, 636, 645, 699, 805, 990, 996, 1024, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1055, 1056, 1058, 1059], "michal": [1045, 1048, 1054, 1055], "michali": 416, "michalkrawczyk": [1054, 1055], "micha\u0142": 1052, "micha\u0142owski": 1050, "michel": [0, 82, 102, 406, 1041, 1043, 1044, 1046, 1048, 1055, 1056], "michelbach": 1045, "michiaki": 1047, "micka\u00ebl": [1049, 1050], "micky774": [1055, 1056], "micro": [49, 312, 342, 373, 715, 721, 737, 738, 746, 791, 792, 795, 796, 1000, 1041, 1049, 1050, 1056, 1059], "micro_roc_auc_ovr": 287, "microarrai": [413, 459, 521, 636, 990], "microcontrol": 1019, "microml": 1019, "micromlgen": 1019, "microphon": 126, "microryzomi": [50, 312, 381, 506], "microryzomys_minutu": 506, "microryzomys_minutus_0": 50, "microsoft": [0, 51, 384, 387, 404], "mid": [63, 349, 1000, 1002], "middl": [43, 61, 70, 95, 130, 204, 357, 383, 1007, 1010], "mideast": [57, 381], "midina": 1048, "midnight": 43, "midpoint": 349, "midpointnorm": 349, "midvidi": 1054, "midwest": [174, 383], "might": [0, 43, 44, 52, 67, 77, 79, 95, 97, 104, 148, 155, 158, 171, 182, 188, 192, 193, 194, 197, 220, 238, 247, 272, 278, 280, 292, 302, 315, 330, 336, 353, 358, 369, 373, 374, 380, 384, 386, 387, 388, 390, 391, 392, 394, 398, 400, 401, 404, 410, 414, 415, 417, 420, 421, 422, 423, 424, 426, 441, 451, 496, 504, 509, 511, 516, 523, 531, 544, 563, 564, 565, 569, 570, 572, 587, 588, 590, 618, 619, 635, 658, 662, 663, 664, 666, 667, 684, 686, 700, 765, 802, 811, 812, 836, 861, 877, 892, 905, 924, 926, 928, 932, 933, 949, 969, 989, 990, 992, 994, 996, 997, 999, 1000, 1002, 1003, 1007, 1008, 1010, 1015, 1016, 1034, 1042, 1044, 1049, 1050, 1052, 1055, 1056, 1057, 1058], "mignon": [1041, 1044, 1045, 1048], "migrat": [386, 1041], "miguel": [1051, 1059], "miguelbarao": 1051, "miguelcsilva": 1059, "mihael": [416, 458, 465], "mihevc": 1051, "mike": 1048, "mikebenfield": 1048, "miketip": [542, 549], "mikhail": [1042, 1043, 1044, 1047, 1048, 1056, 1057], "miki": [1058, 1059], "mikulski": 1052, "milajev": 1045, "milan": 1053, "milana2": 1055, "mileag": 373, "milen": 1048, "mileston": 390, "militari": 104, "mill": 1051, "millawel": 1055, "miller": [381, 1049, 1050, 1054], "million": [77, 91, 181, 197, 424, 700, 997, 1015, 1024, 1055, 1056], "millman": [0, 406, 1050, 1057, 1058], "milman": 1049, "miln": 381, "miltenberg": 1056, "milton": 1058, "milutinov": 1050, "mimic": [187, 220, 360, 826], "mimicri": 360, "min": [43, 49, 50, 51, 52, 53, 62, 64, 67, 87, 93, 109, 125, 128, 139, 141, 148, 151, 152, 158, 167, 174, 178, 180, 181, 182, 188, 192, 202, 208, 209, 215, 222, 223, 226, 241, 251, 252, 255, 298, 305, 306, 312, 314, 316, 319, 321, 322, 324, 336, 343, 357, 395, 416, 419, 421, 490, 491, 493, 520, 542, 543, 546, 548, 549, 557, 558, 571, 635, 639, 640, 662, 663, 664, 665, 690, 691, 712, 765, 788, 811, 812, 861, 869, 870, 882, 891, 898, 949, 965, 991, 996, 1000, 1003, 1010, 1047, 1050, 1052, 1053, 1056], "min_": [331, 416, 423, 882, 996, 1010, 1014, 1015, 1016], "min_arg": 52, "min_batch_s": 952, "min_bin_freq": [456, 469], "min_c": 1002, "min_categori": [848, 1053], "min_cluster_s": [79, 100, 334, 416, 454, 458, 464, 1050], "min_degre": [887, 1054], "min_df": [54, 57, 104, 279, 342, 360, 361, 424, 596, 599, 1041, 1043, 1052, 1059], "min_dist": 251, "min_estim": 143, "min_faces_per_person": [45, 381, 502, 1030], "min_features_to_select": [173, 602, 1049], "min_frequ": [332, 334, 885, 886, 1010, 1055, 1057], "min_grad_norm": [700, 1047], "min_i": 255, "min_idf": 1054, "min_impurity_decreas": [565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923, 1016, 1048], "min_impurity_split": 1048, "min_max_axi": 1050, "min_max_scal": 1010, "min_n": [596, 597, 599, 1041], "min_n_compon": 251, "min_po": [2, 395], "min_resourc": [152, 811, 812], "min_resources_": [811, 812], "min_sampl": [79, 84, 100, 398, 400, 416, 427, 452, 454, 458, 463, 464, 465, 679, 996, 1050, 1054], "min_sample_split": 1056, "min_samples_leaf": [145, 151, 152, 194, 328, 331, 364, 423, 565, 566, 567, 568, 569, 570, 572, 573, 574, 920, 921, 922, 923, 1016, 1047], "min_samples_split": [152, 153, 154, 282, 290, 320, 330, 423, 565, 566, 567, 568, 572, 573, 574, 811, 812, 920, 921, 922, 923, 989, 1016, 1047], "min_val": [929, 936], "min_valu": [635, 1052, 1053], "min_w": 996, "min_weight_fraction_leaf": [565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923, 1016, 1044, 1047, 1048], "min_x": 255, "mina": [1051, 1052], "mincovdet": [2, 113, 114, 418, 477, 478, 481, 483, 484, 1006, 1041, 1048], "mind": [130, 155, 191, 192, 193, 238, 323, 324, 360, 361, 369, 386, 410, 418, 420, 423, 654, 655, 712, 996, 1015, 1019, 1025, 1032], "minden": [416, 460, 470], "mine": [0, 278, 361, 381, 416, 427, 452, 519, 571, 728, 742, 748, 791, 996, 1000, 1006, 1012], "ming": [571, 1006, 1045, 1049, 1050, 1051, 1055], "minghui": [1048, 1049], "mingw": 1044, "minh": 1049, "mini": [2, 47, 99, 125, 332, 375, 400, 424, 448, 450, 455, 457, 459, 461, 539, 541, 544, 545, 546, 547, 548, 550, 551, 553, 554, 1004, 1005, 1041, 1052, 1054], "mini_batch": [459, 461], "minibatch": [47, 79, 416, 421, 457, 542, 684, 868, 869, 870, 1019, 1041], "minibatch_iter": 47, "minibatch_kmean": 361, "minibatch_s": [47, 375], "minibatchdictionarylearn": [2, 125, 128, 375, 421, 539, 546, 550, 553, 554, 1042, 1044, 1051, 1052, 1054, 1055, 1056, 1057, 1058], "minibatchkmean": [2, 57, 71, 73, 78, 79, 85, 93, 94, 96, 98, 122, 189, 361, 375, 416, 421, 448, 450, 455, 520, 787, 1021, 1042, 1047, 1048, 1049, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "minibatchnmf": [2, 54, 375, 421, 1055, 1057, 1058, 1059], "minibatchsparsepca": [2, 539, 541, 545, 548, 550, 551, 553, 554, 1041, 1042, 1052, 1054, 1055, 1056, 1057, 1058], "miniconda": 404, "miniforg": [384, 394, 404], "miniforge3": [384, 394], "minim": [2, 43, 51, 52, 64, 92, 101, 111, 112, 152, 176, 184, 199, 216, 218, 220, 222, 224, 228, 238, 240, 250, 251, 263, 268, 272, 279, 287, 288, 319, 328, 331, 346, 353, 356, 364, 385, 386, 389, 394, 398, 400, 410, 414, 416, 418, 421, 423, 448, 449, 453, 454, 458, 471, 546, 548, 555, 565, 566, 567, 568, 572, 573, 617, 618, 619, 649, 654, 657, 665, 666, 675, 679, 680, 682, 686, 687, 695, 700, 702, 703, 756, 788, 859, 861, 870, 888, 900, 906, 920, 921, 922, 923, 996, 997, 1000, 1003, 1004, 1010, 1012, 1013, 1014, 1015, 1019, 1022, 1032, 1033, 1036, 1045, 1050, 1051], "minima": [182, 208, 421, 455, 700, 997, 1033, 1049], "minimal_reproduc": 394, "minimalist": [391, 424, 1023], "minimis": [52, 277, 416, 420, 666, 667, 1016], "minimum": [2, 48, 90, 92, 113, 152, 153, 155, 173, 209, 230, 251, 257, 288, 305, 306, 388, 395, 404, 409, 413, 416, 423, 424, 449, 453, 454, 458, 462, 464, 477, 478, 481, 482, 483, 484, 519, 521, 549, 560, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 602, 635, 639, 640, 643, 645, 676, 679, 684, 686, 687, 690, 691, 700, 713, 733, 787, 788, 811, 812, 833, 848, 869, 870, 881, 882, 885, 886, 887, 891, 905, 906, 919, 920, 921, 922, 923, 929, 932, 933, 936, 952, 997, 1000, 1004, 1006, 1010, 1012, 1016, 1041, 1044, 1048, 1049, 1053, 1054, 1058], "minimum_cluster_s": 416, "minka": [132, 549, 996], "minknowski": 1054, "minkowski": [427, 452, 458, 463, 464, 465, 696, 707, 786, 787, 788, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 1003, 1041, 1044, 1055, 1056, 1057], "minkowski_dist": [458, 465, 696, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866], "minkowskidist": [707, 1054], "minmax_scal": [2, 317, 319, 882, 1046, 1049], "minmaxscal": [2, 43, 44, 106, 170, 172, 197, 241, 257, 315, 330, 375, 412, 417, 472, 898, 990, 1010, 1043, 1046, 1049, 1051, 1052, 1053, 1057, 1058], "minmaxscalerminmaxscal": 106, "minnesota": 416, "minor": [257, 272, 281, 285, 381, 389, 401, 504, 1000, 1041, 1043, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "minu": [278, 768, 1000], "minut": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 381, 386, 997, 1018], "minutu": [50, 312, 381, 506], "minval": [519, 521], "minwoo": 1041, "minyushkin": 1047, "miola": 1056, "miott": [1041, 1044], "miotto": 1052, "mir": 424, "miroslav": [1042, 1043, 1046], "mirror": [849, 989], "mirza": 1054, "misa": 1056, "misc": [57, 88, 128, 279, 342, 360, 361, 362, 381, 1033], "misc_featur": 257, "miscalibr": 64, "miscellan": [379, 380, 1021, 1047, 1048, 1055, 1056, 1058, 1059, 1060], "miscfeatur": 160, "misclassif": [46, 139, 272, 353, 804, 1014, 1015, 1016, 1042], "misclassifi": [70, 139, 271, 272, 353, 360, 1015], "misclassification_error": 139, "misdetect": 1058, "mise": 1019, "mish": 424, "mishra": [1053, 1054], "mislabel": [271, 423, 1002], "mislead": [72, 146, 147, 153, 192, 387, 403, 423, 561, 562, 565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923, 1036, 1054], "mismatch": [79, 999, 1050], "misread": 245, "miss": [2, 20, 105, 160, 174, 194, 249, 259, 272, 278, 299, 329, 333, 336, 369, 373, 378, 381, 383, 385, 386, 388, 390, 391, 400, 412, 415, 416, 417, 418, 454, 480, 498, 504, 506, 509, 565, 566, 569, 570, 572, 573, 574, 635, 636, 637, 638, 647, 653, 680, 698, 702, 735, 777, 834, 855, 873, 881, 882, 886, 888, 889, 892, 893, 897, 900, 901, 903, 920, 921, 922, 923, 996, 997, 1000, 1019, 1020, 1021, 1022, 1024, 1036, 1043, 1045, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "missclassif": 139, "missforest": [187, 990], "missing": [155, 423, 635, 636, 638, 1050], "missing_featur": [187, 188], "missing_fract": 155, "missing_fraction_list": 155, "missing_r": 188, "missing_sampl": [187, 188], "missing_valu": [187, 188, 259, 400, 635, 636, 637, 638, 777, 990, 1049, 1050], "missingind": [2, 635, 636, 638, 990, 1049, 1050, 1051, 1055, 1057], "mission": [0, 361, 1024], "misspecifi": 64, "misspel": 424, "mistak": [139, 171, 292, 339, 369, 416, 420, 743, 883, 897, 898, 900, 901, 902, 903, 996, 1001], "misti": [43, 193], "mit": [296, 381, 392, 416, 426, 618, 619, 622, 627, 630, 651, 674, 675, 684, 849, 993], "mitar": 1050, "mitig": [64, 90, 155, 194, 326, 374, 375, 997, 1016, 1032, 1033, 1053], "mitra": [1051, 1052, 1056], "mitrov": 1050, "mitzi": [1054, 1055], "miwojc": 1055, "mix": [2, 43, 97, 103, 104, 126, 127, 149, 189, 192, 220, 249, 259, 261, 279, 319, 325, 380, 388, 398, 400, 417, 421, 428, 472, 474, 475, 504, 541, 546, 548, 555, 608, 612, 638, 654, 655, 660, 666, 667, 668, 669, 670, 671, 676, 684, 686, 689, 808, 822, 838, 872, 885, 886, 892, 893, 964, 971, 974, 996, 1005, 1021, 1033, 1053, 1055, 1056], "mixed_encoded_preprocessor": 325, "mixed_pip": 325, "mixed_target": 325, "mixin": [2, 386, 400, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 609, 943, 1043, 1052, 1056], "mixing_": [126, 127, 541, 1033], "mixtur": [2, 46, 48, 70, 79, 90, 92, 100, 123, 188, 208, 265, 266, 289, 309, 312, 335, 381, 382, 400, 416, 421, 422, 426, 631, 805, 806, 808, 1019, 1020, 1021, 1035, 1036, 1041, 1045, 1046, 1047, 1048], "mizil": [62, 64, 414, 445, 447], "mizuki": 1055, "mk": 1016, "mkdir": [47, 392, 394], "mkdtemp": [89, 417], "mkl": [373, 374, 384, 398, 1041], "mkl_num_thread": 374, "mks542": 202, "mksol": 104, "ml": [47, 174, 296, 380, 383, 391, 508, 510, 518, 996, 998, 1019, 1020, 1024], "ml_map": 1027, "mlant": 1055, "mlb": [381, 883], "mlc": 383, "mlcomp": 1041, "mld": 47, "mldata": [1041, 1049], "mle": [113, 132, 549, 1049, 1052], "mlewis1729": 1048, "mlflow": 1019, "mlg": 1045, "mlinari\u0107": 1056, "mline": [48, 113, 234, 305, 348, 351], "mlle": [697, 701, 997], "mlliou112": 1048, "mlo": 181, "mlondschien": 1054, "mlop": 1019, "mlp": [189, 193, 258, 313, 315, 504, 838, 869, 870, 1004, 1021], "mlp_disp": 258, "mlp_model": 193, "mlp_preprocessor": 193, "mlpclassifi": [2, 67, 154, 166, 189, 313, 314, 316, 375, 510, 512, 522, 530, 868, 870, 882, 1001, 1004, 1021, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "mlpregressor": [2, 43, 193, 258, 375, 868, 869, 1004, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "mlpregressormlpregressor": 258, "mlxtend": 1019, "mm": 197, "mm_bunch": 50, "mmap_mod": [410, 966], "mmm": 51, "mmse": [112, 418, 429, 483], "mn193": 1058, "mnb": 1002, "mnist": [66, 189, 198, 211, 228, 235, 299, 313, 315, 504, 666, 838, 869, 892, 935, 996, 1004, 1021], "mnist_10000": 299, "mnist_20000": 299, "mnist_784": [228, 236, 299, 316], "mo": [333, 1052], "mobil": 394, "mock": 1051, "mockdatafram": 1051, "modal": [2, 247, 482, 951], "mode": [2, 48, 49, 81, 82, 113, 220, 247, 299, 301, 317, 328, 384, 386, 394, 395, 398, 413, 419, 423, 427, 451, 452, 455, 457, 460, 467, 470, 479, 480, 486, 490, 495, 516, 517, 565, 569, 572, 600, 603, 604, 606, 607, 608, 618, 635, 652, 653, 666, 667, 674, 676, 681, 682, 683, 684, 687, 690, 691, 697, 701, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 868, 912, 914, 917, 920, 922, 938, 948, 949, 951, 1003, 1006, 1019, 1025, 1026, 1033, 1042, 1050, 1055, 1058], "model": [2, 7, 8, 21, 28, 34, 37, 40, 42, 44, 45, 48, 49, 51, 53, 54, 58, 59, 61, 62, 64, 70, 74, 75, 76, 83, 84, 89, 90, 91, 93, 96, 103, 105, 106, 107, 111, 115, 118, 124, 125, 134, 135, 138, 139, 140, 142, 144, 148, 151, 152, 154, 155, 157, 159, 160, 163, 165, 167, 168, 170, 171, 179, 180, 182, 183, 184, 185, 188, 190, 191, 195, 200, 202, 205, 206, 210, 211, 213, 215, 216, 217, 221, 222, 224, 225, 226, 228, 232, 233, 235, 236, 237, 247, 250, 255, 263, 265, 266, 267, 271, 273, 274, 276, 279, 281, 282, 283, 284, 286, 287, 291, 292, 293, 296, 299, 301, 302, 303, 305, 308, 312, 320, 323, 325, 326, 328, 330, 332, 333, 334, 336, 338, 339, 346, 348, 349, 350, 351, 352, 354, 356, 358, 361, 362, 365, 366, 367, 369, 378, 380, 381, 389, 392, 400, 403, 407, 412, 413, 414, 415, 416, 417, 419, 421, 422, 423, 424, 425, 426, 435, 439, 441, 445, 450, 457, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 496, 497, 498, 504, 506, 508, 509, 510, 511, 517, 530, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 556, 557, 558, 559, 560, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 596, 597, 601, 602, 605, 610, 614, 617, 618, 619, 623, 635, 640, 641, 642, 643, 645, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 699, 709, 714, 719, 729, 730, 731, 732, 742, 743, 749, 758, 761, 793, 796, 797, 800, 805, 806, 807, 808, 811, 812, 813, 814, 822, 823, 824, 825, 829, 830, 831, 834, 835, 836, 837, 838, 839, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 855, 857, 858, 859, 861, 863, 868, 869, 870, 872, 873, 875, 877, 879, 884, 885, 887, 888, 889, 891, 892, 893, 897, 898, 900, 901, 902, 903, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 927, 984, 990, 992, 993, 994, 997, 998, 1001, 1003, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1021, 1022, 1024, 1026, 1028, 1030, 1034, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1060], "model_1": 278, "model_1_scor": 278, "model_2": 278, "model_2_scor": 278, "model__estimator__max_depth": 989, "model_coef": 191, "model_color": 355, "model_detail": 148, "model_displai": 144, "model_fixed_threshold": 272, "model_from_prevision_vers": 410, "model_i": 278, "model_i_scor": 278, "model_idx": 257, "model_k": 278, "model_k_scor": 278, "model_l1": 356, "model_l2": 356, "model_nam": [145, 257, 298], "model_no_cf": 326, "model_param": 235, "model_prop": 43, "model_scor": [278, 298], "model_select": [2, 43, 44, 45, 46, 49, 52, 61, 62, 64, 67, 68, 89, 105, 106, 107, 108, 109, 111, 118, 130, 132, 139, 144, 145, 146, 149, 150, 151, 152, 153, 154, 155, 156, 159, 160, 165, 170, 171, 173, 176, 187, 188, 189, 191, 192, 194, 195, 197, 204, 215, 220, 222, 227, 228, 235, 236, 238, 248, 253, 254, 257, 259, 260, 261, 265, 268, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 301, 302, 303, 307, 308, 314, 316, 317, 321, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 336, 341, 342, 349, 352, 356, 364, 368, 369, 386, 388, 391, 399, 400, 407, 412, 415, 417, 420, 423, 445, 446, 566, 568, 575, 576, 587, 667, 705, 706, 708, 710, 750, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 843, 861, 869, 870, 872, 920, 921, 922, 923, 989, 990, 995, 1000, 1002, 1003, 1008, 1010, 1015, 1020, 1021, 1029, 1030, 1034, 1038, 1045, 1047, 1048], "model_step": 43, "model_titl": 148, "model_with_cf": 326, "moder": [278, 386, 426, 462, 1006], "modern": [43, 155, 424, 476, 511, 598, 698, 702, 738, 910, 997, 1019, 1020, 1057], "modif": [386, 419, 423, 424, 454, 1013, 1058, 1059], "modifi": [67, 80, 86, 107, 109, 120, 121, 203, 204, 217, 218, 230, 240, 241, 242, 254, 257, 265, 334, 354, 358, 386, 388, 390, 400, 416, 423, 426, 451, 455, 462, 467, 476, 490, 491, 492, 493, 503, 518, 589, 618, 619, 621, 627, 684, 686, 697, 701, 737, 738, 776, 791, 792, 795, 930, 982, 983, 996, 1013, 1014, 1020, 1031, 1035, 1036, 1041, 1043, 1044, 1047, 1048, 1050, 1051, 1052, 1053, 1054, 1056], "modified_fil": 386, "modified_hub": [46, 684, 1014], "modified_huber_loss": 230, "modified_tol": [697, 701], "modrak": [1056, 1057], "modroiu": 1000, "modul": [7, 11, 16, 30, 31, 71, 72, 84, 88, 110, 116, 119, 124, 125, 138, 168, 175, 185, 186, 189, 190, 196, 198, 235, 239, 240, 262, 270, 295, 296, 297, 300, 313, 315, 316, 318, 337, 344, 359, 363, 366, 380, 381, 384, 385, 386, 387, 388, 390, 391, 392, 394, 395, 398, 400, 403, 404, 410, 414, 416, 419, 423, 424, 425, 427, 452, 511, 543, 587, 588, 667, 941, 989, 994, 996, 998, 1000, 1001, 1004, 1006, 1007, 1010, 1012, 1014, 1016, 1017, 1024, 1028, 1029, 1034, 1042, 1043, 1044, 1046, 1047, 1051, 1055], "modulo": [424, 1052], "moeller": 1047, "mogavero": 1051, "moham": [1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059], "mohamedbsh": 1056, "mohammad": [1049, 1050], "mohit": [1055, 1058], "mohn": [1049, 1053], "mohr": 1047, "moin": 1053, "mois\u00e9": 1012, "moitra": [1041, 1042, 1043], "mojca": 1052, "mojdeh": 1058, "mola": [1052, 1058], "molden": 1043, "molecul": 997, "molin": 1056, "molla": [1042, 1043], "molnar": [193, 1007], "moment": [373, 421, 426, 448, 623, 631, 869, 870, 964, 1004, 1005], "momentum": [315, 869, 870, 1004], "mon": [43, 155, 193], "mona": [175, 183, 189, 426, 504, 619, 623, 630, 631, 633, 1021], "monaf": 1056, "monei": [0, 238, 1024], "monitor": [150, 204, 228, 389, 400, 561, 562, 567, 568, 569, 570, 1004, 1023, 1044, 1049, 1051, 1053], "mono": [654, 655, 660, 661, 668, 669, 670, 671, 689, 692], "monografia": 996, "monomi": 221, "monotoinc": 329, "monoton": [2, 22, 43, 62, 138, 189, 193, 238, 250, 258, 329, 414, 565, 566, 569, 570, 572, 573, 640, 643, 644, 702, 714, 888, 900, 914, 917, 920, 921, 922, 923, 997, 1001, 1010, 1015, 1021, 1048, 1052, 1056, 1058], "monotonic_cst": [155, 157, 329, 331, 335, 423, 565, 566, 569, 570, 572, 573, 920, 921, 922, 923, 1056, 1059], "mont": [252, 426, 619, 649, 650, 992, 1005], "montecchio": 1045, "montesel": 1059, "month": [0, 43, 181, 193, 325, 381, 386, 390, 401, 1041], "month_co": 43, "month_sin": 43, "monthli": [181, 401, 1000], "montoya": 1048, "montreal": 333, "moodi": 1046, "moon": [278, 315, 321, 360, 361, 530], "moonkyung94": 1055, "moor": [0, 743, 1000, 1024, 1058], "moosmann": 574, "moradizadeh": 1055, "moral": [57, 105, 360, 666, 1049, 1053, 1054, 1059], "morawiec": [1048, 1049], "more": [0, 2, 11, 36, 43, 45, 46, 47, 50, 51, 52, 53, 57, 62, 63, 64, 66, 67, 72, 74, 75, 78, 79, 81, 84, 87, 88, 90, 92, 95, 102, 109, 113, 120, 121, 123, 125, 128, 131, 132, 139, 140, 142, 145, 146, 147, 149, 151, 152, 153, 154, 155, 156, 160, 172, 174, 176, 182, 185, 188, 189, 192, 193, 195, 197, 199, 200, 204, 206, 209, 211, 214, 218, 220, 221, 222, 224, 235, 236, 237, 238, 240, 244, 247, 252, 253, 254, 255, 257, 259, 263, 265, 266, 268, 269, 271, 272, 276, 278, 279, 280, 281, 285, 287, 292, 296, 298, 299, 301, 302, 309, 314, 315, 317, 319, 320, 321, 324, 325, 326, 328, 329, 330, 332, 333, 334, 335, 336, 339, 346, 349, 353, 354, 356, 358, 360, 361, 362, 364, 365, 369, 373, 374, 375, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 393, 394, 399, 400, 401, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 433, 439, 441, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 582, 589, 590, 591, 592, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 705, 706, 707, 708, 709, 710, 711, 712, 713, 715, 716, 717, 718, 720, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 765, 766, 767, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 874, 875, 876, 877, 878, 879, 880, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 945, 947, 949, 951, 963, 966, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1022, 1024, 1025, 1029, 1030, 1031, 1032, 1033, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "moreau": [1047, 1048, 1049, 1050, 1051], "moreov": [165, 182, 321, 332, 369, 390, 416, 420, 426, 905, 970, 1000, 1008, 1024, 1049, 1055, 1056], "moreyra": 1054, "morgan": [1012, 1016], "mori": 1056, "morikko": 1048, "morina": 1054, "moritz": [1054, 1056], "morn": 43, "moroz": 1047, "morril": 1041, "mors": 1052, "mortem": 1034, "moslei": 1000, "mosley2013": 1000, "mosold": 160, "most": [2, 11, 43, 45, 47, 51, 53, 57, 61, 64, 87, 88, 90, 97, 111, 117, 118, 133, 139, 145, 146, 153, 155, 160, 169, 170, 171, 173, 174, 181, 188, 191, 192, 193, 194, 195, 197, 204, 220, 221, 238, 254, 258, 263, 269, 272, 275, 276, 281, 285, 286, 288, 292, 296, 298, 308, 319, 325, 326, 328, 331, 334, 336, 339, 349, 353, 360, 361, 362, 369, 373, 374, 375, 381, 382, 384, 386, 387, 388, 390, 391, 392, 394, 398, 400, 401, 404, 407, 410, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 427, 451, 452, 454, 458, 464, 465, 468, 476, 504, 511, 529, 532, 540, 542, 547, 551, 557, 559, 569, 570, 574, 575, 596, 597, 599, 601, 612, 619, 635, 638, 657, 666, 680, 682, 684, 686, 695, 696, 700, 703, 733, 736, 754, 766, 767, 771, 793, 802, 805, 806, 811, 812, 827, 840, 841, 854, 855, 856, 858, 860, 861, 862, 863, 864, 887, 889, 897, 898, 900, 901, 902, 903, 910, 948, 949, 951, 963, 989, 990, 994, 995, 996, 997, 998, 999, 1000, 1001, 1003, 1006, 1007, 1008, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1024, 1030, 1032, 1033, 1034, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1056, 1058], "most_common": 57, "most_frequ": [281, 559, 635, 638, 862, 990, 1000, 1049, 1051, 1053], "mostli": [0, 2, 81, 104, 220, 238, 324, 394, 398, 400, 421, 423, 424, 529, 787, 788, 1015, 1019, 1024, 1049, 1050, 1051, 1057], "mother": 997, "motiv": [134, 386, 388, 400, 992, 1000, 1010, 1024, 1054], "motmoti": 1051, "motoda": 416, "motor": 238, "motorcycl": [57, 381], "mottl": [1049, 1050], "moudgalya": [1057, 1058], "moufad": 1056, "moulavi": [416, 454], "mount": 394, "mountain": 1049, "mountford": [1057, 1058], "mous": 380, "mouseid": 380, "moussa": 1047, "move": [64, 148, 279, 317, 349, 385, 386, 390, 392, 414, 416, 557, 558, 579, 580, 581, 583, 585, 586, 967, 1033, 1041, 1042, 1046, 1049, 1051, 1054, 1055], "moveabl": 417, "movelikeriv": 1050, "movement": 381, "movi": [424, 1026], "movie_entri": 424, "movie_review": 1034, "moya": 1053, "mp": 996, "mpce": 57, "mpl": [70, 263, 264, 265, 269, 319], "mpl_toolkit": [50, 80, 102, 121, 131, 193, 217, 240, 242, 312], "mplot3d": [80, 102, 121, 131, 193, 217, 240, 242], "mpoemsl": 1055, "mppca": [542, 549], "mprun": 392, "mpy": 424, "mr": [92, 333, 1042, 1045, 1055], "mrandrewandrad": 1047, "mrastgoo": [1056, 1058], "mrg": 394, "mridul": 1047, "mrinal": 1055, "mrinaltyagi": 1055, "mrl09": 421, "mrmjauh": 1048, "mro": [388, 433, 439, 1051, 1052], "mrs2008": 598, "msabati": 1055, "msc": 383, "mschaffenroth": 1051, "mse": [44, 46, 111, 112, 150, 152, 153, 187, 188, 220, 222, 224, 226, 293, 335, 655, 661, 758, 1000, 1016, 1052, 1054], "mse_path_": [209, 655, 659, 661, 663, 669, 671], "mse_valu": 46, "mses_california": 188, "mses_diabet": 188, "msft": 51, "msg": [299, 984], "msle": [759, 1000], "msm": [174, 383], "mssubclass": 160, "mst": 416, "msvc": 1044, "msvcp140": 1055, "mt19937": [285, 290, 935, 1052], "mthorrel": [1048, 1051], "mtrand": 369, "mtse": 687, "mu": [54, 113, 114, 278, 421, 429, 481, 483, 484, 487, 488, 489, 548, 555, 994, 996, 1048, 1051], "mu_i": 1002, "mu_j": 416, "mu_k": 994, "muayyad": 1049, "much": [37, 43, 45, 46, 48, 52, 57, 62, 75, 90, 113, 115, 123, 128, 134, 144, 152, 153, 160, 161, 162, 176, 187, 188, 192, 193, 194, 195, 197, 217, 218, 222, 251, 254, 257, 272, 278, 280, 281, 284, 289, 316, 320, 324, 325, 326, 330, 331, 333, 349, 354, 360, 361, 369, 373, 374, 375, 381, 386, 387, 388, 391, 394, 398, 399, 404, 410, 414, 415, 418, 419, 420, 421, 422, 423, 424, 425, 455, 456, 504, 542, 543, 544, 546, 567, 568, 569, 570, 666, 667, 674, 675, 676, 684, 685, 686, 700, 787, 788, 811, 812, 826, 887, 905, 912, 989, 992, 995, 996, 997, 999, 1000, 1001, 1003, 1004, 1006, 1008, 1012, 1013, 1015, 1016, 1020, 1024, 1029, 1030, 1032, 1033, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "mudd": 1054, "mueller": [0, 108, 130, 143, 211, 252, 340, 356, 357, 405, 1024, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056], "muhammad": [1049, 1050, 1054], "mukherje": 1052, "mula": 1053, "multi": [2, 50, 67, 122, 138, 140, 142, 148, 158, 161, 163, 167, 178, 180, 189, 198, 204, 206, 207, 209, 212, 219, 227, 236, 239, 242, 246, 247, 255, 258, 270, 275, 287, 298, 313, 320, 321, 322, 328, 333, 343, 354, 358, 360, 363, 364, 365, 366, 368, 374, 381, 383, 388, 389, 395, 400, 404, 416, 423, 424, 426, 433, 445, 460, 470, 477, 482, 503, 504, 512, 513, 518, 522, 523, 527, 528, 530, 549, 557, 558, 559, 561, 563, 565, 566, 567, 569, 572, 573, 575, 577, 618, 639, 641, 651, 654, 655, 660, 661, 665, 666, 668, 669, 670, 671, 674, 676, 680, 681, 682, 683, 684, 689, 692, 698, 711, 721, 728, 742, 748, 750, 791, 807, 808, 822, 830, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 859, 860, 862, 868, 869, 870, 873, 879, 892, 896, 907, 908, 912, 914, 917, 920, 921, 922, 924, 925, 926, 932, 935, 938, 989, 1001, 1003, 1007, 1010, 1014, 1019, 1020, 1021, 1022, 1025, 1031, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1054, 1055, 1057, 1058, 1059], "multi_class": [212, 287, 328, 618, 666, 667, 796, 912, 996, 1001, 1015, 1041, 1045, 1049, 1054, 1056, 1059], "multi_confus": 762, "multi_layer_regressor": 423, "multi_output": [395, 932], "multi_target_forest": 1001, "multialign": 290, "multiarch": 394, "multiclass": [2, 31, 63, 66, 145, 198, 212, 236, 248, 255, 257, 260, 270, 275, 283, 285, 288, 298, 317, 346, 357, 381, 382, 388, 389, 391, 400, 407, 416, 423, 445, 460, 470, 497, 504, 512, 565, 567, 569, 572, 575, 576, 602, 610, 618, 639, 640, 641, 666, 667, 674, 676, 681, 682, 683, 684, 710, 714, 716, 737, 738, 742, 743, 746, 751, 762, 791, 792, 795, 796, 797, 802, 808, 809, 811, 812, 813, 814, 822, 824, 826, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 879, 893, 912, 914, 917, 920, 922, 962, 963, 964, 994, 996, 1010, 1011, 1015, 1016, 1021, 1022, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1056, 1057, 1058], "multicollinear": [146, 147, 189, 190, 194, 284, 341, 419, 508, 572, 642, 663, 838, 996, 1008, 1021], "multicor": [1053, 1054], "multidimension": [2, 419, 696, 698, 700, 702, 997, 1003], "multigrid": 470, "multiindex": 1055, "multilabel": [2, 30, 31, 117, 119, 189, 246, 285, 297, 381, 388, 389, 400, 411, 490, 495, 504, 505, 516, 517, 523, 531, 549, 565, 572, 575, 666, 682, 683, 711, 715, 721, 734, 737, 738, 742, 743, 746, 747, 762, 764, 791, 792, 795, 796, 802, 804, 838, 841, 843, 845, 869, 876, 879, 883, 885, 896, 917, 920, 922, 938, 962, 963, 964, 1011, 1021, 1022, 1034, 1036, 1043, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1054, 1055, 1056, 1057, 1058], "multilabel_": [841, 1046], "multilabel_confusion_matrix": [2, 721, 737, 738, 746, 792, 795, 1000, 1050], "multilabelbinar": [2, 400, 841, 876, 885, 1001, 1025, 1044, 1046, 1047, 1049, 1050], "multilay": [398, 998], "multilearn": 1019, "multimetr": [719, 989, 1051, 1056, 1060], "multimetric_": [808, 811, 812, 822], "multimod": 247, "multinomi": [2, 47, 66, 189, 198, 211, 229, 235, 255, 273, 287, 298, 316, 357, 381, 382, 386, 421, 423, 504, 520, 531, 559, 561, 567, 569, 639, 666, 667, 749, 838, 841, 847, 848, 849, 850, 851, 892, 935, 1000, 1016, 1021, 1022, 1034, 1036, 1041, 1045, 1047, 1048, 1049, 1054, 1055, 1059], "multinomialdevi": 1052, "multinomialhmm": 1041, "multinomialnb": [2, 47, 375, 381, 424, 847, 848, 849, 850, 1002, 1034, 1043, 1045, 1048, 1049, 1053, 1054, 1056], "multiouput": 1051, "multioutput": [2, 41, 159, 287, 298, 388, 400, 407, 439, 473, 490, 491, 492, 559, 562, 564, 565, 566, 568, 570, 572, 573, 576, 578, 619, 640, 641, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 729, 731, 736, 753, 754, 756, 758, 759, 761, 793, 796, 798, 799, 833, 841, 843, 844, 845, 846, 855, 863, 870, 879, 913, 915, 918, 920, 921, 922, 923, 938, 963, 964, 1000, 1021, 1022, 1036, 1041, 1042, 1043, 1047, 1048, 1054, 1055], "multioutput_arrai": 386, "multioutput_onli": 388, "multioutputclassifi": [2, 407, 796, 841, 843, 845, 1000, 1048, 1050, 1051, 1052, 1053, 1057, 1058], "multioutputregressor": [2, 159, 407, 439, 473, 490, 491, 492, 562, 564, 566, 568, 570, 573, 576, 578, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 844, 846, 855, 863, 870, 913, 915, 918, 921, 923, 1047, 1048, 1050, 1052, 1053, 1057, 1058], "multipl": [2, 25, 52, 81, 103, 106, 123, 134, 139, 145, 147, 148, 150, 170, 189, 192, 214, 252, 272, 278, 283, 286, 290, 296, 298, 301, 328, 334, 352, 373, 374, 375, 380, 382, 383, 386, 388, 389, 390, 391, 398, 400, 410, 416, 417, 418, 419, 421, 423, 424, 425, 426, 427, 428, 452, 468, 472, 474, 475, 477, 482, 496, 499, 500, 503, 504, 505, 511, 512, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 559, 561, 562, 563, 564, 567, 568, 569, 570, 571, 589, 607, 615, 616, 618, 619, 635, 640, 642, 647, 648, 649, 650, 654, 655, 658, 660, 661, 662, 665, 668, 669, 670, 671, 674, 675, 676, 679, 681, 684, 686, 687, 697, 698, 700, 701, 702, 719, 729, 731, 736, 753, 754, 756, 758, 759, 761, 793, 796, 798, 799, 801, 805, 806, 808, 810, 811, 812, 813, 814, 820, 822, 823, 824, 825, 826, 827, 828, 834, 835, 836, 838, 842, 843, 844, 845, 846, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 874, 877, 889, 893, 901, 904, 905, 912, 913, 914, 917, 928, 943, 948, 949, 971, 974, 992, 995, 996, 997, 1001, 1002, 1003, 1007, 1008, 1013, 1014, 1016, 1019, 1020, 1021, 1025, 1034, 1041, 1042, 1044, 1047, 1048, 1051, 1052, 1053, 1054, 1056, 1057, 1058], "multipleloc": [240, 304], "multiplex": 1016, "multipli": [192, 224, 238, 278, 373, 395, 400, 421, 423, 424, 429, 472, 483, 523, 546, 548, 549, 555, 565, 569, 572, 654, 656, 660, 662, 666, 667, 668, 670, 676, 677, 678, 680, 684, 685, 686, 688, 694, 695, 697, 701, 772, 914, 917, 920, 922, 938, 976, 977, 978, 989, 992, 996, 1000, 1014, 1052], "multiprocess": [398, 400, 966, 1003, 1041, 1049, 1055], "multirespons": 996, "multiscal": 470, "multisurfac": [174, 383], "multitarget": 395, "multitask": [298, 424, 1001], "multitaskelasticnet": [2, 654, 655, 660, 669, 670, 671, 689, 996, 1001, 1041, 1048, 1049, 1052, 1054], "multitaskelasticnetcv": [2, 407, 654, 655, 660, 668, 670, 671, 689, 996, 1001, 1044, 1051, 1052, 1054, 1058], "multitasklasso": [2, 214, 660, 668, 671, 996, 1001, 1041, 1049, 1052, 1054], "multitasklassocv": [2, 407, 669, 670, 1001, 1044, 1051, 1052, 1054, 1058], "multithread": [373, 416, 786, 912, 913, 914, 915, 916, 917, 918], "multivari": [2, 125, 192, 378, 418, 421, 424, 481, 524, 525, 526, 635, 636, 637, 638, 657, 679, 686, 687, 847, 848, 849, 850, 851, 994, 996, 999, 1002, 1019, 1025, 1033, 1036], "multivariate_norm": [115, 118, 263, 429, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489], "multiwai": 1016, "muma": 114, "mungui": 1054, "munoz": [1047, 1053], "muoki": 1053, "murad": 1044, "murashkin": 1045, "murata": [1054, 1055], "murder": 360, "murezzda": 1057, "murmurhash": 395, "murmurhash3": [2, 424, 590, 597, 965], "murmurhash3_32": [2, 395], "murmurhash3_x86_32": [395, 965], "murphi": [414, 651, 993], "murrai": [1047, 1048], "music": 1024, "must": [90, 192, 193, 195, 201, 204, 237, 238, 247, 258, 273, 305, 320, 325, 360, 369, 381, 385, 386, 387, 388, 390, 392, 394, 400, 401, 407, 412, 414, 416, 417, 420, 421, 423, 424, 425, 426, 427, 437, 446, 449, 452, 453, 454, 455, 457, 458, 459, 463, 465, 467, 469, 470, 472, 474, 475, 477, 482, 495, 516, 517, 520, 531, 539, 545, 546, 547, 548, 549, 551, 552, 555, 561, 562, 567, 568, 569, 570, 575, 576, 589, 590, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 618, 619, 625, 628, 635, 636, 637, 638, 640, 641, 646, 650, 651, 656, 657, 660, 666, 667, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 688, 690, 693, 694, 695, 696, 697, 700, 701, 702, 703, 704, 707, 711, 714, 717, 743, 754, 772, 779, 782, 786, 789, 796, 800, 801, 802, 804, 805, 806, 807, 808, 809, 811, 812, 813, 815, 817, 818, 820, 822, 823, 824, 826, 827, 829, 833, 836, 838, 839, 847, 848, 849, 850, 851, 854, 855, 856, 858, 860, 861, 862, 863, 864, 867, 868, 869, 870, 872, 875, 876, 877, 879, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 896, 912, 913, 914, 915, 916, 917, 918, 919, 925, 975, 984, 986, 989, 990, 996, 997, 998, 1000, 1003, 1004, 1006, 1007, 1014, 1015, 1016, 1025, 1034, 1041, 1044, 1048, 1052, 1054, 1055, 1058], "mutat": [369, 1049], "mutual": [2, 72, 73, 84, 90, 93, 168, 189, 400, 423, 425, 454, 600, 603, 604, 607, 608, 614, 615, 616, 617, 712, 713, 723, 763, 765, 794, 803, 989, 996, 1000, 1001, 1021, 1041, 1047, 1057], "mutual_info_classif": [2, 106, 425, 600, 603, 604, 607, 608, 1047, 1053, 1056, 1059], "mutual_info_regress": [2, 169, 332, 425, 600, 603, 604, 607, 608, 617, 1047, 1048, 1053, 1055, 1056, 1057, 1059], "mutual_info_scor": [2, 72, 416, 712, 1000, 1049, 1052, 1053], "mu\u00f1oz": [1054, 1056], "mwestt": 1050, "my": [380, 386, 391, 394, 504], "my_custom_loss_func": 1000, "my_data": 391, "my_dataset": 495, "my_estim": [388, 417], "my_extra_param": 388, "my_featur": 386, "my_fil": 392, "my_func": [387, 392], "my_g": [428, 541], "my_group": [254, 407], "my_kernel": [345, 1015], "my_memb": [96, 98, 99], "my_other_weight": [254, 407], "my_pipelin": 1050, "my_script": 374, "my_test_script": 394, "my_token": 424, "my_weight": [254, 407], "myatt": [1050, 1051], "mycach": [516, 517], "mycluster": 434, "myenugula": 1059, "myer": [1044, 1048], "myestim": [388, 430, 432, 433, 435, 436, 437, 438, 439], "myestimator0": 432, "myestimator1": 432, "mymultioutputestim": 388, "mypi": [386, 390, 404, 409, 1052], "myself": 386, "mysvmlightfil": 516, "mytransform": [388, 440], "m\u00e9hault": [1049, 1050], "m\u00f6rtberg": 1047, "m\u00fcller": [0, 67, 320, 321, 401, 421, 543, 878, 1004, 1010, 1014, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1055], "n": [2, 43, 44, 46, 47, 49, 50, 54, 55, 57, 68, 69, 72, 74, 75, 93, 104, 109, 113, 117, 123, 125, 128, 130, 132, 134, 135, 139, 141, 142, 146, 162, 169, 172, 174, 176, 180, 185, 193, 195, 200, 204, 216, 220, 221, 224, 235, 237, 238, 240, 250, 251, 252, 255, 263, 265, 266, 276, 278, 281, 283, 284, 285, 287, 288, 299, 302, 304, 317, 321, 323, 324, 330, 333, 335, 339, 353, 356, 368, 373, 380, 383, 384, 386, 390, 392, 395, 400, 404, 407, 413, 414, 416, 419, 420, 421, 422, 423, 424, 426, 427, 452, 453, 455, 456, 458, 477, 479, 482, 486, 497, 523, 524, 525, 526, 531, 536, 546, 548, 549, 555, 565, 566, 567, 568, 571, 572, 573, 574, 596, 597, 598, 599, 615, 616, 622, 635, 657, 679, 687, 700, 704, 707, 714, 715, 763, 813, 816, 818, 823, 824, 827, 848, 852, 853, 857, 877, 904, 906, 920, 921, 922, 923, 929, 947, 952, 953, 975, 979, 980, 989, 992, 994, 996, 997, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1014, 1015, 1016, 1025, 1032, 1034, 1041, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059], "n1": 128, "n2": 128, "n4": 128, "n_": [113, 114, 195, 278, 331, 416, 421, 423, 654, 660, 693, 704, 992, 996, 1000, 1002, 1003, 1007, 1010, 1012, 1015, 1016], "n_alpha": [225, 480, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 681, 683, 689, 690, 691, 692, 1044], "n_atom": 1042, "n_averag": 69, "n_bar": 188, "n_batch_iter_": 544, "n_best": 459, "n_bin": [61, 62, 64, 88, 220, 238, 320, 322, 326, 446, 447, 877, 1010], "n_bins_": 877, "n_bootstrap": [281, 1042], "n_bulk_repeat": 49, "n_byte": 251, "n_c": [416, 667], "n_call": [852, 853], "n_candid": [811, 812, 989], "n_candidates_": [290, 811, 812, 989], "n_candidates_0": 989, "n_candidates_i": 989, "n_categori": [326, 848, 886, 1010], "n_categorical_featur": [149, 569, 570, 640, 641], "n_categories_": 848, "n_center": [77, 520], "n_channel": [591, 592, 595], "n_class": [2, 45, 72, 122, 123, 139, 141, 146, 148, 171, 173, 235, 241, 252, 255, 265, 285, 286, 287, 308, 309, 328, 365, 368, 369, 386, 388, 400, 423, 445, 496, 497, 510, 523, 527, 531, 557, 558, 559, 561, 563, 565, 567, 569, 572, 575, 577, 601, 602, 612, 618, 642, 647, 666, 667, 674, 675, 676, 682, 683, 684, 685, 705, 715, 724, 726, 730, 743, 746, 749, 762, 796, 802, 807, 808, 811, 812, 822, 830, 833, 840, 841, 842, 843, 844, 846, 847, 848, 849, 850, 851, 854, 859, 861, 862, 869, 872, 879, 880, 883, 886, 893, 896, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 922, 924, 925, 937, 938, 996, 1000, 1001, 1004, 1011, 1014, 1015, 1030, 1046, 1047, 1048, 1050, 1051, 1052, 1058], "n_classes_": [559, 561, 563, 565, 567, 572, 618, 840, 841, 920, 922, 1042, 1051, 1053], "n_classes_pr": [722, 763], "n_classes_tru": [722, 763], "n_classifi": [66, 577, 578], "n_cluster": [2, 57, 58, 59, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 125, 332, 361, 386, 400, 416, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 467, 468, 469, 470, 471, 519, 521, 718, 800, 801, 1033, 1041, 1045, 1047, 1049, 1050, 1052, 1055], "n_clusters_": [73, 84, 90, 98, 449, 453], "n_clusters_list": 78, "n_clusters_per_class": [67, 122, 143, 171, 173, 275, 309, 314, 321, 391, 523, 613, 615], "n_clusters_rang": 72, "n_clusters_tru": 96, "n_col": [45, 57, 125, 256, 431, 459, 461, 519, 521, 640, 1030], "n_color": 83, "n_column": [413, 459, 461], "n_column_clust": [459, 461, 521], "n_comp": [135, 197], "n_comparison": 278, "n_compon": [43, 44, 45, 51, 54, 79, 87, 92, 93, 94, 104, 106, 107, 108, 117, 118, 121, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 158, 197, 219, 240, 241, 242, 243, 244, 245, 247, 251, 252, 255, 259, 263, 264, 265, 266, 267, 268, 269, 277, 303, 308, 317, 324, 330, 332, 335, 336, 361, 388, 391, 392, 400, 417, 419, 421, 428, 459, 460, 470, 472, 490, 491, 492, 493, 534, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 647, 648, 649, 650, 696, 697, 698, 699, 700, 701, 702, 703, 704, 805, 806, 861, 868, 871, 904, 905, 906, 949, 992, 994, 997, 999, 1003, 1030, 1033, 1042, 1043, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1055, 1058, 1059], "n_components_": [107, 132, 400, 449, 453, 542, 546, 547, 548, 549, 550, 551, 904, 905, 1030, 1050, 1052], "n_components_fa": 132, "n_components_pca": 132, "n_components_pca_ml": 132, "n_components_rang": 251, "n_connected_compon": 471, "n_connected_components_": [449, 453, 1050], "n_core": 145, "n_core_sampl": [427, 452], "n_cpu": [374, 400], "n_cv": [420, 445], "n_cv_alpha": [659, 663], "n_cv_fold": [149, 325, 814, 831, 836, 839], "n_digit": 93, "n_dim": [486, 535, 537, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 1058], "n_dimens": [805, 806], "n_dimensions_of_x": [914, 915, 916, 917, 918], "n_dir": 53, "n_e": 416, "n_element": [426, 625], "n_encoded_featur": [885, 886], "n_error": 306, "n_error_outli": [234, 305, 348], "n_error_outliers_sgd": 234, "n_error_test": [234, 305, 348], "n_error_test_sgd": 234, "n_error_train": [234, 348], "n_error_train_sgd": 234, "n_estim": [46, 49, 63, 67, 139, 140, 141, 142, 143, 144, 145, 147, 148, 150, 151, 152, 153, 154, 158, 159, 162, 187, 195, 241, 256, 260, 265, 275, 290, 321, 328, 330, 373, 399, 400, 423, 425, 561, 562, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 575, 576, 577, 578, 640, 811, 812, 989, 1006, 1007, 1038, 1049, 1057], "n_estimators_": [150, 567, 568], "n_estimators_ful": 150, "n_exampl": 47, "n_face": 256, "n_featur": [45, 47, 54, 62, 63, 64, 66, 67, 68, 69, 70, 75, 87, 93, 95, 96, 111, 112, 113, 114, 115, 122, 123, 125, 132, 139, 141, 143, 145, 146, 171, 173, 174, 187, 188, 197, 199, 202, 204, 206, 214, 215, 219, 223, 224, 235, 237, 241, 247, 251, 252, 254, 263, 268, 275, 281, 285, 287, 288, 290, 291, 309, 314, 321, 328, 329, 330, 332, 334, 335, 336, 356, 360, 361, 362, 369, 373, 379, 380, 386, 388, 391, 398, 399, 400, 407, 416, 418, 419, 421, 423, 424, 427, 428, 429, 431, 433, 434, 435, 438, 439, 440, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 466, 467, 468, 469, 471, 472, 473, 474, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 497, 498, 499, 500, 502, 509, 512, 516, 517, 520, 523, 524, 527, 529, 531, 532, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 704, 705, 706, 708, 709, 710, 718, 733, 766, 767, 768, 769, 771, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 800, 801, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 872, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 949, 975, 976, 977, 978, 979, 980, 981, 982, 983, 992, 996, 1001, 1003, 1004, 1010, 1014, 1015, 1016, 1025, 1030, 1031, 1033, 1034, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "n_feature_influ": 49, "n_features_": [173, 601, 602, 1054, 1056], "n_features_a": 861, "n_features_b": 861, "n_features_in_": [388, 400, 437, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 635, 636, 637, 638, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 1052, 1054, 1056, 1059], "n_features_max": 69, "n_features_missing_ind": 638, "n_features_new": [440, 450, 453, 540, 542, 544, 545, 547, 550, 551, 557, 575, 577, 578, 590, 591, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 636, 638, 643, 646, 647, 648, 649, 650, 861, 868, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 889, 890, 891, 892, 904, 905], "n_features_opt": 106, "n_features_out": 638, "n_features_out_": 891, "n_features_rang": 69, "n_features_to_comput": 1049, "n_features_to_select": [172, 174, 330, 425, 601, 610, 1053, 1055], "n_features_to_select_": 610, "n_features_with_miss": 637, "n_features_with_missing_": 635, "n_fold": [165, 655, 659, 661, 663, 667, 669, 671, 1042, 1043, 1047], "n_gram_rang": 1041, "n_group": [420, 817, 1029, 1047], "n_i": [1002, 1010], "n_imag": 276, "n_index": [854, 855, 856, 858, 860, 862, 863], "n_inform": [62, 64, 67, 122, 143, 146, 171, 173, 199, 204, 223, 224, 275, 281, 291, 309, 314, 321, 328, 356, 388, 391, 523, 532, 561, 562, 563, 564, 572, 573, 613, 614, 615, 616, 617, 654, 655, 660, 668, 669, 670, 673, 689, 690, 691, 842, 1001, 1049], "n_init": [57, 77, 78, 80, 85, 92, 93, 96, 99, 240, 241, 242, 243, 329, 332, 361, 416, 451, 455, 457, 459, 460, 461, 467, 470, 698, 702, 805, 806, 1033, 1041, 1049, 1055, 1056, 1057], "n_init_rang": 96, "n_inlier": 247, "n_input_features_": 1054, "n_instanc": [49, 641], "n_iter": [45, 55, 105, 155, 176, 228, 279, 286, 299, 317, 351, 388, 392, 399, 428, 462, 486, 540, 541, 552, 553, 554, 555, 654, 655, 660, 661, 668, 669, 670, 671, 689, 690, 691, 692, 693, 694, 695, 700, 702, 811, 812, 820, 822, 868, 870, 948, 949, 989, 1014, 1030, 1042, 1047, 1048, 1049, 1053, 1055, 1056, 1057, 1059], "n_iter_": [43, 128, 155, 228, 266, 400, 448, 455, 456, 457, 479, 480, 490, 491, 492, 539, 540, 541, 544, 545, 546, 547, 548, 551, 569, 570, 635, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 682, 684, 685, 686, 687, 688, 698, 700, 805, 806, 861, 869, 870, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 1045, 1048, 1049, 1051, 1054, 1055, 1057], "n_iter_no_chang": [46, 145, 150, 155, 228, 331, 360, 391, 400, 423, 567, 568, 569, 570, 674, 675, 676, 684, 685, 686, 869, 870, 1014, 1049, 1052], "n_iter_search": 286, "n_iter_without_progress": [241, 700, 1046, 1047], "n_iterations_": [290, 811, 812], "n_iters_": 1047, "n_job": [52, 89, 106, 107, 145, 146, 147, 152, 153, 160, 173, 174, 187, 192, 193, 194, 195, 241, 243, 259, 272, 277, 279, 280, 282, 294, 296, 299, 328, 329, 330, 333, 356, 374, 386, 400, 423, 427, 445, 452, 454, 456, 458, 460, 463, 464, 465, 466, 469, 472, 475, 480, 539, 543, 544, 545, 547, 550, 551, 553, 554, 556, 563, 564, 565, 566, 571, 572, 573, 574, 575, 576, 577, 578, 602, 610, 615, 616, 618, 640, 642, 647, 655, 659, 661, 663, 665, 666, 667, 669, 671, 673, 674, 676, 684, 687, 696, 697, 698, 699, 700, 701, 702, 782, 786, 789, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 844, 845, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 871, 874, 907, 908, 966, 989, 1000, 1001, 1003, 1029, 1030, 1034, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1056, 1059], "n_k": [416, 558], "n_kernel": 620, "n_kernel_param": [618, 619], "n_knot": [43, 221, 331, 891, 1010, 1054], "n_l1_ratio": [655, 667, 669, 1044], "n_l1_ratios_": 667, "n_label": [51, 123, 255, 400, 495, 531, 721, 728, 734, 747, 748, 762, 764, 800, 801, 828, 1000, 1047, 1049], "n_labeled_point": [338, 339], "n_layer": [869, 870], "n_layers_": [869, 870], "n_leav": [471, 920, 921, 922, 923], "n_leaves_": [449, 453], "n_left": 571, "n_local_tri": 468, "n_m": 1016, "n_mask": 220, "n_missing_featur": 637, "n_missing_sampl": 188, "n_nearest_featur": [188, 635], "n_neighbor": [51, 79, 97, 102, 161, 187, 240, 241, 242, 244, 247, 257, 299, 301, 302, 305, 306, 307, 308, 311, 324, 328, 330, 360, 423, 460, 610, 615, 616, 636, 696, 697, 699, 701, 703, 704, 854, 855, 856, 858, 860, 861, 865, 907, 908, 990, 997, 1003, 1006, 1013, 1048, 1055, 1057, 1058], "n_neighbors_": [699, 858], "n_neighbors_list": [257, 301], "n_neighbour": 1055, "n_node": [368, 449, 453, 471, 565, 566, 572, 573, 574, 920, 921, 922, 923, 954], "n_node_sampl": 368, "n_nodes_ptr": [565, 566, 572, 573, 574], "n_noise_": 84, "n_nonzero": 134, "n_nonzero_coef": [219, 534, 539, 545, 550, 553, 554, 556, 658, 672, 693, 694, 1059], "n_nonzero_coefs_": [672, 673, 1059], "n_nonzero_column": 362, "n_numerical_featur": 149, "n_order": 200, "n_original_featur": [600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611], "n_out": 574, "n_outlier": [113, 114, 156, 223, 247, 306], "n_output": [368, 400, 423, 433, 439, 440, 445, 450, 453, 473, 477, 490, 491, 492, 540, 542, 544, 545, 547, 550, 551, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 577, 578, 590, 591, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 636, 638, 641, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 668, 669, 670, 671, 672, 673, 674, 675, 676, 678, 680, 681, 682, 683, 684, 686, 687, 729, 731, 736, 753, 754, 756, 758, 759, 761, 762, 793, 796, 798, 799, 807, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 859, 861, 862, 863, 868, 869, 870, 871, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 889, 890, 891, 892, 904, 905, 907, 908, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 938, 971, 1000, 1001, 1016, 1048, 1051], "n_output_featur": 636, "n_output_features_": 887, "n_outputs_": [559, 560, 565, 566, 572, 573, 574, 869, 870, 920, 921, 922, 923], "n_oversampl": [459, 461, 549, 552, 949, 1055], "n_pack": [2, 952, 953], "n_patch": [591, 592, 595], "n_permut": [284, 420, 837], "n_pixel": [256, 276], "n_point": [273, 852, 853], "n_points_per_clust": 100, "n_popul": [395, 969], "n_possible_iterations_": [811, 812], "n_predict": 49, "n_pt": 53, "n_q": 416, "n_quantil": [109, 193, 323, 889, 901, 1050], "n_quantiles_": 889, "n_queri": [696, 854, 855, 856, 858, 860, 862, 863, 864], "n_random_featur": 209, "n_redund": [62, 64, 67, 122, 146, 171, 173, 275, 281, 309, 314, 321, 391, 445, 523, 561, 563, 572, 842], "n_refin": 480, "n_region": 81, "n_regions_plu": 81, "n_regressor": 578, "n_relevant_featur": 214, "n_remaining_candidates_": [811, 812], "n_repeat": [142, 146, 153, 173, 192, 194, 195, 278, 292, 296, 328, 420, 523, 642, 823, 824, 1008], "n_required_iterations_": [811, 812], "n_resourc": 989, "n_resources_": [290, 811, 812, 989], "n_resources_0": 989, "n_resources_i": 989, "n_restarts_optim": [183, 426, 618, 619], "n_retri": [496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 1055, 1059], "n_row": [45, 57, 125, 413, 431, 459, 461, 519, 521, 1030], "n_row_clust": [459, 461, 521], "n_run": [72, 96, 197, 361], "n_sampl": [45, 46, 49, 54, 61, 62, 63, 64, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 102, 104, 109, 111, 112, 113, 114, 115, 118, 123, 125, 126, 130, 132, 139, 141, 142, 143, 144, 145, 146, 151, 152, 153, 154, 156, 157, 166, 167, 173, 174, 185, 187, 188, 191, 199, 201, 202, 204, 206, 208, 210, 212, 214, 215, 219, 220, 221, 223, 224, 228, 232, 235, 237, 238, 240, 241, 242, 243, 244, 245, 247, 251, 252, 254, 257, 264, 266, 267, 268, 269, 275, 276, 278, 281, 282, 285, 287, 288, 289, 290, 291, 293, 299, 309, 321, 322, 323, 326, 329, 330, 332, 334, 335, 336, 340, 347, 350, 351, 356, 360, 361, 369, 379, 383, 386, 388, 391, 395, 398, 399, 400, 407, 415, 416, 418, 419, 420, 421, 423, 427, 428, 429, 431, 433, 434, 435, 438, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 502, 509, 512, 516, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 621, 622, 623, 624, 625, 626, 629, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, 710, 711, 712, 713, 715, 716, 717, 718, 720, 721, 722, 723, 724, 725, 726, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 778, 779, 780, 781, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 937, 938, 949, 951, 953, 962, 969, 971, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 989, 992, 996, 1000, 1001, 1003, 1004, 1010, 1011, 1012, 1014, 1015, 1016, 1025, 1030, 1031, 1032, 1033, 1034, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "n_samples1": 878, "n_samples2": 878, "n_samples_": 549, "n_samples_1": [351, 1015], "n_samples_2": [351, 1015], "n_samples_a": [800, 801], "n_samples_fit": [439, 473, 490, 491, 492, 562, 564, 566, 568, 570, 573, 576, 578, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 696, 845, 846, 854, 855, 856, 858, 860, 862, 863, 864, 870, 913, 915, 918, 921, 923], "n_samples_fit_": [299, 854, 855, 856, 858, 860, 862, 863, 864], "n_samples_i": [620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 782, 783, 784, 785, 786, 787, 788, 789], "n_samples_per_cent": 96, "n_samples_rang": [112, 251], "n_samples_seen": 892, "n_samples_seen_": [542, 881, 882, 892, 1049], "n_samples_test": [291, 914, 915, 916, 917, 918, 1003, 1010], "n_samples_train": [291, 914, 915, 916, 917, 918], "n_samples_transform": [299, 856, 864], "n_samples_x": [619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 782, 783, 784, 785, 786, 787, 788, 789], "n_seed": 469, "n_selected_featur": [600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611], "n_skips_": 1048, "n_skips_invalid_data_": 679, "n_skips_invalid_model_": 679, "n_skips_no_inliers_": 679, "n_spline": [43, 891], "n_split": [43, 52, 145, 151, 155, 187, 188, 192, 265, 273, 278, 280, 283, 288, 292, 296, 335, 341, 349, 356, 369, 420, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829, 835, 1029, 1047, 1049], "n_splits_": [808, 811, 812, 822], "n_steps_": [128, 457, 545, 546, 1054], "n_subpopulation_": 687, "n_subsampl": [687, 938], "n_subsets_of_featur": 602, "n_support_": [914, 915, 916, 917, 918, 1015, 1051], "n_support_vector": 46, "n_sv": [914, 915, 916, 917, 918, 1015, 1051], "n_svd_vec": [459, 461], "n_t": [565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923], "n_t_l": [565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923], "n_t_r": [565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923], "n_target": [400, 419, 490, 491, 492, 493, 532, 564, 619, 651, 654, 655, 658, 659, 660, 661, 662, 664, 665, 668, 669, 670, 671, 672, 673, 679, 680, 681, 682, 683, 689, 692, 693, 694, 695, 1001, 1053, 1055, 1057], "n_task": [214, 996], "n_test": [47, 49, 69, 142, 278, 1041, 1044], "n_test_docu": 47, "n_test_po": 47, "n_threshold": [643, 735, 790, 797], "n_tick": [814, 831, 836, 839], "n_top": 286, "n_top_word": 54, "n_topic": [391, 544, 1048], "n_tot": 707, "n_total_sampl": [338, 339], "n_train": [47, 49, 69, 142, 278, 1041, 1044], "n_train_po": 47, "n_transformed_featur": 872, "n_tree": 46, "n_trees_per_iter": 569, "n_trees_per_iteration_": [567, 568, 569, 570], "n_trials_": 679, "n_uncorrelated_featur": 284, "n_unequ": 707, "n_unique_categori": 325, "n_unique_label": [737, 738, 746, 791, 792, 795, 964], "n_unique_tick": [814, 836], "n_valu": [831, 839, 1049], "n_values_": 1049, "n_values_feature_j": 641, "n_x": [89, 593], "n_y": [89, 593, 1002, 1010], "n_z": 593, "na": [635, 636, 637, 638, 777, 786, 930, 932, 933, 1051, 1052, 1055, 1056, 1057, 1058], "nabarun": 1049, "nabla": 1004, "nabsolut": 226, "nacross": 292, "nada": 57, "nadeau": [278, 1049], "nadia": 1053, "nadim": 1054, "nadirhan": 1055, "nadya": 1047, "nagarajan": [653, 996], "nagarjuna": [1048, 1049], "nagasaka": 1054, "naghshhnejad": [1051, 1052], "nagpal": 91, "naipawat": [1055, 1056], "naiv": [2, 32, 64, 67, 158, 278, 280, 298, 360, 362, 381, 414, 423, 424, 445, 552, 847, 848, 849, 850, 851, 994, 995, 1003, 1008, 1022, 1036, 1041, 1042, 1043, 1044, 1049, 1051, 1054, 1056], "naive_bay": [2, 47, 61, 62, 64, 67, 158, 162, 279, 280, 360, 369, 375, 381, 423, 445, 577, 847, 848, 849, 850, 851, 873, 994, 1001, 1002, 1034, 1042, 1043, 1045, 1046, 1047, 1048], "naive_linear_pipelin": 43, "naive_linear_predict": 43, "naivebay": 375, "naivebayesna": 1027, "naivelycalibratedlinearsvc": [62, 64], "najera": 1048, "najork": [734, 764, 1000], "naka": 1054, "nakamura": 1055, "nakano": [1048, 1049], "nalepa": 1048, "naman": 1058, "name": [2, 43, 45, 46, 48, 49, 50, 51, 55, 57, 62, 64, 66, 67, 72, 79, 80, 93, 97, 105, 107, 109, 115, 126, 131, 142, 143, 144, 145, 149, 152, 155, 160, 192, 193, 194, 209, 218, 220, 222, 224, 226, 227, 235, 237, 238, 240, 241, 247, 253, 254, 256, 257, 261, 265, 272, 273, 275, 276, 279, 281, 282, 285, 287, 288, 292, 296, 299, 307, 308, 314, 315, 321, 323, 325, 332, 333, 336, 342, 354, 360, 361, 362, 374, 375, 380, 381, 384, 386, 388, 390, 391, 393, 394, 400, 404, 407, 413, 416, 420, 423, 424, 426, 430, 432, 437, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 496, 497, 498, 499, 500, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 518, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 584, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 696, 697, 698, 699, 700, 705, 706, 707, 708, 710, 716, 717, 719, 721, 740, 741, 750, 787, 788, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 817, 820, 822, 826, 830, 831, 835, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 931, 932, 933, 936, 940, 941, 942, 944, 956, 957, 958, 960, 963, 970, 984, 988, 989, 994, 996, 1000, 1001, 1007, 1008, 1010, 1016, 1020, 1029, 1030, 1032, 1034, 1041, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "name_to_color": 325, "named_estim": [575, 576, 577, 578], "named_estimators_": [575, 576, 577, 578, 1049, 1051], "named_step": [107, 118, 172, 417, 601, 602, 605, 872, 873, 912, 913, 996, 1030, 1048, 1050], "named_transform": [871, 1056], "named_transformers_": 472, "namedtupl": [2, 625, 958, 1057], "namespac": 412, "namiya": 1048, "nan": [2, 109, 149, 155, 187, 188, 192, 238, 257, 259, 261, 273, 281, 325, 328, 333, 334, 335, 336, 373, 378, 388, 395, 400, 423, 454, 476, 504, 563, 564, 565, 569, 570, 572, 601, 602, 605, 611, 614, 617, 635, 636, 637, 638, 643, 720, 721, 722, 729, 730, 731, 732, 736, 737, 738, 777, 786, 791, 792, 793, 795, 808, 811, 812, 814, 822, 831, 834, 835, 836, 839, 881, 882, 886, 888, 889, 892, 893, 897, 900, 901, 903, 930, 931, 932, 933, 975, 989, 1000, 1010, 1016, 1036, 1044, 1048, 1049, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1058], "nan_euclidean": [636, 770, 786], "nan_euclidean_dist": [2, 328, 770, 990, 1051], "nandana": [1047, 1048, 1049], "nanshan": 1054, "nanta": 1044, "nanxin": 1049, "nanyang": 383, "naois": [1056, 1058], "naoki": [1043, 1053], "naoya": [1047, 1048, 1049, 1050], "naozin555": 1054, "napa": 325, "narasimhan": 859, "nardelli": 1044, "narendra": [1052, 1058], "narendramukherje": 1052, "narendran": 1049, "narin": [245, 1048, 1049], "narinek": [1048, 1049], "narr": [386, 400, 666, 912, 917, 1041, 1042], "narrai": 602, "narrow": [52, 142, 152, 319, 321, 391, 852, 853], "nartayxd": 1055, "nasa": [104, 360, 361, 383], "nasdaq": 51, "naser": 1051, "nasir": 1049, "nass": 1056, "nastegiano": 1055, "nat": [615, 616, 712, 763, 765, 1055], "natasha": 1051, "natchiappan": [1054, 1055], "nate": [1047, 1048, 1054], "nath": 1049, "nathan": [543, 1049, 1053, 1056, 1059], "nathaniel": [1048, 1049, 1051], "nathansquan": 1055, "nati": 1056, "nation": [50, 113, 312, 381, 859], "nativ": [43, 52, 155, 159, 181, 187, 272, 374, 381, 400, 410, 423, 504, 569, 570, 844, 845, 996, 1000, 1001, 1019, 1051, 1053], "native_result": 149, "natl": [697, 701, 997], "natur": [43, 64, 67, 145, 152, 183, 192, 193, 197, 204, 220, 221, 237, 238, 244, 257, 263, 269, 287, 298, 360, 386, 388, 400, 421, 423, 424, 427, 452, 458, 465, 559, 598, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 700, 712, 749, 763, 765, 854, 855, 856, 858, 860, 862, 863, 864, 891, 947, 996, 997, 999, 1000, 1003, 1005, 1010, 1014, 1019, 1041, 1049], "naul": [1046, 1047], "nav": 51, "navarret": [1049, 1050, 1051], "navarro": 1056, "navi": [69, 104, 112, 129, 133, 134, 159, 199, 223, 231, 243, 264, 265, 266, 269, 285, 287, 304, 311, 340, 367], "navig": [394, 1043], "navin": 908, "navistar": 51, "navkal": 1049, "navractil": 1000, "navratil2007": 1000, "nawazish": [1056, 1057], "naziya": 1059, "na\u00efv": 1034, "nb": [47, 132, 158, 369, 849, 1002], "nbclaim": 238, "nber": 49, "nbr": [860, 1003], "nbrs_": [696, 697], "nbsp": [51, 63, 105, 106, 144, 146, 147, 152, 156, 157, 160, 163, 171, 181, 192, 193, 194, 201, 209, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 333, 335, 340, 368], "nbviewer": [51, 63, 105, 106, 144, 146, 147, 156, 157, 160, 163, 171, 181, 192, 193, 194, 201, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 333, 335, 340, 368], "nbyte": [88, 251], "nca": [241, 307, 308, 309, 861, 1003], "nca_pip": 1003, "ncall": 392, "ncanip": 861, "nclass": 273, "ncluster": 79, "ncol": [43, 44, 52, 66, 68, 70, 88, 92, 101, 125, 130, 135, 150, 193, 220, 221, 222, 228, 238, 240, 241, 250, 257, 272, 274, 280, 281, 289, 292, 299, 302, 315, 320, 321, 323, 324, 333, 355, 356, 361], "ncorrect": 278, "ncsu": [174, 383], "ncv": [459, 461], "nd": [1054, 1058], "ndarrai": [88, 93, 121, 220, 261, 276, 277, 278, 386, 387, 388, 392, 393, 412, 424, 427, 428, 431, 432, 434, 437, 438, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 471, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 489, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 505, 508, 509, 510, 511, 512, 513, 515, 516, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 705, 706, 708, 709, 710, 723, 726, 729, 730, 731, 732, 735, 736, 746, 753, 754, 756, 758, 759, 761, 762, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 793, 797, 798, 799, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 929, 930, 931, 932, 937, 938, 946, 948, 949, 950, 951, 955, 962, 964, 965, 969, 972, 973, 975, 976, 977, 978, 981, 986, 987, 1000, 1015, 1020, 1044, 1048, 1051, 1052, 1055, 1056, 1057, 1058], "ndata": 284, "ndataset": [235, 321], "ndbscan": 100, "ndcg": [734, 764, 1000, 1048], "ndcg_score": [2, 734, 1000, 1048, 1051, 1056, 1057], "ndenumer": 232, "ndepend": 193, "ndim": [654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 932, 933], "ndimag": [53, 81, 82, 89, 317, 1033], "ndingwal": 1048, "ndirangu": [1051, 1055], "ne": [1000, 1003], "neal": [996, 1054], "near_uniqu": 326, "nearbi": [416, 1003], "nearer": [2, 856, 864, 1003], "nearest": [2, 33, 51, 53, 67, 68, 74, 75, 85, 86, 89, 93, 96, 101, 106, 111, 115, 120, 125, 128, 156, 166, 180, 188, 211, 232, 236, 242, 245, 256, 257, 271, 281, 303, 305, 308, 309, 316, 317, 324, 345, 349, 354, 358, 378, 383, 395, 398, 400, 416, 422, 423, 427, 430, 440, 452, 454, 456, 458, 460, 465, 469, 470, 504, 510, 512, 615, 616, 635, 636, 638, 639, 643, 696, 697, 699, 700, 704, 800, 801, 808, 838, 852, 853, 854, 855, 856, 858, 859, 860, 861, 862, 863, 864, 865, 866, 872, 873, 877, 892, 974, 997, 1006, 1015, 1020, 1021, 1022, 1028, 1036, 1041, 1043, 1044, 1045, 1046, 1048, 1050, 1051, 1053], "nearest_neighbor": [79, 460, 699], "nearest_neighbor_algorithm": [854, 862, 863], "nearest_neighbors_algorithm": [855, 860], "nearestcentroid": [2, 310, 360, 1001, 1003, 1041, 1045, 1048, 1053, 1056], "nearestneighbor": [2, 299, 332, 404, 416, 427, 452, 454, 456, 469, 696, 697, 701, 854, 855, 856, 858, 862, 863, 864, 1003, 1041, 1045, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "nearli": [37, 62, 281, 381, 400, 772, 1000, 1003, 1012, 1034], "neat": [1019, 1041], "necess": [997, 1003], "necessari": [46, 53, 143, 204, 220, 225, 263, 272, 278, 279, 285, 301, 353, 366, 373, 381, 384, 385, 386, 387, 388, 389, 390, 394, 398, 416, 418, 423, 460, 470, 496, 497, 499, 500, 501, 502, 503, 505, 542, 652, 653, 654, 660, 664, 665, 668, 669, 670, 671, 672, 673, 679, 681, 683, 684, 699, 703, 803, 875, 884, 895, 899, 905, 989, 992, 996, 999, 1002, 1010, 1016, 1034, 1041, 1049], "necessarili": [43, 67, 106, 128, 192, 220, 228, 238, 252, 253, 264, 321, 360, 361, 380, 390, 410, 412, 414, 416, 423, 635, 860, 862, 863, 864, 994, 997, 999, 1000], "need": [0, 30, 43, 48, 51, 68, 81, 83, 88, 90, 92, 115, 127, 137, 145, 149, 151, 152, 153, 155, 160, 174, 176, 181, 187, 188, 192, 208, 222, 237, 238, 241, 247, 250, 252, 254, 257, 258, 263, 264, 268, 269, 272, 276, 278, 280, 281, 283, 296, 298, 299, 301, 324, 328, 335, 341, 349, 360, 361, 369, 373, 374, 375, 380, 381, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 399, 400, 401, 403, 404, 407, 410, 412, 413, 414, 415, 416, 417, 419, 420, 421, 423, 424, 425, 426, 432, 445, 449, 453, 457, 472, 473, 475, 511, 549, 559, 580, 590, 591, 596, 597, 598, 599, 635, 643, 646, 647, 648, 650, 657, 674, 676, 679, 684, 687, 700, 719, 728, 729, 730, 731, 732, 789, 793, 805, 806, 808, 811, 812, 822, 823, 824, 833, 841, 844, 852, 853, 869, 872, 875, 879, 884, 885, 889, 907, 914, 917, 957, 989, 990, 992, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1011, 1013, 1014, 1015, 1016, 1020, 1024, 1031, 1032, 1033, 1034, 1041, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "needl": [174, 383], "needs_proba": [750, 1050, 1058], "needs_threshold": [750, 1058], "neeraj": 1048, "neg": [2, 42, 43, 45, 61, 95, 109, 111, 118, 145, 151, 152, 157, 189, 191, 192, 198, 210, 216, 220, 238, 267, 268, 272, 275, 278, 281, 285, 287, 288, 292, 299, 319, 323, 332, 336, 360, 392, 400, 401, 416, 420, 423, 424, 425, 427, 428, 439, 448, 452, 460, 473, 477, 490, 491, 492, 496, 539, 541, 543, 544, 545, 546, 548, 550, 552, 555, 560, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 576, 578, 596, 599, 600, 603, 604, 606, 607, 608, 610, 612, 613, 614, 615, 616, 617, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 677, 678, 680, 681, 685, 686, 687, 688, 695, 706, 707, 712, 713, 720, 721, 723, 724, 726, 727, 729, 730, 731, 732, 735, 737, 738, 739, 743, 746, 749, 751, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 766, 767, 790, 791, 792, 793, 795, 798, 799, 801, 805, 806, 814, 831, 833, 838, 845, 846, 855, 858, 863, 870, 879, 888, 890, 891, 896, 900, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 947, 949, 998, 1000, 1001, 1003, 1004, 1005, 1006, 1014, 1015, 1021, 1034, 1035, 1036, 1041, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058], "neg_": [814, 831, 1047], "neg_brier_scor": [1000, 1051], "neg_label": [272, 292, 879, 896], "neg_log_alphas_enet": 205, "neg_log_alphas_lasso": 205, "neg_log_alphas_positive_enet": 205, "neg_log_alphas_positive_lasso": 205, "neg_log_loss": [64, 272, 1000], "neg_lr": 281, "neg_lr_bas": 281, "neg_lr_base_std": 281, "neg_mean_absolute_error": [43, 160, 222, 1000], "neg_mean_absolute_percentage_error": [52, 149, 1000, 1008], "neg_mean_gamma_devi": 1000, "neg_mean_pinball_loss_05p_scor": 152, "neg_mean_pinball_loss_95p_scor": 152, "neg_mean_poisson_devi": 1000, "neg_mean_squared_error": [187, 188, 222, 253, 293, 335, 835, 1000, 1008, 1047], "neg_mean_squared_log_error": 1000, "neg_median_absolute_error": 1000, "neg_root_mean_squared_error": [43, 155, 325, 1000], "neg_root_mean_squared_log_error": 1000, "neg_root_mean_squared_log_error_scor": 1058, "negat": [400, 814, 831, 1000], "negate_scor": [253, 814, 831], "negative_class": 720, "negative_likelihood_ratio": [281, 720], "negative_linestyl": 247, "negative_loglik": 111, "negative_mahal_dist": 477, "negative_outlier_factor": 858, "negative_outlier_factor_": [257, 306, 858, 1006], "neglig": [192, 1003, 1044, 1058], "neigh": [789, 854, 855, 856, 858, 860, 862, 863, 864], "neigh_dist": [854, 855, 856, 858, 860, 862, 863, 864], "neigh_ind": [854, 855, 856, 858, 860, 862, 863, 864], "neighbor": [2, 51, 67, 74, 79, 82, 95, 101, 106, 155, 156, 158, 161, 166, 187, 188, 241, 242, 244, 245, 247, 256, 257, 271, 281, 303, 304, 305, 306, 308, 309, 310, 312, 316, 330, 332, 333, 360, 378, 383, 395, 398, 400, 404, 416, 422, 423, 424, 427, 430, 440, 449, 452, 453, 456, 458, 460, 465, 466, 469, 471, 504, 510, 512, 571, 578, 610, 615, 616, 635, 636, 639, 696, 697, 698, 699, 700, 701, 703, 704, 789, 808, 838, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 872, 873, 892, 908, 916, 974, 1001, 1006, 1020, 1021, 1022, 1028, 1033, 1035, 1036, 1041, 1043, 1044, 1045, 1046, 1047, 1048], "neighbor_feat_idx": 635, "neighborhood": [2, 90, 115, 133, 166, 189, 240, 300, 301, 302, 310, 311, 383, 400, 416, 421, 427, 452, 454, 458, 465, 510, 512, 523, 549, 557, 636, 639, 704, 838, 854, 855, 858, 860, 861, 862, 863, 864, 866, 872, 873, 892, 997, 1006, 1021, 1022, 1036, 1050], "neighborhoodcomponentanalysi": 308, "neighborhoodcomponentsanalysi": [2, 241, 307, 308, 309, 1003, 1050, 1055, 1059], "neighbors_algorithm": [696, 697], "neighborsbas": [1053, 1056], "neighborsclassifi": [860, 862, 863, 864, 1041], "neighborsregressor": 1041, "neighbour": [454, 470, 700, 1005], "neighbourhood": [861, 1003], "neighbourhood_components_analysi": 861, "neil": 1053, "neill": 1053, "neither": [188, 192, 328, 360, 369, 398, 414, 445, 602, 636, 936, 1003, 1016], "nelder": 996, "nell": [0, 74, 243, 250, 405, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1050, 1053], "nelson": [0, 1047, 1048, 1053, 1059], "nemour": 51, "neo": 1049, "nep": 1051, "neptun": 1019, "neq": [416, 1000, 1002, 1010], "ness": [188, 238], "nest": [130, 139, 189, 209, 254, 270, 272, 273, 296, 335, 374, 392, 400, 404, 416, 420, 426, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 464, 470, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 512, 527, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 811, 812, 813, 822, 830, 834, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 989, 1000, 1003, 1021, 1041, 1042, 1045, 1047, 1048, 1049, 1055], "nested_lin": 283, "nested_scor": 283, "nesterov": [315, 869, 870, 1004, 1057, 1058], "nesterovs_momentum": [315, 869, 870], "nestor": 1056, "net": [2, 25, 67, 189, 198, 204, 207, 211, 231, 251, 291, 392, 420, 479, 480, 486, 509, 532, 565, 566, 567, 568, 572, 573, 574, 654, 655, 660, 665, 666, 667, 668, 669, 670, 671, 676, 684, 686, 689, 692, 868, 920, 921, 922, 923, 989, 1000, 1005, 1014, 1021, 1022, 1024, 1036, 1041, 1046, 1050, 1051, 1053], "netbsd": 1041, "netnew": 1034, "neto": [598, 738, 1059], "nettei": 1054, "network": [34, 45, 257, 316, 373, 374, 375, 380, 381, 400, 401, 410, 416, 421, 423, 428, 504, 541, 543, 575, 576, 704, 749, 869, 870, 996, 998, 1000, 1014, 1016, 1019, 1022, 1030, 1035, 1036, 1041, 1055, 1059], "networkx": [55, 395], "neural": [34, 44, 45, 67, 278, 316, 400, 410, 420, 421, 423, 428, 541, 543, 546, 548, 555, 575, 576, 647, 653, 704, 749, 805, 861, 868, 869, 870, 878, 992, 996, 997, 998, 1000, 1003, 1006, 1010, 1014, 1016, 1019, 1022, 1024, 1030, 1035, 1036, 1041, 1053], "neural_network": [2, 67, 189, 193, 258, 313, 314, 315, 316, 317, 375, 398, 868, 869, 870, 1001, 1004, 1021, 1043, 1058], "neuraxl": 1019, "neuro": 1019, "neurodebian": 0, "neuroimag": [1018, 1024], "neuron": [869, 870, 998, 1004], "neutral": 724, "nevalu": 160, "never": [145, 255, 336, 369, 386, 395, 398, 410, 415, 416, 417, 419, 420, 458, 465, 531, 563, 564, 565, 572, 872, 873, 992, 1010, 1051, 1054], "nevertheless": [43, 195, 423], "new": [2, 43, 46, 47, 49, 85, 91, 93, 95, 104, 105, 121, 132, 139, 141, 143, 144, 145, 150, 152, 155, 159, 160, 171, 174, 176, 182, 188, 194, 195, 220, 226, 234, 247, 254, 272, 277, 280, 285, 298, 303, 305, 325, 329, 332, 335, 336, 339, 342, 348, 353, 369, 374, 375, 380, 381, 383, 384, 385, 388, 389, 390, 392, 394, 395, 399, 400, 401, 404, 410, 414, 415, 416, 417, 420, 421, 422, 423, 424, 425, 426, 441, 445, 446, 448, 450, 451, 453, 455, 456, 457, 460, 470, 471, 480, 490, 491, 492, 512, 516, 517, 542, 549, 552, 563, 564, 565, 566, 571, 572, 573, 574, 589, 610, 638, 639, 643, 648, 649, 650, 653, 654, 660, 696, 697, 698, 705, 706, 708, 709, 710, 796, 805, 806, 807, 808, 811, 812, 814, 822, 830, 831, 842, 858, 881, 882, 887, 888, 889, 891, 892, 893, 900, 901, 909, 927, 930, 935, 970, 975, 989, 990, 992, 996, 1000, 1001, 1003, 1004, 1005, 1006, 1010, 1012, 1013, 1014, 1015, 1020, 1024, 1025, 1026, 1029, 1032, 1034, 1039, 1043, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "new_data": [303, 388], "new_valu": [575, 576, 577, 578], "newaxi": [51, 53, 57, 61, 77, 115, 134, 140, 177, 201, 210, 216, 221, 222, 223, 225, 226, 237, 250, 252, 293, 304, 311, 366, 367, 413, 544, 996], "newei": 1049, "newer": [176, 385, 404, 421], "newgroups20": 235, "newli": [384, 399, 423, 471, 1007, 1047, 1048, 1056], "newsgroup": [2, 46, 54, 57, 251, 279, 342, 361, 362, 379, 413, 424, 496, 497, 1026, 1036], "newsgroups_test": 381, "newsgroups_train": [381, 496], "newsgroups_vector": 497, "newshap": 182, "newsl": [893, 1010], "newslett": 380, "newsweed": 1034, "newswir": 381, "newton": [220, 238, 317, 618, 656, 666, 667, 677, 688, 869, 870, 996, 1045, 1046, 1048, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "newton_cg": 1051, "next": [46, 62, 95, 113, 148, 149, 153, 163, 183, 191, 195, 213, 217, 220, 248, 254, 256, 260, 261, 265, 273, 284, 298, 324, 325, 326, 330, 339, 360, 364, 368, 369, 384, 386, 388, 390, 410, 413, 416, 417, 420, 423, 516, 517, 618, 642, 700, 706, 708, 710, 789, 805, 806, 838, 966, 989, 993, 999, 1000, 1010, 1024, 1027, 1038, 1041, 1054, 1055], "nezar": 1051, "nff": 707, "nfit": 339, "nfkd": [596, 597, 599, 1051], "nfor": 255, "nfrom": 181, "nft": 707, "ng": [416, 421, 699, 858, 1004, 1006, 1052], "ngiam": 1004, "ngo": 1053, "ngram_rang": [279, 342, 424, 596, 597, 599], "ngram_vector": 424, "ngroup": 273, "ngshya": 1052, "nguyen": [1051, 1052, 1055, 1056], "nguy\u1ec5n": 1056, "ni": [153, 1047, 1052], "nic": 1054, "nice": [43, 102, 221, 254, 319, 373, 421, 1034], "nicer": 639, "nichol": 1045, "nichola": [1049, 1050, 1052], "nicholson": [1047, 1048, 1049], "nick": [174, 383, 1041, 1047, 1048, 1049, 1050], "nicki": 1055, "nickledav": 1047, "nicknam": 381, "nico": [1047, 1054], "nicol": 1048, "nicola": [0, 174, 323, 405, 666, 996, 1013, 1041, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "nicolashug": 1050, "nicolasservel": 1052, "nicolau": 1049, "nicula": [0, 125, 255, 317, 405, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1050], "niculescu": [62, 64, 414, 445, 447], "nidhin": 1051, "niederb\u00fchl": 1049, "niederhut": [1049, 1051], "nielsen": [751, 1049], "nielsenmarkus11": [1048, 1049], "nigam": [847, 1002], "nigel": 1054, "night": 52, "nightli": [0, 374, 389, 390], "nightwalkx": 1057, "nihal": 1056, "nihar": 1049, "niket": 1055, "nikhil": 1055, "nikita": [1048, 1049, 1051, 1054, 1055, 1056], "nikla": [1051, 1052], "nikolai": [1044, 1045, 1046, 1047, 1049, 1050, 1055, 1057], "nil": 1053, "nilearn": 1019, "nilesh": 1049, "nilichen": 153, "nilotp": [643, 645], "nima": 1056, "nima10khodaveisi": 1056, "nimbus1after2a1sun7show": 200, "nine": 1025, "ninertia": 99, "ningchi": 1047, "ninh": 197, "ninja": [384, 1024], "nip": [132, 383, 523, 549, 574, 649, 1000], "nipal": [419, 491, 492], "nipy_spectr": [51, 74, 81, 82, 86, 87, 95, 96, 131], "nirvan": [1049, 1053], "nishan": 1051, "nishihara": 1053, "nishu": 1057, "nist": [383, 1000], "nistir": 383, "nit": 386, "nitinramvelraj": 1056, "nitish": 1048, "nitya": 1051, "niuk": 1057, "niyogi": 997, "nizam": 1049, "nizhibitski": 1042, "nk": 704, "nkish": 1052, "nkmean": 79, "nl": 392, "nl1_ratio": 211, "nlasso": 204, "nlathia": 1047, "nlearn": 315, "nlog": 182, "nlogn": 700, "nlp": [381, 421, 424, 847, 851, 998, 1024], "nls_max_it": 1046, "nltk": [424, 1018, 1019], "nm": 373, "nmcd": 113, "nmd": 243, "nmean": 129, "nmf": [2, 11, 54, 106, 392, 424, 543, 546, 552, 555, 1035, 1036, 1041, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1059], "nmf_estim": 125, "nmi": [72, 416, 725, 744, 745, 765], "nmixtur": 79, "nmle": 113, "nmse": [44, 293], "nmslib": 299, "nmslib_": 299, "nmslibtransform": 299, "nn": [256, 424, 703, 1032], "nn_candid": 290, "nn_compon": [251, 252], "nn_sampl": [251, 290], "nndsvd": [421, 546, 548, 555, 1050, 1053], "nndsvda": [54, 421, 546, 548, 555, 1050, 1053], "nndsvdar": [421, 546, 548, 555, 1050], "nneq": 707, "nnl": [215, 665], "nnlnr": [1056, 1057], "nnmf": [424, 1035, 1036, 1041], "nntp": [360, 381, 1034], "nnz": [206, 361, 381, 707], "no_chang": 909, "no_interact": [569, 570, 1056], "no_mathjax": 386, "no_structur": [79, 97], "no_valid": 388, "no_weight": 233, "no_weights_handl": 233, "noa": [1052, 1058], "noah": 996, "noc": 51, "noced": 666, "nodar": 1054, "node": [2, 51, 76, 149, 153, 204, 328, 334, 335, 364, 368, 394, 395, 416, 418, 421, 423, 449, 450, 453, 471, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 658, 662, 664, 690, 691, 700, 852, 853, 920, 921, 922, 923, 924, 926, 954, 1003, 1005, 1006, 1007, 1016, 1044, 1045, 1046, 1047, 1048, 1050, 1053, 1054, 1055, 1056, 1058], "node_count": [328, 364, 368, 920, 921, 922, 923], "node_depth": 368, "node_id": [368, 924, 926], "node_ind": 368, "node_index": 368, "node_position_model": 51, "noel": [0, 139, 140, 141, 406, 1041, 1042, 1043, 1044, 1045, 1053], "noelano": 1053, "nof": 156, "nogil": [386, 387], "noinfo": 257, "noir": 325, "nois": [44, 49, 53, 58, 59, 64, 67, 69, 75, 79, 84, 87, 89, 90, 96, 97, 102, 109, 118, 125, 126, 128, 130, 132, 140, 142, 152, 157, 158, 175, 176, 177, 181, 185, 189, 199, 201, 202, 204, 209, 210, 215, 218, 219, 222, 223, 224, 225, 237, 243, 245, 247, 249, 250, 253, 278, 286, 291, 293, 311, 314, 315, 321, 326, 329, 335, 355, 366, 367, 369, 382, 388, 391, 414, 416, 421, 423, 425, 426, 427, 452, 454, 460, 519, 521, 522, 523, 524, 525, 526, 530, 532, 533, 538, 540, 542, 549, 614, 615, 616, 617, 619, 621, 622, 623, 624, 625, 629, 630, 632, 633, 652, 653, 657, 658, 659, 661, 662, 663, 664, 671, 672, 673, 679, 687, 693, 694, 700, 889, 901, 907, 993, 995, 996, 997, 1000, 1003, 1013, 1021, 1032, 1033, 1042, 1047, 1052, 1054, 1055], "noise_coef": 89, "noise_kernel": 181, "noise_level": [176, 181, 182, 620, 633], "noise_level_bound": [181, 182, 633], "noise_level_grid": 182, "noise_std": 183, "noise_vari": [208, 540, 664, 996, 1055], "noise_variance_": [125, 208, 540, 542, 549, 664, 1048, 1055], "noise_variance_init": 540, "noiseless": [128, 998], "noisi": [44, 69, 84, 90, 97, 126, 139, 170, 176, 182, 204, 219, 222, 243, 250, 269, 279, 285, 287, 288, 324, 366, 367, 369, 416, 424, 426, 427, 452, 454, 458, 529, 532, 949, 995, 997, 1003, 1015, 1019], "noisier": 997, "noisili": 193, "noisy_circl": [79, 97], "noisy_moon": [79, 97], "noiz": 117, "nolan": 1058, "noll": [220, 238], "nomenclatur": [996, 1047], "nomin": [193, 380, 400, 401, 423, 424, 589, 590, 724, 1010, 1020], "non": [0, 2, 25, 42, 44, 45, 48, 49, 52, 53, 61, 62, 64, 69, 70, 72, 84, 92, 97, 105, 109, 113, 115, 126, 127, 128, 130, 141, 149, 157, 158, 160, 170, 171, 173, 180, 182, 188, 189, 191, 192, 193, 194, 195, 198, 199, 204, 206, 210, 213, 214, 216, 219, 221, 222, 226, 234, 235, 236, 238, 243, 244, 248, 249, 250, 251, 253, 257, 263, 265, 269, 270, 271, 272, 273, 278, 287, 296, 299, 303, 305, 317, 319, 321, 323, 324, 329, 330, 331, 332, 334, 335, 342, 344, 346, 351, 352, 353, 356, 357, 360, 361, 362, 368, 369, 373, 374, 378, 381, 382, 386, 387, 388, 391, 392, 394, 395, 398, 400, 401, 414, 416, 417, 420, 422, 423, 424, 425, 426, 428, 445, 449, 453, 454, 458, 460, 464, 470, 471, 472, 473, 475, 476, 496, 504, 505, 511, 512, 516, 534, 540, 543, 544, 546, 548, 552, 555, 557, 559, 560, 561, 565, 566, 567, 568, 569, 570, 572, 573, 574, 580, 596, 597, 599, 600, 603, 604, 605, 606, 607, 608, 611, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 638, 639, 643, 646, 651, 658, 660, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 680, 684, 685, 686, 693, 694, 695, 696, 697, 698, 699, 700, 702, 706, 707, 710, 714, 715, 720, 723, 725, 727, 728, 734, 735, 736, 743, 745, 747, 748, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 766, 767, 786, 790, 793, 796, 797, 798, 799, 802, 805, 806, 808, 809, 813, 815, 816, 817, 818, 820, 826, 834, 838, 841, 860, 862, 863, 864, 867, 872, 873, 875, 876, 877, 880, 884, 885, 886, 887, 888, 889, 891, 892, 899, 900, 901, 902, 903, 905, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 931, 932, 933, 947, 949, 953, 955, 963, 989, 990, 991, 992, 993, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1011, 1012, 1013, 1014, 1015, 1016, 1020, 1021, 1032, 1033, 1034, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "non_determinist": [388, 1055], "non_neg": [590, 1048], "non_negative_factor": [2, 1050, 1052, 1053, 1054, 1058], "non_nest": 283, "non_nested_scor": 283, "non_nested_scores_lin": 283, "non_noisy_label": 334, "non_outliers_mask": 319, "non_zero": [46, 51], "nonblasdotwarn": 1053, "none": [43, 47, 48, 49, 52, 55, 63, 66, 69, 74, 76, 77, 79, 87, 89, 90, 91, 97, 127, 130, 134, 143, 148, 149, 151, 154, 155, 167, 174, 177, 183, 184, 195, 199, 220, 221, 228, 231, 238, 240, 253, 254, 255, 257, 271, 273, 278, 279, 290, 304, 306, 310, 323, 326, 330, 331, 339, 342, 347, 349, 350, 353, 354, 355, 360, 361, 381, 383, 386, 388, 393, 395, 400, 407, 410, 416, 420, 423, 425, 426, 427, 428, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 511, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 705, 706, 708, 709, 710, 711, 715, 716, 717, 719, 720, 721, 722, 724, 726, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 740, 742, 743, 746, 747, 748, 749, 750, 751, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 795, 796, 797, 798, 799, 801, 802, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 901, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 929, 931, 932, 933, 935, 936, 937, 938, 941, 943, 948, 949, 952, 953, 954, 955, 959, 960, 963, 966, 969, 971, 974, 975, 981, 984, 985, 987, 989, 996, 1000, 1010, 1013, 1016, 1025, 1029, 1034, 1036, 1041, 1042, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "nonecheck": 387, "nonetheless": [400, 1000], "nonexist": 640, "nonflavanoid": 383, "nonlinear": [293, 331, 652, 696, 697, 701, 704, 878, 996, 997, 1005, 1010], "nonmetr": [698, 702, 997], "nonneg": [416, 421, 461, 546, 548, 555, 889], "nonner": 1052, "nono": 1027, "nonoclusteringclusteringkmeanskmeansyesyesspectralclusteringspectr": 1027, "nonoisomapisomapspectralembeddingspectr": 1027, "nonojustlookingjust": 1027, "nonolassolassoelasticnetelasticnetyesyesridgeregressionridgeregressionsvr": 1027, "nonolinearsvclinear": 1027, "nonononoyesyesmeanshiftmeanshiftvbgmmvbgmmyesyesminibatchkmeansminibatch": 1027, "nonopredict": 1027, "nonopredictingstructurepredict": 1027, "nonosvcsvcensembleclassifiersensembl": 1027, "nonosvr": 1027, "nonotoughlucktough": 1027, "nonoverlap": 383, "nonparametr": [425, 426, 615, 616], "nonzero": [55, 57, 134, 219, 251, 282, 362, 413, 427, 452, 531, 532, 539, 545, 550, 556, 596, 599, 693, 694, 707, 854, 855, 858, 860, 862, 863, 1000], "nonzero_coef": 996, "noptic": 100, "noptimum": 182, "noqa": [80, 102, 121, 131, 152, 174, 187, 188, 193, 217, 240, 242, 289, 290, 330, 360, 390, 587, 588, 635, 811, 812, 989, 1050], "nor": [152, 281, 360, 369, 373, 391, 398, 414, 424, 445, 454, 602, 936, 1004, 1016, 1052], "norbert": [0, 376, 1043, 1053, 1054, 1055], "nordbi": 1058, "nore\u00f1a": 1054, "norm": [2, 51, 53, 54, 55, 66, 70, 75, 89, 128, 179, 182, 199, 204, 206, 211, 243, 263, 264, 265, 267, 269, 275, 279, 304, 319, 349, 361, 392, 395, 400, 416, 424, 425, 450, 451, 455, 467, 468, 472, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 497, 539, 542, 545, 546, 547, 548, 549, 550, 552, 553, 554, 555, 556, 597, 598, 599, 605, 651, 654, 655, 660, 661, 665, 666, 667, 668, 669, 670, 671, 672, 680, 682, 684, 686, 689, 692, 693, 694, 698, 700, 701, 702, 778, 849, 884, 899, 912, 914, 917, 982, 983, 993, 996, 998, 1000, 1010, 1014, 1044, 1046, 1048, 1052], "norm1": 472, "norm2": 472, "norm_diag": 535, "norm_laplacian": 703, "norm_ord": [605, 1048], "norm_y_weight": 1053, "normal": [2, 25, 36, 44, 49, 51, 55, 57, 58, 63, 65, 70, 72, 75, 79, 81, 92, 96, 97, 101, 107, 109, 111, 112, 113, 117, 118, 126, 139, 140, 142, 145, 151, 152, 155, 156, 157, 169, 179, 182, 183, 188, 189, 191, 192, 198, 199, 200, 201, 202, 204, 210, 213, 215, 218, 222, 223, 224, 226, 234, 238, 243, 257, 263, 268, 269, 271, 272, 275, 278, 284, 304, 305, 308, 318, 320, 324, 329, 332, 335, 336, 341, 349, 361, 362, 369, 378, 381, 382, 383, 386, 391, 395, 399, 400, 412, 413, 414, 416, 417, 419, 422, 423, 424, 428, 448, 457, 459, 460, 461, 470, 472, 473, 483, 490, 491, 492, 497, 504, 520, 523, 527, 534, 535, 541, 544, 549, 550, 552, 556, 557, 560, 561, 562, 565, 566, 567, 568, 570, 571, 572, 573, 574, 587, 588, 590, 596, 597, 598, 599, 619, 633, 635, 647, 666, 667, 677, 680, 684, 688, 695, 699, 703, 705, 711, 712, 714, 726, 732, 734, 742, 744, 749, 753, 757, 758, 760, 763, 764, 765, 769, 778, 802, 803, 804, 811, 812, 838, 840, 849, 851, 857, 858, 861, 872, 873, 876, 877, 880, 882, 885, 886, 887, 888, 889, 890, 892, 897, 898, 900, 901, 902, 903, 907, 908, 920, 921, 922, 923, 948, 949, 953, 976, 977, 982, 983, 989, 992, 994, 996, 997, 998, 999, 1002, 1006, 1011, 1013, 1015, 1016, 1021, 1030, 1032, 1033, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "normalesup": [51, 68, 81, 101, 252], "normalis": [192, 619, 796, 1034], "normalization_": [647, 992], "normalize_compon": [1049, 1051], "normalize_i": [181, 426, 619, 1055], "normalized_discounted_cumulative_gain": 764, "normalized_mutual_info_scor": [2, 72, 416, 744, 763, 803, 1000, 1049, 1055], "normalized_stress": [240, 698, 702, 997, 1056], "normalized_weight": 201, "norms_squar": 694, "north": [383, 416], "northern": 325, "northrop": 51, "northwestern": [323, 666], "norvan": 1051, "nose": [383, 1044, 1048], "nosetest": 1043, "not_memb": 192, "notabl": [254, 319, 380, 400, 415, 504, 736, 885, 997, 999, 1003, 1045, 1048, 1055], "notarstefano": [1049, 1050], "notat": [156, 400, 417, 421, 424, 598, 720, 996, 1000, 1025, 1050, 1057], "notch": 1024, "note": [0, 30, 43, 44, 46, 47, 50, 51, 53, 57, 58, 63, 64, 68, 72, 88, 101, 105, 106, 113, 115, 117, 118, 123, 128, 142, 143, 145, 148, 152, 153, 157, 174, 176, 183, 187, 191, 192, 193, 194, 195, 197, 208, 209, 213, 220, 221, 222, 224, 228, 234, 236, 238, 240, 241, 242, 244, 247, 248, 250, 252, 253, 254, 255, 257, 264, 272, 273, 274, 278, 281, 284, 285, 286, 292, 298, 299, 301, 305, 306, 315, 319, 320, 323, 328, 329, 330, 331, 332, 333, 334, 335, 336, 339, 341, 343, 349, 353, 360, 368, 373, 374, 380, 383, 384, 386, 387, 388, 390, 392, 393, 398, 399, 400, 404, 407, 410, 411, 414, 416, 418, 419, 421, 423, 424, 425, 426, 427, 428, 429, 430, 431, 439, 441, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 467, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 495, 498, 504, 506, 512, 517, 523, 527, 535, 538, 541, 542, 546, 547, 548, 549, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 605, 607, 608, 610, 611, 612, 614, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 637, 638, 640, 641, 643, 644, 646, 649, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 703, 704, 707, 708, 715, 716, 721, 723, 728, 729, 730, 731, 732, 736, 737, 738, 740, 742, 746, 749, 754, 762, 763, 766, 771, 772, 776, 778, 782, 786, 790, 791, 792, 793, 795, 796, 797, 800, 801, 802, 804, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 822, 823, 824, 825, 826, 827, 828, 829, 830, 833, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 925, 928, 938, 939, 948, 949, 960, 963, 975, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1003, 1004, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1023, 1025, 1032, 1033, 1034, 1036, 1039, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058, 1059], "notebook": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 387, 388, 392, 417, 476, 910, 1016, 1018, 1019, 1020, 1052, 1055], "notes_neighbor": 1041, "notfittederror": [2, 137, 400, 861, 984, 1045, 1047, 1050, 1051, 1057, 1058], "noth": [57, 104, 336, 360, 361, 391, 550, 722, 875, 884, 933, 1010], "nothman": [0, 106, 401, 405, 424, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059], "notic": [46, 52, 62, 63, 70, 88, 92, 113, 142, 144, 145, 152, 155, 173, 199, 204, 247, 260, 275, 276, 278, 279, 281, 287, 288, 299, 324, 353, 360, 361, 362, 369, 388, 391, 401, 415, 420, 423, 504, 549, 571, 989, 999, 1000, 1006, 1034, 1038, 1054], "notifi": [2, 580, 581, 582, 1039, 1051], "notimplementederror": [473, 561, 562, 601, 602, 610, 899, 909, 1048, 1058], "notin": 416, "notion": [287, 353, 361, 375, 398, 416, 421, 423, 996, 1000], "notmatthancock": [1049, 1051], "noto": 1054, "noun": 400, "nouri": [373, 1042, 1044], "novak": 1044, "novarti": 51, "novaya": [1051, 1054], "novel": [234, 305, 348, 369, 414, 989], "novelti": [189, 234, 247, 257, 300, 306, 348, 858, 1021, 1022, 1035, 1036, 1041, 1049], "novemb": [174, 220, 238, 383, 1046, 1047, 1049], "novic": 1043, "now": [43, 44, 46, 52, 55, 58, 88, 92, 105, 118, 130, 139, 140, 144, 146, 148, 149, 152, 153, 160, 163, 174, 176, 181, 182, 183, 188, 191, 192, 193, 194, 197, 199, 201, 206, 208, 209, 221, 222, 224, 244, 252, 254, 272, 274, 278, 281, 289, 290, 292, 296, 302, 324, 329, 330, 332, 333, 334, 335, 336, 340, 349, 360, 361, 362, 369, 373, 375, 381, 386, 387, 388, 392, 398, 399, 400, 404, 413, 416, 420, 421, 423, 424, 428, 501, 516, 517, 520, 544, 557, 587, 588, 590, 635, 638, 657, 661, 666, 671, 692, 734, 764, 805, 806, 811, 812, 844, 859, 871, 872, 975, 989, 990, 996, 1000, 1006, 1009, 1010, 1015, 1016, 1018, 1020, 1025, 1032, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "nowadai": 386, "nozawa": [1056, 1057], "np": [2, 43, 44, 46, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 109, 111, 112, 113, 114, 115, 117, 118, 123, 126, 127, 128, 129, 131, 132, 134, 135, 140, 141, 142, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 167, 169, 170, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 199, 200, 201, 202, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 241, 242, 243, 245, 247, 250, 251, 252, 253, 254, 255, 256, 257, 259, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 293, 294, 298, 299, 303, 304, 305, 306, 308, 309, 310, 311, 312, 314, 317, 319, 320, 321, 322, 323, 324, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 347, 348, 349, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 365, 366, 367, 368, 369, 373, 380, 381, 386, 388, 391, 392, 395, 398, 400, 407, 413, 416, 417, 420, 421, 422, 423, 424, 426, 429, 430, 431, 432, 433, 434, 437, 438, 439, 440, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 493, 504, 505, 516, 517, 528, 539, 540, 541, 542, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 565, 566, 567, 568, 569, 571, 572, 573, 574, 577, 578, 589, 590, 593, 594, 596, 597, 601, 602, 605, 609, 612, 614, 617, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 649, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 676, 678, 679, 680, 682, 683, 684, 685, 686, 689, 690, 691, 692, 695, 699, 700, 702, 703, 707, 710, 711, 714, 715, 717, 720, 721, 722, 723, 734, 735, 737, 738, 740, 742, 743, 746, 747, 762, 764, 771, 777, 781, 786, 789, 790, 791, 792, 795, 796, 797, 802, 804, 805, 806, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 834, 835, 836, 838, 839, 840, 841, 844, 845, 847, 848, 849, 850, 851, 852, 853, 857, 858, 859, 860, 862, 863, 864, 868, 869, 876, 877, 879, 885, 886, 887, 888, 889, 891, 892, 893, 900, 901, 904, 905, 907, 908, 909, 912, 914, 915, 917, 918, 920, 921, 922, 923, 928, 929, 930, 931, 932, 933, 935, 937, 938, 947, 948, 949, 954, 955, 962, 963, 965, 969, 971, 974, 975, 976, 977, 978, 979, 980, 981, 986, 989, 990, 995, 996, 998, 1000, 1001, 1003, 1004, 1006, 1010, 1011, 1012, 1014, 1015, 1016, 1025, 1029, 1030, 1032, 1033, 1034, 1042, 1044, 1047, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "npach": [1056, 1057], "npo": 243, "npolynomi": 43, "nprior": 263, "npropag": 79, "nqy18": 424, "nreceiv": 287, "nrow": [43, 44, 66, 68, 70, 92, 101, 107, 125, 155, 185, 193, 220, 222, 228, 238, 240, 241, 244, 257, 272, 280, 281, 299, 321, 323, 324, 333, 339, 355, 356, 1030], "nsampl": [388, 805, 806], "nsup": 53, "nswdemand": 155, "nswprice": 155, "nt": 55, "nt_uri": 55, "ntest": 308, "ntf": 707, "nth": [285, 715, 1000], "nthe": [193, 276, 368], "ntime": [50, 289], "nto": [226, 287], "ntol": 174, "ntrain": 85, "ntree": 43, "ntrue": [45, 338, 339, 1030], "ntt": 707, "ntu": [197, 380, 495, 516, 517, 666], "nu": [2, 46, 48, 50, 185, 234, 247, 348, 373, 423, 426, 627, 685, 914, 915, 916, 1006, 1014, 1015, 1052, 1056], "nuanc": 400, "nuc": 296, "nuclear": [174, 383], "nuclei": [174, 383], "nudge_dataset": 317, "nuff": 1048, "nugmanov": [1049, 1050], "nuisanc": 426, "nukariya": [1053, 1054], "null": [79, 105, 192, 193, 194, 272, 278, 284, 416, 420, 504, 656, 677, 688, 712, 739, 765, 803, 837, 996, 997, 1000, 1015, 1051], "null_count": 52, "nullabl": [635, 636, 637, 638, 1052, 1056], "nullformatt": [240, 242, 245, 299], "nullloc": 304, "num": [43, 51, 105, 174, 176, 181, 182, 183, 193, 194, 222, 285, 286, 332, 334, 335, 423, 504, 640], "num_col": 261, "num_cor": 392, "num_depend": 272, "num_featur": [998, 1056], "num_linear_processor": 160, "num_missing_cel": 155, "num_pip": 261, "num_preprocess": 472, "num_proc": [249, 329], "num_sampl": [808, 822, 1056], "num_selector": 160, "num_sent": 104, "num_thread": 299, "num_tree_processor": 160, "num_trial": 283, "numba": [299, 1020], "number": [2, 43, 44, 46, 47, 49, 51, 52, 53, 57, 58, 62, 63, 64, 68, 69, 71, 73, 74, 76, 78, 79, 81, 82, 83, 84, 85, 88, 89, 90, 92, 96, 97, 98, 102, 104, 105, 106, 107, 109, 115, 117, 118, 122, 123, 125, 127, 129, 130, 132, 139, 140, 142, 145, 147, 148, 150, 151, 152, 153, 156, 160, 162, 170, 171, 172, 174, 184, 185, 188, 189, 192, 193, 197, 204, 209, 219, 220, 221, 222, 227, 228, 234, 235, 236, 237, 238, 240, 247, 251, 255, 257, 258, 263, 264, 266, 268, 269, 271, 272, 273, 276, 277, 278, 279, 280, 283, 284, 285, 286, 287, 296, 299, 301, 305, 306, 319, 321, 322, 325, 328, 329, 330, 331, 332, 333, 334, 336, 342, 349, 354, 356, 361, 362, 364, 368, 369, 374, 375, 378, 380, 381, 382, 383, 384, 386, 389, 390, 392, 393, 394, 395, 398, 399, 400, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 439, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 581, 589, 590, 591, 592, 596, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 707, 709, 711, 712, 713, 715, 720, 721, 722, 724, 726, 728, 732, 736, 737, 738, 739, 742, 743, 746, 748, 760, 763, 782, 786, 789, 790, 791, 792, 793, 794, 795, 796, 800, 801, 802, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 874, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 901, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 932, 933, 936, 948, 949, 952, 953, 969, 971, 974, 975, 992, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1014, 1015, 1016, 1017, 1019, 1020, 1021, 1025, 1032, 1033, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "number_norm": 57, "numbernormalizingvector": 57, "numer": [2, 43, 52, 57, 101, 105, 109, 147, 149, 160, 174, 181, 184, 193, 194, 209, 220, 238, 257, 259, 261, 309, 325, 331, 335, 362, 380, 381, 383, 389, 391, 392, 398, 399, 400, 416, 418, 423, 424, 425, 426, 428, 429, 448, 451, 455, 467, 479, 480, 483, 486, 497, 498, 499, 504, 508, 509, 510, 512, 513, 518, 539, 541, 543, 548, 549, 555, 569, 570, 575, 589, 598, 619, 625, 628, 635, 638, 640, 641, 654, 660, 662, 680, 695, 698, 702, 722, 786, 796, 802, 808, 811, 812, 814, 822, 831, 834, 835, 836, 839, 847, 848, 849, 850, 851, 869, 870, 875, 880, 885, 886, 893, 924, 925, 926, 932, 933, 948, 949, 989, 990, 996, 997, 1001, 1008, 1010, 1011, 1016, 1023, 1024, 1025, 1034, 1041, 1042, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "numeric_featur": [105, 332], "numeric_onli": 193, "numeric_preprocessor": 259, "numeric_transform": [105, 332], "numerical_column": [192, 194, 475], "numerical_columns_subset": 149, "numerical_featur": [193, 325], "numerical_pip": 194, "numerical_transform": 105, "numfocu": 0, "numpi": [2, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 109, 111, 112, 113, 114, 115, 117, 118, 121, 123, 125, 126, 127, 128, 129, 131, 132, 134, 135, 140, 141, 142, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 167, 169, 170, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 199, 200, 201, 202, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 241, 242, 243, 245, 247, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 293, 294, 298, 299, 303, 304, 305, 306, 308, 309, 310, 311, 312, 314, 317, 319, 320, 321, 322, 323, 324, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 347, 348, 349, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 365, 366, 367, 368, 369, 373, 379, 380, 381, 384, 386, 387, 388, 389, 390, 392, 394, 395, 398, 399, 400, 404, 407, 409, 410, 412, 413, 416, 417, 420, 421, 422, 423, 424, 429, 430, 431, 432, 433, 434, 437, 438, 439, 440, 447, 448, 449, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 493, 498, 501, 502, 504, 511, 514, 516, 517, 529, 535, 539, 542, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 577, 578, 589, 590, 593, 594, 596, 597, 599, 609, 612, 626, 635, 636, 637, 638, 639, 640, 641, 651, 654, 655, 657, 660, 661, 665, 666, 667, 668, 669, 670, 671, 674, 675, 676, 678, 680, 684, 685, 686, 692, 695, 696, 699, 700, 701, 702, 703, 707, 710, 711, 714, 715, 717, 720, 722, 734, 735, 737, 738, 740, 742, 743, 746, 747, 762, 764, 781, 787, 789, 790, 791, 792, 795, 796, 797, 802, 804, 805, 806, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 835, 838, 839, 840, 841, 844, 845, 847, 848, 849, 850, 851, 852, 853, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 875, 876, 879, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 912, 914, 915, 917, 918, 920, 928, 929, 930, 931, 935, 937, 946, 947, 948, 949, 953, 954, 955, 962, 963, 969, 971, 974, 975, 976, 977, 978, 979, 980, 981, 986, 987, 989, 990, 995, 996, 998, 1000, 1001, 1003, 1006, 1010, 1012, 1015, 1016, 1018, 1020, 1025, 1028, 1029, 1030, 1032, 1033, 1034, 1041, 1044, 1045, 1047, 1048, 1049, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "numpydoc": [386, 400, 404, 409], "nune": 1042, "nuniformli": 156, "nuniqu": 325, "nurseit": 1058, "nusvc": [2, 373, 445, 915, 1001, 1015, 1041, 1042, 1043, 1046, 1049, 1051, 1052, 1053, 1055], "nusvr": [2, 46, 373, 918, 1015, 1043, 1049, 1051, 1052, 1053, 1055, 1056], "nutshel": 998, "nv": 51, "nvidia": [0, 398], "nvirginica": 287, "nwanna": 1056, "nweight": 162, "nwith": [72, 92, 96, 173, 361], "nx": [50, 312, 381, 506], "nxorabl": 1051, "ny": [50, 52, 277, 312, 381, 383, 506, 990, 1012], "nyc": [1018, 1024], "nymark": 1056, "nystroem": [2, 43, 187, 234, 247, 252, 378, 648, 649, 650, 685, 878, 917, 918, 1036, 1042, 1048, 1051, 1053, 1054, 1055], "nystroem_approx_svm": 252, "nystroem_scor": 252, "nystroem_tim": 252, "nystrom": [887, 1050, 1051], "nystr\u00f6m": [43, 992], "nyu": [0, 202, 861], "nz": 538, "nzw": 1049, "n\u00e1jera": [1045, 1046, 1047, 1048], "n\u00e1pole": 1054, "o": [0, 55, 57, 64, 66, 73, 84, 90, 95, 96, 98, 99, 115, 117, 122, 127, 157, 174, 184, 208, 213, 218, 220, 235, 253, 263, 272, 278, 280, 287, 319, 320, 324, 329, 332, 335, 342, 353, 364, 373, 381, 383, 386, 404, 416, 418, 421, 423, 427, 429, 452, 455, 456, 458, 481, 483, 507, 542, 612, 635, 674, 675, 700, 840, 868, 883, 924, 969, 992, 994, 996, 997, 1000, 1001, 1003, 1004, 1014, 1015, 1016, 1041, 1044, 1047, 1049, 1050, 1053, 1054, 1056, 1057, 1058], "oa": [2, 49, 65, 70, 110, 114, 115, 132, 154, 189, 308, 310, 418, 477, 478, 481, 482, 484, 485, 520, 557, 808, 994, 1021], "oa_ms": 112, "oa_shrinkag": 112, "oak": 325, "oarc": 996, "ob2019": 1000, "obaja": 1045, "obatin": 324, "obei": [400, 998], "obj": [254, 410, 575, 576, 939, 957, 959, 960, 961, 966], "obj_func": [618, 619], "object": [2, 43, 50, 53, 54, 57, 63, 64, 79, 85, 97, 101, 104, 105, 128, 137, 155, 160, 165, 173, 181, 189, 193, 204, 216, 220, 236, 238, 246, 254, 258, 260, 261, 272, 276, 285, 287, 288, 290, 312, 325, 331, 332, 334, 335, 338, 361, 362, 369, 379, 380, 381, 386, 387, 389, 391, 392, 393, 395, 399, 400, 401, 407, 410, 416, 417, 418, 421, 424, 425, 426, 430, 432, 437, 439, 441, 442, 443, 444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 695, 696, 697, 698, 699, 700, 701, 702, 705, 706, 707, 708, 709, 710, 719, 726, 740, 741, 750, 766, 767, 789, 790, 797, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 927, 932, 933, 934, 935, 936, 939, 943, 945, 955, 956, 957, 958, 959, 960, 961, 963, 965, 966, 985, 986, 988, 996, 997, 998, 999, 1003, 1006, 1007, 1010, 1013, 1014, 1015, 1019, 1020, 1021, 1025, 1026, 1028, 1029, 1032, 1034, 1036, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "object_nam": [254, 957, 960], "obozinski": 421, "obscur": [1007, 1057], "observ": [2, 43, 44, 46, 48, 50, 52, 53, 58, 61, 64, 70, 72, 75, 78, 88, 97, 105, 111, 113, 114, 115, 126, 127, 130, 132, 139, 142, 143, 145, 146, 152, 155, 156, 159, 166, 167, 174, 176, 179, 181, 182, 183, 185, 192, 193, 194, 199, 200, 215, 216, 218, 220, 221, 222, 224, 234, 238, 244, 245, 250, 251, 257, 272, 274, 278, 280, 281, 285, 292, 299, 302, 305, 312, 324, 334, 336, 341, 348, 349, 353, 354, 360, 361, 362, 366, 367, 381, 383, 400, 404, 414, 416, 418, 419, 420, 421, 422, 425, 426, 449, 451, 453, 454, 455, 457, 467, 468, 477, 478, 479, 480, 481, 482, 483, 484, 532, 540, 559, 560, 571, 618, 619, 654, 660, 665, 709, 724, 726, 766, 829, 850, 858, 891, 893, 996, 999, 1000, 1004, 1005, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1023, 1026, 1028, 1029, 1031, 1042, 1054, 1055, 1056, 1057], "observatori": 181, "obsolet": [1041, 1057], "obstruct": 1048, "obtain": [22, 43, 46, 48, 51, 52, 58, 64, 83, 90, 92, 93, 105, 108, 109, 130, 132, 139, 149, 152, 153, 158, 165, 174, 178, 180, 192, 193, 204, 220, 222, 224, 234, 244, 257, 263, 264, 265, 272, 274, 278, 279, 280, 284, 287, 302, 324, 331, 347, 353, 361, 362, 368, 369, 381, 383, 388, 400, 410, 414, 415, 416, 418, 419, 421, 423, 424, 425, 426, 445, 450, 477, 504, 540, 541, 563, 564, 565, 566, 567, 568, 571, 572, 573, 601, 614, 622, 653, 667, 669, 674, 676, 680, 682, 684, 685, 695, 716, 720, 734, 747, 764, 801, 814, 831, 837, 840, 841, 844, 858, 869, 889, 901, 914, 917, 920, 921, 949, 990, 992, 994, 996, 997, 999, 1000, 1001, 1003, 1004, 1006, 1007, 1010, 1014, 1015, 1047, 1049, 1052, 1054, 1055, 1056, 1057, 1058], "obviat": 992, "obviou": [192, 353, 369, 373, 413, 421], "obvious": [188, 373, 1034], "oc": 1056, "occam": 1032, "occas": 386, "occasion": [401, 735, 1050], "occup": [192, 319, 335, 504], "occupation_cler": 192, "occupation_manag": 192, "occupation_oth": 192, "occupation_profession": 192, "occupation_sal": 192, "occupation_servic": 192, "occupi": [416, 1000], "occur": [54, 104, 150, 220, 224, 238, 356, 369, 386, 388, 394, 401, 413, 416, 418, 420, 424, 452, 516, 517, 580, 589, 598, 635, 679, 806, 808, 811, 812, 814, 822, 831, 834, 835, 836, 839, 882, 937, 1000, 1002, 1010, 1034, 1041, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "occurr": [2, 220, 325, 361, 362, 381, 386, 416, 424, 577, 578, 589, 597, 598, 625, 635, 636, 637, 638, 791, 847, 875, 1002, 1042, 1047], "ocean": 312, "ocsvm": [48, 234], "oct": [700, 777, 997, 1003], "octob": [112, 381, 1041, 1048, 1054, 1055, 1057], "od280": 383, "od315": 383, "odd": [281, 423, 522, 720, 1000, 1048, 1049], "ofcategoriesknownnumb": 1027, "off": [44, 51, 53, 72, 74, 75, 82, 83, 87, 88, 111, 115, 117, 125, 145, 155, 173, 174, 189, 224, 241, 252, 256, 270, 271, 277, 279, 280, 281, 296, 319, 336, 339, 341, 343, 349, 358, 360, 381, 386, 388, 400, 415, 416, 418, 425, 450, 504, 561, 562, 567, 568, 596, 599, 642, 664, 666, 700, 723, 805, 806, 808, 811, 812, 822, 824, 830, 835, 873, 892, 953, 999, 1005, 1015, 1020, 1021, 1041, 1045, 1046, 1048], "offer": [43, 145, 388, 394, 398, 399, 400, 404, 410, 420, 421, 423, 424, 989, 990, 1001, 1004, 1016, 1019, 1020, 1024, 1047, 1059], "offic": 1024, "offici": [381, 388, 398, 400, 404, 501, 505, 1019, 1034, 1049, 1050, 1053], "offlin": [272, 373, 386], "offset": [142, 197, 398, 418, 421, 477, 516, 517, 571, 640, 641, 649, 650, 652, 653, 685, 736, 783, 785, 858, 916, 1000, 1014, 1032, 1049], "offset_": [477, 571, 685, 858, 916, 1049], "offset_init": 685, "offsetbox": 241, "offsetimag": 241, "ofmulticlass": 1015, "often": [43, 57, 61, 62, 64, 69, 104, 108, 145, 155, 158, 180, 187, 192, 193, 221, 238, 241, 257, 265, 280, 283, 319, 324, 349, 358, 360, 361, 362, 373, 374, 380, 381, 383, 386, 388, 391, 394, 398, 399, 400, 403, 410, 414, 416, 417, 418, 420, 421, 423, 424, 426, 428, 476, 529, 532, 541, 544, 640, 654, 655, 660, 661, 668, 669, 670, 671, 680, 682, 695, 736, 882, 890, 898, 910, 989, 990, 992, 995, 996, 997, 998, 999, 1000, 1002, 1003, 1005, 1006, 1007, 1010, 1013, 1014, 1016, 1025, 1027, 1032, 1033, 1034, 1042, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "og": 424, "ogbonna": 1054, "ogordon100": 1054, "ogrid": 53, "ogu": 424, "ogura": 1056, "oh": [885, 1051], "ohad": 1055, "ohayon": [1049, 1050, 1057], "ohio": 381, "ohno": 414, "oj_lappi": 1053, "oja": [428, 541], "ojala": [284, 420, 837], "ojeda": 1055, "ok": [49, 386, 1006], "okal": 1045, "okbalefthand": 1047, "okhlopkov": [1047, 1048], "okon": 1055, "okroshiashvili": 1054, "ol": [199, 210, 215, 217, 218, 226, 237, 331, 664, 996], "ol2001": 990, "olatunji": 1056, "old": [238, 386, 390, 392, 416, 476, 544, 654, 660, 910, 997, 1020, 1041, 1046, 1047, 1049, 1054, 1055, 1056], "olden": 1049, "older": [222, 254, 385, 390, 410, 472, 1023, 1039, 1044, 1051, 1053], "oldest": [390, 504], "oldid": 1000, "oldja": 1053, "oleg": 1051, "oleggio": 1045, "olegovich": 1048, "oleh": [1053, 1055], "oleksandr": [1049, 1050, 1051, 1052, 1055], "oleksii": 1058, "olemiss": 687, "olga": [636, 990], "oli": 1048, "oliblum90": [1048, 1049], "olicairn": 1052, "olimpio": 1049, "oliph": 1041, "oliv": [341, 343, 1049, 1050, 1052, 1053, 1054], "oliveira": [1047, 1049, 1051, 1055], "olivetti": [2, 125, 147, 379, 421, 503, 1036, 1041, 1049], "olivetti_fac": 503, "olivi": [0, 54, 55, 72, 83, 96, 209, 241, 279, 281, 360, 361, 362, 401, 405, 908, 1013, 1018, 1020, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "oll": 1056, "olr": 199, "olsen": 1048, "olshen": [920, 921, 1016], "olson": 1047, "olszewski": 1054, "olvi": [174, 383], "om": 1048, "omar": [0, 405, 1051, 1056, 1057, 1058, 1059, 1060], "omarmanzoor": 1057, "omega": [356, 419, 994], "omega_": 994, "omega_k": [419, 994], "omer": 1046, "omit": [146, 191, 192, 343, 391, 429, 483, 542, 674, 676, 684, 815, 817, 840, 841, 844, 847, 848, 849, 850, 851, 869, 998, 1005], "omohundro": 1003, "omp": [2, 128, 134, 219, 421, 539, 545, 550, 556, 672, 673, 693, 694, 1022, 1036, 1041, 1049], "omp_cv": 219, "omp_get_max_thread": 387, "omp_num_thread": 374, "omtcyfz": 1048, "onc": [2, 43, 47, 52, 85, 171, 174, 176, 181, 241, 254, 257, 272, 276, 279, 292, 296, 299, 325, 328, 332, 360, 362, 368, 369, 373, 375, 380, 381, 384, 386, 390, 391, 392, 393, 394, 399, 400, 401, 410, 415, 416, 417, 419, 420, 421, 423, 424, 425, 426, 457, 459, 461, 480, 516, 517, 546, 552, 559, 567, 568, 598, 599, 605, 619, 627, 635, 655, 659, 661, 663, 669, 671, 673, 674, 675, 676, 684, 685, 686, 705, 720, 724, 726, 744, 789, 809, 813, 816, 826, 830, 847, 848, 849, 850, 851, 924, 996, 997, 1003, 1010, 1014, 1015, 1016, 1025, 1034, 1038, 1041, 1049, 1051, 1052, 1053, 1054, 1058], "one": [0, 2, 30, 43, 47, 48, 49, 52, 54, 55, 62, 63, 64, 68, 69, 70, 72, 75, 82, 88, 90, 92, 93, 95, 96, 99, 101, 105, 114, 120, 121, 122, 125, 128, 130, 134, 144, 145, 150, 152, 155, 156, 160, 163, 173, 174, 176, 183, 184, 187, 191, 192, 193, 194, 195, 197, 199, 200, 204, 209, 210, 212, 213, 214, 216, 220, 222, 229, 230, 235, 238, 242, 247, 254, 255, 257, 265, 268, 272, 274, 275, 276, 278, 279, 281, 282, 285, 286, 287, 288, 296, 298, 299, 304, 317, 320, 321, 324, 325, 328, 330, 331, 332, 336, 341, 348, 349, 357, 360, 361, 362, 364, 368, 369, 373, 374, 375, 380, 381, 382, 383, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 400, 401, 403, 404, 407, 410, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 452, 453, 454, 455, 457, 458, 459, 460, 461, 463, 464, 465, 468, 470, 472, 477, 482, 495, 496, 498, 499, 500, 501, 502, 503, 504, 508, 509, 510, 511, 512, 513, 516, 517, 518, 520, 522, 542, 547, 548, 549, 551, 555, 559, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 577, 589, 591, 592, 596, 597, 598, 599, 618, 619, 623, 624, 628, 635, 638, 640, 641, 642, 643, 651, 655, 656, 657, 658, 662, 665, 666, 667, 669, 674, 676, 677, 679, 681, 682, 683, 684, 686, 688, 696, 700, 703, 707, 711, 717, 719, 728, 737, 738, 742, 746, 758, 759, 762, 771, 779, 782, 786, 787, 788, 789, 791, 792, 795, 796, 798, 799, 800, 801, 804, 805, 806, 807, 808, 811, 812, 814, 815, 816, 818, 820, 822, 826, 827, 830, 831, 833, 835, 836, 838, 839, 840, 841, 842, 844, 845, 852, 853, 854, 855, 856, 857, 858, 860, 861, 862, 863, 864, 868, 872, 875, 876, 877, 879, 880, 882, 883, 884, 885, 886, 891, 892, 893, 896, 898, 912, 914, 915, 916, 917, 918, 920, 921, 922, 923, 928, 938, 941, 951, 971, 989, 990, 992, 994, 995, 997, 998, 999, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1014, 1015, 1016, 1017, 1018, 1019, 1024, 1025, 1027, 1029, 1031, 1032, 1033, 1034, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "one_class": 255, "one_hot": [325, 336], "one_hot_encod": [43, 149], "one_hot_encoder_": 574, "one_hot_linear_pipelin": 43, "one_hot_linear_predict": 43, "one_hot_poly_pipelin": 43, "one_hot_poly_predict": 43, "one_hot_result": 149, "one_hot_tim": 43, "one_imag": [424, 592, 595], "one_vs_on": [426, 618, 1001], "one_vs_rest": [618, 1001], "oneclasssvm": [2, 48, 50, 234, 247, 331, 348, 571, 685, 858, 1006, 1014, 1015, 1043, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056], "oned": 404, "onehot": [259, 320, 321, 417, 877, 1010], "onehot_categor": [220, 238], "onehotencod": [2, 43, 105, 144, 149, 160, 192, 193, 220, 238, 249, 257, 259, 261, 325, 329, 331, 334, 335, 336, 380, 400, 417, 423, 474, 475, 574, 589, 590, 875, 879, 880, 883, 886, 893, 990, 1010, 1042, 1045, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "onehotencoderonehotencod": [105, 144, 160, 192, 193, 249, 259, 329, 332], "ones": [43, 50, 70, 78, 90, 105, 114, 150, 156, 176, 197, 204, 224, 225, 247, 250, 254, 278, 286, 289, 306, 323, 339, 358, 373, 374, 386, 394, 400, 416, 418, 420, 423, 431, 434, 438, 458, 540, 574, 589, 618, 619, 626, 652, 653, 666, 667, 678, 684, 711, 804, 810, 815, 826, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 887, 891, 954, 996, 1000, 1005, 1006, 1010, 1015, 1032, 1041, 1049, 1050, 1051], "onetoonefeaturemixin": [2, 388, 440], "onevsoneclassifi": [2, 296, 407, 841, 842, 1042, 1044, 1045, 1047, 1048, 1050, 1053, 1055, 1058], "onevsrestclassifi": [2, 66, 212, 235, 255, 285, 287, 296, 407, 414, 666, 667, 840, 842, 912, 1025, 1042, 1043, 1045, 1047, 1048, 1054, 1055, 1058, 1059], "ong": 716, "ongari": 1058, "onggo": 1057, "ongo": [334, 387, 401], "onli": [2, 25, 30, 43, 46, 50, 53, 54, 58, 61, 62, 63, 64, 66, 69, 70, 72, 74, 75, 80, 84, 88, 90, 93, 101, 104, 105, 106, 108, 109, 114, 121, 128, 129, 131, 135, 139, 141, 146, 147, 148, 149, 151, 159, 160, 169, 170, 171, 174, 176, 178, 183, 185, 188, 189, 191, 192, 193, 197, 198, 203, 204, 209, 216, 220, 221, 223, 226, 228, 229, 238, 240, 241, 247, 249, 251, 253, 254, 258, 261, 263, 264, 265, 268, 269, 272, 274, 276, 278, 280, 281, 284, 285, 286, 287, 289, 290, 292, 296, 298, 299, 305, 307, 310, 312, 316, 319, 320, 324, 325, 330, 331, 338, 339, 341, 345, 346, 349, 353, 354, 356, 357, 360, 361, 362, 364, 365, 368, 369, 373, 374, 375, 379, 380, 381, 383, 384, 386, 388, 390, 391, 392, 393, 394, 395, 398, 400, 401, 404, 407, 410, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 431, 432, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 467, 469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 497, 498, 499, 500, 502, 504, 505, 508, 509, 510, 511, 512, 513, 516, 517, 518, 520, 524, 527, 531, 532, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 707, 715, 717, 721, 734, 737, 738, 742, 744, 745, 746, 749, 750, 751, 764, 766, 768, 782, 786, 787, 788, 789, 791, 792, 795, 796, 800, 801, 802, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 817, 822, 826, 830, 831, 833, 834, 835, 836, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 867, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 928, 930, 931, 932, 933, 936, 938, 941, 949, 951, 954, 956, 961, 966, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1019, 1020, 1021, 1024, 1032, 1033, 1034, 1038, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1053, 1055, 1056, 1057, 1058, 1059], "onlin": [2, 44, 47, 54, 71, 86, 125, 128, 189, 198, 228, 234, 256, 272, 315, 375, 381, 385, 391, 400, 416, 421, 424, 426, 450, 454, 455, 457, 503, 510, 539, 544, 545, 546, 547, 553, 554, 590, 592, 666, 674, 675, 676, 684, 686, 838, 847, 848, 849, 850, 851, 854, 855, 860, 862, 863, 881, 882, 892, 912, 913, 992, 996, 1004, 1006, 1018, 1021, 1022, 1024, 1032, 1036, 1041, 1045, 1046, 1048, 1056], "onlineldavb": 544, "only_non_neg": 1054, "only_physical_cor": 145, "onnx": [1019, 1020, 1036], "onnxruntim": 410, "onto": [118, 241, 242, 252, 319, 398, 421, 424, 428, 454, 456, 469, 541, 547, 551, 635, 636, 638, 696, 994, 998, 1003], "onward": [886, 1045, 1059], "onx": 410, "oob": [138, 151, 189, 423, 523, 572, 1020, 1021, 1043, 1054, 1058], "oob_best_it": 151, "oob_color": 151, "oob_decision_function_": [563, 565, 572], "oob_error": 143, "oob_improvement_": [151, 423, 567, 568, 1043], "oob_lin": 151, "oob_prediction_": [564, 566, 573], "oob_scor": [143, 423, 563, 564, 565, 566, 572, 573, 1046, 1048], "oob_score_": [143, 563, 564, 565, 566, 567, 568, 572, 573, 1043, 1057], "oob_scores_": [567, 568, 1057], "op": [390, 435, 666, 667, 674, 675, 676, 684, 685, 686, 869, 870, 912, 1010], "opaqu": 1008, "open": [47, 51, 55, 242, 380, 381, 384, 385, 386, 390, 392, 398, 399, 401, 410, 417, 424, 495, 504, 516, 517, 990, 1019, 1024, 1028, 1044, 1048, 1049, 1051, 1057], "open_pric": 51, "openbla": [373, 374, 384, 398, 1054, 1058, 1059], "openblas_num_thread": 374, "opencv": 381, "opengl": 1034, "opengraph": [386, 404, 409], "openml": [2, 43, 52, 105, 160, 181, 192, 220, 228, 236, 238, 248, 272, 292, 296, 298, 316, 379, 404, 504, 1036, 1049, 1051, 1054], "openml100": 380, "openmp": [329, 384, 389, 398, 400, 416, 423, 1052, 1054, 1057], "openrec": 1019, "opentsn": 700, "oper": [2, 19, 53, 57, 174, 184, 189, 248, 253, 260, 270, 272, 273, 275, 285, 362, 373, 374, 383, 384, 386, 389, 392, 398, 400, 401, 404, 410, 412, 415, 420, 421, 423, 424, 425, 429, 456, 469, 476, 483, 490, 491, 492, 493, 512, 541, 542, 549, 559, 560, 574, 580, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 624, 629, 632, 638, 643, 651, 666, 697, 701, 710, 714, 715, 716, 735, 782, 789, 790, 796, 797, 827, 838, 841, 852, 853, 875, 879, 884, 895, 896, 910, 917, 920, 951, 973, 996, 1003, 1010, 1015, 1019, 1021, 1024, 1032, 1045, 1047, 1048, 1049, 1051, 1052, 1057], "operand": 426, "operation": [238, 1024], "operatornam": [421, 749, 996, 1000, 1016], "opinion": 401, "opitz": 1000, "opportun": [542, 1014], "oppos": [102, 254, 390, 412, 416, 908, 1003, 1015, 1025, 1041, 1059], "opposit": [62, 88, 102, 130, 192, 193, 209, 272, 285, 400, 414, 418, 420, 425, 451, 455, 457, 477, 546, 548, 555, 571, 720, 738, 858, 916, 1041], "opposite_lof_scor": 858, "opt": [384, 388], "opta": 905, "optic": [2, 71, 79, 189, 332, 341, 379, 427, 452, 454, 463, 464, 465, 510, 1021, 1035, 1036, 1050, 1054, 1055, 1056, 1057, 1058, 1059], "optim": [46, 52, 53, 64, 88, 89, 92, 95, 106, 111, 112, 125, 150, 151, 153, 155, 173, 174, 176, 177, 180, 181, 182, 183, 184, 204, 208, 209, 213, 228, 236, 253, 257, 272, 276, 283, 286, 291, 292, 296, 298, 303, 317, 319, 324, 332, 336, 341, 351, 356, 360, 361, 362, 369, 373, 380, 383, 386, 388, 389, 398, 400, 404, 411, 413, 415, 416, 418, 420, 421, 423, 425, 426, 427, 452, 455, 456, 457, 458, 460, 465, 469, 470, 480, 481, 487, 539, 542, 543, 545, 547, 551, 565, 566, 567, 568, 582, 618, 619, 627, 628, 643, 646, 648, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 677, 678, 680, 681, 682, 684, 685, 686, 688, 689, 690, 691, 692, 695, 698, 700, 702, 703, 709, 731, 738, 807, 808, 822, 830, 854, 855, 856, 858, 860, 861, 862, 863, 864, 869, 870, 888, 900, 904, 905, 912, 913, 914, 915, 916, 917, 918, 992, 993, 994, 995, 996, 997, 1000, 1001, 1002, 1003, 1004, 1005, 1014, 1015, 1016, 1019, 1024, 1029, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1055, 1056, 1057], "optima": 426, "optimis": [388, 416, 1003, 1044, 1054, 1056], "optimist": [52, 209, 283, 360, 369, 715, 996, 1000], "optimum": [96, 182, 192, 197, 272, 291, 415, 421, 480, 996, 999], "option": [2, 43, 66, 81, 87, 132, 145, 153, 182, 188, 201, 204, 221, 257, 272, 281, 287, 329, 336, 360, 364, 369, 375, 380, 381, 382, 384, 386, 387, 389, 391, 392, 394, 395, 398, 400, 401, 404, 416, 417, 419, 420, 421, 423, 424, 427, 440, 445, 449, 450, 451, 452, 453, 454, 455, 456, 457, 460, 467, 469, 470, 471, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 593, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 695, 696, 697, 698, 700, 702, 703, 719, 721, 725, 737, 738, 743, 744, 745, 765, 766, 767, 772, 774, 775, 779, 782, 783, 784, 785, 786, 789, 791, 792, 795, 800, 801, 803, 807, 809, 810, 811, 812, 814, 815, 817, 826, 830, 831, 836, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 859, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 901, 904, 905, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 939, 986, 989, 990, 996, 999, 1000, 1003, 1010, 1013, 1015, 1016, 1020, 1032, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "option_context": 238, "ora": 1054, "oracl": [2, 69, 220, 238, 429, 477, 478, 481, 482, 483, 484, 994, 1041], "orallo": 1000, "orang": [46, 48, 88, 113, 123, 126, 127, 132, 139, 154, 155, 157, 183, 188, 208, 209, 230, 255, 266, 272, 310, 329, 335, 367, 1001, 1058], "orazbayev": 1055, "orbit": [360, 361], "order": [2, 43, 53, 58, 61, 64, 82, 90, 99, 100, 106, 111, 120, 134, 147, 148, 149, 153, 155, 167, 181, 191, 192, 195, 197, 209, 213, 216, 220, 221, 226, 234, 238, 242, 251, 254, 257, 261, 265, 273, 276, 278, 285, 298, 317, 319, 324, 325, 326, 330, 331, 336, 356, 360, 362, 369, 373, 374, 381, 386, 387, 388, 391, 392, 395, 400, 404, 407, 410, 416, 417, 418, 420, 421, 422, 423, 424, 426, 428, 448, 451, 454, 455, 457, 458, 463, 464, 465, 467, 472, 496, 497, 498, 503, 505, 523, 542, 543, 547, 548, 549, 551, 555, 559, 561, 563, 564, 565, 566, 567, 571, 572, 573, 574, 575, 589, 596, 599, 601, 602, 605, 614, 615, 616, 618, 630, 635, 639, 648, 666, 667, 673, 684, 693, 694, 696, 697, 701, 705, 707, 708, 710, 712, 720, 721, 726, 730, 734, 737, 738, 746, 748, 749, 750, 762, 764, 786, 790, 791, 792, 795, 796, 797, 802, 807, 808, 809, 811, 812, 813, 815, 819, 822, 826, 827, 830, 833, 840, 841, 843, 844, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 862, 869, 872, 883, 885, 886, 887, 891, 892, 893, 896, 897, 898, 900, 901, 902, 903, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 932, 933, 938, 949, 964, 969, 990, 996, 997, 1000, 1001, 1003, 1004, 1010, 1013, 1014, 1015, 1016, 1020, 1029, 1031, 1032, 1034, 1041, 1043, 1044, 1045, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "order_": [843, 846], "order_centroid": 361, "ordered_sampl": 238, "ordereddict": 143, "ordering_": [100, 416, 458, 463, 464, 465], "ordin": [43, 88, 105, 160, 257, 322, 325, 326, 330, 333, 380, 400, 423, 504, 575, 717, 877, 880, 885, 886, 893, 996, 997, 1010, 1020, 1049, 1055], "ordinal_encod": [149, 257], "ordinal_result": 149, "ordinalencod": [2, 149, 160, 193, 194, 220, 257, 325, 333, 380, 400, 589, 848, 880, 885, 893, 990, 1002, 1010, 1049, 1050, 1053, 1054, 1055, 1056, 1057, 1058], "ordinalencoderordinalencod": [160, 193, 194, 325], "ordinari": [2, 127, 189, 198, 199, 202, 204, 210, 216, 222, 223, 225, 237, 331, 643, 654, 660, 662, 663, 664, 665, 680, 686, 690, 691, 695, 1014, 1021, 1022, 1036], "ordinarili": [398, 400], "ordowski": 1000, "oregon": 325, "oren": 1049, "oresti": 1050, "orfano": [1054, 1055, 1056, 1057, 1058], "org": [43, 51, 53, 54, 55, 61, 63, 68, 72, 81, 83, 96, 101, 105, 106, 144, 146, 147, 156, 157, 160, 163, 171, 181, 185, 192, 193, 194, 197, 201, 211, 212, 220, 228, 236, 238, 241, 248, 249, 250, 252, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 281, 285, 290, 292, 298, 316, 317, 325, 329, 330, 332, 333, 335, 338, 339, 340, 343, 360, 361, 362, 368, 374, 379, 384, 386, 389, 392, 394, 401, 420, 603, 644, 676, 679, 684, 703, 713, 777, 854, 855, 860, 861, 862, 863, 890, 906, 920, 921, 996, 1000, 1016, 1036, 1049, 1053], "organ": [0, 50, 52, 104, 113, 360, 380, 385, 386, 401, 860, 1019], "ori": 1047, "orient": [66, 125, 192, 240, 319, 400, 924, 997], "orig": [53, 306], "orig_coin": [81, 82], "orig_data_ax": 130, "origin": [43, 44, 53, 58, 59, 81, 82, 83, 86, 91, 93, 108, 109, 121, 125, 127, 128, 134, 155, 158, 170, 171, 174, 176, 178, 180, 181, 187, 188, 193, 197, 208, 209, 224, 240, 241, 242, 244, 245, 251, 252, 253, 257, 269, 272, 275, 281, 302, 307, 317, 320, 324, 334, 339, 353, 360, 362, 369, 374, 381, 383, 385, 386, 388, 390, 391, 398, 400, 410, 413, 416, 417, 420, 421, 423, 424, 426, 427, 428, 429, 441, 445, 449, 451, 452, 453, 454, 455, 457, 458, 467, 471, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 501, 502, 503, 509, 527, 539, 541, 542, 543, 545, 546, 547, 548, 549, 551, 552, 553, 554, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 581, 584, 589, 590, 592, 596, 598, 599, 602, 615, 616, 618, 619, 622, 638, 640, 643, 646, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 700, 704, 709, 736, 771, 777, 807, 809, 810, 815, 817, 826, 830, 837, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 858, 859, 862, 863, 869, 870, 872, 875, 876, 877, 878, 879, 880, 881, 884, 885, 886, 888, 889, 890, 891, 892, 901, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 930, 932, 933, 937, 938, 959, 971, 974, 993, 994, 996, 997, 999, 1000, 1003, 1006, 1011, 1012, 1013, 1014, 1017, 1019, 1024, 1025, 1034, 1044, 1045, 1047, 1049, 1051, 1053, 1055, 1057], "original_param": 154, "original_shap": 83, "original_sklearn_vers": [410, 584], "original_space_centroid": 361, "orii": 1043, "orphan": [456, 469, 1041], "orr": [1004, 1014], "orr\u00f9": 1044, "orthogon": [2, 37, 126, 127, 128, 134, 189, 198, 291, 421, 534, 539, 545, 547, 550, 551, 556, 672, 673, 693, 694, 1012, 1021, 1022, 1036, 1041], "orthogonal_mp": [2, 556, 672, 673, 694, 996], "orthogonal_mp_gram": [2, 672, 673, 693, 1055], "orthogonalmatchingpursuit": [2, 219, 673, 693, 694, 996, 1001, 1041, 1043, 1046, 1049, 1054, 1059], "orthogonalmatchingpursuitcv": [2, 219, 407, 672, 1043, 1054, 1058], "orthonorm": [2, 45, 395, 948, 992, 1030], "orthotrop": 1003, "ortiz": [1051, 1057], "osa": 1049, "osaid": 1049, "osborn": [1044, 1045], "oscar": [1044, 1048], "oscil": [157, 193, 225, 416, 448], "oscillatori": [221, 1010], "osei": 1055, "osendorf": [1041, 1042], "oserror": [404, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506], "osindero": [868, 1005], "osman": [1050, 1056], "osx": 373, "other": [0, 2, 25, 43, 47, 51, 52, 61, 64, 66, 67, 69, 72, 75, 79, 87, 92, 101, 103, 105, 106, 118, 127, 128, 130, 132, 142, 144, 145, 148, 149, 152, 153, 155, 156, 162, 169, 187, 188, 189, 191, 192, 193, 194, 197, 199, 213, 220, 224, 238, 240, 241, 242, 244, 247, 248, 249, 251, 253, 254, 257, 258, 265, 268, 272, 273, 275, 278, 279, 280, 287, 288, 292, 296, 304, 305, 306, 318, 319, 323, 324, 326, 328, 329, 331, 335, 336, 338, 349, 353, 355, 358, 360, 361, 364, 368, 369, 373, 378, 379, 381, 382, 383, 384, 386, 388, 390, 391, 392, 394, 395, 399, 400, 401, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 424, 425, 426, 427, 445, 451, 452, 454, 455, 456, 457, 458, 460, 465, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 496, 504, 505, 511, 541, 542, 543, 549, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 597, 598, 599, 602, 605, 610, 618, 619, 620, 621, 628, 635, 636, 638, 643, 647, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 698, 700, 704, 707, 712, 726, 771, 782, 786, 793, 800, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 822, 825, 826, 827, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 867, 869, 870, 872, 873, 875, 877, 878, 879, 881, 882, 884, 885, 886, 888, 889, 890, 891, 892, 893, 900, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 943, 957, 989, 990, 992, 993, 994, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1020, 1021, 1022, 1023, 1024, 1025, 1029, 1032, 1033, 1036, 1042, 1044, 1045, 1047, 1048, 1049, 1050, 1054, 1055, 1056, 1057, 1058], "other_parti": 272, "other_payment_plan": 272, "other_scor": 391, "otherwis": [50, 91, 97, 141, 185, 188, 201, 222, 228, 272, 312, 353, 356, 369, 375, 388, 390, 392, 400, 407, 416, 418, 420, 424, 426, 441, 442, 443, 444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 457, 459, 461, 462, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 504, 535, 541, 542, 543, 544, 546, 548, 549, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 598, 599, 602, 605, 610, 618, 619, 622, 639, 640, 641, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 693, 694, 698, 700, 704, 705, 706, 708, 710, 711, 715, 717, 721, 722, 732, 734, 735, 736, 737, 738, 746, 749, 760, 762, 763, 764, 774, 782, 786, 789, 790, 791, 792, 793, 795, 796, 797, 800, 801, 802, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 822, 826, 827, 830, 831, 836, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 867, 869, 870, 872, 875, 876, 877, 878, 879, 883, 884, 891, 892, 893, 894, 897, 898, 899, 901, 902, 903, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 925, 927, 933, 935, 948, 949, 959, 961, 984, 986, 995, 996, 997, 1000, 1003, 1004, 1006, 1007, 1010, 1012, 1014, 1015, 1019, 1024, 1025, 1043, 1049, 1050, 1051, 1054, 1057], "ott": 1045, "oudshoorn": [635, 990], "ought": 373, "our": [0, 43, 44, 46, 50, 51, 52, 77, 88, 91, 104, 105, 113, 114, 118, 125, 126, 139, 140, 146, 149, 150, 152, 153, 169, 174, 176, 181, 183, 189, 191, 192, 193, 194, 195, 220, 224, 238, 242, 244, 254, 271, 272, 278, 281, 284, 285, 302, 316, 319, 325, 329, 331, 336, 343, 346, 352, 354, 356, 360, 361, 362, 369, 374, 385, 390, 391, 394, 398, 399, 400, 401, 407, 416, 420, 423, 424, 426, 427, 452, 458, 571, 652, 700, 716, 728, 734, 746, 764, 854, 855, 856, 858, 860, 862, 863, 864, 989, 990, 996, 997, 1000, 1006, 1010, 1013, 1014, 1015, 1020, 1023, 1024, 1025, 1032, 1033, 1034, 1048, 1049, 1051, 1052, 1055, 1056, 1058], "our_rand_r": 1050, "oura": [1054, 1055, 1056], "ourselv": 1024, "ouss1508": [1056, 1057], "out": [0, 2, 42, 43, 46, 48, 49, 51, 52, 54, 55, 63, 66, 75, 85, 90, 91, 104, 105, 132, 137, 138, 143, 145, 146, 153, 154, 167, 184, 189, 191, 192, 194, 204, 220, 222, 224, 228, 238, 254, 257, 263, 265, 272, 276, 278, 281, 286, 290, 296, 298, 324, 325, 331, 341, 343, 345, 346, 349, 356, 360, 372, 381, 383, 384, 386, 388, 389, 390, 392, 398, 400, 410, 416, 419, 421, 423, 424, 426, 432, 442, 443, 444, 450, 451, 453, 454, 455, 457, 480, 490, 491, 492, 493, 507, 523, 524, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 596, 597, 599, 612, 615, 616, 642, 647, 648, 649, 650, 659, 663, 674, 676, 681, 683, 684, 696, 697, 700, 709, 735, 749, 750, 808, 810, 811, 812, 813, 815, 816, 817, 818, 822, 838, 847, 848, 849, 850, 851, 856, 861, 864, 868, 869, 870, 878, 882, 889, 901, 904, 905, 927, 962, 964, 969, 990, 994, 995, 999, 1000, 1001, 1003, 1008, 1010, 1020, 1021, 1022, 1024, 1027, 1029, 1032, 1034, 1036, 1041, 1043, 1045, 1047, 1049, 1050, 1053, 1054, 1057, 1059], "out_activation_": [869, 870], "out_bounds_predict": 222, "out_fil": [924, 1016], "out_of_bound": [250, 643], "out_of_cluster_doc": 57, "outcom": [43, 145, 192, 400, 423, 577, 666, 717, 750, 802, 840, 907, 908, 909, 914, 917, 996, 1000, 1016, 1023, 1027, 1034, 1045, 1049, 1051], "outdat": 389, "outer": [58, 130, 283, 340, 459, 522, 648, 658, 659, 662, 992, 1042], "outer_cv": [283, 335], "outer_numb": 340, "outermost": 353, "outli": [48, 113, 400, 477, 482, 996, 1006], "outlier": [2, 42, 70, 79, 89, 113, 114, 152, 156, 176, 189, 198, 218, 222, 223, 224, 225, 226, 234, 246, 300, 318, 323, 326, 348, 358, 381, 400, 416, 418, 423, 438, 454, 472, 474, 477, 478, 481, 482, 483, 484, 498, 499, 500, 504, 518, 520, 530, 532, 571, 639, 647, 657, 678, 679, 680, 684, 685, 686, 687, 700, 710, 838, 858, 862, 873, 881, 882, 884, 885, 886, 888, 889, 890, 891, 892, 897, 898, 899, 900, 901, 902, 903, 915, 916, 918, 1000, 1014, 1015, 1019, 1021, 1022, 1035, 1036, 1041, 1046, 1047, 1049, 1060], "outlier_detector": [257, 438], "outlier_label": [862, 1051], "outlier_label_": 862, "outlier_mask": 223, "outlier_plot": 113, "outliermixin": [2, 1058], "outliers_": 657, "outliers_cov": 113, "outliers_fract": 247, "outliers_index": 114, "outliers_offset": 114, "outlin": [101, 148, 386, 388, 400, 401, 403, 416, 989, 1036], "outlying": 1006, "outperform": [111, 118, 155, 160, 296, 324, 398, 420, 423, 460, 470, 1002, 1010], "output": [2, 30, 31, 51, 54, 62, 64, 72, 88, 94, 128, 138, 139, 140, 142, 148, 160, 163, 166, 167, 176, 184, 187, 188, 189, 192, 216, 246, 254, 258, 261, 266, 271, 272, 276, 278, 281, 285, 287, 288, 292, 296, 299, 320, 323, 325, 326, 328, 331, 332, 334, 336, 361, 362, 363, 364, 366, 368, 379, 380, 381, 383, 386, 388, 392, 394, 398, 399, 400, 414, 415, 416, 417, 419, 420, 423, 424, 425, 426, 432, 437, 440, 445, 449, 450, 451, 453, 454, 455, 457, 458, 460, 467, 468, 470, 471, 472, 473, 474, 475, 476, 490, 491, 492, 493, 496, 499, 500, 501, 502, 503, 504, 505, 511, 513, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 556, 557, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 619, 635, 636, 637, 638, 639, 640, 641, 643, 646, 647, 648, 649, 650, 654, 655, 658, 660, 661, 662, 665, 666, 668, 669, 670, 671, 674, 675, 676, 679, 681, 682, 684, 686, 687, 689, 690, 691, 692, 696, 697, 698, 700, 702, 704, 707, 708, 721, 722, 729, 731, 732, 734, 736, 743, 753, 754, 756, 758, 759, 760, 761, 762, 764, 769, 775, 780, 793, 796, 798, 799, 805, 806, 807, 810, 811, 812, 813, 814, 820, 822, 823, 824, 825, 826, 827, 828, 830, 833, 836, 837, 838, 840, 841, 842, 843, 844, 845, 846, 855, 856, 857, 861, 862, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 900, 901, 904, 905, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 933, 935, 938, 949, 950, 956, 957, 959, 967, 987, 989, 990, 992, 994, 996, 997, 1000, 1001, 1002, 1003, 1004, 1007, 1010, 1015, 1021, 1022, 1025, 1026, 1028, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "output_dict": [721, 1049, 1053], "output_distribut": [109, 319, 323, 417, 888, 889, 900, 901, 1010], "output_fil": 495, "output_indices_": [472, 1054], "output_label": 340, "output_label_arrai": 340, "outputcodeclassifi": [2, 296, 407, 840, 841, 1048, 1053, 1057, 1058], "outputs_2d_": [854, 862, 1051], "outreach": 401, "outsid": [45, 48, 57, 148, 221, 222, 250, 261, 410, 424, 454, 643, 891, 1006, 1030, 1049], "outward": 319, "outweigh": 1045, "ouvert": [766, 767, 998], "ova": [229, 674, 676, 684, 1014], "ovb": [191, 192], "over": [2, 30, 43, 46, 47, 48, 58, 61, 63, 64, 67, 72, 85, 90, 91, 106, 107, 108, 125, 142, 145, 150, 155, 156, 169, 173, 176, 184, 187, 191, 193, 202, 214, 220, 228, 238, 247, 257, 272, 278, 279, 281, 283, 285, 286, 287, 290, 304, 312, 314, 315, 321, 331, 332, 334, 338, 360, 361, 373, 374, 375, 381, 382, 385, 386, 387, 388, 392, 399, 400, 412, 414, 416, 417, 420, 421, 422, 423, 424, 428, 454, 457, 472, 480, 517, 541, 542, 544, 545, 546, 547, 554, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 589, 590, 596, 597, 599, 602, 610, 638, 640, 641, 642, 652, 653, 654, 655, 660, 661, 666, 668, 669, 670, 671, 673, 674, 675, 676, 684, 685, 686, 693, 694, 705, 724, 726, 747, 771, 796, 801, 805, 808, 811, 812, 814, 819, 820, 822, 831, 833, 834, 835, 836, 837, 839, 868, 869, 870, 871, 887, 891, 912, 920, 922, 929, 938, 989, 996, 997, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1019, 1020, 1024, 1030, 1033, 1041, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1054], "overal": [43, 78, 83, 139, 142, 145, 150, 160, 181, 238, 272, 275, 299, 324, 325, 361, 373, 385, 386, 392, 413, 414, 423, 455, 457, 472, 479, 480, 486, 557, 893, 997, 1000, 1016, 1024, 1051], "overallqu": 160, "overcom": [146, 224, 373, 424], "overcomplet": 421, "overconstrain": 155, "overestim": [132, 369, 420], "overfit": [43, 64, 144, 150, 152, 155, 189, 193, 194, 195, 199, 221, 224, 247, 265, 270, 272, 273, 279, 283, 292, 294, 314, 320, 321, 323, 324, 325, 326, 349, 356, 364, 366, 367, 381, 400, 414, 415, 420, 423, 445, 496, 497, 569, 570, 575, 576, 665, 808, 811, 812, 822, 830, 834, 835, 869, 870, 872, 887, 891, 995, 1004, 1006, 1008, 1010, 1016, 1021, 1024, 1032, 1044], "overflow": [385, 394, 398, 1023, 1044, 1048, 1049, 1050, 1051, 1052, 1054], "overflowerror": 1051, "overhead": [47, 299, 374, 375, 386, 392, 395, 398, 400, 423, 449, 453, 457, 542, 707, 844, 845, 847, 848, 849, 850, 851, 852, 853, 1002, 1003, 1044, 1049, 1050, 1053], "overlai": [394, 640], "overlaid": 1007, "overlap": [2, 51, 52, 72, 90, 121, 153, 173, 243, 265, 361, 413, 416, 420, 423, 424, 595, 800, 801, 809, 813, 815, 816, 817, 818, 826, 997, 1010, 1047], "overli": [52, 62, 63, 209, 283, 369, 421, 1000], "overlin": [278, 413], "overparameter": 996, "overrid": [388, 424, 454, 458, 465, 550, 556, 596, 597, 599, 601, 602, 605, 664, 672, 693, 694, 814, 831, 854, 855, 856, 858, 860, 862, 863, 864, 1041, 1049, 1051, 1055, 1057], "overridden": [388, 400, 426, 550, 556, 624, 629, 632, 702, 1049, 1050, 1057], "oversampl": [552, 1041], "oversc": 1056, "overset": [421, 1007], "overst": 192, "oversubscript": [786, 1055], "overview": [109, 189, 283, 295, 298, 387, 389, 399, 400, 504, 742, 751, 808, 824, 835, 840, 841, 842, 920, 1002, 1014, 1021, 1035, 1036], "overwhelm": 386, "overwrit": [155, 454, 504, 639, 1025, 1041, 1052, 1057, 1058], "overwrite_": 1041, "overwritten": [450, 540, 541, 542, 544, 549, 556, 615, 616, 652, 653, 654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 680, 682, 687, 689, 690, 691, 692, 694, 970, 1054], "ovo": [296, 328, 796, 840, 914, 917, 1000, 1001, 1015], "ovo_tpr": 287, "ovo_tre": 296, "ovr": [2, 66, 212, 235, 296, 298, 328, 357, 666, 667, 796, 841, 912, 914, 917, 1000, 1001, 1015, 1041, 1046, 1047, 1049, 1050, 1051, 1055, 1056], "ovr_jaccard_scor": 298, "ovr_tre": 296, "ow": 95, "owen": [657, 1050, 1051], "own": [2, 16, 52, 70, 145, 238, 254, 268, 299, 301, 340, 361, 374, 380, 389, 390, 391, 394, 395, 404, 415, 416, 428, 432, 448, 462, 541, 565, 572, 654, 805, 806, 854, 855, 856, 858, 860, 862, 863, 864, 886, 920, 922, 938, 943, 996, 1002, 1003, 1006, 1010, 1015, 1019, 1024, 1033, 1034, 1048, 1049, 1051, 1058], "own_telephon": 272, "owner": [254, 381, 383, 956, 957], "ownership": 388, "oyamada": 1046, "oyindamola": 1056, "oywa": 1051, "ozga": 1049, "ozsvald": 1043, "p": [0, 2, 50, 53, 61, 63, 64, 76, 96, 113, 114, 117, 123, 132, 151, 170, 174, 179, 197, 232, 237, 238, 240, 242, 251, 266, 278, 284, 285, 312, 380, 381, 383, 384, 391, 394, 413, 414, 415, 416, 418, 419, 421, 423, 425, 426, 427, 429, 450, 452, 454, 455, 458, 463, 464, 465, 477, 479, 482, 483, 486, 506, 536, 542, 546, 548, 549, 555, 557, 558, 559, 561, 563, 564, 565, 566, 567, 569, 572, 573, 574, 598, 600, 601, 602, 603, 604, 606, 607, 608, 612, 613, 614, 615, 616, 617, 623, 624, 635, 648, 651, 696, 698, 700, 702, 707, 713, 723, 732, 749, 760, 794, 796, 810, 816, 817, 818, 821, 837, 844, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 868, 872, 873, 888, 900, 906, 922, 923, 924, 993, 994, 996, 997, 998, 1000, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1014, 1015, 1029, 1032, 1041, 1042, 1044, 1047, 1049, 1056, 1057, 1058], "p0": 63, "p1": [63, 162], "p1d": 63, "p2": [63, 162, 238], "p3": 162, "p4": 162, "p5": 949, "p592": 143, "p_": [170, 1000, 1003, 1016], "p_c": [123, 531], "p_e": 724, "p_grid": 283, "p_i": [1000, 1003], "p_k": [285, 1000], "p_n": [285, 715, 1000], "p_o": 724, "p_val": 278, "p_val_uncorrect": 278, "p_valu": [612, 613, 614], "p_w": 123, "p_w_c": [123, 531], "pa": [674, 675, 909, 996, 1000, 1013], "pab": [1056, 1057], "pablo": [1051, 1054, 1055], "pabloduque0": 1054, "pace": 381, "pacha": 1049, "pacif": 278, "pack": [395, 1049], "packag": [0, 81, 88, 187, 254, 299, 374, 379, 380, 383, 384, 386, 387, 388, 390, 392, 394, 395, 398, 400, 404, 410, 418, 423, 424, 460, 486, 654, 655, 990, 996, 999, 1003, 1010, 1016, 1024, 1028, 1041, 1047, 1049, 1050, 1051], "packet": 373, "packg": 404, "pacman": 404, "paczuski": [1049, 1050], "pad": [125, 148, 187, 193, 240, 257, 360, 365, 424, 596, 597, 599], "page": [0, 51, 55, 63, 105, 106, 144, 146, 147, 156, 157, 160, 163, 171, 174, 181, 192, 193, 194, 201, 240, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 333, 335, 340, 368, 373, 381, 383, 386, 388, 390, 392, 394, 401, 416, 418, 481, 524, 525, 526, 636, 652, 842, 907, 949, 990, 996, 1000, 1001, 1025, 1034, 1039, 1041, 1045, 1046], "page_links_en": 55, "page_links_filenam": 55, "page_links_url": 55, "pagerank": 55, "pagh": [197, 992], "pai": [0, 192, 238, 272, 386], "paid": 996, "pain": 398, "paint": [924, 926], "pair": [2, 49, 52, 72, 79, 93, 99, 130, 141, 143, 148, 152, 167, 180, 184, 200, 203, 212, 229, 232, 238, 251, 273, 278, 285, 287, 343, 345, 347, 349, 350, 351, 353, 361, 365, 381, 398, 400, 413, 414, 417, 420, 424, 426, 445, 448, 449, 453, 458, 465, 471, 479, 480, 486, 501, 516, 517, 590, 600, 603, 604, 606, 607, 608, 618, 621, 622, 623, 625, 627, 628, 630, 631, 633, 635, 640, 641, 651, 653, 700, 707, 708, 713, 714, 715, 723, 739, 748, 766, 767, 771, 774, 777, 778, 779, 780, 781, 782, 784, 786, 787, 788, 789, 790, 794, 840, 852, 853, 927, 1000, 1001, 1002, 1003, 1010, 1016, 1041, 1053, 1054, 1056, 1057, 1058], "pair_confusion_matrix": [2, 416, 1053], "pair_list": 287, "pair_scor": 287, "paired_cosine_dist": 2, "paired_dist": [2, 771, 777, 786, 1045], "paired_euclidean_dist": 2, "paired_manhattan_dist": 2, "pairidx": 365, "pairplot": [191, 192], "pairwis": [2, 37, 99, 191, 192, 251, 257, 287, 328, 332, 333, 360, 373, 378, 388, 400, 412, 416, 421, 426, 454, 462, 466, 469, 470, 476, 495, 516, 517, 543, 569, 570, 628, 646, 647, 648, 649, 650, 651, 696, 698, 700, 702, 704, 707, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 796, 800, 801, 840, 856, 860, 864, 878, 910, 992, 1000, 1003, 1012, 1015, 1036, 1041, 1042, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1055, 1056, 1057, 1058, 1059, 1060], "pairwise_bayesian": 278, "pairwise_bayesian_df": 278, "pairwise_comp_df": 278, "pairwise_dist": [2, 75, 336, 400, 416, 427, 452, 454, 458, 465, 696, 704, 770, 779, 787, 788, 800, 801, 856, 858, 860, 864, 998, 1041, 1045, 1047, 1049, 1050, 1052, 1053, 1058, 1059], "pairwise_dist_chunk_s": [476, 910], "pairwise_distance_funct": [700, 704, 786, 789, 1003], "pairwise_distances_argmin": [2, 83, 99, 332, 788, 1049, 1055, 1056, 1057, 1058], "pairwise_distances_argmin_min": [2, 332, 787, 1044, 1049, 1055, 1056, 1057, 1058], "pairwise_distances_chunk": [2, 373, 786, 1049, 1052, 1058], "pairwise_indices_": 840, "pairwise_kernel": [2, 400, 426, 460, 470, 651, 773, 878, 998, 1041, 1048, 1058], "pairwise_kernel_funct": [628, 651, 782], "pairwise_kernels_kwarg": 628, "pairwise_t_test": 278, "pairwisedistancesreduct": 374, "pairwisekernel": [2, 426], "paislei": [421, 544], "pakdd": 416, "pal": [1049, 1055], "palac": 83, "palacio": 1054, "palafox": 1041, "palett": [83, 192, 278], "palevioletr": [234, 305, 348], "palioura": [847, 1002], "paliw": 1049, "palladium": 1024, "palmol": 51, "paltri": 1032, "pami": [383, 416, 733], "pamnani": 1049, "pan": 1027, "panchal": 1053, "pancholi": 1048, "panda": [2, 43, 51, 52, 62, 104, 105, 106, 139, 145, 146, 149, 152, 155, 157, 173, 181, 187, 191, 192, 193, 194, 195, 199, 204, 209, 220, 224, 228, 238, 257, 258, 261, 268, 272, 276, 278, 279, 281, 289, 290, 292, 296, 324, 325, 326, 328, 331, 332, 356, 360, 361, 380, 381, 384, 385, 386, 388, 389, 394, 400, 404, 409, 417, 440, 450, 451, 453, 455, 457, 472, 474, 476, 490, 491, 492, 493, 497, 498, 499, 500, 504, 508, 509, 510, 512, 513, 518, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 569, 570, 574, 575, 576, 577, 578, 589, 590, 591, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 640, 641, 643, 646, 647, 648, 649, 650, 696, 697, 700, 808, 811, 812, 822, 838, 856, 861, 864, 868, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 910, 928, 989, 990, 1010, 1019, 1020, 1034, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "pandata": [1056, 1057], "pandei": [1048, 1053], "panel": [269, 304, 319, 422, 1019], "panga": [1056, 1057], "panico": [1049, 1053], "pankaj": 1053, "pano": 1047, "panpiort8": [1051, 1053], "paolo": [0, 406, 1041, 1045, 1051, 1059], "papadopoulo": [1054, 1055, 1056, 1057, 1058], "papapanagiot": 1048, "paper": [0, 174, 197, 272, 278, 383, 392, 398, 416, 418, 423, 450, 457, 486, 512, 542, 549, 571, 649, 666, 674, 675, 679, 684, 687, 700, 796, 849, 858, 861, 904, 905, 996, 1000, 1003, 1006, 1015, 1034, 1041, 1048, 1049], "paper355": 679, "papier": [672, 693, 694], "par": 1010, "paraboloid": 996, "paradi": 1056, "paradigm": 996, "paragraph": [424, 511, 1034], "paralel": 1057, "parallel": [2, 53, 138, 143, 145, 146, 148, 189, 193, 194, 195, 222, 279, 329, 330, 332, 354, 368, 372, 378, 384, 386, 387, 389, 390, 398, 400, 417, 425, 427, 428, 445, 452, 454, 456, 457, 458, 460, 465, 466, 469, 472, 475, 480, 503, 539, 541, 542, 543, 545, 547, 549, 550, 551, 553, 554, 556, 563, 564, 565, 566, 571, 572, 573, 574, 575, 576, 577, 578, 597, 602, 610, 615, 616, 618, 640, 642, 647, 666, 696, 697, 698, 699, 700, 701, 702, 782, 786, 789, 808, 811, 812, 814, 819, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 844, 845, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 871, 874, 907, 908, 967, 970, 1020, 1021, 1029, 1034, 1036, 1041, 1044, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1056, 1057], "parallel_backend": [2, 374, 427, 445, 452, 454, 456, 458, 460, 465, 466, 469, 472, 475, 480, 539, 543, 544, 545, 547, 550, 551, 553, 554, 556, 563, 564, 565, 566, 571, 572, 573, 574, 575, 576, 577, 578, 602, 610, 615, 616, 618, 640, 642, 647, 655, 659, 661, 663, 665, 666, 667, 669, 671, 673, 674, 676, 684, 687, 696, 697, 698, 699, 700, 701, 702, 782, 786, 789, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 844, 845, 854, 855, 858, 860, 862, 863, 865, 866, 871, 874, 907, 908, 1049, 1059], "parallel_batch_queri": 299, "parallel_coordin": 279, "parallel_help": 1051, "parallelbackendbas": 970, "parallelis": [279, 476, 910, 1048], "param": [79, 90, 96, 97, 105, 150, 151, 153, 154, 240, 253, 254, 276, 278, 286, 290, 303, 315, 335, 386, 388, 400, 407, 423, 426, 430, 433, 439, 440, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 692, 696, 697, 698, 699, 700, 805, 806, 807, 808, 811, 812, 820, 822, 830, 833, 834, 835, 836, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 956, 957, 960, 989, 1047, 1051, 1052, 1054, 1055, 1058, 1059], "param1": [388, 1031], "param2": [388, 1031], "param3": 388, "param_": 145, "param_c": [289, 808], "param_classifier__c": 105, "param_covariance_typ": 268, "param_degre": 808, "param_dist": [286, 290, 330], "param_distribut": [105, 176, 279, 286, 290, 330, 399, 812, 820, 822, 1057], "param_gamma": [289, 808, 822], "param_grid": [43, 45, 105, 106, 107, 108, 145, 152, 253, 259, 268, 272, 276, 277, 278, 282, 283, 286, 289, 296, 301, 321, 335, 349, 400, 407, 417, 423, 750, 808, 811, 819, 820, 989, 1000, 1029, 1030], "param_kernel": [808, 822], "param_list": 820, "param_min_samples_split": 282, "param_n_compon": 268, "param_nam": [145, 279, 294, 334, 356, 407, 831, 839, 995, 1034], "param_pca__n_compon": 107, "param_preprocessor__cat__selector__percentil": 105, "param_preprocessor__num__imputer__strategi": 105, "param_rang": [294, 334, 356, 831, 839, 995, 1057], "param_reduce_dim__n_compon": 277, "param_valu": 46, "paramet": [2, 25, 27, 43, 44, 48, 49, 50, 53, 54, 64, 70, 79, 89, 90, 93, 95, 96, 97, 105, 106, 107, 112, 114, 115, 123, 125, 137, 139, 141, 143, 145, 148, 149, 150, 153, 154, 155, 165, 171, 174, 176, 177, 180, 181, 182, 183, 184, 185, 187, 188, 189, 192, 193, 199, 200, 201, 202, 204, 205, 207, 208, 209, 211, 220, 222, 224, 225, 228, 237, 238, 244, 245, 247, 249, 252, 253, 254, 263, 264, 265, 266, 268, 269, 271, 272, 277, 278, 279, 280, 282, 283, 286, 289, 290, 291, 294, 296, 299, 301, 302, 305, 306, 312, 314, 315, 317, 319, 320, 321, 324, 328, 329, 331, 332, 333, 334, 342, 344, 346, 351, 353, 354, 355, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 374, 375, 378, 379, 381, 389, 391, 392, 393, 394, 395, 398, 407, 411, 414, 415, 416, 418, 419, 420, 421, 422, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 584, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 941, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 969, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 990, 991, 992, 993, 994, 995, 997, 999, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1016, 1019, 1020, 1021, 1026, 1028, 1030, 1031, 1032, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "parameter": [364, 426, 622, 623, 630, 631, 805, 806, 996, 997, 1005, 1010, 1016], "parameter_grid": 279, "parameter_nam": [575, 576, 577, 578], "parametergrid": [2, 808, 1043, 1049], "parameters_str": 90, "parametersampl": [2, 822, 1043, 1049, 1053], "parametr": [2, 48, 61, 62, 115, 250, 303, 323, 331, 414, 417, 422, 423, 445, 559, 561, 643, 693, 704, 888, 900, 943, 944, 996, 999, 1002, 1003, 1010, 1013, 1016, 1049, 1051, 1054], "parametrize_with_check": [2, 328, 388, 943, 1051, 1052], "params_str": 290, "parcel": [89, 102, 416], "parch": [194, 333], "pardeep": 1053, "parel": 1045, "parent": [47, 191, 254, 386, 390, 400, 416, 450, 471, 957, 958, 1041, 1058], "parent_hourly_wag": 191, "parenthes": 939, "parenthesi": [76, 386], "paresh": [1050, 1051], "pareto": 222, "pargent": 1010, "pari": [0, 383, 417, 474, 772, 880, 1011, 1055], "pariet": [1024, 1041], "parikh": [1050, 1055, 1056, 1057, 1058, 1059], "paris_in_radian": 772, "paristech": [0, 61, 62, 77, 247], "pariti": 1016, "parizi": 1056, "park": [1046, 1051, 1053, 1056, 1057], "parmet": 1058, "parmind": 1048, "parra": 1049, "parri": [1046, 1047, 1048], "parrot": 360, "pars": [47, 55, 373, 380, 381, 387, 516], "parse_vers": [222, 678], "parser": [47, 52, 155, 272, 292, 328, 332, 504, 1056, 1057], "parsimoni": [421, 1010], "parsing_tim": 47, "parson": [1052, 1054], "part": [0, 44, 67, 71, 86, 96, 105, 115, 125, 128, 142, 145, 148, 152, 158, 165, 166, 167, 171, 181, 189, 199, 254, 256, 266, 272, 273, 275, 293, 314, 321, 324, 326, 362, 375, 381, 383, 386, 388, 392, 394, 399, 400, 404, 412, 414, 415, 416, 420, 421, 423, 424, 426, 454, 457, 501, 502, 503, 529, 539, 545, 550, 582, 592, 593, 594, 621, 633, 801, 877, 895, 897, 898, 899, 900, 901, 902, 903, 989, 990, 992, 997, 1001, 1018, 1019, 1020, 1021, 1022, 1024, 1027, 1034, 1036, 1041, 1049, 1050, 1052, 1054, 1056, 1060], "part3": 420, "part_of_speech": 424, "partev": [1055, 1056, 1057, 1058], "parthiv": 1053, "parti": [238, 296, 334, 374, 385, 398, 410, 810, 817, 1041, 1052, 1057, 1058], "partial": [2, 43, 47, 51, 85, 116, 117, 157, 189, 190, 238, 246, 330, 333, 383, 386, 400, 403, 418, 419, 421, 423, 426, 472, 490, 491, 492, 493, 504, 509, 542, 544, 549, 570, 597, 640, 641, 665, 796, 838, 840, 841, 868, 869, 870, 873, 885, 886, 889, 892, 921, 997, 1004, 1014, 1021, 1034, 1036, 1038, 1042, 1049, 1050, 1054, 1058], "partial_correl": 51, "partial_depend": [2, 193, 640, 1007, 1042, 1050, 1051, 1052, 1053, 1056, 1057], "partial_fit": [47, 85, 125, 332, 375, 388, 400, 416, 421, 450, 457, 542, 544, 545, 546, 597, 605, 666, 667, 674, 675, 676, 684, 685, 686, 840, 841, 844, 845, 847, 848, 849, 850, 851, 868, 869, 870, 881, 882, 892, 912, 996, 1002, 1004, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1054, 1055, 1056, 1057, 1058], "partial_fit_": 1054, "partial_fit_classifi": 47, "partial_fit_param": [605, 840, 841, 844, 845], "partialdependencedisplai": [2, 155, 157, 193, 258, 329, 330, 331, 333, 335, 393, 641, 1007, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "particip": [0, 385, 386, 401, 1024], "particl": 1005, "particular": [0, 43, 50, 53, 64, 72, 74, 75, 95, 105, 111, 123, 130, 133, 149, 152, 155, 156, 180, 187, 192, 193, 220, 222, 228, 252, 272, 275, 279, 281, 287, 299, 308, 312, 319, 328, 329, 332, 361, 362, 369, 373, 374, 380, 381, 384, 385, 386, 388, 390, 391, 392, 394, 395, 399, 400, 404, 416, 417, 420, 421, 423, 424, 425, 426, 454, 477, 481, 504, 552, 571, 617, 661, 666, 671, 680, 682, 692, 695, 720, 736, 793, 844, 931, 933, 990, 992, 994, 996, 1000, 1003, 1004, 1005, 1006, 1008, 1010, 1020, 1024, 1033, 1041, 1044, 1048, 1049, 1050, 1052, 1054, 1055, 1056, 1058], "particularli": [58, 67, 104, 105, 108, 134, 158, 192, 221, 249, 278, 292, 321, 329, 336, 358, 369, 373, 386, 388, 395, 400, 416, 417, 419, 422, 424, 504, 814, 831, 849, 949, 969, 996, 997, 1000, 1002, 1008, 1020, 1024, 1033, 1041, 1046, 1048, 1049, 1055], "partit": [81, 101, 104, 156, 158, 278, 316, 400, 413, 414, 416, 420, 423, 457, 459, 461, 470, 519, 565, 566, 567, 568, 571, 572, 573, 712, 713, 723, 794, 860, 920, 921, 922, 923, 999, 1003, 1006, 1010, 1016, 1034], "partli": [81, 777], "partnership": 1024, "parvu": 383, "pasbi": [1048, 1049], "pascal": 1000, "pascual": 1044, "paskov": 1048, "pass": [2, 43, 46, 47, 58, 59, 70, 73, 145, 155, 157, 171, 201, 204, 221, 248, 250, 251, 254, 257, 258, 260, 268, 272, 276, 279, 326, 328, 331, 336, 354, 362, 369, 373, 374, 375, 381, 386, 387, 388, 391, 392, 393, 394, 395, 398, 400, 407, 410, 412, 415, 416, 417, 420, 421, 423, 424, 426, 427, 428, 433, 434, 438, 439, 445, 446, 448, 450, 451, 452, 454, 455, 456, 457, 458, 460, 462, 465, 467, 468, 470, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 496, 499, 500, 503, 504, 505, 511, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 589, 590, 596, 597, 598, 599, 601, 602, 605, 615, 616, 618, 619, 625, 628, 634, 639, 640, 642, 643, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 692, 695, 696, 697, 698, 699, 700, 701, 702, 703, 705, 706, 707, 708, 709, 710, 719, 740, 741, 750, 771, 782, 786, 787, 788, 789, 796, 800, 801, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 820, 822, 823, 824, 825, 826, 827, 828, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 883, 884, 885, 886, 887, 889, 891, 892, 893, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 931, 932, 933, 939, 943, 944, 948, 949, 951, 953, 955, 957, 960, 961, 970, 971, 974, 989, 990, 996, 998, 1000, 1001, 1002, 1003, 1004, 1007, 1010, 1013, 1014, 1015, 1020, 1024, 1025, 1029, 1038, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "passiv": [2, 47, 227, 674, 675, 1022, 1036, 1042], "passiveaggress": [375, 424], "passiveaggressiveclassifi": [2, 47, 227, 373, 375, 996, 1001, 1042, 1045, 1046, 1048, 1049, 1052, 1054, 1059], "passiveaggressiveregressor": [2, 375, 996, 1042, 1045, 1048, 1049, 1052, 1054, 1059], "passo": [0, 406, 1041, 1042], "passthrough": [43, 106, 149, 192, 193, 220, 238, 257, 325, 333, 417, 472, 475, 575, 576, 871, 872, 1010, 1050, 1052, 1055, 1056, 1058], "passthrough_numer": [220, 238], "passthroughpassthrough": [193, 325], "past": [50, 52, 390, 391, 394, 398, 401, 420, 421, 423, 546, 563, 564, 686, 1024, 1026, 1057], "pat": [636, 990], "patch": [2, 70, 85, 257, 263, 264, 265, 268, 269, 273, 381, 390, 398, 421, 423, 563, 564, 591, 592, 595, 1041, 1049], "patch_height": [591, 592, 595], "patch_siz": [85, 128, 424, 591, 592, 595], "patch_width": [591, 592, 595], "patchextractor": [2, 424, 1057], "patel": [1049, 1051, 1052, 1053, 1055], "path": [2, 47, 55, 189, 198, 205, 206, 209, 214, 224, 236, 356, 364, 380, 384, 386, 390, 394, 395, 400, 410, 449, 453, 458, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 511, 512, 513, 516, 517, 556, 565, 566, 571, 572, 573, 574, 601, 602, 605, 654, 655, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 689, 690, 691, 692, 693, 694, 696, 872, 873, 919, 920, 921, 922, 923, 954, 989, 996, 997, 1006, 1020, 1021, 1041, 1042, 1045, 1047, 1048, 1050, 1051, 1053, 1054, 1056, 1057], "path_length": 954, "path_method": [696, 997], "pathak": [1056, 1057], "patheffect": 75, "pathlib": [47, 1056, 1057], "pathlik": [504, 1057], "patholog": [87, 999, 1047], "pathwai": 387, "pati": 1043, "patienc": [394, 400], "patient": [46, 163, 174, 188, 383, 394, 415, 420, 996, 1032], "patil": [1055, 1058], "paton": 1054, "patric": [1053, 1054], "patricio": 1055, "patrick": [1048, 1049, 1054, 1055, 1058, 1059], "patrini": [1046, 1047, 1048], "pattaniyil": 1051, "pattern": [43, 52, 58, 98, 115, 121, 124, 132, 176, 187, 189, 193, 204, 224, 254, 257, 331, 353, 360, 361, 362, 369, 383, 386, 388, 401, 413, 416, 417, 421, 423, 424, 456, 472, 474, 512, 540, 542, 549, 563, 564, 646, 716, 733, 749, 777, 796, 797, 805, 892, 992, 994, 996, 1000, 1001, 1007, 1015, 1017, 1020, 1021, 1024, 1053], "patterson": [502, 1046], "paul": [381, 1044, 1047, 1048, 1049, 1050, 1054, 1055], "paula": [1051, 1052, 1059], "pauli": 1046, "paulo": [1048, 1054, 1056], "paus": 81, "pava": 643, "pave": 1032, "pavel": [1042, 1050], "pavlo": [1049, 1050], "pavlyk": [1049, 1050, 1051, 1052], "pawel": 1050, "pawe\u0142": [1044, 1048, 1053, 1054], "payn": 1051, "pazzani": 64, "pb_q": [331, 996], "pbl": 152, "pc": [57, 342, 362, 381], "pca": [2, 11, 42, 45, 69, 80, 86, 103, 104, 106, 108, 109, 118, 124, 127, 134, 135, 166, 189, 217, 241, 243, 250, 252, 255, 259, 277, 286, 289, 299, 303, 308, 317, 331, 369, 378, 388, 400, 412, 416, 417, 422, 432, 481, 484, 492, 504, 510, 512, 522, 540, 541, 542, 543, 547, 548, 551, 552, 557, 651, 666, 696, 698, 700, 704, 808, 834, 838, 861, 868, 871, 872, 874, 882, 890, 892, 992, 994, 997, 1003, 1010, 1014, 1016, 1021, 1030, 1035, 1036, 1041, 1043, 1044, 1045, 1047, 1048, 1049, 1052, 1054, 1055, 1056, 1058, 1059], "pca0": 432, "pca1": [417, 432], "pca2": [417, 432], "pca_2": 118, "pca__n_compon": [107, 1030], "pca_back_proj_ax": 130, "pca_estim": 125, "pca_proj_ax": 130, "pca_scor": 132, "pcapca": [106, 259], "pcd": [868, 1005], "pchelintsev": 1053, "pclass": [105, 194, 261, 328, 332, 333], "pcolor": 177, "pcolormesh": [70, 158, 167, 203, 302, 307, 345, 349, 353, 639], "pcr": [118, 419], "pd": [43, 51, 62, 105, 106, 139, 145, 146, 152, 157, 173, 187, 191, 192, 193, 194, 195, 199, 204, 209, 220, 224, 228, 238, 258, 261, 268, 276, 278, 279, 281, 289, 290, 292, 296, 324, 325, 326, 331, 332, 356, 360, 361, 391, 400, 417, 472, 474, 635, 636, 637, 638, 640, 786, 930, 932, 933, 989, 990, 1007, 1010, 1052, 1054, 1055, 1056, 1058], "pd2000": 1000, "pd_": 1007, "pd_line_kw": 640, "pd_result": 640, "pdb": 394, "pdbcl": 394, "pdf": [174, 278, 304, 319, 383, 386, 416, 425, 450, 457, 539, 542, 545, 549, 649, 652, 657, 666, 672, 674, 675, 679, 684, 687, 690, 691, 693, 694, 700, 849, 850, 861, 868, 905, 907, 996, 1013, 1016, 1023, 1037, 1041], "pdist": [700, 786, 789], "pdp": [2, 640, 1007, 1055], "pdp_lim": 640, "pdp_line_kw": 640, "pe": 591, "pe_tran": 591, "peai": 1050, "peak": [43, 52, 64, 193, 414, 420, 1055], "pear": 1001, "pearson": [2, 614, 617, 1054], "pearu": 1041, "pedersen": [1045, 1057], "pedigo": [1053, 1054], "pedregosa": [0, 207, 225, 241, 311, 406, 1041, 1042, 1043, 1044, 1045, 1047], "pedro": [105, 1042, 1044, 1045, 1049], "peek": [193, 386, 1007], "peer": 1024, "peev": [1049, 1052], "pegaso": 1014, "pei": [416, 1048], "peixinho": 1055, "pelennor": 1055, "penal": [2, 53, 66, 115, 160, 204, 209, 213, 220, 224, 236, 238, 324, 356, 416, 418, 421, 423, 425, 477, 478, 479, 480, 481, 482, 483, 484, 486, 569, 570, 655, 660, 661, 669, 671, 684, 713, 723, 742, 794, 803, 885, 912, 913, 919, 996, 1000, 1002, 1004, 1014, 1015, 1032], "penalis": [205, 218, 235, 704], "penalti": [2, 25, 46, 49, 66, 115, 189, 198, 199, 204, 205, 209, 213, 220, 224, 227, 235, 236, 249, 286, 314, 331, 342, 354, 360, 373, 394, 398, 418, 421, 425, 479, 480, 481, 482, 483, 484, 486, 510, 539, 545, 546, 547, 548, 550, 551, 555, 556, 605, 651, 654, 655, 656, 657, 660, 661, 662, 665, 666, 667, 668, 669, 670, 676, 677, 678, 680, 684, 686, 688, 689, 695, 822, 892, 912, 913, 915, 917, 918, 919, 989, 996, 999, 1004, 1010, 1014, 1015, 1021, 1032, 1034, 1043, 1046, 1048, 1050, 1051, 1053, 1054, 1056, 1057], "peng": [687, 996, 1047, 1048, 1049, 1051, 1053], "peopl": [2, 45, 104, 192, 256, 281, 360, 361, 374, 375, 381, 383, 385, 386, 390, 401, 422, 501, 502, 649, 849, 1019, 1030], "pep": [51, 394, 1041], "pep073": 387, "pep101": 390, "pep257": 400, "pep8": [388, 390, 394], "pepsi": 51, "per": [43, 49, 58, 70, 83, 88, 99, 122, 144, 145, 149, 181, 183, 192, 193, 220, 235, 238, 257, 261, 264, 272, 274, 285, 287, 319, 325, 330, 335, 336, 356, 360, 362, 373, 381, 382, 386, 391, 392, 395, 398, 400, 414, 416, 420, 421, 422, 423, 424, 426, 454, 456, 458, 465, 469, 472, 476, 495, 504, 508, 510, 511, 512, 516, 518, 520, 523, 531, 540, 542, 543, 544, 547, 549, 551, 557, 558, 569, 570, 577, 591, 596, 599, 618, 619, 640, 641, 649, 650, 666, 667, 674, 675, 676, 679, 681, 682, 683, 684, 686, 700, 704, 721, 724, 728, 730, 749, 762, 766, 767, 789, 791, 805, 806, 833, 840, 841, 842, 844, 845, 848, 850, 868, 871, 877, 879, 881, 882, 885, 886, 892, 893, 910, 912, 913, 914, 915, 916, 917, 918, 937, 938, 949, 975, 989, 992, 996, 999, 1000, 1001, 1004, 1007, 1014, 1015, 1016, 1019, 1020, 1032, 1034, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1053, 1054, 1055, 1057, 1058], "perc": 273, "percal": 392, "percent": [139, 500, 608, 1013], "percent10": [257, 500], "percentag": [2, 52, 89, 133, 149, 211, 238, 273, 281, 284, 420, 425, 542, 549, 552, 557, 601, 602, 656, 677, 688, 711, 742, 754, 826, 827, 828, 842, 924, 926, 1001, 1016, 1043, 1047, 1053, 1054], "percentil": [2, 49, 52, 105, 152, 155, 257, 261, 319, 373, 600, 603, 604, 606, 607, 608, 611, 614, 640, 641, 756, 1010, 1046, 1054], "percentile_5_predict": 52, "percentile_95_predict": 52, "percentile_perf_in_u": 49, "percentiles_class": 273, "percept": [169, 193, 1007], "perceptron": [2, 47, 67, 148, 158, 167, 178, 180, 189, 227, 230, 236, 258, 313, 321, 322, 343, 354, 358, 375, 398, 424, 522, 523, 530, 674, 684, 838, 868, 869, 870, 873, 892, 998, 1001, 1005, 1014, 1021, 1022, 1036, 1045, 1047, 1048, 1049, 1053], "percol": 74, "perdisci": [416, 450], "perdok": 1056, "pere": 1058, "peredachi": [615, 616], "pereira": [1046, 1049, 1050], "peretti": 1056, "perez": [1049, 1056], "perf_count": 257, "perfect": [58, 63, 72, 104, 114, 128, 130, 216, 220, 360, 361, 386, 390, 416, 420, 561, 562, 698, 702, 712, 713, 716, 725, 734, 736, 739, 745, 751, 764, 765, 793, 794, 803, 996, 1000, 1003, 1015, 1024, 1032, 1055], "perfectli": [63, 64, 72, 281, 293, 353, 403, 416, 423, 446, 575, 614, 712, 713, 723, 725, 744, 745, 765, 794, 803, 885, 995, 997, 1000, 1015, 1054, 1055], "perform": [2, 25, 27, 29, 30, 41, 43, 46, 52, 55, 57, 61, 62, 63, 68, 71, 73, 75, 83, 84, 88, 92, 93, 94, 95, 96, 97, 99, 101, 102, 104, 105, 108, 111, 118, 120, 128, 134, 137, 139, 145, 147, 149, 150, 151, 153, 154, 155, 159, 160, 165, 169, 173, 174, 177, 185, 187, 188, 189, 192, 193, 194, 195, 197, 204, 209, 220, 222, 224, 226, 227, 228, 237, 238, 241, 242, 244, 247, 252, 255, 257, 264, 265, 268, 270, 272, 273, 274, 275, 276, 278, 279, 280, 283, 284, 286, 287, 289, 291, 292, 294, 296, 298, 299, 312, 317, 319, 321, 323, 325, 326, 328, 334, 335, 337, 339, 340, 349, 352, 353, 356, 360, 362, 369, 372, 374, 375, 381, 383, 388, 389, 390, 392, 394, 395, 398, 399, 400, 403, 407, 410, 411, 412, 413, 414, 417, 418, 419, 421, 422, 423, 424, 425, 426, 427, 428, 434, 438, 448, 450, 451, 452, 454, 455, 456, 458, 460, 462, 463, 467, 469, 476, 477, 490, 491, 492, 493, 502, 510, 520, 523, 539, 540, 541, 543, 545, 550, 551, 552, 553, 554, 556, 558, 559, 560, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 589, 590, 591, 596, 597, 598, 599, 602, 609, 610, 611, 618, 619, 635, 638, 639, 646, 648, 653, 659, 662, 663, 664, 666, 672, 673, 674, 675, 676, 678, 681, 683, 684, 685, 686, 690, 691, 693, 695, 697, 698, 701, 702, 705, 711, 712, 713, 715, 716, 720, 721, 734, 737, 738, 746, 748, 750, 763, 764, 765, 786, 791, 792, 794, 795, 796, 802, 803, 804, 805, 806, 808, 811, 812, 819, 820, 822, 826, 833, 834, 835, 837, 838, 841, 844, 845, 847, 848, 849, 850, 851, 852, 853, 859, 861, 867, 868, 869, 870, 872, 873, 875, 878, 879, 881, 882, 884, 885, 886, 888, 889, 892, 893, 895, 897, 898, 899, 901, 902, 903, 907, 908, 910, 914, 915, 916, 917, 918, 920, 921, 922, 923, 932, 933, 973, 984, 989, 990, 992, 994, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1019, 1020, 1021, 1024, 1025, 1026, 1029, 1032, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058], "performancetip": 392, "perhap": [104, 148, 383, 385, 394, 400, 422, 1020], "perimet": [174, 383], "period": [2, 52, 155, 176, 181, 185, 390, 400, 401, 414, 426, 623, 829, 891, 1049, 1054, 1056], "periodic_spline_transform": 43, "periodicity_bound": [176, 181, 185, 623], "peripheri": 416, "perla": 1044, "perm_scores_iri": 284, "perm_scores_rand": 284, "perm_sorted_idx": 195, "permalink": 390, "perman": 394, "permiss": [385, 390, 401, 404, 1024, 1056], "permit": [417, 475, 596, 597, 599, 808, 811, 812, 822, 834, 873, 874, 1000, 1001, 1002, 1047], "permut": [2, 58, 59, 72, 114, 147, 153, 167, 169, 189, 190, 236, 270, 278, 323, 326, 341, 403, 411, 416, 423, 472, 504, 508, 512, 567, 568, 572, 573, 635, 638, 642, 687, 712, 713, 725, 744, 745, 763, 765, 803, 825, 827, 837, 838, 872, 886, 917, 920, 921, 949, 969, 971, 974, 1000, 1014, 1021, 1029, 1032, 1036, 1041, 1047, 1054, 1056], "permutation_import": [2, 146, 147, 153, 194, 195, 328, 423, 561, 562, 565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923, 1008, 1051, 1053, 1054, 1058], "permutation_scor": 837, "permutation_test_scor": [2, 284, 407, 420, 1041, 1048, 1053], "permuted_categori": 326, "perp_tol": 544, "perpendicular": [70, 354], "perperogl": 1010, "perplex": [189, 239, 240, 242, 244, 299, 522, 533, 544, 700, 997, 1021, 1046, 1048, 1055], "perri": 1051, "perrin": 1047, "perrot": [0, 1041], "persian": 1019, "persist": [394, 398, 421, 454, 618, 619, 868, 1005, 1019, 1036, 1047, 1050], "persola": 1049, "person": [45, 192, 272, 281, 381, 385, 420, 424, 501, 502, 503, 1010, 1030, 1049], "personal_statu": 272, "perspect": [90, 95, 220, 292, 373, 381, 398, 401, 538, 651, 912, 993], "pertin": 220, "perturb": [192, 237, 317, 421, 423, 999], "peru": [50, 312, 381, 506], "pervas": [369, 386], "pessimist": [151, 423], "pessoa": 1054, "pestrickland": 1047, "pet": [331, 335, 796, 1000], "pet_cat": 331, "pet_dog": 331, "pet_fish": 331, "petal": [80, 121, 133, 135, 148, 261, 330, 333, 383, 417, 925, 1016, 1031, 1032], "petal_col": 333, "petar": 1056, "pete": [1048, 1052, 1053], "peter": [0, 50, 98, 151, 153, 154, 279, 360, 361, 406, 416, 456, 458, 465, 657, 800, 801, 996, 1000, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1054, 1056, 1057, 1058], "peterlongo": 1058, "peterson": [1041, 1043], "petfood": 1024, "petrov": [1048, 1049, 1057], "petrushev": 1050, "pe\u00f1a": 1045, "pfaffel": 1054, "pfahring": [843, 1001], "pfe": 51, "pfister": 1010, "pfizer": 51, "pft": 221, "pg": [51, 392, 657, 996, 1046], "pg_i": 657, "pgithub": 1053, "ph": 1053, "pham": [197, 992, 1048], "phan": 421, "pharmaceut": 383, "pharuj": 257, "phase": [43, 204, 214, 373, 635, 992, 997, 1003, 1024, 1049, 1051], "phase_nois": 75, "phd": [0, 416, 423, 1020, 1024], "phenol": 383, "phenomena": 181, "phenomenon": [361, 1010], "phi": [75, 421, 423, 751, 878, 992, 1000, 1010, 1015], "phil": [92, 1046, 1057], "philipp": [1043, 1044, 1047, 1056], "phillip": [2, 50, 312, 381, 506], "phlypo": 1044, "phongpanagnam": 1054, "phongpanangam": 1054, "photo": 83, "photogrammetr": 996, "php": [1000, 1019], "phrase": 424, "phy": [615, 616], "phyo": 1055, "physic": [2, 104, 145, 374, 513, 965, 996, 1057], "physician": 415, "physiolog": [281, 383, 1032], "pi": [43, 53, 70, 74, 75, 126, 134, 157, 159, 169, 176, 200, 204, 208, 214, 221, 242, 263, 264, 265, 268, 269, 293, 312, 329, 335, 367, 404, 422, 426, 524, 525, 526, 623, 650, 994, 995, 996, 1002, 1033], "pianomania": 1046, "pick": [83, 90, 95, 195, 255, 286, 332, 338, 381, 386, 390, 416, 423, 451, 468, 531, 681, 922, 923, 989, 996, 997, 999, 1014, 1052], "pickl": [390, 400, 424, 597, 852, 853, 1019, 1020, 1036, 1043, 1046, 1047, 1048, 1049, 1050, 1051, 1054, 1055, 1056, 1057, 1058], "pickleabl": [876, 1047], "pickup": 1049, "pico": [1044, 1045], "pict": [842, 1001], "pictur": [51, 55, 59, 71, 83, 101, 189, 251, 269, 381, 401, 416, 421, 424, 470, 501, 502, 529, 1020, 1021], "piec": [70, 82, 221, 374, 999], "piecewis": [134, 331, 413, 991, 996, 1010, 1016], "pierr": [1041, 1049, 1050, 1052, 1054, 1056, 1058, 1059], "pierreablin": 1049, "pierreattard": [1054, 1055], "pierretallott": [1049, 1050, 1051], "pierron": 1044, "piet": [1055, 1056], "pieter": [55, 1047, 1048, 1055], "pietro": [1041, 1044, 1058], "pietruh": 1049, "pig": 791, "pillow": [386, 404, 409], "pim": 1050, "pin": [392, 410], "pinaki": 1049, "pinbal": [2, 52, 152, 155, 331, 423, 570, 678, 731, 756, 996, 1054, 1055], "pinball_loss_05": 52, "pinball_loss_50": 52, "pinball_loss_95": 52, "ping": [905, 1012, 1047, 1048], "pink": 200, "pinki": 1055, "pinot": 325, "pinto": 1041, "pintor": 1052, "pinvh": [1048, 1050], "piontek": 1057, "piotr": [1049, 1050], "pip": [299, 328, 329, 330, 331, 332, 333, 334, 335, 336, 374, 384, 386, 390, 392, 404, 410, 412, 1016], "pip3": [384, 404], "pipe": [106, 107, 149, 172, 254, 259, 277, 325, 330, 331, 399, 407, 417, 424, 598, 872, 897, 898, 900, 901, 902, 903, 989, 1010, 1030], "pipe_sgd": 234, "pipegraph": 398, "pipelin": [2, 7, 43, 67, 89, 93, 105, 108, 109, 118, 144, 145, 149, 166, 168, 170, 172, 173, 174, 187, 188, 193, 194, 197, 199, 208, 209, 220, 221, 226, 234, 238, 241, 246, 247, 248, 250, 252, 257, 258, 261, 270, 272, 275, 277, 278, 285, 286, 289, 292, 293, 299, 301, 302, 307, 308, 314, 317, 321, 324, 326, 328, 329, 330, 331, 332, 333, 334, 342, 360, 361, 369, 373, 378, 380, 381, 386, 389, 400, 407, 410, 420, 424, 426, 430, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 496, 510, 523, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 613, 615, 618, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 705, 706, 708, 709, 710, 721, 805, 806, 807, 808, 809, 810, 811, 812, 815, 817, 822, 826, 830, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 989, 990, 992, 996, 1003, 1004, 1009, 1010, 1014, 1015, 1019, 1020, 1021, 1022, 1024, 1026, 1028, 1036, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1058], "pipelineifittedpipelin": [105, 144, 171, 192, 194, 248, 258, 261, 285, 332], "pipelineinot": [160, 249, 259, 279, 292, 325, 329], "pipelinepipelin": [105, 106, 259, 272], "pita": 1058, "pitfal": [174, 189, 190, 191, 194, 216, 224, 225, 278, 330, 399, 400, 403, 420, 473, 475, 504, 661, 680, 681, 709, 761, 823, 835, 838, 873, 885, 892, 996, 1021, 1036], "pitkin": [193, 1007], "pitt": 57, "pitter": 1056, "pivot": [81, 289, 290], "pivot_t": 289, "pixel": [2, 44, 45, 53, 58, 68, 82, 83, 88, 125, 138, 146, 172, 189, 194, 195, 197, 251, 276, 316, 317, 383, 416, 421, 423, 424, 425, 501, 502, 503, 572, 593, 594, 615, 616, 642, 1003, 1005, 1016, 1021, 1030, 1033], "pixelwis": 125, "pixi": 410, "piyg": 321, "pkdd": 0, "pkg": 384, "pkgsrc": 404, "pkl": 410, "pl": [2, 52, 107, 118, 181, 224, 335, 383, 419, 490, 491, 492, 493, 1046], "place": [2, 43, 95, 248, 258, 303, 373, 386, 387, 388, 391, 393, 401, 414, 424, 426, 449, 453, 454, 490, 491, 492, 523, 589, 598, 636, 638, 639, 776, 789, 805, 895, 897, 898, 899, 900, 901, 902, 903, 979, 980, 1019, 1041, 1048, 1051, 1052, 1054, 1058, 1059], "placehold": [57, 390, 635, 636, 637, 638, 823, 824, 827, 828, 990], "plagre": 1048, "plai": [126, 153, 178, 203, 229, 271, 310, 345, 346, 373, 1034], "plain": [351, 426, 665, 1014], "plan": [51, 380, 384, 386, 387, 401, 410, 1010, 1044], "planar": 416, "plane": [51, 174, 232, 252, 305, 351, 353, 354, 358, 383, 460, 470, 994, 996, 1015, 1032], "plant": [284, 287, 288, 379, 1000, 1036], "plasma": 319, "plasma_r": 319, "plateau": [145, 150, 173, 272, 276, 280], "platform": [389, 400, 401, 1019, 1023, 1024, 1046, 1049, 1050, 1052, 1054, 1055, 1058], "platt": [414, 445, 914, 915, 917, 918, 1015], "platypu": 360, "pldtc325": 1048, "pleas": [0, 2, 51, 55, 63, 105, 106, 144, 146, 147, 153, 156, 157, 160, 163, 171, 181, 192, 193, 194, 201, 224, 248, 249, 250, 252, 254, 257, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 299, 309, 317, 325, 328, 329, 330, 331, 332, 333, 334, 335, 336, 340, 353, 368, 374, 380, 381, 384, 386, 387, 388, 390, 394, 398, 399, 400, 404, 407, 410, 412, 416, 423, 424, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 504, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 602, 603, 604, 605, 606, 607, 608, 611, 618, 619, 635, 636, 637, 638, 639, 640, 641, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 835, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 901, 904, 905, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 989, 1000, 1004, 1010, 1014, 1015, 1019, 1020, 1023, 1025, 1032, 1034, 1041, 1044, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "pleasant": [385, 1024], "plenti": 62, "plgreenliru": 1052, "plo": [380, 615, 616], "plot": [2, 43, 44, 45, 50, 51, 52, 54, 62, 63, 64, 65, 67, 68, 69, 71, 72, 75, 77, 78, 80, 89, 90, 91, 93, 94, 95, 96, 97, 100, 106, 107, 108, 109, 112, 113, 114, 118, 119, 125, 128, 129, 132, 133, 134, 135, 138, 139, 141, 142, 143, 144, 146, 150, 151, 152, 154, 155, 157, 158, 159, 167, 169, 170, 172, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 189, 190, 191, 192, 194, 195, 197, 198, 202, 203, 205, 207, 208, 209, 210, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 230, 232, 233, 235, 236, 237, 238, 242, 243, 244, 245, 246, 247, 250, 251, 253, 255, 256, 261, 263, 264, 265, 267, 269, 270, 271, 272, 273, 278, 279, 281, 283, 284, 288, 289, 290, 292, 293, 296, 299, 301, 302, 303, 304, 305, 307, 308, 309, 310, 311, 312, 314, 315, 316, 319, 320, 321, 322, 323, 324, 326, 329, 332, 333, 334, 335, 339, 340, 343, 344, 345, 349, 350, 351, 354, 355, 356, 357, 358, 361, 362, 363, 364, 366, 367, 368, 386, 389, 395, 398, 403, 404, 411, 414, 416, 418, 420, 422, 423, 446, 449, 454, 458, 464, 472, 479, 504, 509, 510, 512, 520, 523, 527, 531, 561, 565, 568, 570, 572, 573, 577, 578, 618, 630, 639, 640, 641, 665, 666, 680, 684, 705, 706, 708, 709, 710, 711, 726, 735, 743, 769, 790, 792, 795, 796, 797, 808, 814, 825, 831, 833, 834, 835, 836, 839, 841, 850, 854, 870, 873, 885, 886, 887, 889, 892, 912, 914, 917, 920, 921, 926, 993, 994, 996, 997, 999, 1000, 1003, 1004, 1006, 1014, 1015, 1016, 1019, 1020, 1021, 1029, 1030, 1032, 1036, 1042, 1044, 1045, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "plot_": [331, 404], "plot_2d": [123, 240], "plot_3d": 240, "plot_accuraci": 47, "plot_adaboost_multiclass": [139, 1021], "plot_adaboost_regress": [140, 1021], "plot_adaboost_twoclass": [141, 1021], "plot_adjusted_for_chance_measur": [72, 1021], "plot_affinity_propag": [73, 448, 462, 1021], "plot_agglomerative_clust": [74, 1021], "plot_agglomerative_clustering_metr": [75, 1021], "plot_agglomerative_dendrogram": [76, 1021], "plot_all_sc": [319, 1021], "plot_anomaly_comparison": [247, 1021], "plot_ard": [199, 652, 1021], "plot_arg": 315, "plot_bayesian_ridge_curvefit": [200, 1021], "plot_benchmark_throughput": 49, "plot_bias_vari": [142, 1021], "plot_bicluster_newsgroup": [57, 1021], "plot_birch_vs_minibatchkmean": [77, 1021], "plot_bisect_kmean": [78, 1021], "plot_caching_nearest_neighbor": [301, 1021], "plot_calibr": [61, 1021], "plot_calibration_curv": [62, 1021], "plot_calibration_multiclass": [63, 1021], "plot_causal_interpret": [191, 1021], "plot_chance_level": [257, 272, 285, 287, 288, 708, 710, 1057], "plot_classif": [302, 1021], "plot_classification_prob": [66, 1021], "plot_classifier_chain_yeast": [298, 1021], "plot_classifier_comparison": [67, 321, 1021], "plot_clust": 87, "plot_cluster_comparison": [79, 1021], "plot_cluster_iri": [80, 1021], "plot_coin_segment": [81, 1021], "plot_coin_ward_segment": [82, 1021], "plot_color": [141, 365], "plot_color_quant": [83, 1021], "plot_column_transform": [104, 1021], "plot_column_transformer_mixed_typ": [105, 1021], "plot_compare_calibr": [64, 1021], "plot_compare_cross_decomposit": [117, 1021], "plot_compare_gpr_krr": [176, 1021], "plot_compare_method": [240, 1021], "plot_compare_reduct": [106, 1021], "plot_concentration_prior": [263, 1021], "plot_confusion_matrix": [271, 328, 1021, 1051, 1052, 1053, 1054], "plot_cost_complexity_prun": [364, 1021], "plot_cost_sensitive_learn": [272, 1021], "plot_covariance_estim": [111, 1021], "plot_custom_kernel": [345, 1021], "plot_cv_diabet": [165, 1021], "plot_cv_indic": [273, 1021], "plot_cv_predict": [274, 1021], "plot_cyclical_feature_engin": [43, 1021], "plot_dbscan": [84, 427, 452, 1021], "plot_decision_funct": 358, "plot_dendrogram": 76, "plot_det": [275, 1021], "plot_det_curv": [1053, 1054], "plot_dict_face_patch": [85, 1021], "plot_digit": 44, "plot_digits_agglomer": [86, 1021], "plot_digits_classif": [68, 1021], "plot_digits_classification_exercis": [166, 1021], "plot_digits_denois": [44, 1021], "plot_digits_kde_sampl": [303, 1021], "plot_digits_last_imag": [120, 1021], "plot_digits_linkag": [87, 1021], "plot_digits_pip": [107, 1021], "plot_discret": [320, 1021], "plot_discretization_classif": [321, 1021], "plot_discretization_strategi": [322, 1021], "plot_display_object_visu": [248, 1021], "plot_distribut": 319, "plot_document_classification_20newsgroup": [360, 1021], "plot_document_clust": [361, 1021], "plot_elastic_net_precomputed_gram_matrix_with_weighted_sampl": [201, 1021], "plot_ellips": [70, 263], "plot_embed": 241, "plot_ensemble_oob": [143, 1021], "plot_estimator_represent": [249, 1021], "plot_f_test_vs_mi": [169, 1021], "plot_face_compress": [88, 1021], "plot_face_recognit": [45, 1021], "plot_faces_decomposit": [125, 1021], "plot_feature_agglomeration_vs_univariate_select": [89, 1021], "plot_feature_effect": 360, "plot_feature_select": [170, 1021], "plot_feature_selection_pipelin": [171, 1021], "plot_feature_transform": [144, 1021], "plot_feature_union": [108, 1021], "plot_fig": 217, "plot_forest_hist_grad_boosting_comparison": [145, 1021], "plot_forest_import": [146, 1021], "plot_forest_importances_fac": [147, 1021], "plot_forest_iri": [148, 1021], "plot_galleri": [45, 125, 1030], "plot_gmm": [264, 1021], "plot_gmm_covari": [265, 1021], "plot_gmm_init": [266, 1021], "plot_gmm_pdf": [267, 1021], "plot_gmm_select": [268, 1021], "plot_gmm_sin": [269, 1021], "plot_gpc": [177, 1021], "plot_gpc_iri": [178, 1021], "plot_gpc_isoprob": [179, 1021], "plot_gpc_xor": [180, 1021], "plot_gpr_co2": [181, 1021], "plot_gpr_noisi": [182, 1021], "plot_gpr_noisy_target": [183, 1021], "plot_gpr_on_structured_data": [184, 1021], "plot_gpr_prior_posterior": [185, 1021], "plot_gpr_sampl": 185, "plot_gradient_boosting_categor": [149, 1021], "plot_gradient_boosting_early_stop": [150, 1021], "plot_gradient_boosting_oob": [151, 1021], "plot_gradient_boosting_quantil": [152, 1021], "plot_gradient_boosting_regress": [153, 1021], "plot_gradient_boosting_regular": [154, 1021], "plot_grid_search_digit": [276, 1021], "plot_grid_search_refit_cal": [277, 1021], "plot_grid_search_stat": [278, 1021], "plot_grid_search_text_feature_extract": [279, 1021], "plot_hashing_vs_dict_vector": [362, 1021], "plot_hdbscan": [90, 1021], "plot_hgbt_regress": [155, 1021], "plot_huber_vs_ridg": [202, 1021], "plot_hyperplan": [212, 229, 255], "plot_ica_blind_source_separ": [126, 1021], "plot_ica_vs_pca": [127, 1021], "plot_idx": 148, "plot_image_denois": [128, 1021], "plot_incremental_pca": [129, 1021], "plot_indic": 281, "plot_inductive_clust": [91, 1021], "plot_influ": 46, "plot_info": 149, "plot_iris_dataset": [121, 1021], "plot_iris_dtc": [365, 1021], "plot_iris_exercis": [167, 1021], "plot_iris_logist": [203, 1021], "plot_iris_svc": [346, 1021], "plot_isolation_forest": [156, 1021], "plot_isotonic_regress": [250, 1021], "plot_iterative_imputer_variants_comparison": [187, 1021], "plot_johnson_lindenstrauss_bound": [251, 1021], "plot_kde_1d": [304, 1021], "plot_kernel_approxim": [252, 1021], "plot_kernel_pca": [130, 1021], "plot_kernel_ridge_regress": [253, 1021], "plot_kind": 43, "plot_kmeans_assumpt": [92, 1021], "plot_kmeans_digit": [93, 1021], "plot_kmeans_plusplu": [94, 1021], "plot_kmeans_silhouette_analysi": [95, 1021], "plot_kmeans_stability_low_dim_dens": [96, 1021], "plot_label_propagation_digit": [338, 1021], "plot_label_propagation_digits_active_learn": [339, 1021], "plot_label_propagation_structur": [340, 1021], "plot_lasso_and_elasticnet": [204, 1021], "plot_lasso_coordinate_descent_path": [205, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 1021], "plot_lasso_dense_vs_sparse_data": [206, 1021], "plot_lasso_lar": [207, 1021], "plot_lasso_lars_": [208, 1021], "plot_lasso_model_select": [209, 655, 661, 1021], "plot_lda": [69, 1021], "plot_lda_qda": [70, 1021], "plot_learning_curv": [280, 1021], "plot_likelihood_ratio": [281, 1021], "plot_linear_model_coefficient_interpret": [192, 1021], "plot_linearsvc_support_vector": [347, 1021], "plot_linkage_comparison": [97, 1021], "plot_lle_digit": [241, 1021], "plot_lof_novelty_detect": [305, 1021], "plot_lof_outlier_detect": [306, 1021], "plot_logist": [210, 1021], "plot_logistic_l1_l2_spars": [211, 1021], "plot_logistic_multinomi": [212, 1021], "plot_logistic_path": [213, 1021], "plot_lw_vs_oa": [112, 1021], "plot_mahalanobis_dist": [113, 1021], "plot_manifold_spher": [242, 1021], "plot_map_data_to_norm": [323, 1021], "plot_md": [243, 1021], "plot_mean_shift": [98, 469, 1021], "plot_metadata_rout": [254, 1021], "plot_method": [48, 70, 203, 234, 302, 307, 345, 347, 348, 350, 351, 353, 639], "plot_mini_batch_kmean": [99, 1021], "plot_missing_valu": [188, 1021], "plot_mlp_alpha": [314, 1021], "plot_mlp_training_curv": [315, 1021], "plot_mnist_filt": [316, 1021], "plot_model_complexity_influ": [46, 1021], "plot_monotonic_constraint": [157, 1021], "plot_multi_metric_evalu": [282, 1021], "plot_multi_task_lasso_support": [214, 1021], "plot_multiclass_overview": [296, 1021], "plot_multilabel": [255, 1021], "plot_multioutput_face_complet": [256, 1021], "plot_n_features_influ": 49, "plot_nca_classif": [307, 1021], "plot_nca_dim_reduct": [308, 1021], "plot_nca_illustr": [309, 1021], "plot_nearest_centroid": [310, 1021], "plot_nested_cross_validation_iri": [283, 1021], "plot_nnl": [215, 1021], "plot_num": [79, 97, 247], "plot_obs_pr": 238, "plot_ol": [216, 1021], "plot_ols_3d": [217, 1021], "plot_ols_ridge_vari": [218, 1021], "plot_omp": [219, 1021], "plot_on_dataset": 315, "plot_oneclass": [348, 1021], "plot_opt": [100, 1021], "plot_out_of_core_classif": [47, 1021], "plot_outlier_detection_bench": [257, 1021], "plot_outlier_detection_win": [48, 1021], "plot_partial_depend": [193, 328, 329, 330, 1021, 1046, 1050, 1051, 1052, 1053, 1054, 1055], "plot_partial_dependence_visualization_api": [258, 1021], "plot_pca_iri": [131, 1021], "plot_pca_vs_fa_model_select": [132, 1021], "plot_pca_vs_lda": [133, 1021], "plot_pcr_vs_pl": [118, 1021], "plot_permutation_import": [194, 195, 1021], "plot_permutation_importance_multicollinear": [195, 1021], "plot_permutation_tests_for_classif": [284, 1021], "plot_pipeline_displai": [259, 1021], "plot_poisson_regression_non_normal_loss": [220, 1021], "plot_polynomial_interpol": [221, 887, 891, 1021], "plot_precision_recal": [285, 1021], "plot_precision_recall_curv": [328, 1051, 1053, 1054], "plot_prediction_lat": [49, 1021], "plot_quantile_regress": [222, 1021], "plot_random_dataset": [122, 1021], "plot_random_forest_embed": [158, 1021], "plot_random_forest_regression_multioutput": [159, 1021], "plot_random_multilabel_dataset": [123, 1021], "plot_randomized_search": [286, 1021], "plot_rang": 141, "plot_ransac": [223, 1021], "plot_rbf_paramet": [349, 1021], "plot_rbm_logistic_classif": [317, 1021], "plot_regress": [311, 1021], "plot_release_highlights_0_22_0": [328, 1021], "plot_release_highlights_0_23_0": [329, 1021], "plot_release_highlights_0_24_0": [330, 1021], "plot_release_highlights_1_0_0": [331, 1021], "plot_release_highlights_1_1_0": [332, 1021], "plot_release_highlights_1_2_0": [333, 1021], "plot_release_highlights_1_3_0": [334, 1021], "plot_release_highlights_1_4_0": [335, 1021], "plot_release_highlights_1_5_0": [336, 1021], "plot_result": [70, 149, 263, 264, 269], "plot_rfe_digit": [172, 1021], "plot_rfe_with_cross_valid": [173, 1021], "plot_ridge_coeff": [224, 1021], "plot_ridge_path": [225, 1021], "plot_robust_fit": [226, 1021], "plot_robust_vs_empirical_covari": [114, 1021], "plot_roc": [287, 1021], "plot_roc_crossv": [288, 1021], "plot_roc_curv": [328, 1051, 1053], "plot_roc_curve_visualization_api": [260, 1021], "plot_roc_pr_curv": 272, "plot_sampl": [127, 269], "plot_scalable_poly_kernel": [197, 1021], "plot_scaling_import": [324, 1021], "plot_scatt": 91, "plot_segmentation_toi": [101, 1021], "plot_select_from_model_diabet": [174, 1021], "plot_self_training_varying_threshold": [341, 1021], "plot_semi_supervised_newsgroup": [342, 1021], "plot_semi_supervised_versus_svm_iri": [343, 1021], "plot_separating_hyperplan": [350, 1021], "plot_separating_hyperplane_unbalanc": [351, 1021], "plot_set_output": [261, 1021], "plot_sgd_comparison": [227, 1021], "plot_sgd_early_stop": [228, 1021], "plot_sgd_iri": [229, 1021], "plot_sgd_loss_funct": [230, 1021], "plot_sgd_penalti": [231, 1021], "plot_sgd_separating_hyperplan": [232, 1021], "plot_sgd_weighted_sampl": [233, 1021], "plot_sgdocsvm_vs_ocsvm": [234, 1021], "plot_sparse_cod": [134, 1021], "plot_sparse_cov": [115, 1021], "plot_sparse_logistic_regression_20newsgroup": [235, 1021], "plot_sparse_logistic_regression_mnist": [236, 1021], "plot_species_distribut": 50, "plot_species_distribution_model": [50, 506, 1021], "plot_species_kd": [312, 1021], "plot_spectral_biclust": [58, 1021], "plot_spectral_coclust": [59, 1021], "plot_stack_predictor": [160, 1021], "plot_step": [141, 148, 365], "plot_step_coars": 148, "plot_stock_market": [51, 1021], "plot_subfigur": 255, "plot_successive_halving_heatmap": [289, 1021], "plot_successive_halving_iter": [290, 1021], "plot_surfac": [193, 217], "plot_svm_anova": [352, 1021], "plot_svm_kernel": [353, 1021], "plot_svm_margin": [354, 1021], "plot_svm_regress": [355, 1021], "plot_svm_scale_c": [356, 1021], "plot_svm_tie_break": [357, 1021], "plot_swissrol": [244, 1021], "plot_t_sne_perplex": [245, 1021], "plot_target_encod": [325, 1021], "plot_target_encoder_cross_v": [326, 1021], "plot_theilsen": [237, 1021], "plot_time_series_lagged_featur": [52, 1021], "plot_titl": 263, "plot_tomography_l1_reconstruct": [53, 1021], "plot_top_word": 54, "plot_topics_extraction_with_nmf_lda": [54, 1021], "plot_train_error_vs_test_error": [291, 1021], "plot_training_data_with_decision_boundari": 353, "plot_transformed_target": [109, 1021], "plot_tre": [2, 365, 368, 1016, 1050, 1052, 1053, 1054, 1056, 1057, 1059], "plot_tree_regress": [366, 1021], "plot_tree_regression_multioutput": [367, 1021], "plot_tuned_decision_threshold": [292, 1021], "plot_tweedie_regression_insurance_claim": [238, 1021], "plot_underfitting_overfit": [293, 1021], "plot_unveil_tree_structur": [368, 1021], "plot_validation_curv": [294, 1021], "plot_varimax_fa": [135, 1021], "plot_voting_decision_region": [161, 1021], "plot_voting_proba": [162, 1021], "plot_voting_regressor": [163, 1021], "plot_ward_structured_vs_unstructur": [102, 1021], "plot_weighted_sampl": [358, 1021], "plotli": [145, 279, 386, 404, 409], "pls1": [419, 492], "pls2": [419, 492], "plsca": [117, 491], "plscanon": [2, 117, 490, 492, 493, 1001, 1022, 1036, 1045, 1049, 1051, 1053, 1055, 1059], "plsregress": [2, 117, 118, 1001, 1022, 1036, 1048, 1051, 1053, 1055, 1057, 1059], "plssvd": [2, 490, 491, 1022, 1036, 1053, 1055, 1059], "plsw2a": 419, "plt": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 106, 107, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 195, 197, 199, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 250, 251, 252, 253, 255, 256, 257, 258, 260, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 277, 278, 280, 281, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 332, 333, 335, 338, 339, 340, 341, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 393, 446, 510, 639, 640, 705, 706, 708, 709, 710, 814, 831, 926, 1007, 1029, 1030, 1031, 1032, 1033, 1038], "plu": [285, 383, 391, 687, 843, 846, 1001, 1014], "plug": [421, 996, 1024, 1034], "plugin": 404, "plural": 1047, "plusnet": 224, "pm": [185, 193, 288, 423, 1000], "pmlr": 704, "pmml": 1019, "png": [0, 68, 924], "pnucci": 1057, "po": [153, 243, 424], "podshumok": [1047, 1048], "poesio": 724, "poetri": 410, "poh": [1049, 1050], "point": [2, 8, 37, 43, 48, 50, 52, 53, 63, 67, 72, 73, 75, 76, 83, 84, 87, 90, 93, 95, 99, 102, 113, 114, 117, 121, 122, 123, 124, 126, 128, 130, 139, 141, 145, 148, 149, 150, 155, 158, 173, 174, 178, 183, 184, 189, 192, 193, 194, 199, 203, 209, 212, 214, 216, 218, 220, 221, 222, 224, 226, 229, 232, 233, 237, 238, 240, 241, 242, 243, 244, 247, 250, 252, 265, 269, 270, 271, 275, 279, 280, 281, 285, 287, 288, 296, 298, 299, 302, 303, 304, 305, 306, 307, 308, 310, 312, 314, 320, 321, 323, 325, 336, 338, 339, 341, 343, 345, 349, 350, 351, 353, 354, 357, 358, 360, 361, 362, 365, 369, 373, 374, 375, 380, 381, 382, 383, 384, 385, 386, 388, 390, 391, 392, 394, 398, 400, 401, 415, 416, 421, 422, 423, 424, 427, 428, 448, 449, 450, 451, 452, 454, 455, 456, 457, 458, 460, 462, 463, 464, 465, 466, 468, 469, 477, 480, 482, 504, 506, 512, 520, 522, 523, 527, 530, 533, 538, 541, 543, 549, 560, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 618, 619, 636, 639, 640, 641, 645, 646, 647, 652, 653, 659, 663, 665, 666, 678, 679, 681, 683, 684, 686, 687, 690, 691, 696, 697, 698, 699, 700, 701, 702, 709, 714, 715, 718, 721, 725, 731, 733, 739, 744, 745, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 772, 787, 788, 798, 799, 805, 806, 808, 822, 824, 830, 833, 835, 842, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 865, 866, 869, 870, 873, 877, 882, 891, 892, 906, 907, 908, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 930, 992, 994, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1015, 1016, 1019, 1020, 1021, 1029, 1032, 1033, 1034, 1036, 1041, 1042, 1043, 1045, 1047, 1048, 1049, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "pointer": [386, 394, 450, 1050], "pointplot": 155, "points_color": 240, "pointwis": [142, 183, 427, 452], "poisson": [2, 43, 52, 189, 198, 255, 382, 423, 472, 473, 504, 531, 560, 566, 570, 573, 656, 677, 680, 688, 714, 732, 753, 757, 758, 760, 838, 872, 873, 876, 877, 885, 886, 887, 892, 921, 923, 953, 996, 1016, 1021, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "poisson_gbrt": 220, "poisson_glm": 220, "poissonregressor": [2, 220, 238, 329, 332, 656, 688, 996, 1052, 1055, 1056], "pokorni": 1056, "pola": 52, "polar": [107, 181, 386, 404, 409, 440, 450, 451, 453, 455, 457, 472, 476, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 569, 570, 574, 575, 576, 577, 578, 589, 590, 591, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 696, 697, 700, 856, 861, 864, 868, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 910, 1034, 1058, 1059], "pole": 242, "poli": [43, 167, 197, 278, 346, 353, 355, 460, 543, 628, 773, 782, 808, 887, 914, 915, 916, 917, 918, 996, 1010, 1032], "polici": [155, 191, 192, 220, 238, 272, 400, 543, 549, 996, 1056], "policyhold": [220, 238, 996], "polit": [57, 360, 381, 385, 996, 1001], "polli": 360, "pollut": [360, 736, 793, 1000, 1006], "polmauri": 1048, "poloso": 1055, "polycollect": [814, 831], "polynomi": [2, 54, 187, 189, 196, 198, 220, 226, 252, 259, 278, 293, 304, 330, 331, 346, 355, 378, 382, 460, 499, 628, 647, 648, 649, 651, 653, 680, 773, 782, 783, 838, 873, 882, 884, 887, 891, 912, 914, 915, 916, 917, 918, 995, 1015, 1021, 1022, 1036, 1053, 1054], "polynomial_featur": 293, "polynomial_kernel": [2, 773, 998, 1058], "polynomialcountsketch": [2, 197, 647, 649, 992, 1053, 1055, 1058], "polynomialfeatur": [2, 43, 199, 220, 221, 226, 259, 293, 330, 353, 891, 996, 1010, 1045, 1049, 1050, 1051, 1054, 1055, 1057, 1058], "polynomialfeaturespolynomialfeatur": 259, "polysemi": 421, "polytop": 523, "pomegran": 1019, "ponc": [421, 539, 545], "poncho": 1024, "pone": 380, "ponnuthurai": 383, "ponzi": 325, "pooch": [88, 386, 404, 409], "pooja": [1056, 1057, 1058], "pool": [287, 398, 453, 643, 969, 1020, 1052], "pooling_func": [453, 1049], "poolqc": 149, "poolsawat": [1055, 1056], "poor": [193, 197, 284, 294, 341, 414, 420, 421, 698, 702, 746, 849, 852, 853, 994, 995, 997, 1002, 1020, 1025, 1048, 1049, 1050, 1052, 1054], "poor_scor": 388, "poorer": [149, 369, 421], "poorest": 1002, "poorli": [62, 64, 97, 111, 118, 142, 154, 244, 374, 416, 423, 536, 638, 996, 997, 1047], "poorna": [1051, 1053], "pop": [368, 398, 927, 1029, 1049], "popa": [1051, 1052], "popitem": 927, "popo": 1044, "popul": [106, 111, 113, 155, 192, 220, 257, 281, 319, 381, 395, 400, 418, 448, 498, 720, 726, 854, 855, 856, 858, 860, 862, 863, 864, 969, 1000, 1006, 1010, 1016], "popular": [6, 10, 187, 244, 381, 384, 391, 394, 398, 400, 422, 423, 424, 426, 460, 470, 990, 992, 996, 998, 1005, 1014, 1020, 1029, 1034], "port": [384, 404, 1051], "portabl": [410, 1019], "porter": 1019, "portfolio": [220, 238, 994], "portion": [45, 47, 114, 150, 174, 287, 373, 381, 383, 386, 392, 400, 796, 833, 850, 989, 999, 1003, 1030, 1034], "portland": [416, 427, 452], "portnoi": [996, 1058], "portrait": [45, 421, 1030], "pos_class": 47, "pos_label": [248, 257, 272, 292, 400, 415, 446, 447, 706, 708, 710, 714, 715, 717, 735, 737, 738, 746, 790, 791, 792, 795, 797, 807, 879, 896, 1000, 1049, 1053, 1055, 1059], "pos_lr": 281, "pos_lr_bas": 281, "pos_lr_base_std": 281, "pos_tagg": 424, "pos_vector": 424, "pos_window": 424, "pose": [224, 286, 996, 1033], "posit": [0, 2, 43, 45, 47, 50, 51, 61, 62, 64, 102, 135, 155, 157, 162, 172, 191, 192, 204, 205, 215, 220, 221, 222, 224, 238, 243, 251, 257, 272, 275, 278, 281, 285, 287, 288, 292, 319, 329, 330, 334, 336, 360, 368, 373, 381, 385, 386, 388, 393, 395, 400, 401, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 428, 446, 447, 450, 454, 455, 457, 472, 475, 502, 506, 508, 512, 516, 517, 518, 533, 535, 537, 538, 539, 541, 543, 544, 545, 550, 553, 554, 556, 557, 558, 565, 569, 570, 571, 572, 600, 601, 602, 603, 604, 606, 607, 608, 614, 618, 619, 628, 639, 640, 651, 654, 655, 656, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 677, 680, 681, 682, 683, 685, 688, 689, 690, 691, 692, 695, 698, 706, 708, 710, 715, 717, 720, 721, 723, 724, 726, 728, 730, 732, 735, 737, 738, 739, 743, 744, 746, 747, 748, 749, 750, 751, 752, 760, 762, 766, 774, 790, 791, 792, 795, 796, 797, 805, 806, 807, 811, 812, 835, 852, 853, 854, 856, 858, 860, 862, 864, 865, 875, 876, 879, 885, 888, 891, 896, 900, 904, 905, 907, 908, 912, 913, 916, 917, 918, 920, 922, 929, 947, 949, 965, 967, 991, 992, 996, 998, 1000, 1001, 1003, 1004, 1005, 1007, 1010, 1015, 1030, 1032, 1034, 1042, 1044, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "position": 400, "positive_class": [47, 720], "positive_cod": [125, 539, 545, 550, 553, 554], "positive_dict": [125, 539, 545, 553, 554], "positive_featur": 391, "positive_likelihood_ratio": [281, 720], "posix": [374, 398], "possa": 1048, "possibl": [0, 30, 43, 52, 55, 63, 64, 72, 84, 90, 105, 111, 125, 142, 145, 155, 157, 176, 192, 193, 194, 195, 220, 237, 238, 252, 254, 272, 278, 279, 280, 281, 283, 284, 285, 287, 288, 298, 328, 349, 356, 360, 361, 369, 373, 374, 375, 379, 380, 381, 386, 387, 388, 389, 390, 392, 394, 398, 399, 400, 404, 407, 410, 413, 414, 415, 416, 417, 419, 420, 421, 423, 424, 426, 428, 430, 439, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 470, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 504, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 640, 641, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 696, 697, 698, 699, 700, 717, 729, 730, 731, 732, 736, 750, 764, 786, 791, 793, 796, 805, 806, 807, 808, 810, 811, 812, 814, 820, 821, 822, 826, 827, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 930, 932, 933, 936, 941, 971, 974, 989, 992, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1015, 1016, 1020, 1024, 1025, 1032, 1033, 1034, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1054, 1055, 1056, 1057], "possibli": [92, 118, 174, 220, 235, 353, 361, 383, 385, 394, 410, 416, 423, 424, 459, 461, 597, 847, 848, 849, 850, 851, 917, 918, 920, 921, 922, 923, 989, 992, 997, 1003, 1010, 1056], "post": [2, 46, 54, 57, 104, 173, 174, 189, 248, 270, 282, 285, 296, 332, 336, 341, 360, 361, 362, 363, 368, 373, 381, 385, 386, 390, 391, 399, 411, 416, 456, 496, 497, 504, 508, 559, 569, 666, 708, 710, 720, 726, 750, 792, 795, 807, 808, 824, 830, 835, 838, 873, 892, 910, 920, 1000, 1016, 1021, 1023, 1024, 1034, 1036, 1052], "post1": [384, 404, 408, 409, 1039], "poster": [360, 385, 386, 1033], "posterior": [92, 175, 176, 177, 182, 189, 199, 272, 278, 292, 421, 426, 557, 558, 560, 618, 619, 621, 622, 623, 627, 630, 631, 635, 652, 653, 716, 805, 807, 830, 994, 1019, 1021, 1047, 1050], "posteriori": [996, 1002], "postfit_hook": 46, "postpon": [388, 390], "postprocess": [61, 414, 543, 549], "postprocessor": 1052, "postscript": 924, "potenti": [2, 43, 64, 90, 111, 155, 188, 191, 193, 199, 272, 305, 306, 314, 334, 335, 353, 362, 373, 374, 384, 400, 404, 407, 415, 416, 420, 423, 424, 476, 490, 491, 492, 493, 504, 532, 557, 565, 566, 569, 570, 572, 573, 581, 614, 619, 642, 771, 830, 902, 903, 910, 920, 921, 922, 923, 1006, 1014, 1016, 1019, 1034, 1044, 1051, 1052, 1055, 1058, 1059], "poughon": 1048, "poundal": 104, "pour": 1000, "pourbozorg": [1049, 1050, 1051], "pow": [684, 685, 686, 869, 870], "powel": [45, 381], "power": [2, 43, 46, 55, 145, 150, 191, 221, 238, 269, 281, 286, 303, 319, 320, 323, 338, 346, 373, 374, 399, 414, 416, 419, 422, 423, 424, 427, 452, 490, 491, 492, 540, 543, 549, 552, 638, 688, 702, 732, 755, 757, 760, 854, 855, 862, 863, 865, 866, 887, 888, 889, 900, 901, 948, 949, 996, 997, 1000, 1008, 1010, 1014, 1015, 1024, 1044, 1047, 1049, 1051, 1052, 1054, 1058], "power_iter": 55, "power_iteration_norm": [412, 549, 552, 948, 949, 1055], "power_t": [684, 685, 686, 869, 870, 1014], "power_transform": [2, 888, 901, 1049], "powers_": 887, "powershel": 384, "powertransform": [2, 323, 889, 900, 990, 1010, 1049, 1052, 1055, 1057], "pox": 296, "poznik": [1054, 1055, 1056], "pp": [0, 98, 174, 277, 383, 416, 418, 424, 427, 428, 452, 456, 460, 470, 519, 541, 542, 549, 598, 643, 651, 672, 693, 694, 728, 734, 738, 748, 764, 777, 791, 847, 849, 851, 868, 888, 900, 993, 1000, 1002, 1003, 1013], "pp2013": 992, "pp84": 426, "ppc64le": 394, "ppf": 278, "ppm": 181, "pprint": [55, 152, 254, 279, 381, 944], "pq": 333, "pr": [0, 162, 374, 386, 389, 394, 424, 749, 1000, 1023, 1051, 1053], "pr_displai": 248, "pr_number": 394, "prabakaran": [1049, 1050, 1053, 1055, 1056], "prabhakar": 421, "practic": [64, 88, 105, 113, 118, 128, 145, 149, 150, 155, 176, 191, 192, 197, 204, 222, 247, 253, 279, 286, 305, 306, 330, 336, 349, 353, 374, 386, 388, 389, 392, 394, 399, 400, 416, 418, 420, 421, 422, 423, 424, 426, 455, 460, 470, 529, 532, 597, 640, 641, 678, 805, 851, 905, 912, 989, 990, 994, 996, 999, 1000, 1001, 1002, 1003, 1006, 1007, 1010, 1019, 1020, 1022, 1024, 1025, 1034, 1035, 1036, 1043, 1047, 1049, 1051, 1053], "practicalswift": 1047, "practis": 225, "practition": [143, 224], "pradeep": [1049, 1050], "pragmat": 386, "prakash": [1046, 1048, 1054], "pramod": 1055, "pranayanchuri": 1054, "prang": 387, "prasanth": 1056, "pratama": 1052, "pratap": [1045, 1048, 1055], "prathmesh": 1050, "pratik": 1048, "pratiqu": 383, "pravar": 1049, "pravarmahajan": [1048, 1049], "pre": [44, 105, 192, 209, 319, 362, 384, 386, 400, 404, 415, 418, 420, 421, 423, 424, 425, 427, 428, 451, 452, 455, 467, 541, 543, 698, 720, 771, 807, 875, 917, 1000, 1005, 1010, 1015, 1016, 1019, 1020, 1036, 1044, 1049, 1055, 1059, 1060], "pre_dispatch": [808, 814, 822, 831, 833, 834, 835, 836, 839, 966, 1044], "preambl": 90, "prec": [115, 248, 535, 1000], "prec_": 115, "prec_macro": 420, "preced": [374, 386, 495, 1000, 1041], "precipit": 414, "precis": [2, 8, 45, 52, 62, 68, 104, 109, 115, 125, 171, 182, 183, 189, 197, 248, 270, 271, 272, 276, 317, 319, 338, 339, 386, 388, 400, 413, 414, 415, 416, 418, 421, 423, 451, 477, 478, 479, 480, 481, 482, 483, 484, 486, 512, 531, 540, 542, 549, 552, 652, 653, 654, 656, 658, 659, 660, 662, 663, 664, 677, 680, 682, 688, 690, 691, 695, 707, 708, 714, 715, 716, 721, 735, 737, 738, 739, 747, 749, 771, 790, 791, 792, 795, 796, 805, 806, 830, 838, 841, 852, 853, 858, 873, 892, 896, 912, 917, 924, 926, 949, 994, 996, 1003, 1004, 1015, 1021, 1030, 1034, 1041, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "precision_": [51, 115, 477, 478, 479, 480, 481, 482, 483, 484], "precision_macro": [420, 1029], "precision_recall_curv": [2, 248, 285, 708, 714, 715, 735, 1000, 1042, 1043, 1047, 1054, 1055, 1057, 1059], "precision_recall_fscore_support": [2, 721, 737, 738, 792, 795, 1000, 1045, 1049, 1051, 1057], "precision_scor": [2, 62, 272, 285, 716, 795, 1000, 1041, 1043, 1044, 1045, 1046, 1051, 1057], "precision_threshold": 276, "precisionrecalldisplai": [2, 272, 285, 331, 790, 792, 795, 1000, 1051, 1054, 1057, 1058, 1059], "precisions_": [805, 806], "precisions_cholesky_": [805, 806, 1055], "precisions_init": [806, 1055, 1057], "precompil": 384, "precomput": [124, 125, 126, 189, 198, 243, 299, 301, 388, 395, 398, 400, 416, 424, 427, 439, 448, 449, 452, 453, 454, 458, 460, 465, 473, 479, 490, 491, 492, 532, 539, 543, 545, 548, 549, 550, 556, 562, 564, 566, 568, 570, 573, 576, 578, 618, 619, 628, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 689, 690, 692, 693, 696, 698, 699, 700, 704, 782, 786, 789, 800, 801, 845, 846, 854, 855, 856, 858, 859, 860, 862, 863, 864, 870, 913, 914, 915, 916, 917, 918, 921, 923, 976, 977, 978, 992, 996, 998, 1003, 1015, 1020, 1021, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1054, 1055, 1056, 1057, 1058, 1059], "precompute_dist": [1045, 1052], "precompute_gram": 1043, "precomputed_nearest_neighbor": [460, 699], "precondit": [416, 460, 470, 703, 1016, 1057], "pred": [43, 46, 50, 52, 68, 357, 360, 381, 656, 677, 688, 705, 710, 714, 726, 737, 738, 746, 791, 792, 795, 796, 1000], "pred1": 163, "pred2": 163, "pred3": 163, "pred4": 163, "pred_background": 50, "pred_decis": [743, 1000, 1054], "pred_entropi": [338, 339], "pred_nam": [45, 1030], "pred_ort": 410, "pred_scor": 46, "pred_test": 50, "pred_typ": 49, "predecessor": [139, 458, 463, 464, 465, 1058], "predecessor_": [458, 465], "predecessor_correct": [458, 464], "predefin": [2, 282, 821, 989, 1003, 1029, 1056, 1058], "predefinedsplit": [2, 420, 1029, 1045], "predetermin": [416, 997], "predict": [2, 5, 13, 27, 42, 45, 46, 47, 50, 60, 62, 63, 64, 66, 68, 70, 72, 79, 83, 91, 92, 93, 97, 104, 105, 106, 107, 109, 117, 135, 137, 138, 139, 141, 142, 143, 145, 147, 148, 149, 150, 153, 155, 156, 157, 158, 159, 160, 161, 162, 166, 167, 171, 172, 174, 175, 176, 178, 179, 181, 182, 183, 184, 185, 187, 188, 189, 192, 193, 194, 195, 197, 199, 202, 203, 204, 212, 215, 216, 217, 218, 221, 222, 223, 224, 226, 227, 228, 229, 234, 235, 237, 238, 247, 248, 250, 252, 254, 256, 264, 265, 266, 267, 268, 269, 270, 271, 276, 278, 280, 281, 284, 287, 288, 292, 293, 296, 298, 302, 305, 306, 307, 310, 311, 317, 319, 320, 324, 325, 328, 329, 330, 331, 332, 334, 335, 336, 339, 341, 342, 343, 345, 346, 348, 349, 353, 355, 356, 357, 360, 361, 365, 366, 367, 368, 369, 372, 374, 378, 381, 383, 386, 388, 393, 395, 400, 403, 407, 410, 411, 412, 414, 416, 417, 419, 421, 423, 424, 425, 430, 433, 438, 439, 445, 446, 447, 448, 450, 451, 452, 455, 456, 457, 473, 477, 490, 491, 492, 495, 509, 516, 532, 542, 549, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 585, 590, 601, 602, 610, 614, 618, 619, 621, 622, 623, 624, 630, 633, 635, 636, 638, 639, 640, 641, 642, 643, 645, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 705, 706, 708, 709, 710, 711, 713, 714, 715, 716, 717, 718, 720, 722, 723, 726, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 742, 743, 746, 749, 750, 751, 754, 756, 758, 760, 764, 790, 791, 792, 793, 794, 795, 796, 797, 801, 802, 804, 805, 806, 807, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 858, 859, 862, 863, 869, 870, 872, 879, 892, 893, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 974, 989, 990, 991, 992, 993, 994, 995, 996, 998, 999, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1024, 1026, 1028, 1029, 1030, 1034, 1036, 1038, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "predict_ecoc": 1045, "predict_joint_log_proba": [847, 848, 849, 850, 851, 1056], "predict_log_proba": [388, 400, 557, 558, 559, 561, 563, 565, 567, 572, 601, 602, 666, 667, 684, 807, 808, 811, 812, 822, 830, 833, 843, 847, 848, 849, 850, 851, 869, 872, 909, 914, 917, 920, 922, 1015, 1041, 1054, 1058], "predict_ovo": 1045, "predict_ovr": 1045, "predict_param": [254, 473, 575, 576, 1054], "predict_proba": [30, 61, 62, 63, 64, 66, 70, 158, 162, 174, 177, 178, 179, 180, 272, 287, 292, 298, 314, 321, 324, 328, 330, 336, 360, 388, 393, 400, 414, 415, 423, 445, 446, 557, 558, 559, 561, 563, 565, 567, 569, 572, 575, 577, 601, 602, 618, 627, 628, 630, 631, 639, 640, 641, 666, 667, 684, 706, 708, 710, 730, 749, 750, 796, 805, 806, 807, 808, 811, 812, 822, 830, 833, 840, 841, 842, 843, 844, 847, 848, 849, 850, 851, 854, 862, 869, 872, 879, 907, 908, 909, 914, 917, 920, 922, 996, 1000, 1002, 1004, 1007, 1013, 1014, 1015, 1016, 1041, 1042, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1059], "predict_proba_ovr": 1045, "predicted_label": [338, 339], "prediction_df": 155, "prediction_perform": 46, "prediction_performance_comput": 46, "prediction_performance_label": 46, "prediction_pow": 46, "prediction_tim": [46, 47], "prediction_titl": [45, 1030], "predictionerrordisplai": [2, 43, 52, 109, 160, 192, 274, 333, 1000, 1056, 1058], "predictions_kr": 176, "predictive_analyt": 1016, "predictive_word": 360, "predictor": [2, 109, 138, 149, 163, 187, 189, 220, 238, 249, 388, 399, 400, 417, 419, 420, 423, 426, 474, 475, 490, 491, 492, 504, 524, 525, 526, 563, 564, 570, 573, 576, 610, 618, 638, 640, 641, 656, 661, 665, 677, 681, 688, 709, 833, 835, 844, 845, 872, 873, 885, 886, 892, 974, 996, 1001, 1021, 1042, 1048, 1051], "predispatch": [814, 831, 836, 839], "predit": 118, "predomin": [388, 1042], "prefer": [73, 79, 90, 155, 269, 287, 319, 369, 373, 374, 375, 386, 387, 388, 400, 416, 420, 421, 423, 424, 448, 462, 479, 480, 486, 495, 516, 517, 635, 640, 641, 662, 666, 667, 709, 734, 736, 750, 765, 766, 843, 861, 887, 912, 913, 954, 966, 989, 992, 994, 996, 1000, 1005, 1015, 1016, 1019, 1023, 1032, 1042, 1048, 1050, 1054, 1055, 1058], "prefetch": 966, "prefit": [63, 272, 400, 414, 415, 425, 445, 575, 576, 605, 807, 830, 1020, 1053, 1054, 1055, 1060], "prefix": [2, 55, 104, 279, 301, 328, 386, 390, 392, 394, 426, 432, 450, 451, 453, 455, 457, 472, 475, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 647, 648, 649, 650, 696, 697, 700, 814, 836, 856, 861, 864, 868, 871, 872, 878, 904, 905, 1047, 1048, 1054, 1056, 1059], "prein": [0, 376, 1053, 1054, 1055], "preiss": 1054, "preliminari": 470, "prematur": 1054, "prepar": [221, 254, 360, 373, 388, 389, 392, 394, 1016, 1024, 1049, 1057], "prepend": [192, 1041], "preprint": 383, "preprocess": [2, 43, 44, 45, 49, 64, 67, 77, 79, 84, 88, 90, 93, 97, 104, 105, 106, 107, 109, 118, 125, 135, 144, 149, 170, 172, 174, 181, 185, 194, 197, 199, 201, 208, 209, 211, 220, 221, 226, 236, 238, 241, 248, 249, 258, 261, 272, 275, 285, 287, 292, 293, 302, 307, 308, 314, 315, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 342, 349, 352, 361, 375, 378, 380, 383, 386, 391, 399, 400, 410, 412, 413, 416, 417, 420, 423, 424, 425, 472, 473, 474, 475, 497, 575, 589, 590, 596, 597, 599, 638, 666, 667, 680, 682, 684, 686, 695, 841, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 912, 913, 914, 915, 917, 918, 990, 996, 1001, 1004, 1011, 1014, 1015, 1017, 1019, 1021, 1023, 1024, 1025, 1030, 1031, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1060], "preprocessor": [105, 160, 192, 220, 249, 257, 259, 325, 329, 331, 332, 333, 335, 417, 424, 596, 597, 599, 1019, 1034, 1041, 1044, 1049, 1051], "preprocessor__cat__selector__percentil": 105, "preprocessor__num__imputer__strategi": 105, "preprocessor_list": 257, "prescrib": 400, "presenc": [2, 48, 95, 97, 113, 114, 137, 191, 195, 204, 224, 257, 319, 384, 387, 400, 418, 421, 720, 734, 764, 777, 841, 875, 883, 885, 892, 984, 990, 996, 1000, 1001, 1014, 1023, 1044, 1045, 1047, 1051, 1053, 1055], "present": [43, 44, 52, 78, 84, 123, 125, 132, 144, 145, 152, 155, 156, 173, 174, 182, 185, 199, 202, 204, 209, 220, 247, 250, 254, 268, 272, 276, 281, 284, 287, 288, 299, 319, 322, 324, 361, 383, 384, 388, 391, 398, 400, 407, 416, 418, 421, 423, 424, 434, 435, 438, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 472, 476, 477, 478, 479, 480, 481, 482, 483, 484, 497, 498, 499, 500, 504, 508, 509, 510, 511, 512, 513, 518, 539, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 557, 558, 569, 570, 571, 574, 577, 578, 589, 590, 591, 596, 597, 599, 625, 635, 636, 637, 638, 658, 662, 685, 696, 697, 698, 699, 720, 737, 738, 746, 777, 791, 792, 795, 805, 806, 808, 811, 812, 820, 822, 836, 854, 855, 856, 858, 860, 862, 863, 864, 871, 876, 884, 885, 886, 887, 888, 890, 893, 904, 905, 916, 924, 926, 927, 949, 984, 999, 1000, 1001, 1002, 1007, 1010, 1018, 1020, 1044, 1049, 1051, 1052, 1053, 1055, 1056, 1058], "preserv": [37, 43, 83, 130, 244, 251, 273, 388, 389, 420, 421, 423, 424, 589, 596, 597, 599, 654, 660, 704, 750, 782, 786, 826, 827, 828, 896, 932, 933, 990, 996, 997, 1010, 1012, 1019, 1029, 1033, 1041, 1044, 1045, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1059], "preserves_dtyp": 388, "preservs": 1055, "preset": [674, 676, 684, 1004], "presort": [1046, 1051], "press": [381, 416, 421, 426, 427, 452, 598, 618, 619, 622, 627, 630, 651, 847, 851, 993, 996, 998, 1002], "pressur": [174, 383, 1032], "preston": [1046, 1047, 1048], "presum": [192, 298, 416, 424, 847], "prettenhof": [0, 50, 151, 153, 154, 279, 360, 361, 406, 1041, 1042, 1043, 1044, 1045, 1046], "pretti": [193, 244, 276, 360, 373, 386, 398, 869, 870, 1004, 1050], "preuss": 1057, "prev_scor": 55, "preval": [139, 328, 400, 708, 720, 1000], "prevalence_pos_label": [285, 708], "prevent": [43, 90, 150, 152, 171, 191, 221, 224, 319, 325, 326, 349, 360, 364, 369, 386, 388, 390, 398, 399, 410, 416, 421, 424, 450, 457, 496, 497, 569, 570, 598, 599, 619, 736, 793, 869, 870, 897, 898, 900, 901, 902, 903, 1000, 1002, 1005, 1006, 1010, 1016, 1032, 1043, 1044, 1046, 1048, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1059], "previou": [43, 78, 88, 105, 125, 142, 149, 150, 152, 160, 176, 181, 182, 191, 192, 193, 204, 206, 221, 251, 253, 254, 272, 278, 281, 285, 319, 324, 332, 360, 361, 362, 369, 373, 381, 386, 388, 391, 392, 394, 398, 400, 401, 404, 415, 416, 423, 424, 476, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 638, 654, 656, 660, 661, 666, 668, 670, 674, 675, 676, 677, 684, 685, 686, 688, 715, 827, 843, 846, 861, 869, 870, 909, 926, 996, 1000, 1004, 1010, 1020, 1025, 1034, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "previous": [46, 88, 92, 105, 139, 182, 192, 272, 276, 285, 292, 332, 381, 394, 398, 404, 416, 421, 424, 448, 451, 462, 532, 542, 549, 657, 666, 667, 674, 675, 676, 684, 685, 686, 912, 996, 1010, 1019, 1038, 1041, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "previous_loss": [674, 675, 676, 685], "previs": 248, "price": [51, 109, 149, 150, 155, 160, 257, 325, 990, 996, 1024, 1030], "priceless": 386, "prieur": 1054, "primal": [666, 667, 685, 912, 913, 1014, 1015], "primari": [388, 400, 421, 523, 1007, 1023, 1024], "primarili": [269, 283, 386, 400, 412, 416, 958, 1024, 1050, 1051], "primat": 360, "primdal": 1049, "primit": 1056, "princ": 1054, "princip": [2, 42, 116, 117, 121, 127, 129, 130, 131, 133, 158, 189, 240, 252, 255, 308, 324, 330, 378, 416, 419, 428, 492, 539, 540, 541, 542, 543, 545, 547, 548, 549, 550, 551, 552, 553, 554, 558, 665, 696, 697, 698, 700, 701, 838, 861, 873, 892, 948, 949, 997, 1003, 1021, 1035, 1036, 1041], "principl": [139, 183, 304, 362, 386, 398, 400, 401, 420, 423, 949, 989, 999, 1003, 1014, 1048], "print": [2, 43, 45, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 61, 63, 66, 68, 73, 77, 78, 81, 82, 83, 84, 85, 87, 88, 93, 95, 96, 98, 102, 104, 105, 107, 108, 109, 113, 117, 118, 123, 125, 128, 132, 133, 135, 139, 142, 145, 146, 147, 148, 149, 151, 153, 155, 165, 166, 170, 171, 173, 174, 176, 177, 179, 181, 185, 191, 193, 194, 195, 197, 204, 205, 206, 207, 211, 212, 215, 216, 220, 222, 223, 224, 227, 228, 235, 236, 238, 241, 242, 245, 249, 251, 253, 254, 257, 261, 266, 271, 272, 276, 277, 278, 279, 281, 283, 286, 287, 291, 299, 303, 310, 312, 315, 316, 317, 321, 324, 326, 328, 329, 330, 332, 334, 335, 336, 338, 339, 342, 349, 360, 361, 362, 364, 368, 369, 373, 380, 381, 384, 387, 388, 394, 400, 407, 410, 417, 420, 423, 424, 426, 472, 475, 476, 480, 486, 498, 502, 510, 520, 521, 549, 552, 557, 558, 567, 568, 569, 570, 572, 573, 577, 578, 585, 591, 592, 593, 595, 596, 597, 599, 620, 625, 626, 638, 654, 655, 657, 658, 660, 661, 662, 664, 668, 669, 670, 671, 674, 675, 684, 685, 692, 704, 721, 725, 745, 803, 805, 806, 807, 809, 810, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829, 830, 834, 835, 836, 837, 839, 841, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 858, 859, 860, 861, 862, 863, 864, 869, 870, 871, 872, 873, 874, 882, 888, 892, 900, 910, 911, 912, 913, 914, 917, 919, 925, 931, 936, 961, 984, 990, 1000, 1001, 1002, 1003, 1008, 1016, 1025, 1029, 1030, 1032, 1033, 1034, 1041, 1043, 1049, 1050, 1052, 1056], "print_changed_onli": [476, 910, 1050, 1052, 1053], "print_datafram": 276, "print_progress": 966, "print_rout": 254, "printabl": 1023, "prior": [2, 42, 46, 55, 81, 82, 92, 100, 101, 102, 123, 175, 176, 182, 188, 189, 194, 199, 201, 204, 262, 264, 268, 269, 272, 278, 289, 309, 386, 388, 390, 400, 404, 407, 416, 419, 421, 423, 426, 473, 531, 544, 556, 557, 558, 559, 567, 619, 621, 622, 623, 627, 630, 631, 638, 652, 653, 654, 655, 659, 660, 662, 663, 664, 668, 669, 670, 680, 686, 689, 724, 805, 847, 848, 849, 850, 851, 872, 873, 887, 914, 917, 967, 989, 992, 994, 996, 999, 1000, 1002, 1008, 1016, 1017, 1021, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1054, 1057], "prior_k": 557, "priori": [220, 237, 287, 298, 319, 400, 416, 423, 596, 602, 999, 1057], "priorit": [415, 1020, 1048], "prioriti": [385, 640, 840, 841, 1020, 1044], "priors_": [557, 558], "privaci": 1019, "privat": [0, 390, 400, 401, 928, 1024, 1041, 1049, 1051, 1052, 1054, 1055], "privileg": [257, 394], "priyam": 1056, "priyash": 1059, "prng": [115, 1033], "pro": 999, "proanthocyanin": 383, "prob_pos_clf": 61, "prob_pos_isoton": 61, "prob_pos_sigmoid": 61, "prob_pr": [446, 447], "prob_tru": [446, 447], "proba": [62, 64, 162, 445, 920, 922], "proba_": [914, 917, 1052], "proba_map": 90, "proba_neg_class": [62, 64], "proba_pos_class": [62, 64], "probabilist": [54, 64, 66, 115, 124, 125, 134, 135, 175, 176, 179, 182, 183, 189, 253, 272, 360, 400, 414, 422, 423, 445, 481, 484, 540, 542, 543, 549, 567, 596, 597, 618, 630, 651, 653, 684, 711, 749, 808, 834, 879, 914, 915, 917, 918, 993, 994, 996, 999, 1000, 1005, 1010, 1015, 1016, 1019, 1021, 1024, 1041, 1044, 1048], "probabilisticpca": [1041, 1044], "probabilities_": [90, 454], "probabilities_or_label": 577, "probabl": [0, 2, 5, 30, 52, 60, 64, 65, 70, 90, 109, 122, 123, 138, 155, 161, 169, 175, 176, 177, 178, 189, 192, 212, 232, 235, 236, 240, 244, 248, 250, 251, 272, 278, 280, 281, 284, 285, 288, 292, 296, 298, 317, 319, 323, 328, 330, 336, 341, 343, 355, 356, 373, 381, 382, 388, 392, 398, 400, 415, 416, 420, 421, 424, 425, 426, 442, 443, 444, 445, 446, 447, 454, 455, 457, 512, 520, 523, 531, 535, 557, 558, 559, 561, 563, 565, 567, 569, 572, 575, 577, 578, 601, 602, 618, 621, 622, 630, 635, 639, 640, 641, 666, 667, 679, 684, 700, 706, 708, 710, 711, 714, 715, 717, 720, 724, 728, 730, 734, 735, 737, 747, 748, 749, 750, 764, 790, 792, 795, 796, 797, 802, 805, 806, 807, 808, 811, 812, 822, 830, 837, 838, 841, 843, 844, 847, 848, 849, 850, 851, 854, 857, 862, 868, 869, 893, 905, 906, 907, 908, 909, 912, 914, 917, 920, 922, 994, 995, 996, 997, 998, 999, 1000, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1012, 1013, 1014, 1016, 1020, 1021, 1022, 1034, 1036, 1041, 1043, 1045, 1047, 1049, 1050, 1051, 1052, 1053, 1055], "probable_clust": 91, "probas_pr": [790, 1059], "probb_": [914, 917, 1052], "probe": 1008, "probinette4": 1053, "probl": [615, 616], "problem": [2, 11, 25, 42, 43, 44, 45, 50, 52, 53, 54, 63, 72, 89, 90, 92, 101, 125, 139, 142, 145, 147, 152, 153, 176, 189, 194, 197, 199, 204, 206, 209, 213, 214, 220, 222, 224, 237, 238, 242, 247, 248, 255, 257, 260, 276, 278, 283, 287, 288, 292, 293, 296, 298, 299, 304, 311, 323, 331, 335, 336, 346, 349, 353, 356, 357, 360, 361, 368, 369, 373, 381, 382, 383, 384, 385, 387, 388, 391, 392, 395, 398, 400, 414, 415, 416, 418, 420, 422, 423, 424, 425, 426, 427, 428, 452, 455, 457, 458, 460, 465, 470, 473, 486, 511, 516, 517, 523, 524, 525, 526, 531, 532, 536, 539, 541, 545, 547, 550, 551, 552, 553, 554, 555, 556, 559, 560, 565, 569, 572, 575, 579, 581, 597, 618, 639, 651, 656, 658, 660, 662, 663, 664, 665, 666, 667, 672, 673, 674, 676, 677, 680, 681, 682, 683, 684, 685, 687, 688, 693, 694, 695, 696, 697, 699, 701, 703, 716, 724, 737, 738, 743, 746, 747, 791, 792, 795, 796, 805, 806, 809, 810, 811, 812, 813, 815, 816, 817, 818, 823, 824, 825, 826, 827, 828, 832, 840, 841, 842, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 878, 879, 885, 893, 896, 902, 903, 912, 913, 920, 922, 938, 949, 990, 991, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1008, 1010, 1014, 1017, 1020, 1022, 1024, 1026, 1027, 1028, 1034, 1035, 1036, 1041, 1042, 1044, 1046, 1047, 1048, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "problemat": [43, 192, 272, 274, 417, 990, 1049], "proc": [64, 112, 414, 424, 458, 697, 701, 847, 989, 997, 1002, 1006], "proce": [85, 171, 201, 384, 390, 419, 420, 423, 448, 996], "procedur": [25, 81, 91, 145, 152, 174, 200, 208, 268, 280, 322, 326, 349, 360, 369, 386, 388, 398, 399, 400, 401, 414, 418, 420, 421, 423, 425, 539, 545, 546, 548, 553, 554, 555, 561, 562, 563, 564, 567, 568, 601, 603, 610, 617, 652, 680, 682, 695, 736, 793, 869, 870, 889, 901, 971, 989, 996, 1002, 1010, 1013, 1014, 1015, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "proceed": [113, 174, 381, 383, 416, 427, 447, 452, 519, 704, 716, 734, 764, 859, 909, 1000, 1012, 1013, 1014], "process": [0, 2, 19, 37, 43, 44, 47, 57, 63, 66, 67, 70, 80, 81, 82, 83, 85, 91, 92, 101, 104, 106, 108, 112, 114, 122, 126, 127, 129, 137, 139, 148, 150, 152, 157, 158, 165, 166, 167, 191, 199, 202, 222, 224, 230, 232, 233, 253, 254, 255, 257, 263, 264, 267, 269, 272, 278, 280, 281, 290, 296, 314, 319, 321, 322, 330, 334, 339, 343, 353, 354, 361, 362, 364, 373, 374, 375, 381, 385, 386, 388, 390, 392, 395, 398, 399, 400, 410, 416, 417, 418, 420, 421, 422, 423, 424, 425, 429, 456, 457, 483, 504, 512, 531, 542, 543, 544, 545, 546, 569, 570, 571, 596, 597, 599, 618, 619, 621, 622, 623, 625, 626, 627, 630, 631, 633, 635, 640, 641, 647, 651, 672, 680, 693, 694, 711, 731, 749, 789, 805, 807, 808, 811, 812, 822, 830, 833, 834, 835, 844, 845, 861, 875, 879, 881, 882, 883, 892, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 966, 989, 992, 996, 1000, 1003, 1010, 1012, 1014, 1016, 1018, 1019, 1020, 1021, 1022, 1024, 1025, 1026, 1033, 1034, 1036, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1057, 1058], "process_rout": [2, 254, 1058], "processor": [105, 160, 192, 427, 445, 452, 454, 456, 458, 460, 465, 466, 469, 472, 475, 480, 539, 543, 544, 545, 547, 550, 551, 553, 554, 556, 563, 564, 565, 566, 571, 572, 573, 574, 575, 576, 577, 578, 602, 610, 615, 616, 618, 640, 642, 647, 655, 659, 661, 663, 665, 666, 667, 669, 671, 673, 674, 676, 684, 687, 696, 697, 698, 699, 700, 701, 702, 782, 786, 789, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 854, 855, 858, 860, 862, 863, 865, 866, 871, 874, 907, 908], "procter": 51, "prod": [361, 629], "prod_": 1002, "prod_i": 992, "proding": 1057, "produc": [52, 53, 62, 63, 79, 92, 104, 128, 152, 153, 154, 156, 204, 284, 317, 341, 369, 374, 381, 382, 386, 388, 391, 400, 401, 416, 417, 420, 421, 423, 448, 451, 454, 460, 527, 544, 567, 571, 589, 596, 601, 602, 640, 641, 810, 811, 812, 820, 825, 828, 833, 877, 887, 914, 917, 991, 992, 996, 998, 999, 1000, 1003, 1006, 1007, 1011, 1013, 1014, 1015, 1025, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "product": [2, 58, 105, 125, 161, 176, 181, 193, 353, 369, 373, 388, 389, 392, 395, 413, 421, 423, 459, 546, 548, 555, 590, 597, 598, 599, 621, 622, 641, 648, 672, 673, 693, 694, 769, 771, 783, 785, 884, 887, 904, 905, 950, 989, 992, 996, 998, 1010, 1012, 1014, 1015, 1019, 1024, 1036, 1049], "production": 1024, "prof": 392, "profession": 192, "professor": 1024, "profil": [220, 373, 386, 389, 529, 532, 996, 1024], "profile_default": 392, "profit": [0, 272, 336, 1058], "prog": [174, 383], "prognosi": [174, 383], "program": [0, 85, 174, 361, 369, 374, 375, 383, 384, 386, 388, 392, 398, 516, 643, 678, 902, 903, 996, 1015, 1016, 1019, 1020, 1023, 1041, 1043], "programmat": [388, 507, 1050], "progress": [43, 46, 47, 125, 163, 174, 188, 213, 304, 332, 383, 390, 391, 401, 407, 412, 416, 567, 568, 700, 841, 843, 846, 861, 869, 870, 1024, 1032, 1034, 1041, 1043, 1050, 1055], "prohibit": [191, 257, 420, 423, 635, 1005, 1013, 1048], "proj": [53, 657], "proj_gradi": 392, "proj_oper": 53, "project": [2, 37, 45, 47, 50, 53, 55, 69, 80, 90, 93, 102, 121, 124, 125, 127, 129, 131, 135, 141, 180, 182, 184, 185, 189, 193, 217, 240, 241, 242, 244, 246, 252, 255, 264, 303, 308, 312, 317, 346, 354, 361, 373, 378, 380, 384, 385, 386, 391, 392, 395, 400, 401, 404, 413, 419, 421, 422, 428, 448, 454, 459, 460, 470, 482, 490, 491, 492, 493, 497, 510, 512, 539, 541, 542, 543, 545, 547, 549, 550, 551, 552, 556, 557, 581, 590, 597, 649, 650, 657, 680, 682, 696, 699, 703, 704, 842, 861, 889, 904, 905, 906, 948, 949, 994, 996, 997, 998, 1001, 1003, 1004, 1006, 1013, 1016, 1021, 1024, 1025, 1030, 1033, 1036, 1041, 1042, 1044, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "projected_data": 251, "projected_dist": 251, "projectedgradientnmf": 1046, "prokopi": [1046, 1049], "prolifer": 388, "prolin": [57, 324, 383], "promin": [128, 400], "promis": [400, 1020], "promot": [192, 450, 716, 1019, 1052, 1054, 1058], "prompt": [384, 386, 404, 409, 424, 1025], "prone": [64, 220, 265, 323, 398, 414], "pronounc": [74, 75, 87, 181], "proof": [398, 423, 906, 1012], "prop": [107, 114, 226, 265, 305, 348, 368, 1030], "propag": [2, 58, 68, 71, 72, 84, 98, 99, 120, 189, 337, 381, 448, 462, 510, 520, 522, 705, 712, 713, 721, 722, 725, 726, 745, 801, 803, 872, 886, 907, 908, 909, 966, 967, 1004, 1021, 1022, 1035, 1036, 1041, 1053, 1056], "proper": [64, 90, 209, 238, 272, 375, 388, 392, 414, 423, 457, 549, 561, 684, 949, 975, 995, 996, 997, 1000, 1015, 1041, 1051, 1052, 1053, 1054, 1055, 1056, 1058], "properli": [43, 52, 62, 90, 157, 181, 273, 328, 375, 384, 386, 390, 394, 422, 912, 913, 914, 915, 916, 917, 918, 989, 1044, 1046, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "properti": [51, 62, 183, 184, 222, 237, 264, 301, 324, 368, 373, 379, 386, 388, 404, 413, 414, 416, 418, 421, 423, 425, 426, 431, 450, 453, 459, 460, 461, 472, 473, 550, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 599, 601, 602, 605, 618, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 640, 654, 660, 663, 668, 670, 682, 683, 707, 712, 713, 716, 807, 808, 811, 812, 822, 830, 840, 841, 871, 872, 885, 886, 887, 893, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 989, 992, 995, 996, 997, 1000, 1001, 1003, 1006, 1010, 1013, 1015, 1016, 1017, 1020, 1025, 1046, 1050, 1051, 1054, 1055, 1058, 1059], "property_magnitud": 272, "propon": 104, "proport": [54, 63, 75, 155, 173, 206, 220, 227, 233, 247, 257, 272, 281, 302, 306, 309, 356, 358, 373, 381, 414, 416, 418, 420, 421, 423, 424, 446, 447, 454, 477, 482, 523, 557, 558, 563, 565, 567, 568, 569, 570, 571, 572, 591, 592, 596, 599, 635, 640, 666, 667, 674, 675, 676, 682, 683, 684, 686, 704, 709, 720, 730, 809, 810, 811, 812, 825, 828, 838, 858, 869, 870, 886, 912, 913, 914, 917, 918, 920, 922, 924, 926, 938, 989, 999, 1000, 1003, 1006, 1014, 1015, 1016, 1046, 1058], "propos": [92, 111, 112, 299, 381, 386, 388, 398, 400, 416, 418, 423, 428, 458, 543, 615, 616, 684, 685, 686, 869, 870, 996, 999, 1003, 1014, 1048], "proprietari": 1016, "propto": [422, 1002], "prorokovi\u0107": 1059, "protect": [387, 390, 966], "protein": 380, "protocol": [410, 1000, 1044, 1057, 1058], "protocol_typ": 257, "prototyp": 1024, "prove": [126, 1024], "proven": [278, 994, 998, 1024], "provenc": 325, "provid": [0, 2, 30, 31, 44, 47, 50, 52, 61, 64, 66, 70, 72, 77, 90, 95, 114, 125, 141, 146, 147, 155, 158, 160, 176, 182, 192, 193, 199, 206, 208, 209, 221, 224, 241, 245, 248, 249, 254, 268, 272, 278, 279, 280, 284, 309, 312, 316, 319, 323, 328, 329, 331, 333, 347, 353, 354, 356, 360, 361, 364, 368, 369, 373, 375, 378, 380, 381, 382, 384, 385, 386, 387, 388, 389, 392, 394, 395, 398, 399, 400, 403, 404, 407, 410, 412, 413, 415, 416, 417, 418, 420, 421, 423, 424, 425, 426, 427, 428, 430, 437, 445, 448, 450, 451, 452, 454, 455, 457, 458, 460, 467, 468, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 501, 502, 504, 506, 509, 540, 541, 542, 543, 546, 548, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 598, 599, 601, 602, 609, 613, 618, 619, 635, 640, 641, 642, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 698, 702, 707, 719, 730, 743, 749, 750, 772, 782, 786, 796, 800, 802, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 820, 821, 822, 826, 827, 828, 829, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 869, 870, 872, 875, 877, 878, 879, 882, 883, 884, 887, 889, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 927, 938, 943, 957, 959, 976, 977, 978, 989, 990, 992, 995, 996, 997, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1013, 1014, 1015, 1016, 1017, 1019, 1020, 1023, 1024, 1025, 1029, 1032, 1034, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "provinc": 325, "provost": [796, 1000], "proxi": [191, 192, 421, 868, 1029, 1046], "prun": 392, "prune": [189, 363, 368, 425, 508, 565, 566, 567, 568, 572, 573, 601, 652, 838, 920, 921, 922, 923, 1003, 1021, 1022, 1036, 1041, 1044, 1051, 1052], "przybocki": 1000, "ps_lsvm_score": 197, "ps_lsvm_time": 197, "pseudo": [221, 317, 388, 420, 428, 448, 460, 462, 470, 477, 478, 479, 481, 482, 483, 484, 541, 569, 570, 571, 635, 642, 647, 649, 650, 654, 655, 660, 661, 668, 669, 670, 671, 685, 699, 703, 811, 812, 820, 822, 861, 868, 904, 905, 909, 912, 913, 914, 917, 948, 949, 996, 1012, 1046, 1055], "pseudo_likelihood": 868, "pseudocount": [544, 1049], "psf": [0, 386], "psi": 421, "psi_1": 421, "psi_2": 421, "psi_n": 421, "pspachtholz": [1051, 1052, 1053], "psycholog": [416, 713, 724], "psychometrica": 643, "psychometrika": [698, 702, 997], "pt": [50, 381, 425, 888, 1010], "pt_i": 309, "pt_j": 309, "ptocca": 1051, "ptp": 51, "pts_": 50, "pts_test": 50, "pts_train": 50, "pub": [245, 850, 907], "public": [0, 112, 380, 386, 388, 390, 391, 398, 399, 400, 401, 420, 423, 476, 672, 679, 693, 694, 700, 910, 996, 1004, 1041, 1046, 1047, 1052, 1053, 1054, 1057], "publicli": [386, 1051], "publish": [380, 381, 388, 390, 394, 400, 1012, 1020, 1053], "pubu": [234, 251, 305, 348], "pubu_r": 113, "puerta": 1056, "puggioni": 1045, "puhuk": [1055, 1056], "pujalt": 1055, "pulapakura": [1058, 1059], "pulchritud": 360, "pulido": 1054, "pulkit": [1049, 1050, 1052], "pull": [104, 331, 374, 384, 389, 400, 401, 1023, 1051], "puls": 383, "punctuat": [424, 596, 597, 599], "puneet": 1048, "puneeth": [1058, 1059], "puor": 128, "puor_r": 180, "pure": [113, 114, 118, 204, 220, 400, 416, 481, 487, 504, 565, 566, 567, 568, 572, 573, 574, 713, 723, 794, 803, 920, 921, 922, 923, 1010], "pure_emp_cov": 114, "pure_loc": 114, "pure_x": 114, "purepremium": 238, "puriti": [141, 924, 926], "purna": 1055, "purpl": [111, 123, 244], "purport": 1048, "purpos": [48, 51, 72, 118, 150, 155, 187, 234, 235, 236, 240, 242, 255, 266, 268, 272, 274, 275, 349, 350, 356, 360, 361, 369, 381, 386, 388, 399, 400, 401, 404, 409, 413, 416, 417, 421, 423, 424, 425, 426, 834, 835, 872, 997, 1000, 1001, 1003, 1006, 1019, 1025, 1053, 1055, 1059], "pursu": 192, "pursuit": [2, 126, 128, 134, 189, 198, 291, 421, 482, 534, 539, 545, 550, 556, 672, 673, 693, 694, 1021, 1022, 1036, 1041], "push": [64, 386, 390, 414, 1023], "pushd": 394, "put": [75, 93, 167, 176, 178, 252, 259, 263, 292, 314, 321, 332, 343, 354, 358, 375, 388, 390, 391, 394, 410, 426, 451, 455, 467, 523, 622, 655, 669, 805, 889, 893, 901, 914, 915, 916, 917, 918, 939, 990, 997, 999, 1000, 1001, 1007, 1010, 1026, 1028, 1034], "putnam": 1047, "putschblo": 1054, "pvalu": [2, 600, 603, 604, 606, 607, 608, 837], "pvalue_iri": 284, "pvalue_rand": 284, "pvalues_": [170, 600, 603, 604, 606, 607, 608, 1041], "pvnguyen": 1045, "pwalchessen": 1053, "pwd": 394, "px": [145, 279], "pxd": 386, "py": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 374, 384, 386, 387, 390, 392, 394, 400, 404, 424, 427, 448, 452, 462, 469, 506, 538, 652, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 887, 891, 944, 1000, 1019, 1021, 1034, 1041, 1043, 1047, 1051, 1055], "py3": 404, "py39": 404, "pyamg": [81, 404, 409, 416, 460, 470, 699, 703], "pyarrow": [404, 409], "pybrain": 1041, "pycon": [410, 1018], "pyd": 387, "pydata": [43, 386, 394, 404, 409, 410, 1018, 1024], "pydata_2013": 1024, "pydebug": 392, "pyflak": 388, "pyfunc": [707, 1003], "pyfuncdist": 707, "pymc": 1019, "pynndesc": 299, "pynndescenttransform": 299, "pyodid": 386, "pyoxid": 1054, "pypi": [374, 384, 388, 390, 392, 404, 1016, 1049, 1053, 1055, 1056, 1058], "pyplot": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 106, 107, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 195, 197, 199, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 250, 251, 252, 253, 255, 256, 257, 258, 260, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 277, 278, 280, 281, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 332, 333, 335, 338, 339, 340, 341, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 386, 393, 446, 510, 639, 640, 705, 706, 708, 709, 710, 814, 831, 1029, 1030, 1031, 1032, 1033, 1038, 1055], "pyplpt": 380, "pyproject": 390, "pypy3": 1049, "pysniak": 1044, "pystruct": [398, 1019], "pytabl": 380, "pytb": 394, "pytest": [2, 328, 374, 384, 386, 388, 389, 404, 409, 412, 943, 944, 1051, 1054], "python": [0, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 373, 375, 380, 384, 386, 387, 388, 389, 390, 391, 394, 395, 398, 400, 404, 409, 410, 412, 417, 424, 504, 516, 517, 589, 707, 819, 886, 1000, 1010, 1015, 1016, 1020, 1023, 1024, 1025, 1026, 1028, 1034, 1041, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1058], "python2": 1049, "python3": [384, 404], "python37": 404, "pythonsoftwarefound": 404, "pythonx": 384, "pytorch": [45, 336, 398, 1019, 1020, 1030, 1057, 1058], "pytorch_enable_mps_fallback": 412, "pyx": [386, 387, 392, 394], "p\u00e9rez": 1049, "p\u00f6lsterl": [1048, 1051, 1054], "q": [51, 105, 117, 152, 220, 331, 413, 416, 421, 948, 996, 1015], "q1": 517, "q327": 383, "q_": 1015, "q_m": 1016, "q_max": [890, 902], "q_min": [890, 902], "qaiser": 1058, "qda": [67, 383, 557, 558, 1022, 1036, 1046], "qdeffens": [1051, 1054], "qemu": 394, "qi": [517, 1053], "qian": [1047, 1052], "qiang": 1045, "qianm": 1053, "qid": [495, 516, 517, 1042, 1047], "qimu": 1047, "qin": [0, 320, 383, 405, 424, 1048, 1049, 1050, 1051, 1052], "qingi": 1049, "qinhanmin2005": 320, "qizhi": 1052, "qmarcou": 1058, "qn": 517, "qp": 1015, "qr": [81, 222, 412, 542, 549, 552, 948, 949, 997, 1047, 1058], "qt": [323, 889], "qtconsol": 392, "quad": [426, 1003, 1014], "quadcontourset": 639, "quadmesh": 639, "quadrant": 319, "quadrat": [2, 12, 43, 48, 65, 69, 113, 114, 115, 181, 185, 189, 234, 257, 268, 280, 331, 448, 466, 469, 557, 558, 631, 639, 656, 666, 667, 677, 684, 688, 724, 917, 918, 996, 997, 1000, 1003, 1006, 1010, 1014, 1015, 1021, 1022, 1036, 1042], "quadraticdiscriminantanalysi": [2, 67, 70, 557, 994, 1001, 1003, 1041, 1046, 1048, 1056], "quadro": 1054, "quadv": 1055, "qualifi": 391, "qualit": [44, 45, 88, 90, 96, 145, 152, 220, 333, 381, 416, 447, 709, 1030, 1056], "qualiti": [0, 13, 27, 45, 58, 61, 72, 81, 83, 84, 93, 128, 148, 155, 192, 226, 271, 276, 285, 286, 287, 353, 386, 394, 398, 400, 411, 416, 418, 421, 460, 470, 477, 482, 565, 566, 567, 568, 572, 573, 751, 822, 904, 905, 920, 921, 922, 923, 949, 995, 997, 1005, 1012, 1016, 1019, 1020, 1024, 1029, 1030, 1036], "quang": 1052, "quansight": 0, "quantifi": [13, 27, 43, 72, 84, 111, 181, 238, 272, 285, 336, 388, 400, 411, 581, 875, 995, 1008, 1010, 1036], "quantil": [2, 79, 88, 98, 122, 139, 141, 189, 198, 274, 319, 322, 323, 398, 423, 446, 447, 466, 527, 560, 561, 568, 570, 665, 678, 731, 753, 756, 758, 835, 877, 889, 890, 891, 901, 902, 1000, 1010, 1021, 1022, 1036, 1041, 1045, 1048, 1050, 1054, 1055, 1057, 1059], "quantile_list": 52, "quantile_rang": [319, 890, 902, 1047], "quantile_regress": 222, "quantile_transform": [2, 109, 889, 900, 1010, 1048, 1049, 1050, 1059], "quantileregressor": [2, 331, 996, 1000, 1054, 1055, 1056], "quantiles_": [889, 1010, 1051], "quantiletransform": [2, 109, 193, 323, 417, 473, 888, 901, 990, 1010, 1048, 1049, 1050, 1051, 1052, 1057, 1059], "quantiletransformerquantiletransform": 193, "quantit": [43, 44, 45, 52, 62, 96, 152, 155, 163, 174, 274, 293, 383, 1030], "quantiti": [51, 149, 278, 285, 330, 373, 400, 416, 423, 729, 730, 731, 732, 793, 868, 989, 991, 994, 996, 1046], "quantiz": [45, 71, 81, 93, 128, 189, 380, 381, 416, 451, 455, 457, 514, 787, 877, 974, 1010, 1021], "quantum": 998, "quartil": 890, "quartimax": [540, 1053], "quasi": [388, 869, 870, 996], "quazi": [1048, 1049], "queensland": 383, "quentin": [1048, 1049, 1050, 1057, 1058], "queqichao": 1045, "queri": [199, 302, 312, 373, 422, 427, 452, 454, 458, 465, 560, 618, 619, 636, 652, 653, 734, 764, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 1000, 1003, 1016, 1019, 1023, 1043, 1045, 1046, 1049], "query_id": [495, 516, 517], "query_radiu": [852, 853], "question": [0, 165, 191, 272, 278, 356, 385, 386, 391, 394, 410, 420, 423, 841, 914, 917, 996, 999, 1000, 1006, 1024], "queue": [47, 1003, 1044], "quick": [43, 130, 260, 386, 388, 392, 404, 614, 838, 1000, 1001, 1010, 1024, 1032, 1038], "quicker": 999, "quickest": 384, "quickli": [74, 258, 315, 328, 383, 386, 387, 420, 423, 700, 786, 996, 1003, 1004, 1024, 1034, 1052], "quinlan": 1016, "quinonez": 1049, "quintana": 1000, "quiroz": [72, 92, 145, 155, 199, 204, 257, 279, 281, 324, 360, 361, 362], "quit": [43, 52, 64, 88, 92, 118, 142, 165, 174, 192, 193, 218, 238, 272, 286, 296, 331, 360, 373, 391, 399, 416, 424, 995, 997, 1002, 1024, 1049], "quiver": 127, "quot": [37, 51, 52, 54, 104, 279, 360, 361, 374, 380, 381, 384, 386, 390, 404, 412, 496, 497, 504, 1000, 1012, 1015, 1034, 1056], "quota": [1054, 1055], "quotat": 381, "quotient": 1000, "r": [0, 2, 47, 49, 50, 51, 52, 53, 61, 62, 63, 64, 74, 78, 100, 109, 111, 112, 113, 114, 118, 125, 132, 135, 139, 142, 143, 148, 152, 153, 154, 163, 170, 177, 178, 179, 183, 184, 185, 187, 188, 192, 202, 204, 205, 209, 220, 227, 230, 238, 245, 250, 253, 263, 266, 269, 277, 278, 281, 283, 284, 285, 288, 291, 294, 298, 301, 302, 306, 310, 312, 325, 332, 351, 353, 362, 369, 381, 383, 387, 390, 398, 400, 410, 413, 414, 416, 418, 419, 420, 421, 423, 424, 433, 439, 445, 454, 459, 461, 473, 477, 482, 486, 490, 491, 492, 506, 512, 521, 528, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 577, 578, 596, 597, 598, 599, 614, 617, 618, 619, 635, 643, 647, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 687, 688, 693, 694, 700, 704, 724, 729, 730, 731, 732, 736, 738, 789, 793, 796, 807, 808, 822, 825, 830, 840, 841, 842, 843, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 858, 859, 861, 862, 863, 869, 870, 883, 888, 900, 907, 908, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 925, 966, 990, 992, 994, 996, 997, 1000, 1001, 1002, 1003, 1004, 1007, 1008, 1010, 1014, 1015, 1016, 1019, 1034, 1041, 1045, 1048, 1051, 1052, 1053, 1054, 1056, 1058], "r0": [811, 812], "r1": 578, "r11": [220, 238], "r2": [109, 140, 145, 160, 191, 193, 215, 253, 388, 417, 423, 562, 578, 681, 835, 870, 1000, 1008, 1050], "r2007": 423, "r22": 220, "r25": 238, "r26": 220, "r2_score": [2, 109, 191, 204, 215, 216, 412, 423, 439, 473, 490, 491, 492, 562, 564, 566, 568, 570, 573, 576, 578, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 732, 736, 845, 846, 855, 863, 870, 913, 915, 918, 921, 923, 989, 1000, 1042, 1044, 1050, 1054, 1055, 1059], "r2_score_ard": 204, "r2_score_enet": 204, "r2_score_lasso": 204, "r2_score_nnl": 215, "r2_score_ol": 215, "r2_with_abl": 191, "r2_without_": 191, "r3": 578, "r72": 220, "r73": 238, "r82": 220, "r93": 220, "r_": [50, 134, 233, 234, 264, 285, 305, 306, 348, 354, 358, 416, 715, 1000, 1016], "r_0": 989, "r_k": 285, "r_multi": 1008, "r_n": [285, 715, 1000], "r_regress": [2, 425, 614, 1054, 1055, 1058], "r_squar": 399, "ra": 257, "raamana": [1049, 1050], "rabbit": [332, 334, 1010], "raccoon": [88, 128, 421], "raccoon_fac": [88, 128], "race": [192, 335, 381, 504, 1044], "race_hispan": 192, "race_oth": 192, "race_whit": 192, "rachel": [1053, 1056], "rachelcjordan": 1052, "rachez": [1046, 1047], "rachit": [1047, 1053, 1056], "rachum": 1053, "radar": 1024, "radford": 996, "radhakrishnan": 1049, "radial": [2, 44, 130, 176, 181, 183, 349, 353, 378, 460, 630, 699, 998, 1015, 1036], "radian": [312, 707, 772], "radii": [852, 853], "radiu": [2, 174, 294, 306, 349, 383, 416, 450, 458, 696, 772, 789, 852, 853, 854, 855, 856, 860, 862, 863, 864, 866, 1003, 1043, 1045, 1055, 1058], "radius1": 101, "radius2": 101, "radius3": 101, "radius4": 101, "radius_neighbor": [332, 860, 862, 863, 864, 1045, 1050, 1051, 1053, 1054, 1055, 1056], "radius_neighbors_graph": [2, 416, 427, 452, 854, 855, 856, 858, 860, 862, 863, 864, 865, 1003, 1045, 1050, 1053], "radiusneighborsclassifi": [2, 332, 854, 855, 860, 863, 1001, 1003, 1041, 1043, 1047, 1049, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "radiusneighborsregressor": [2, 332, 854, 855, 860, 862, 1001, 1003, 1041, 1043, 1049, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "radiusneighborstransform": [2, 328, 856, 1003, 1051, 1053, 1055, 1056], "radostin": [1049, 1050], "raduspaimoc": 1052, "raf": 1050, "rafael": [1024, 1042, 1043, 1045, 1048], "rafal": [1056, 1057], "rafei": 1053, "raff": 1044, "raffaello": 1050, "rafiqu": [1049, 1050], "raghav": [0, 282, 319, 406, 1045, 1046, 1047, 1048, 1049, 1053], "raghavan": [421, 598, 847, 851, 998, 1000, 1002], "raghu": [416, 450], "raghunathan": [1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1059], "raghuv": [1056, 1057], "raghuwanshi": 1055, "rah": 649, "rahiel": 1045, "rahil": [1055, 1056, 1057, 1058, 1059], "rahimi": [649, 992], "rahmaan": 1051, "rahman": [1048, 1049, 1053], "rahn": [1048, 1051], "rahul": [1053, 1058], "rai": [0, 406, 1000, 1041, 1051, 1053, 1054], "raimundo": 1049, "rain": [43, 52, 193, 415, 996], "rainbow": [61, 242], "rainfal": 996, "rais": [2, 137, 221, 254, 255, 272, 281, 323, 331, 386, 388, 390, 391, 392, 395, 398, 400, 407, 410, 417, 420, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 517, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 581, 584, 585, 589, 590, 596, 597, 598, 599, 601, 602, 610, 611, 618, 619, 625, 637, 640, 643, 644, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 704, 706, 710, 717, 719, 720, 721, 722, 735, 737, 738, 746, 786, 790, 791, 792, 795, 796, 797, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 817, 822, 826, 830, 831, 834, 835, 836, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 861, 862, 863, 867, 869, 870, 871, 872, 875, 876, 877, 878, 879, 884, 885, 886, 890, 891, 892, 899, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 927, 930, 932, 933, 935, 936, 953, 957, 961, 984, 985, 986, 987, 1000, 1010, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "raisadz": 1059, "raise_exc": [719, 1060], "raise_except": 986, "raise_warn": [281, 720, 986], "raj": [1058, 1059], "rajagopalan": [0, 406, 1049, 1053], "rajaona": [1047, 1048], "rajat": [1044, 1051], "rajborirug": 257, "rajdeep": 1050, "rajendra": 1049, "raji": [1056, 1057], "rakotoarison": [1048, 1049, 1051], "ralf": [1044, 1047, 1048, 1056, 1057, 1059], "ralph": 1059, "ram": [55, 88, 375, 410, 423, 904, 905, 1002, 1015, 1034, 1047, 1053, 1056, 1057], "ramakrishnan": [416, 450], "ramana": [1047, 1048], "ramanath": 1046, "ramesh": [381, 1024, 1044, 1047, 1051], "rameshwar": [1048, 1049], "ramil": [1049, 1050], "rammig": [1024, 1047], "ramo": 1056, "rampin": 1048, "ramyanp": [1053, 1054], "ramzi": 1053, "ram\u00edrez": 1000, "rand": [2, 53, 61, 72, 73, 74, 75, 79, 84, 93, 97, 132, 142, 157, 159, 169, 199, 204, 242, 243, 247, 253, 254, 293, 311, 329, 330, 335, 342, 343, 355, 361, 366, 367, 395, 407, 552, 712, 713, 723, 765, 789, 794, 904, 905, 907, 908, 909, 1012, 1025, 1041, 1052, 1053], "rand_index": 713, "rand_scor": [2, 72, 416, 723, 1000, 1053], "randal": [892, 1045, 1055], "randi": 1047, "randint": [50, 72, 114, 123, 151, 188, 194, 243, 250, 254, 256, 290, 330, 335, 388, 391, 399, 407, 812, 829, 847, 848, 849, 851, 989, 990], "randn": [53, 69, 70, 74, 89, 100, 101, 113, 114, 128, 132, 156, 169, 176, 180, 191, 194, 209, 214, 215, 219, 233, 234, 237, 264, 267, 268, 273, 285, 287, 288, 293, 305, 306, 326, 329, 330, 335, 348, 353, 354, 358, 388, 391, 651, 678, 680, 686, 695, 829, 915, 918], "randolf": 1059, "random": [2, 14, 37, 43, 44, 45, 46, 50, 51, 52, 53, 58, 59, 61, 62, 63, 64, 67, 69, 70, 72, 74, 75, 79, 80, 83, 85, 87, 89, 90, 92, 93, 95, 96, 97, 99, 100, 101, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 123, 126, 127, 128, 131, 132, 138, 140, 142, 144, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 160, 163, 167, 169, 170, 173, 176, 177, 180, 182, 183, 185, 187, 188, 189, 190, 191, 199, 200, 201, 202, 204, 209, 210, 214, 215, 218, 219, 220, 221, 222, 223, 226, 227, 229, 233, 234, 237, 238, 240, 241, 243, 244, 245, 246, 247, 252, 253, 254, 255, 256, 257, 263, 264, 266, 267, 268, 269, 270, 273, 275, 276, 277, 278, 279, 281, 283, 285, 287, 288, 289, 290, 293, 298, 299, 304, 305, 306, 311, 314, 320, 322, 323, 326, 329, 330, 332, 334, 336, 338, 339, 342, 343, 348, 349, 351, 352, 353, 354, 355, 358, 360, 361, 366, 367, 373, 374, 378, 382, 389, 391, 398, 399, 400, 407, 411, 412, 414, 416, 424, 425, 429, 441, 448, 451, 455, 457, 459, 460, 461, 462, 466, 467, 468, 470, 472, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 496, 497, 498, 499, 500, 503, 504, 505, 510, 511, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 540, 543, 544, 546, 547, 548, 549, 552, 555, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 581, 590, 591, 592, 597, 615, 616, 618, 619, 635, 638, 640, 642, 647, 648, 649, 650, 651, 654, 655, 657, 658, 660, 661, 662, 666, 668, 669, 670, 671, 678, 679, 680, 684, 685, 686, 687, 695, 697, 698, 699, 700, 701, 702, 703, 709, 712, 713, 716, 739, 751, 789, 796, 801, 805, 806, 808, 810, 811, 812, 813, 820, 822, 823, 824, 825, 826, 827, 828, 829, 830, 837, 838, 843, 845, 846, 847, 848, 849, 851, 852, 853, 857, 861, 868, 869, 870, 872, 875, 877, 886, 889, 893, 901, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 935, 946, 948, 949, 969, 971, 974, 990, 992, 995, 997, 999, 1000, 1004, 1005, 1006, 1008, 1010, 1015, 1016, 1019, 1020, 1021, 1022, 1025, 1029, 1030, 1032, 1033, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "random_": 209, "random_02": 209, "random_05": 209, "random_08": 209, "random_11": 209, "random_cat": [194, 1008], "random_choice_csc": 1051, "random_forest": 144, "random_from_data": [266, 805, 806, 999], "random_label": 72, "random_num": [194, 1008], "random_offset_": [649, 650], "random_project": [2, 241, 251, 904, 905, 906, 1012, 1017, 1042, 1047, 1057, 1058], "random_sampl": [204, 852, 853, 857], "random_se": [49, 123, 148], "random_search": [279, 286], "random_st": [43, 44, 45, 46, 49, 51, 52, 54, 57, 58, 59, 61, 62, 63, 64, 66, 67, 73, 77, 78, 79, 81, 83, 84, 85, 88, 90, 91, 92, 93, 94, 95, 96, 97, 104, 105, 109, 115, 118, 123, 125, 127, 130, 139, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 162, 163, 165, 170, 171, 173, 176, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 201, 202, 206, 212, 219, 220, 223, 224, 226, 227, 228, 232, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 252, 255, 256, 257, 258, 260, 261, 263, 265, 266, 269, 271, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 288, 289, 290, 292, 296, 298, 299, 302, 303, 307, 308, 309, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 341, 347, 349, 350, 351, 356, 357, 360, 361, 364, 368, 369, 388, 391, 395, 399, 400, 412, 415, 416, 417, 420, 421, 423, 424, 428, 441, 445, 446, 448, 451, 455, 457, 459, 460, 461, 462, 466, 467, 468, 470, 477, 482, 486, 495, 496, 499, 500, 503, 505, 511, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 591, 592, 601, 602, 613, 614, 615, 616, 617, 618, 619, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 635, 640, 641, 642, 643, 646, 647, 648, 649, 650, 654, 655, 657, 658, 659, 660, 661, 662, 663, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 679, 680, 682, 684, 685, 686, 687, 689, 690, 691, 693, 694, 695, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, 710, 718, 743, 796, 800, 801, 805, 806, 807, 810, 811, 812, 813, 814, 820, 822, 823, 824, 825, 826, 827, 828, 830, 831, 836, 837, 838, 839, 840, 842, 843, 844, 845, 846, 857, 861, 868, 869, 870, 872, 877, 889, 893, 901, 904, 905, 912, 913, 914, 917, 919, 920, 921, 922, 923, 925, 926, 946, 948, 949, 969, 971, 974, 989, 990, 992, 995, 1000, 1001, 1002, 1003, 1004, 1007, 1008, 1010, 1015, 1016, 1025, 1029, 1030, 1034, 1038, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054], "random_state_": [388, 544, 635, 861, 1055], "random_tre": 574, "random_tree_embed": 144, "random_unlabeled_point": [330, 907, 908, 909], "random_weights_": [649, 650], "randomforest": [49, 148, 373, 423, 920, 921, 1046], "randomforestclassifi": [2, 63, 64, 67, 91, 143, 144, 145, 146, 147, 148, 162, 194, 195, 259, 260, 275, 290, 328, 330, 335, 360, 369, 399, 400, 414, 423, 425, 565, 566, 567, 569, 574, 575, 577, 811, 812, 830, 842, 922, 989, 990, 1001, 1008, 1024, 1038, 1045, 1046, 1049, 1050, 1051, 1054, 1055, 1056, 1057, 1058], "randomforestclassifierifittedrandomforestclassifi": [63, 146, 147, 335], "randomforestclassifierinot": 335, "randomforestclassifierrandomforestclassifi": [63, 194, 259, 290], "randomforestregressor": [2, 49, 145, 159, 160, 163, 187, 188, 330, 335, 399, 423, 565, 566, 568, 570, 574, 576, 578, 640, 641, 922, 990, 1001, 1046, 1047, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058], "randomforestregressorrandomforestregressor": [160, 163], "randomgeek78": 1055, "randomized_range_find": [2, 395, 1042, 1047], "randomized_svd": [2, 55, 395, 459, 461, 540, 549, 552, 554, 1041, 1042, 1047, 1054, 1055, 1056], "randomized_svd_low_rank": 1048, "randomizedlasso": 1048, "randomizedlogisticregress": 1048, "randomizedpca": [1024, 1041, 1043, 1044, 1046, 1047, 1048], "randomizedsearchcv": [2, 45, 105, 176, 279, 286, 330, 369, 399, 407, 583, 989, 1000, 1014, 1019, 1030, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1056, 1058, 1059], "randomizedsearchcvinot": 105, "randomli": [2, 52, 72, 83, 85, 96, 105, 117, 119, 141, 142, 155, 156, 179, 187, 189, 193, 232, 237, 251, 255, 268, 273, 284, 296, 298, 338, 369, 374, 395, 398, 399, 416, 420, 423, 426, 457, 466, 520, 523, 527, 531, 539, 545, 553, 554, 559, 567, 568, 569, 570, 571, 572, 573, 618, 619, 679, 687, 698, 702, 724, 805, 806, 868, 906, 920, 921, 922, 923, 999, 1001, 1003, 1006, 1008, 1012, 1016, 1021, 1032, 1034, 1052, 1056, 1058], "randomst": [2, 44, 53, 58, 59, 61, 67, 70, 72, 79, 85, 96, 97, 114, 115, 118, 125, 127, 132, 140, 151, 152, 155, 156, 157, 159, 170, 176, 177, 180, 182, 183, 185, 187, 188, 191, 194, 199, 200, 201, 202, 204, 209, 214, 221, 222, 227, 234, 243, 247, 253, 254, 263, 266, 273, 281, 284, 285, 287, 288, 289, 290, 314, 320, 322, 323, 326, 329, 330, 332, 334, 335, 338, 339, 343, 352, 366, 367, 388, 391, 395, 400, 407, 421, 428, 429, 448, 451, 455, 457, 459, 460, 461, 462, 466, 467, 468, 470, 477, 478, 482, 483, 484, 486, 487, 488, 489, 496, 499, 500, 503, 505, 511, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 591, 592, 615, 616, 618, 619, 635, 640, 642, 647, 648, 649, 650, 651, 654, 655, 657, 658, 660, 661, 662, 666, 667, 668, 669, 670, 671, 674, 675, 676, 678, 679, 680, 682, 684, 685, 686, 687, 695, 697, 698, 699, 700, 701, 702, 703, 709, 789, 801, 805, 806, 810, 811, 812, 813, 814, 820, 822, 823, 824, 825, 826, 827, 828, 830, 836, 837, 838, 842, 843, 846, 847, 848, 849, 851, 852, 853, 857, 861, 868, 869, 870, 877, 889, 893, 901, 904, 905, 907, 908, 909, 912, 913, 914, 917, 918, 920, 921, 922, 923, 935, 948, 949, 969, 971, 974, 1010, 1025, 1036], "randomtreesembed": [2, 144, 158, 241, 423, 922, 1042, 1049, 1050, 1054, 1055, 1056], "randomtreesembedding_": 574, "randomtreesembeddingrandomtreesembed": 144, "rang": [2, 43, 44, 45, 46, 47, 49, 51, 55, 57, 58, 62, 63, 64, 68, 69, 72, 73, 75, 77, 81, 82, 83, 85, 86, 90, 95, 96, 98, 99, 111, 112, 114, 115, 139, 141, 142, 143, 146, 152, 155, 159, 169, 172, 173, 177, 192, 193, 197, 204, 209, 210, 214, 218, 220, 221, 224, 227, 228, 236, 238, 241, 243, 250, 251, 256, 257, 263, 265, 268, 269, 272, 273, 277, 278, 279, 281, 282, 283, 285, 286, 287, 289, 290, 291, 293, 298, 303, 309, 312, 317, 319, 324, 325, 328, 332, 333, 339, 349, 356, 360, 361, 365, 368, 374, 380, 381, 383, 386, 388, 392, 395, 400, 410, 416, 420, 423, 426, 448, 469, 477, 479, 480, 481, 482, 483, 484, 486, 489, 499, 502, 503, 522, 535, 549, 561, 562, 567, 568, 571, 596, 597, 599, 637, 640, 646, 648, 656, 657, 677, 679, 684, 685, 686, 688, 700, 720, 739, 754, 796, 838, 844, 858, 860, 862, 863, 868, 882, 889, 890, 891, 897, 898, 901, 902, 905, 906, 948, 949, 989, 996, 1000, 1004, 1014, 1020, 1024, 1028, 1029, 1030, 1032, 1046, 1047, 1048, 1049, 1051, 1054, 1057], "range_n_clust": 95, "range_n_outli": 114, "rangeindex": [192, 272, 504], "rangl": [992, 1000, 1014, 1015], "ranjanikrishnan": 1054, "rank": [2, 43, 55, 62, 113, 129, 132, 146, 172, 194, 195, 238, 276, 278, 286, 382, 411, 413, 414, 418, 419, 421, 423, 424, 516, 517, 529, 532, 557, 558, 601, 602, 614, 656, 665, 677, 688, 704, 728, 734, 735, 747, 748, 764, 796, 802, 811, 812, 949, 989, 991, 992, 997, 1008, 1010, 1024, 1036, 1042, 1047, 1050, 1051, 1055, 1056, 1059], "rank_": 665, "rank_t": 808, "rank_test_": 282, "rank_test_precis": [276, 282], "rank_test_recal": 276, "rank_test_scor": [278, 286, 808, 822, 1047], "rankdata": 1048, "ranked_exposur": [220, 238], "ranked_frequ": 220, "ranked_pure_premium": 238, "ranking_": [172, 601, 602], "rankylau": 1049, "ransac": [2, 189, 198, 226, 237, 532, 657, 665, 679, 686, 687, 1021], "ransacregressor": [2, 223, 226, 237, 407, 657, 686, 687, 996, 1001, 1044, 1046, 1047, 1048, 1049, 1052, 1054, 1055, 1059], "rao": [420, 1053, 1056], "raphael": 1058, "rapha\u00ebl": 1051, "raphson": [656, 677, 688], "rapid": 1024, "rapidli": [224, 280, 1015, 1024, 1028], "rare": [64, 193, 325, 369, 390, 398, 400, 403, 414, 416, 420, 597, 656, 666, 667, 677, 688, 912, 937, 996, 1010, 1024, 1048, 1049, 1050, 1054, 1056, 1059], "rarer": [360, 362, 424], "raschka": [324, 1046, 1047, 1048, 1049, 1050, 1053], "rashchedrin": 1048, "rasmu": [197, 1048], "rasmussen": [181, 426, 618, 619, 622, 627, 630], "raspberri": 404, "raster": 104, "rastgoo": 1058, "rastogi": 1049, "rastrojo": 713, "rasul": [1046, 1048, 1049], "rat": [50, 312, 381, 506], "rate": [2, 43, 139, 143, 149, 155, 169, 193, 220, 227, 238, 251, 257, 272, 275, 278, 285, 287, 288, 315, 316, 317, 375, 386, 415, 416, 417, 421, 425, 454, 474, 544, 561, 562, 567, 568, 569, 570, 600, 603, 604, 606, 607, 608, 614, 652, 653, 676, 684, 685, 686, 700, 706, 710, 735, 790, 797, 868, 869, 870, 906, 989, 996, 997, 1000, 1003, 1004, 1014, 1016, 1024, 1045, 1049, 1050], "rather": [51, 64, 88, 115, 139, 142, 155, 187, 192, 220, 221, 234, 257, 292, 323, 324, 360, 361, 369, 374, 382, 384, 386, 388, 391, 392, 394, 398, 399, 400, 401, 416, 420, 421, 423, 424, 426, 456, 469, 471, 472, 475, 573, 589, 596, 597, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 637, 654, 655, 660, 661, 668, 669, 670, 671, 789, 822, 843, 845, 846, 875, 912, 913, 924, 949, 994, 996, 997, 1000, 1002, 1003, 1007, 1020, 1029, 1032, 1041, 1042, 1043, 1044, 1048, 1049, 1050, 1051, 1056, 1057, 1059], "ratio": [2, 46, 88, 101, 107, 133, 189, 251, 253, 266, 270, 373, 386, 416, 418, 420, 423, 458, 464, 501, 502, 523, 549, 557, 558, 559, 639, 666, 718, 720, 724, 733, 738, 744, 747, 790, 791, 792, 795, 803, 835, 838, 858, 905, 969, 994, 1006, 1016, 1021, 1030, 1056, 1058], "ration": [2, 181, 272, 631, 998], "rationalquadrat": [2, 181, 185, 426, 624], "raton": 996, "raul": [1043, 1044], "rausch": [341, 343, 1049, 1050, 1053], "rauscho": [341, 343], "rauwuckl": 1053, "ravel": [2, 44, 53, 55, 57, 63, 77, 88, 89, 93, 113, 134, 140, 142, 148, 152, 158, 159, 160, 167, 176, 178, 180, 181, 182, 183, 192, 199, 210, 211, 213, 220, 233, 234, 241, 245, 247, 251, 253, 257, 261, 265, 267, 272, 281, 285, 287, 292, 299, 304, 305, 311, 312, 314, 315, 316, 317, 321, 322, 332, 336, 343, 349, 354, 355, 357, 358, 360, 366, 367, 473, 501, 502, 503, 639, 726, 987, 1000, 1057], "ravi": [1053, 1056], "raw": [2, 17, 43, 51, 54, 72, 114, 127, 160, 181, 192, 197, 317, 326, 340, 362, 373, 381, 388, 394, 400, 414, 416, 418, 421, 424, 477, 482, 509, 510, 511, 567, 568, 569, 571, 590, 596, 597, 598, 599, 642, 685, 698, 702, 713, 794, 858, 916, 997, 1000, 1004, 1006, 1007, 1010, 1013, 1031, 1033, 1042, 1046, 1049, 1052, 1058], "raw_coef_": [912, 913], "raw_covariance_": [418, 477, 482], "raw_data": 362, "raw_docu": [596, 599], "raw_location_": [418, 477, 482], "raw_model": 326, "raw_pixel_classifi": 317, "raw_support_": [477, 482], "raw_target_regr": 417, "raw_valu": [729, 731, 736, 753, 754, 756, 758, 759, 761, 793, 798, 799, 1000, 1049, 1052], "raw_x": [424, 590], "raytheon": 51, "raz": 1055, "razor": 1032, "ra\u00fal": 1050, "rb": [47, 410], "rbf": [2, 44, 45, 49, 50, 66, 67, 130, 161, 167, 176, 177, 178, 180, 181, 182, 183, 185, 189, 197, 234, 246, 247, 253, 276, 278, 280, 283, 294, 305, 343, 344, 346, 355, 378, 417, 421, 423, 460, 470, 510, 512, 543, 549, 618, 619, 620, 621, 624, 626, 627, 628, 629, 631, 632, 639, 647, 648, 649, 650, 651, 684, 699, 773, 782, 784, 808, 819, 822, 828, 872, 892, 907, 908, 912, 914, 915, 916, 917, 918, 989, 992, 993, 995, 997, 1000, 1006, 1010, 1013, 1021, 1025, 1027, 1030, 1036, 1047, 1052], "rbf_featur": [649, 992], "rbf_kernel": [2, 773, 998, 1045], "rbf_svc": [343, 1015], "rbfsampler": [2, 252, 647, 648, 650, 992, 1025, 1045, 1055, 1056], "rbm": [2, 317, 868, 869, 870, 1005], "rbm_features_classifi": 317, "rc": [234, 390], "rc1": 390, "rceil": [413, 1006], "rcond": 134, "rcparam": [47, 247, 252, 326], "rcv1": [2, 379, 505, 1036, 1046], "rcwoolston": 1052, "rd": 424, "rd9e56ef97513": 2, "rda": 383, "rdbu": [67, 70, 125, 236, 314, 349, 354], "rdbu_r": [89, 115, 135, 349], "rdownload": 47, "rdylbu": [148, 365], "re": [43, 47, 53, 63, 64, 91, 104, 105, 139, 149, 179, 191, 192, 238, 254, 264, 268, 281, 283, 287, 329, 360, 362, 374, 386, 387, 390, 394, 399, 401, 407, 414, 420, 424, 477, 478, 479, 480, 481, 482, 483, 484, 563, 564, 565, 566, 569, 570, 571, 572, 573, 574, 654, 660, 668, 670, 810, 825, 828, 920, 921, 922, 923, 996, 1001, 1003, 1010, 1015, 1020, 1024, 1034, 1041, 1045, 1046, 1048, 1050, 1060], "reach": [96, 145, 150, 174, 220, 222, 236, 238, 272, 280, 332, 349, 368, 391, 401, 404, 416, 421, 425, 458, 465, 516, 517, 601, 602, 635, 652, 653, 654, 655, 660, 661, 662, 663, 664, 668, 669, 670, 671, 674, 675, 676, 684, 685, 686, 687, 689, 690, 691, 692, 737, 738, 791, 805, 806, 869, 870, 909, 989, 1000, 1004, 1014, 1016, 1024, 1052, 1056, 1057, 1058], "reachability_": [100, 416, 458, 463, 464, 465], "reachabl": [2, 90, 100, 454, 458, 463, 464, 465, 858, 954], "reactiv": 392, "read": [47, 52, 55, 125, 240, 285, 328, 329, 330, 332, 334, 373, 380, 387, 388, 389, 390, 391, 393, 394, 398, 399, 400, 410, 416, 427, 428, 429, 430, 433, 439, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 467, 469, 470, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 618, 619, 621, 622, 623, 624, 627, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 703, 705, 706, 708, 709, 710, 711, 712, 713, 715, 716, 717, 718, 720, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 765, 766, 767, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 859, 860, 861, 862, 863, 864, 865, 866, 868, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 945, 989, 996, 1000, 1001, 1019, 1024, 1027, 1034, 1042, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1058, 1059], "read_byt": 47, "read_csv": [51, 391, 504, 1056], "read_csv_kwarg": [504, 1057], "readabl": [115, 279, 331, 391, 392, 394, 542, 1050, 1053, 1054, 1055, 1056], "reader": [45, 77, 331, 375, 386, 1030], "readi": [43, 46, 181, 221, 272, 381, 386, 390, 394], "readili": [332, 421, 1016, 1024], "readm": [394, 424, 501], "readonli": [912, 913, 1054, 1056, 1057], "readonly_memmap": 1058, "readthedoc": 400, "real": [52, 67, 70, 90, 92, 104, 108, 111, 113, 114, 139, 155, 179, 192, 224, 244, 247, 257, 271, 272, 284, 293, 303, 306, 320, 321, 348, 353, 362, 373, 379, 380, 383, 390, 392, 395, 398, 399, 400, 413, 414, 416, 418, 420, 421, 423, 424, 477, 497, 498, 501, 502, 503, 504, 505, 508, 509, 512, 518, 559, 560, 561, 563, 564, 565, 566, 567, 568, 572, 573, 600, 602, 603, 604, 605, 606, 607, 608, 639, 707, 712, 732, 736, 760, 763, 765, 793, 803, 837, 869, 870, 914, 915, 916, 917, 918, 921, 923, 990, 991, 992, 997, 1000, 1002, 1004, 1005, 1006, 1016, 1018, 1021, 1036, 1041, 1054, 1058], "real_cov": [111, 112, 429, 478, 481, 482, 483, 484, 487, 488, 489], "real_data": 303, "realist": [43, 47, 280, 287, 288, 346, 381, 1000], "realiti": 382, "realiz": [220, 1024], "realli": [111, 194, 209, 390, 391, 392, 1000, 1006, 1024, 1055], "reappli": 423, "rearrang": [58, 59, 413], "reason": [43, 47, 51, 64, 77, 88, 104, 152, 155, 174, 192, 193, 197, 220, 221, 228, 238, 247, 251, 252, 254, 257, 272, 275, 278, 279, 284, 296, 299, 320, 324, 353, 361, 362, 369, 373, 374, 375, 381, 385, 386, 387, 388, 390, 394, 398, 399, 400, 401, 415, 416, 417, 418, 421, 423, 424, 516, 540, 582, 646, 654, 660, 662, 680, 695, 700, 771, 808, 822, 856, 861, 868, 887, 909, 989, 990, 995, 996, 997, 1000, 1002, 1003, 1004, 1006, 1010, 1014, 1015, 1024, 1034, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "reassign": [85, 386, 455, 457, 1042, 1046], "reassignment_ratio": 457, "rebalanc": 400, "rebas": 390, "rebecca": 1048, "rebekah": [1049, 1050, 1051], "reboul": 1051, "rebuild": [373, 384, 410, 424, 450], "rebuilt": [68, 384, 852, 853], "rec": [57, 362, 381, 649], "rec_l1": 53, "rec_l2": 53, "rec_macro": 420, "recal": [2, 45, 62, 68, 104, 115, 130, 171, 189, 248, 257, 270, 272, 276, 296, 317, 338, 339, 386, 400, 415, 416, 512, 612, 708, 714, 715, 716, 720, 721, 735, 737, 738, 739, 790, 791, 792, 795, 796, 830, 838, 841, 873, 892, 896, 912, 996, 1016, 1021, 1030, 1034, 1044, 1045, 1048, 1050, 1051, 1053, 1054, 1055, 1057, 1058], "recalcul": [258, 260, 416, 1038, 1041], "recall_macro": [420, 1000], "recall_scor": [2, 62, 272, 285, 420, 716, 792, 1000, 1041, 1043, 1044, 1045, 1046, 1051, 1057], "recant": 401, "receiv": [0, 2, 57, 165, 189, 248, 254, 260, 270, 272, 273, 275, 362, 369, 386, 388, 394, 400, 415, 420, 423, 512, 666, 710, 714, 716, 735, 790, 796, 797, 827, 838, 840, 841, 879, 917, 1001, 1004, 1005, 1014, 1021, 1051, 1052], "recent": [52, 222, 254, 384, 387, 391, 394, 400, 416, 476, 546, 573, 1014, 1024, 1044, 1053], "recherch": 0, "recht": [649, 992], "recip": [390, 410, 997, 1024], "reciproc": [382, 1000], "reckon": 381, "recogn": [43, 44, 65, 86, 88, 118, 120, 128, 147, 172, 189, 221, 271, 303, 331, 338, 339, 392, 407, 416, 424, 510, 705, 721, 838, 917, 1000, 1021, 1025, 1058], "recognit": [42, 48, 54, 125, 189, 253, 256, 317, 324, 379, 391, 421, 423, 425, 502, 510, 540, 542, 549, 705, 716, 721, 749, 777, 796, 797, 805, 822, 838, 892, 917, 992, 996, 1000, 1001, 1005, 1015, 1017, 1021, 1025, 1028, 1036, 1041], "recommend": [118, 147, 187, 237, 248, 254, 274, 287, 323, 330, 353, 373, 374, 380, 384, 386, 388, 392, 394, 398, 404, 410, 419, 420, 421, 423, 425, 446, 455, 457, 459, 468, 504, 516, 543, 546, 552, 557, 569, 570, 577, 590, 591, 597, 614, 619, 639, 640, 646, 666, 667, 678, 684, 700, 705, 706, 708, 710, 814, 820, 822, 831, 868, 875, 877, 884, 891, 892, 897, 898, 900, 901, 902, 903, 905, 914, 917, 949, 989, 997, 1000, 1002, 1004, 1007, 1010, 1012, 1014, 1015, 1016, 1018, 1024, 1036, 1043, 1044, 1050, 1051, 1052, 1053, 1055, 1057], "recompil": [387, 392, 404], "recomput": [90, 91, 258, 260, 301, 328, 477, 482, 996, 1012, 1046, 1057], "reconstruct": [2, 42, 55, 58, 101, 125, 126, 130, 189, 219, 243, 244, 332, 410, 421, 424, 490, 491, 492, 539, 541, 543, 545, 546, 547, 548, 550, 551, 553, 554, 556, 591, 595, 660, 680, 696, 697, 701, 904, 905, 996, 997, 1021, 1055], "reconstruct_from_patches_2d": [2, 128, 424, 591], "reconstruction_err_": [546, 548], "reconstruction_error": 696, "reconstruction_error_": 697, "record": [2, 50, 126, 143, 155, 194, 254, 272, 325, 362, 373, 386, 410, 416, 418, 458, 465, 506, 628, 651, 700, 779, 782, 786, 787, 788, 789, 835, 858, 1054, 1055], "recov": [75, 100, 115, 126, 127, 132, 149, 176, 191, 204, 219, 220, 224, 240, 362, 418, 422, 425, 428, 468, 541, 567, 996, 997, 999, 1020, 1033, 1047], "recoveri": [51, 115, 204, 219, 418, 425], "recreat": [83, 258], "recreate_imag": 83, "rect": [47, 87, 199], "rect_colorbar": 319, "rect_histi": 319, "rect_histx": 319, "rect_scatt": 319, "rectangl": 47, "rectangular": [381, 400, 949, 1020], "rectifi": [869, 870], "recurs": [2, 18, 52, 156, 165, 168, 171, 174, 189, 273, 276, 277, 283, 292, 303, 364, 388, 416, 420, 448, 449, 450, 453, 471, 510, 523, 571, 601, 602, 605, 610, 640, 641, 666, 827, 872, 882, 1000, 1003, 1006, 1007, 1016, 1021, 1022, 1033, 1036, 1041, 1051, 1052], "recursionerror": 1059, "red": [48, 49, 50, 63, 69, 70, 95, 113, 123, 125, 126, 127, 142, 160, 163, 185, 197, 199, 200, 210, 218, 245, 258, 273, 284, 312, 315, 320, 324, 325, 340, 349, 367, 384, 400, 416, 421, 1001], "reda": 1047, "redden": 1052, "reddi": [1048, 1049, 1050, 1055, 1058], "redefin": [58, 152, 192], "redesign": [398, 1041], "redirects_en": 55, "redirects_filenam": 55, "redirects_url": 55, "redistribut": 450, "redo": 361, "reduc": [2, 37, 43, 46, 77, 80, 81, 82, 83, 88, 105, 106, 111, 142, 152, 154, 155, 158, 171, 192, 199, 200, 204, 218, 224, 225, 228, 249, 251, 254, 257, 279, 285, 296, 308, 321, 324, 325, 333, 361, 362, 369, 378, 380, 383, 386, 392, 398, 400, 410, 414, 415, 416, 418, 420, 421, 423, 424, 425, 427, 452, 453, 458, 465, 468, 501, 542, 552, 557, 563, 564, 565, 566, 571, 572, 573, 574, 581, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 618, 635, 651, 660, 680, 681, 682, 683, 695, 700, 703, 789, 808, 811, 812, 814, 822, 831, 833, 834, 835, 836, 839, 881, 882, 889, 901, 904, 905, 912, 913, 920, 921, 922, 923, 989, 992, 994, 995, 996, 997, 1000, 1003, 1012, 1013, 1015, 1017, 1025, 1033, 1041, 1043, 1044, 1045, 1046, 1047, 1050, 1051, 1052, 1053, 1055, 1057, 1059], "reduce_dim": [106, 259, 277, 417], "reduce_dim__k": 106, "reduce_dim__n_compon": [106, 277, 417], "reduce_func": [789, 1052], "reduced_data": 93, "reducer_label": 106, "reduct": [2, 11, 45, 57, 89, 92, 103, 107, 118, 125, 133, 142, 158, 189, 239, 241, 242, 245, 251, 255, 300, 307, 309, 332, 346, 369, 373, 378, 416, 417, 419, 421, 423, 425, 476, 490, 491, 492, 493, 510, 538, 540, 542, 543, 546, 547, 548, 549, 552, 555, 557, 561, 562, 565, 566, 567, 568, 572, 573, 574, 607, 615, 696, 697, 698, 699, 700, 701, 789, 808, 838, 854, 861, 868, 872, 873, 882, 892, 910, 912, 920, 921, 922, 923, 992, 997, 1012, 1016, 1020, 1021, 1022, 1024, 1030, 1036, 1042, 1043, 1044, 1047, 1055, 1056, 1057], "redund": [62, 64, 135, 173, 264, 269, 335, 369, 382, 385, 386, 391, 400, 414, 523, 642, 1020, 1034, 1053], "redundantli": 400, "ref": [386, 394, 990, 1047], "ref_lin": 446, "refactor": [332, 1041, 1043, 1044, 1045, 1051, 1054, 1055, 1056], "refer": [43, 44, 72, 73, 95, 98, 105, 113, 121, 139, 153, 155, 160, 174, 181, 185, 194, 208, 238, 254, 257, 272, 278, 283, 284, 285, 292, 302, 309, 319, 328, 329, 330, 331, 332, 333, 334, 335, 336, 361, 374, 380, 381, 383, 384, 386, 387, 388, 390, 391, 392, 393, 394, 398, 399, 400, 401, 404, 407, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 423, 424, 425, 427, 428, 429, 445, 446, 447, 448, 450, 452, 454, 455, 456, 458, 459, 460, 461, 462, 465, 470, 471, 472, 473, 474, 475, 476, 477, 480, 481, 482, 483, 506, 511, 519, 521, 523, 524, 525, 526, 527, 528, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 548, 549, 552, 555, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 598, 601, 602, 603, 610, 615, 616, 618, 619, 622, 627, 630, 631, 635, 636, 639, 640, 642, 643, 644, 645, 646, 647, 650, 651, 652, 653, 655, 657, 659, 661, 663, 664, 666, 669, 671, 673, 674, 675, 676, 679, 681, 683, 684, 686, 687, 690, 691, 696, 697, 698, 699, 700, 701, 702, 703, 704, 709, 712, 713, 715, 716, 717, 718, 720, 722, 723, 724, 725, 726, 727, 728, 729, 731, 732, 733, 734, 735, 737, 738, 739, 742, 743, 744, 745, 746, 748, 749, 751, 764, 766, 767, 777, 791, 793, 794, 796, 797, 800, 801, 803, 805, 806, 808, 809, 810, 811, 812, 813, 814, 822, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 839, 842, 843, 847, 848, 849, 851, 854, 857, 858, 859, 861, 868, 869, 870, 872, 877, 878, 879, 881, 882, 884, 885, 886, 888, 889, 890, 892, 893, 900, 905, 906, 907, 908, 909, 910, 912, 914, 915, 917, 918, 920, 921, 922, 923, 937, 949, 966, 989, 992, 993, 994, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1020, 1023, 1025, 1029, 1033, 1034, 1041, 1045, 1046, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "referenc": [383, 386, 388, 394, 400, 904, 905, 1003, 1048, 1054], "references_": 889, "refin": [62, 115, 480, 717, 1000, 1034], "refit": [146, 165, 171, 173, 189, 270, 277, 279, 282, 285, 286, 290, 400, 415, 420, 426, 510, 575, 635, 667, 673, 721, 808, 811, 812, 822, 830, 838, 917, 989, 996, 1000, 1021, 1048, 1049, 1050, 1059], "refit_strategi": 276, "refit_time_": [808, 811, 812, 822, 1049], "reflect": [51, 75, 81, 82, 113, 123, 126, 149, 193, 194, 220, 238, 287, 303, 361, 382, 385, 386, 390, 400, 403, 413, 458, 464, 997, 1000, 1006, 1008, 1033, 1042, 1050, 1059], "reformul": 385, "refrain": [221, 386], "refug": 100, "refurbish": 7, "refus": [272, 398, 902, 903], "reg": [153, 192, 200, 254, 320, 329, 354, 423, 566, 568, 576, 658, 659, 661, 662, 663, 664, 665, 671, 672, 673, 678, 679, 686, 687, 697, 701, 923, 996, 1046], "reg1": [163, 423], "reg2": [163, 423], "reg3": [163, 423], "reg_covar": [263, 805, 806], "reg_nnl": 215, "reg_ol": 215, "reg_param": 558, "regard": [0, 11, 44, 46, 50, 52, 88, 90, 105, 121, 130, 166, 176, 181, 193, 194, 209, 217, 222, 242, 253, 257, 280, 287, 288, 302, 361, 381, 382, 386, 387, 391, 398, 400, 410, 416, 421, 423, 424, 426, 451, 455, 460, 467, 470, 509, 622, 627, 664, 666, 709, 751, 806, 814, 830, 831, 836, 854, 855, 993, 996, 1000, 1002, 1003, 1005, 1007, 1014, 1015, 1016, 1027, 1034, 1048, 1051], "regardless": [238, 279, 280, 281, 374, 386, 416, 543, 640, 641, 666, 712, 723, 1000, 1012, 1049, 1056, 1057], "regedit": 404, "regener": 877, "regex": [278, 362, 472, 474], "regexp": [596, 597, 599], "regim": [43, 400, 912, 913, 999], "region": [51, 55, 59, 62, 71, 82, 83, 84, 88, 91, 101, 161, 183, 189, 192, 220, 238, 247, 251, 252, 269, 322, 349, 356, 383, 393, 400, 416, 423, 426, 456, 458, 464, 470, 595, 997, 1000, 1003, 1006, 1010, 1014, 1016, 1021, 1033], "region_1": 325, "region_2": 325, "regist": [2, 204, 360, 392, 970], "register_parallel_backend": [2, 1049, 1059], "registri": [384, 404, 1019], "regr": [216, 417, 562, 564, 573, 654, 655, 675, 845, 870, 913, 915, 918, 1015, 1032], "regr_1": [140, 366, 367], "regr_2": [140, 366, 367], "regr_3": 367, "regr_multirf": 159, "regr_rf": 159, "regress": [2, 14, 19, 22, 24, 31, 40, 46, 49, 53, 62, 64, 66, 89, 103, 105, 113, 114, 116, 121, 126, 127, 128, 135, 138, 139, 142, 144, 145, 146, 147, 150, 151, 154, 155, 159, 160, 166, 172, 174, 175, 177, 185, 187, 188, 189, 191, 192, 193, 195, 198, 202, 204, 205, 206, 207, 210, 214, 215, 217, 221, 223, 224, 225, 226, 229, 231, 236, 243, 246, 248, 256, 257, 258, 261, 272, 274, 286, 289, 291, 292, 293, 298, 300, 302, 316, 317, 319, 320, 323, 324, 330, 331, 332, 333, 335, 344, 345, 356, 357, 360, 363, 364, 368, 374, 375, 378, 379, 381, 383, 386, 388, 391, 394, 395, 398, 399, 400, 411, 414, 418, 419, 420, 421, 423, 425, 439, 445, 472, 473, 482, 492, 497, 498, 500, 504, 509, 510, 512, 513, 520, 524, 525, 526, 532, 536, 539, 543, 545, 547, 549, 550, 551, 553, 554, 556, 560, 561, 562, 563, 564, 565, 566, 567, 568, 570, 572, 573, 574, 575, 578, 600, 601, 602, 603, 604, 605, 606, 607, 608, 612, 613, 614, 617, 618, 619, 622, 623, 630, 631, 633, 639, 640, 641, 642, 643, 645, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 702, 709, 714, 729, 731, 732, 736, 749, 750, 753, 754, 755, 756, 757, 758, 759, 760, 761, 793, 798, 799, 808, 811, 812, 814, 822, 831, 835, 836, 838, 839, 841, 843, 845, 846, 854, 855, 860, 862, 863, 869, 870, 872, 873, 876, 877, 879, 885, 886, 887, 889, 892, 893, 896, 901, 913, 914, 915, 917, 918, 919, 920, 921, 922, 923, 924, 926, 932, 935, 937, 953, 989, 990, 992, 995, 997, 1007, 1008, 1010, 1011, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1028, 1031, 1036, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "regression_data": 46, "regression_model": 1048, "regression_test": 394, "regressioncriterion": 1049, "regressionregressionramdomizedpcaramdom": 1027, "regressor": [2, 30, 43, 109, 118, 153, 159, 160, 163, 176, 181, 188, 189, 192, 198, 200, 202, 204, 220, 221, 223, 226, 237, 238, 254, 281, 293, 304, 324, 329, 330, 373, 386, 388, 398, 400, 414, 417, 426, 439, 442, 443, 444, 473, 490, 491, 492, 493, 532, 559, 560, 561, 562, 563, 564, 565, 566, 568, 570, 573, 574, 575, 576, 577, 578, 613, 614, 617, 619, 640, 641, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 677, 678, 680, 681, 686, 687, 709, 840, 841, 844, 845, 846, 855, 863, 868, 869, 870, 873, 879, 887, 892, 893, 913, 915, 918, 920, 921, 922, 923, 926, 941, 943, 989, 990, 996, 1000, 1001, 1003, 1008, 1014, 1019, 1021, 1022, 1029, 1036, 1041, 1042, 1046, 1047, 1048, 1050, 1051, 1054, 1055, 1056, 1058], "regressor_": [192, 473, 601, 602, 605], "regressor__sample_weight": 220, "regressor_with_": 191, "regressor_without_": 191, "regressorchain": [2, 407, 843, 845, 1049, 1052, 1056], "regressormixin": [2, 254, 388, 400, 473, 1052], "regul": 0, "regular": [2, 62, 64, 67, 71, 75, 92, 94, 95, 96, 105, 107, 112, 130, 138, 148, 150, 151, 153, 158, 165, 167, 176, 177, 178, 180, 183, 185, 187, 189, 191, 198, 199, 200, 202, 204, 205, 207, 208, 209, 211, 216, 218, 220, 227, 234, 236, 238, 253, 264, 271, 274, 279, 280, 282, 291, 304, 305, 313, 315, 316, 317, 321, 322, 324, 325, 326, 343, 344, 346, 348, 349, 350, 353, 354, 358, 360, 362, 364, 373, 386, 398, 399, 414, 416, 418, 419, 421, 422, 423, 426, 445, 451, 455, 479, 480, 484, 486, 487, 488, 489, 512, 520, 522, 523, 528, 530, 532, 536, 546, 547, 548, 551, 555, 556, 558, 567, 569, 570, 596, 597, 599, 646, 651, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 695, 697, 701, 743, 749, 758, 805, 806, 825, 838, 839, 869, 870, 873, 892, 912, 913, 914, 915, 917, 918, 919, 989, 990, 992, 993, 994, 997, 999, 1005, 1006, 1010, 1013, 1014, 1015, 1021, 1022, 1024, 1029, 1030, 1032, 1036, 1041, 1042, 1043, 1045, 1046, 1050, 1051, 1053, 1054, 1059], "regularis": [224, 429, 481, 483], "regularli": [148, 296, 398, 1002], "regulatori": 155, "rehan": 1056, "rehman": 1049, "reiichiro": [1048, 1049], "reilli": 1058, "reimburs": 272, "reimplement": [392, 398, 400, 1047, 1051], "reinforc": 1020, "reinit": 394, "reiniti": 398, "reinstal": 404, "reintroduc": 1057, "reitsam": 1053, "reject": [255, 272, 400, 401, 531, 679, 735, 932, 933, 996, 1000, 1049], "rel": [43, 45, 47, 55, 58, 64, 90, 96, 130, 146, 181, 195, 197, 200, 220, 238, 266, 305, 306, 320, 329, 332, 349, 353, 360, 361, 381, 385, 388, 394, 400, 414, 416, 420, 423, 424, 426, 448, 451, 455, 457, 467, 529, 532, 539, 542, 545, 549, 553, 554, 565, 566, 567, 568, 572, 573, 574, 612, 657, 666, 667, 679, 680, 682, 698, 702, 737, 755, 808, 811, 812, 814, 822, 831, 836, 839, 852, 853, 857, 869, 870, 881, 882, 892, 908, 912, 913, 914, 917, 919, 920, 921, 922, 923, 996, 997, 1000, 1002, 1003, 1004, 1006, 1030], "relabel": [385, 826, 827, 909], "relat": [8, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 380, 381, 382, 385, 386, 390, 391, 393, 394, 395, 398, 400, 401, 403, 407, 410, 415, 416, 417, 418, 419, 420, 421, 423, 426, 458, 472, 477, 504, 557, 558, 570, 571, 647, 681, 685, 700, 709, 731, 751, 829, 835, 870, 871, 873, 876, 877, 882, 885, 887, 888, 891, 900, 916, 989, 992, 994, 1000, 1001, 1003, 1004, 1007, 1010, 1015, 1016, 1017, 1020, 1021, 1023, 1036, 1041, 1045, 1046, 1047, 1049, 1050, 1053, 1054, 1057], "relate_point": 309, "relationship": [2, 43, 52, 58, 139, 140, 155, 182, 191, 192, 199, 204, 220, 222, 223, 285, 292, 298, 320, 326, 335, 400, 416, 418, 420, 470, 504, 644, 722, 997, 1000, 1002, 1003, 1007, 1008, 1032, 1046], "relative_tim": 266, "relax": [46, 416, 424, 461, 1013, 1048], "releas": [0, 54, 90, 105, 143, 144, 157, 174, 187, 188, 193, 194, 197, 220, 221, 222, 249, 254, 259, 260, 261, 272, 273, 290, 292, 296, 301, 325, 341, 368, 374, 384, 386, 387, 389, 394, 398, 400, 424, 451, 454, 455, 472, 475, 498, 499, 504, 509, 510, 512, 520, 523, 529, 532, 546, 549, 569, 570, 572, 573, 575, 607, 610, 636, 638, 640, 642, 648, 654, 656, 660, 666, 677, 688, 696, 705, 709, 710, 725, 726, 740, 750, 756, 786, 796, 803, 807, 808, 809, 811, 812, 814, 822, 830, 831, 834, 835, 838, 854, 856, 873, 877, 882, 885, 886, 887, 891, 892, 893, 909, 910, 912, 917, 920, 921, 944, 1016, 1021, 1041, 1042, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "release_highlight": 1021, "relev": [46, 48, 57, 110, 114, 174, 189, 199, 214, 223, 278, 279, 285, 369, 373, 375, 381, 383, 385, 386, 388, 390, 391, 392, 400, 401, 407, 418, 419, 425, 426, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 541, 542, 549, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 598, 599, 602, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 734, 748, 764, 807, 809, 810, 811, 812, 815, 817, 826, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 890, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 1000, 1001, 1006, 1017, 1020, 1021, 1044, 1049, 1055], "reli": [130, 145, 149, 174, 195, 208, 209, 296, 299, 329, 333, 360, 373, 374, 388, 391, 394, 395, 398, 400, 412, 413, 416, 421, 423, 424, 557, 601, 605, 615, 616, 786, 836, 839, 877, 966, 989, 992, 994, 996, 1000, 1003, 1008, 1010, 1015, 1024, 1049, 1050, 1051, 1055, 1057, 1058], "reliabl": [2, 62, 64, 414, 420, 446, 447, 654, 1016, 1024], "relianc": [130, 224], "religion": [57, 279, 360, 361, 362, 381, 1001, 1034], "reloc": 1050, "relova": 1054, "relu": [869, 870], "remain": [47, 62, 64, 105, 139, 146, 151, 153, 173, 192, 220, 224, 236, 263, 276, 280, 284, 287, 413, 416, 417, 418, 420, 424, 454, 472, 475, 523, 524, 529, 536, 542, 578, 618, 619, 771, 777, 810, 811, 812, 813, 816, 818, 847, 848, 849, 851, 953, 989, 990, 992, 999, 1000, 1004, 1010, 1016, 1020, 1043, 1049, 1055, 1058], "remaind": [43, 149, 192, 209, 220, 222, 238, 257, 333, 364, 417, 472, 475, 1041, 1048, 1049, 1050, 1053, 1054, 1057, 1059], "remaining_column": 472, "remark": [90, 118, 174, 272, 375, 386, 1010], "remedi": 237, "rememb": [90, 388, 391, 404, 424, 1003, 1007, 1016], "remi": 1048, "remind": 254, "reminisc": 128, "remot": [197, 339, 386, 389], "remov": [1, 2, 44, 54, 55, 89, 90, 104, 109, 172, 174, 187, 188, 192, 195, 279, 319, 326, 328, 329, 330, 335, 360, 361, 364, 369, 378, 381, 385, 386, 387, 388, 390, 391, 395, 400, 404, 409, 416, 417, 420, 423, 424, 426, 427, 449, 450, 452, 453, 458, 465, 490, 491, 492, 493, 496, 497, 535, 542, 543, 545, 546, 547, 548, 549, 554, 561, 575, 576, 577, 578, 587, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 619, 638, 652, 662, 663, 664, 666, 667, 674, 681, 683, 684, 685, 687, 700, 717, 750, 758, 759, 786, 787, 788, 790, 808, 811, 812, 814, 822, 831, 833, 834, 835, 836, 859, 871, 872, 876, 877, 889, 890, 892, 901, 927, 943, 944, 990, 997, 1003, 1016, 1022, 1026, 1036, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "remove_zero_eig": [543, 1043, 1050], "rempfler": 1052, "renam": [268, 279, 386, 390, 416, 454, 455, 467, 479, 480, 486, 535, 544, 561, 562, 563, 564, 565, 566, 571, 572, 573, 574, 885, 1041, 1042, 1043, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "rename_axi": 278, "render": [51, 63, 88, 105, 106, 144, 146, 147, 156, 157, 160, 163, 171, 181, 192, 193, 194, 201, 215, 224, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 333, 335, 340, 368, 386, 388, 390, 391, 392, 400, 559, 597, 639, 708, 710, 889, 901, 924, 926, 999, 1016, 1054, 1058], "rene": 1054, "renni": [2, 847, 849, 1002, 1049], "renorm": 63, "rent": 43, "rental": [43, 52, 193, 1007], "reorder": [58, 131, 400, 705, 726, 1020, 1049], "reordered_data": 58, "reordered_row": 58, "reorgan": 1047, "rep": 383, "reparameter": 1015, "reparametr": 356, "repartit": 43, "repeat": [2, 49, 69, 101, 112, 114, 151, 174, 176, 182, 183, 193, 197, 222, 272, 273, 278, 279, 290, 296, 339, 361, 362, 388, 395, 400, 401, 413, 414, 416, 421, 424, 425, 596, 601, 615, 616, 623, 635, 642, 667, 813, 823, 824, 827, 938, 990, 999, 1036, 1049, 1051], "repeatedkfold": [2, 192, 420, 813, 824, 1048], "repeatedli": [139, 332, 369, 400, 416, 423, 426, 516, 554, 674, 675, 684, 685, 686, 789, 990, 1004, 1029], "repeatedstratifiedkfold": [2, 278, 292, 296, 420, 823, 827, 1048], "repercuss": 324, "repetit": [278, 292, 296, 391, 420, 823, 824, 1008, 1055], "replac": [2, 43, 52, 62, 113, 129, 139, 155, 176, 181, 183, 187, 193, 206, 221, 281, 299, 321, 326, 330, 351, 384, 386, 388, 390, 392, 395, 400, 410, 417, 420, 423, 424, 449, 453, 472, 511, 523, 563, 564, 571, 590, 596, 597, 598, 599, 615, 616, 635, 638, 642, 647, 649, 736, 793, 814, 820, 822, 831, 871, 872, 875, 895, 908, 915, 969, 971, 974, 989, 990, 992, 996, 1000, 1010, 1015, 1016, 1019, 1020, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1056, 1057, 1058], "replai": [811, 812], "repli": [54, 360, 385, 386, 389], "replic": [278, 385, 388, 1036], "repo": [386, 390, 1020, 1023], "report": [0, 2, 43, 47, 52, 68, 104, 109, 171, 184, 208, 272, 276, 286, 292, 296, 328, 338, 369, 381, 385, 387, 388, 389, 392, 394, 398, 400, 404, 410, 416, 420, 619, 657, 666, 672, 693, 694, 708, 721, 737, 738, 746, 791, 792, 795, 841, 850, 869, 870, 907, 925, 943, 996, 1003, 1008, 1019, 1020, 1023, 1042, 1045, 1048, 1049, 1051, 1052, 1054, 1056, 1057], "reporthook": 47, "repositori": [43, 47, 52, 197, 272, 334, 379, 381, 383, 384, 386, 388, 390, 394, 398, 401, 404, 512, 1019, 1023, 1036], "repr": [585, 1052, 1053, 1055], "repreat": 278, "repres": [43, 47, 49, 51, 52, 54, 58, 63, 68, 70, 79, 83, 84, 85, 88, 122, 125, 127, 133, 134, 146, 147, 156, 192, 199, 207, 212, 222, 224, 225, 229, 242, 244, 252, 257, 266, 271, 272, 275, 278, 281, 285, 304, 321, 353, 360, 362, 368, 375, 378, 381, 383, 388, 398, 399, 400, 401, 410, 414, 416, 420, 421, 422, 423, 424, 425, 446, 450, 454, 460, 471, 472, 478, 479, 480, 481, 482, 483, 484, 496, 498, 499, 500, 502, 504, 506, 508, 509, 510, 512, 513, 518, 535, 542, 544, 546, 548, 549, 555, 563, 571, 589, 596, 599, 602, 637, 640, 642, 648, 684, 686, 705, 707, 709, 719, 738, 751, 797, 808, 810, 821, 822, 825, 828, 830, 835, 837, 838, 841, 842, 848, 854, 855, 856, 858, 859, 860, 862, 863, 864, 869, 870, 879, 885, 886, 909, 912, 913, 932, 933, 953, 990, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1008, 1010, 1011, 1013, 1014, 1016, 1025, 1030, 1031, 1033, 1047, 1049, 1052, 1053, 1056, 1059], "represent": [2, 43, 51, 55, 58, 63, 88, 105, 106, 125, 128, 144, 146, 147, 156, 157, 158, 160, 163, 171, 181, 192, 194, 197, 201, 204, 240, 241, 242, 248, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 296, 309, 317, 325, 330, 332, 333, 335, 340, 361, 362, 368, 369, 378, 380, 389, 400, 410, 416, 417, 421, 422, 423, 430, 471, 539, 543, 545, 548, 550, 556, 574, 596, 598, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 638, 651, 654, 660, 666, 667, 668, 670, 674, 675, 676, 684, 685, 686, 777, 805, 806, 814, 831, 868, 881, 885, 886, 890, 892, 905, 912, 924, 926, 929, 945, 966, 992, 997, 999, 1001, 1003, 1004, 1005, 1007, 1010, 1015, 1020, 1025, 1026, 1028, 1032, 1034, 1041, 1042, 1045, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "reproduc": [44, 51, 95, 139, 192, 197, 208, 287, 296, 317, 374, 385, 386, 388, 389, 394, 398, 400, 416, 420, 421, 424, 428, 448, 462, 468, 477, 482, 496, 499, 500, 503, 505, 511, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 559, 561, 562, 563, 564, 567, 568, 569, 570, 571, 615, 616, 618, 619, 642, 647, 648, 649, 650, 654, 655, 658, 660, 661, 662, 668, 669, 670, 671, 674, 675, 676, 679, 684, 686, 687, 697, 698, 700, 701, 702, 801, 805, 806, 810, 811, 812, 813, 814, 820, 822, 823, 824, 825, 826, 827, 828, 836, 837, 838, 842, 843, 846, 857, 861, 868, 869, 870, 877, 889, 893, 901, 904, 905, 912, 913, 914, 917, 948, 949, 971, 974, 992, 1019, 1023, 1041, 1049, 1054, 1055], "reproduct": [398, 996], "request": [2, 47, 55, 81, 220, 238, 254, 331, 374, 380, 384, 385, 389, 400, 401, 407, 410, 421, 424, 425, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 589, 590, 596, 598, 599, 602, 607, 608, 618, 619, 640, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 707, 807, 809, 810, 815, 817, 826, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 956, 957, 959, 1000, 1003, 1023, 1034, 1047, 1048, 1049, 1058, 1059], "request_rout": 254, "requir": [30, 31, 43, 46, 53, 62, 80, 81, 83, 88, 90, 92, 93, 102, 104, 121, 129, 131, 144, 145, 149, 150, 153, 155, 156, 160, 174, 193, 204, 209, 217, 220, 240, 242, 248, 251, 254, 257, 261, 272, 279, 287, 289, 292, 299, 301, 319, 324, 330, 331, 360, 361, 362, 380, 383, 384, 386, 387, 388, 390, 392, 394, 398, 400, 401, 404, 407, 410, 412, 416, 417, 418, 420, 421, 423, 424, 425, 427, 433, 439, 445, 446, 447, 452, 454, 458, 460, 465, 470, 472, 475, 477, 490, 491, 492, 504, 516, 529, 532, 543, 549, 557, 558, 559, 561, 563, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 580, 587, 588, 589, 618, 619, 627, 635, 640, 641, 642, 651, 654, 655, 660, 661, 666, 667, 674, 675, 676, 679, 682, 683, 684, 685, 686, 694, 697, 699, 700, 701, 703, 707, 732, 737, 738, 750, 755, 757, 760, 771, 792, 795, 807, 808, 811, 812, 815, 817, 822, 830, 835, 840, 841, 842, 843, 844, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 858, 859, 860, 862, 863, 864, 869, 872, 873, 874, 876, 886, 887, 888, 892, 900, 904, 905, 907, 908, 912, 913, 914, 917, 920, 921, 922, 923, 957, 960, 966, 986, 989, 994, 995, 996, 997, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1014, 1015, 1016, 1020, 1025, 1032, 1034, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "requires_fit": 388, "requires_i": [388, 433, 439, 1052], "requires_positive_i": 388, "requires_positive_x": [388, 1051, 1056], "requires_vector_input": [620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633], "requisit": 388, "rerais": 1058, "rerun": [51, 63, 77, 105, 106, 144, 146, 147, 156, 157, 160, 163, 171, 181, 192, 193, 194, 201, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 333, 335, 340, 368, 394], "resampl": [2, 87, 152, 192, 238, 303, 395, 398, 400, 563, 564, 974, 1020, 1050, 1054], "resampled_arrai": 971, "rescal": [43, 81, 82, 90, 130, 201, 208, 243, 257, 319, 358, 418, 423, 428, 477, 478, 479, 480, 481, 482, 483, 484, 541, 546, 654, 657, 660, 884, 890, 914, 915, 916, 917, 918, 1000, 1010, 1033, 1045, 1046], "rescaled_coin": [81, 82, 1033], "rescu": [410, 424], "research": [0, 174, 191, 272, 278, 284, 296, 381, 383, 398, 416, 509, 521, 643, 653, 700, 743, 837, 842, 989, 997, 1001, 1003, 1015, 1019, 1020, 1024], "resembl": [74, 224, 254], "reserv": [272, 325, 569, 570, 1024, 1025], "reserva": 325, "reservoir": 969, "reservoir_sampl": 969, "reset": [261, 369, 394, 542, 684, 685, 686, 852, 853, 881, 882, 892, 1043], "reset_n_cal": [852, 853], "reshama": [0, 371, 376, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1059], "reshap": [2, 43, 44, 45, 53, 61, 68, 81, 82, 83, 85, 86, 88, 89, 93, 106, 113, 117, 125, 128, 134, 142, 147, 148, 158, 167, 172, 176, 178, 179, 180, 181, 182, 183, 185, 199, 211, 217, 233, 234, 236, 237, 241, 243, 245, 247, 252, 256, 267, 276, 303, 305, 312, 314, 316, 317, 320, 321, 322, 326, 328, 331, 332, 334, 335, 343, 348, 349, 354, 357, 358, 398, 413, 421, 423, 424, 453, 473, 592, 639, 740, 838, 887, 891, 996, 1010, 1016, 1030, 1033, 1046], "resid": 381, "residence_sinc": 272, "residenti": 160, "residu": [2, 109, 216, 222, 274, 439, 473, 490, 491, 492, 560, 562, 564, 566, 568, 570, 573, 576, 578, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 679, 680, 681, 682, 686, 687, 693, 694, 709, 752, 793, 845, 846, 855, 863, 870, 913, 915, 918, 921, 923, 996, 1000, 1032, 1053, 1054, 1056], "residual_metr": 1047, "residual_threshold": [237, 679, 996, 1054], "residual_vs_predict": [43, 52, 109, 274, 333, 709], "residues_": 1046, "resign": 401, "resili": 424, "resist": [113, 114, 386], "resiz": [45, 81, 82, 258, 381, 501, 502, 1030], "resolut": [43, 50, 55, 134, 193, 311, 312, 349, 401, 414, 1025, 1051], "resolv": [55, 385, 386, 390, 394, 401, 424, 454, 460, 470, 699, 703, 949, 990, 1000, 1048, 1050, 1051, 1054, 1059], "resort": [280, 381, 410, 563, 1051], "resourc": [55, 77, 152, 155, 187, 220, 316, 330, 372, 389, 398, 399, 400, 415, 423, 811, 812, 1001, 1020, 1024, 1026, 1036, 1049, 1054, 1055, 1060], "resourcewarn": 1044, "resp": [381, 423, 605, 805, 806, 1014, 1049], "respect": [64, 90, 102, 121, 130, 139, 143, 145, 148, 157, 184, 197, 199, 204, 209, 222, 234, 237, 240, 242, 248, 251, 253, 257, 268, 272, 287, 305, 306, 317, 324, 332, 346, 353, 373, 374, 381, 382, 386, 414, 416, 419, 421, 423, 424, 426, 454, 472, 475, 478, 479, 480, 481, 482, 483, 484, 542, 548, 549, 555, 561, 569, 570, 605, 618, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 644, 651, 679, 698, 702, 720, 736, 790, 793, 805, 806, 848, 858, 869, 870, 924, 926, 989, 993, 994, 996, 997, 1000, 1003, 1004, 1005, 1006, 1010, 1015, 1019, 1023, 1024, 1044, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "respond": [192, 386, 416], "respons": [0, 25, 174, 193, 216, 220, 223, 254, 288, 360, 383, 392, 400, 416, 417, 423, 454, 472, 490, 491, 492, 639, 640, 641, 682, 683, 706, 708, 710, 750, 805, 806, 1001, 1007, 1025, 1058], "response_method": [48, 66, 70, 91, 141, 156, 161, 203, 212, 229, 234, 272, 281, 302, 307, 310, 324, 336, 345, 346, 348, 353, 365, 639, 640, 641, 706, 708, 710, 750, 807, 830, 1000, 1058], "rest": [2, 30, 62, 66, 149, 153, 189, 198, 204, 229, 235, 254, 257, 266, 296, 298, 328, 342, 346, 357, 392, 400, 426, 520, 618, 639, 652, 666, 667, 684, 762, 796, 840, 841, 842, 861, 912, 914, 917, 996, 1000, 1001, 1004, 1007, 1015, 1021, 1024, 1045, 1046, 1055, 1056, 1057, 1059], "restart": [92, 389, 394, 455, 539, 545, 546, 551, 553, 554, 618, 619, 997, 1054], "restor": [1044, 1049, 1050, 1051, 1052, 1056], "restrict": [2, 64, 101, 102, 107, 117, 187, 189, 210, 237, 313, 388, 392, 398, 414, 416, 423, 424, 473, 501, 510, 540, 589, 618, 661, 662, 663, 664, 666, 690, 691, 721, 790, 796, 797, 838, 860, 862, 863, 864, 866, 868, 869, 870, 872, 898, 1000, 1016, 1021, 1035, 1036, 1041, 1043, 1051, 1053, 1058], "restructuredtext": 386, "result": [2, 27, 37, 43, 44, 45, 48, 52, 53, 57, 61, 62, 63, 66, 68, 70, 72, 75, 77, 78, 79, 81, 83, 88, 89, 90, 95, 97, 101, 105, 107, 109, 114, 118, 125, 128, 130, 131, 135, 142, 143, 144, 146, 149, 150, 152, 153, 156, 158, 159, 167, 173, 174, 176, 178, 180, 184, 187, 192, 193, 194, 195, 200, 205, 206, 209, 210, 215, 221, 222, 224, 228, 234, 235, 238, 240, 241, 244, 247, 250, 252, 258, 263, 268, 269, 271, 272, 273, 276, 278, 279, 281, 284, 285, 286, 287, 289, 290, 292, 294, 296, 299, 301, 305, 314, 315, 316, 319, 320, 321, 324, 328, 330, 332, 333, 334, 335, 336, 338, 341, 343, 349, 353, 354, 356, 360, 362, 366, 367, 368, 373, 374, 375, 380, 381, 383, 386, 388, 390, 391, 392, 394, 398, 399, 400, 401, 410, 412, 413, 414, 416, 418, 419, 420, 421, 422, 423, 424, 425, 426, 428, 441, 448, 449, 451, 453, 454, 455, 458, 459, 460, 461, 462, 463, 465, 467, 470, 472, 475, 477, 478, 479, 480, 481, 482, 483, 484, 487, 497, 516, 517, 519, 521, 539, 540, 541, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 559, 560, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 577, 587, 588, 589, 590, 592, 596, 597, 599, 615, 616, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 638, 639, 640, 642, 644, 648, 651, 660, 661, 666, 672, 673, 674, 675, 683, 684, 685, 686, 694, 697, 698, 699, 700, 701, 702, 703, 716, 718, 719, 720, 725, 733, 734, 736, 737, 738, 739, 740, 744, 745, 746, 762, 764, 765, 772, 779, 782, 786, 787, 788, 789, 791, 792, 793, 795, 801, 802, 805, 806, 808, 810, 811, 812, 813, 818, 822, 823, 824, 827, 828, 833, 839, 840, 841, 843, 844, 845, 846, 852, 853, 854, 855, 856, 857, 858, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 874, 876, 877, 885, 886, 889, 890, 893, 901, 905, 909, 912, 914, 917, 920, 921, 922, 923, 924, 925, 932, 933, 948, 949, 951, 955, 965, 966, 971, 974, 990, 992, 994, 995, 996, 997, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1014, 1015, 1016, 1019, 1020, 1023, 1025, 1029, 1030, 1032, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "results_df": [228, 278, 325], "results_for_preval": 281, "results_sc": 356, "retail": 1024, "retain": [2, 199, 400, 416, 419, 420, 424, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 502, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 703, 704, 807, 809, 810, 815, 817, 826, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 885, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 989, 1013, 1041], "retbin": 1010, "retent": [600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611], "retrac": 254, "retract": 386, "retrain": [410, 1020, 1057, 1059], "retri": [194, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 1049, 1055, 1059], "retriev": [2, 118, 192, 224, 285, 361, 368, 390, 400, 421, 424, 425, 476, 504, 598, 601, 602, 634, 661, 671, 692, 707, 734, 738, 740, 741, 764, 789, 847, 851, 884, 910, 996, 998, 1000, 1002, 1019, 1020, 1033, 1046, 1051, 1053, 1055, 1058], "return": [2, 30, 43, 45, 46, 47, 49, 50, 52, 53, 55, 57, 61, 62, 64, 69, 70, 72, 75, 83, 88, 91, 96, 104, 109, 123, 132, 134, 137, 139, 142, 144, 151, 152, 155, 156, 160, 174, 179, 182, 184, 188, 195, 199, 200, 208, 209, 212, 220, 221, 228, 229, 230, 238, 254, 257, 260, 261, 266, 268, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 285, 293, 299, 304, 309, 312, 317, 319, 321, 324, 328, 336, 345, 349, 360, 362, 364, 368, 373, 379, 380, 381, 386, 387, 388, 392, 393, 395, 398, 400, 414, 415, 416, 417, 420, 421, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 932, 933, 935, 936, 937, 938, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 966, 967, 969, 970, 971, 972, 973, 974, 975, 981, 984, 985, 986, 987, 988, 990, 1000, 1003, 1007, 1008, 1015, 1016, 1020, 1025, 1030, 1032, 1034, 1038, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "return_a": [593, 594, 966, 1044], "return_cent": [520, 1052], "return_cod": 554, "return_cost": [479, 480, 486], "return_count": [341, 361, 864], "return_cov": [400, 575, 576, 619, 872], "return_dist": [89, 471, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 1003, 1045], "return_distribut": [123, 531], "return_estim": [43, 192, 292, 335, 420, 835, 1049], "return_ind": 531, "return_indic": [420, 835, 1057], "return_inner_stat": 1055, "return_intercept": [695, 1050], "return_invers": [154, 388], "return_log": [852, 853], "return_model": [1043, 1045], "return_n_it": [428, 462, 467, 486, 553, 554, 654, 655, 660, 661, 668, 669, 670, 671, 689, 690, 691, 692, 693, 694, 695, 702, 1055], "return_norm": [899, 1048], "return_path": [690, 691, 693, 694], "return_std": [176, 181, 182, 183, 185, 199, 200, 400, 560, 575, 576, 619, 621, 622, 623, 624, 633, 635, 652, 653, 872, 1048, 1049, 1053, 1058], "return_sum_weight": 981, "return_tim": [280, 836, 1051], "return_train_scor": [145, 282, 292, 325, 420, 808, 811, 812, 822, 835, 1047, 1048, 1050], "return_x_i": [44, 46, 54, 93, 104, 105, 106, 107, 125, 145, 149, 163, 165, 166, 170, 187, 188, 194, 195, 197, 205, 207, 208, 209, 211, 216, 217, 227, 235, 236, 248, 256, 257, 260, 261, 274, 277, 280, 285, 286, 294, 296, 298, 301, 308, 315, 316, 317, 324, 328, 330, 332, 333, 334, 335, 341, 352, 362, 364, 379, 391, 392, 399, 410, 416, 417, 420, 423, 425, 428, 436, 454, 496, 497, 498, 499, 500, 502, 503, 504, 505, 508, 509, 510, 512, 513, 518, 540, 541, 542, 543, 566, 569, 570, 575, 576, 600, 603, 604, 606, 607, 608, 609, 610, 618, 627, 628, 630, 631, 646, 647, 666, 667, 676, 681, 682, 683, 696, 697, 698, 699, 701, 703, 709, 719, 796, 811, 812, 814, 840, 845, 856, 861, 864, 921, 922, 923, 990, 995, 1000, 1001, 1002, 1003, 1010, 1025, 1029, 1030, 1032, 1033, 1038, 1047, 1049, 1051, 1054], "return_x_mean": 428, "reuben": 1041, "reus": [52, 176, 213, 272, 279, 328, 362, 388, 400, 416, 417, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 642, 654, 656, 657, 660, 666, 668, 670, 674, 675, 676, 677, 684, 685, 686, 688, 869, 870, 1008, 1012, 1024, 1048, 1058], "reuter": [373, 381], "reuters21578": 47, "reuterspars": 47, "rev": [386, 615, 616], "revamp": 1051, "reveal": [43, 52, 192, 194, 360, 392, 413, 997, 1057], "revers": [57, 109, 174, 225, 278, 542, 549, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 619, 797, 872, 1000, 1041, 1042, 1051, 1053, 1057], "revert": [126, 638, 640, 641, 1048, 1053, 1058], "review": [296, 325, 373, 381, 388, 389, 390, 391, 392, 398, 401, 420, 421, 543, 549, 1000, 1010, 1026], "revillet": 1041, "revis": [401, 678], "revisit": [416, 427, 452], "revolv": 997, "reward": 386, "reweight": [139, 361, 400, 418, 423, 598, 599, 656, 677, 688], "reweight_covari": [477, 482], "rewrit": [392, 398, 1016, 1033, 1041], "rewritten": [386, 657, 1043, 1045], "rey": 1056, "reza": 1051, "rezazadeh": 1054, "rf": [144, 145, 159, 162, 163, 194, 328, 369, 423, 575, 577, 578], "rf_123": 369, "rf__n_estim": 423, "rf_appli": 144, "rf_cst": 335, "rf_inst": 369, "rf_leaves_yield": 144, "rf_model": 144, "rf_no_cst": 335, "rf_pipelin": 160, "rfc": [64, 260, 328, 1038], "rfc_disp": [260, 328, 1038], "rfe": [2, 172, 173, 407, 425, 602, 605, 610, 1041, 1045, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "rfecv": [2, 173, 407, 425, 601, 605, 610, 1045, 1047, 1049, 1051, 1052, 1053, 1054, 1057, 1058, 1059], "rgb": [83, 381, 424, 501, 502, 591, 592, 595], "rgr_lasso": 53, "rgr_ridg": 53, "rhinehart": 1048, "rho": [231, 421, 685, 996, 1014, 1042], "rho_k": 422, "ri": [416, 713, 794], "ribeiro": [598, 738, 1054], "ricardo": [1044, 1054, 1055, 1058], "ricardojnf": 1054, "riccadonna": 751, "riccardo": [1052, 1058], "rice": [50, 312, 381, 506, 1054], "rich": [87, 155, 394, 398, 416, 447, 1024, 1052, 1055], "richard": [381, 425, 666, 1042, 1051, 1053, 1055, 1056, 1059], "richardscottoz": 1054, "richer": [87, 134, 416], "richi": 1049, "rick": 1052, "ricker": 134, "ricker_funct": 134, "ricker_matrix": 134, "rickiepark": 1048, "rid": [48, 1014], "riddel": [1044, 1046, 1048], "ridg": [2, 24, 44, 49, 53, 89, 109, 126, 127, 160, 165, 174, 175, 181, 183, 187, 189, 191, 192, 193, 198, 199, 204, 207, 210, 213, 216, 220, 221, 246, 256, 291, 320, 323, 355, 356, 360, 373, 398, 412, 421, 423, 426, 532, 543, 547, 551, 619, 623, 630, 633, 651, 652, 653, 655, 657, 665, 669, 681, 682, 683, 686, 695, 709, 758, 808, 814, 822, 845, 918, 1000, 1001, 1008, 1010, 1014, 1015, 1021, 1022, 1032, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1050, 1051, 1054, 1055, 1056, 1057, 1059], "ridge_alpha": [547, 551, 1048], "ridge_cv": 109, "ridge_cv_with_trans_target": 109, "ridge_glm": 220, "ridge_regress": [2, 1049, 1050, 1056], "ridgeclassifi": [2, 360, 373, 680, 681, 683, 996, 1001, 1046, 1050, 1054, 1055, 1056, 1059], "ridgeclassifiercv": [2, 407, 681, 682, 796, 996, 1000, 1001, 1049, 1051, 1052, 1054, 1055, 1059], "ridgecv": [2, 43, 109, 160, 174, 192, 256, 400, 407, 423, 576, 651, 680, 683, 996, 1001, 1041, 1043, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1059], "ridgecvridgecv": [160, 192], "ridgeregress": 388, "ridgeridg": 192, "ridgewai": [151, 423], "riedmann": 1053, "ries": 1055, "rifkin": 996, "right": [45, 46, 50, 51, 53, 54, 67, 70, 74, 77, 78, 79, 80, 86, 88, 95, 97, 99, 112, 113, 115, 121, 122, 123, 127, 128, 130, 132, 134, 139, 141, 142, 143, 152, 153, 154, 155, 162, 170, 176, 179, 188, 195, 210, 221, 222, 223, 224, 226, 227, 230, 231, 247, 250, 251, 263, 265, 266, 268, 269, 272, 273, 274, 278, 281, 285, 288, 289, 291, 292, 304, 312, 314, 317, 319, 321, 324, 334, 335, 339, 349, 351, 353, 356, 358, 360, 365, 368, 369, 386, 388, 398, 401, 413, 415, 416, 419, 421, 422, 423, 426, 472, 490, 491, 492, 493, 542, 549, 552, 565, 566, 567, 568, 569, 570, 572, 573, 574, 595, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 635, 643, 684, 686, 877, 920, 921, 922, 923, 924, 936, 949, 989, 992, 994, 996, 998, 1000, 1002, 1003, 1007, 1012, 1014, 1015, 1016, 1019, 1020, 1024, 1026, 1030, 1032, 1033, 1043, 1049, 1055, 1057, 1058], "right_impur": [565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923], "rightarrow": [426, 627, 1004], "rijn": [380, 1049], "rileran": 1055, "rio": [1051, 1053, 1054, 1055], "ripe": 325, "rise": 181, "rishabh": 1055, "rishi": 1053, "rishikesh": 1048, "risk": [16, 48, 90, 155, 220, 224, 238, 320, 356, 369, 385, 386, 400, 415, 420, 423, 575, 576, 897, 898, 900, 901, 902, 903, 996, 1000, 1024, 1048], "riski": 238, "riskiest": [220, 238], "ritchi": 1052, "rithvik": 1053, "ritter": [1055, 1056], "ritual": 360, "rival": [43, 909, 1013], "rk": 100, "rkf": [420, 823], "rl2007": 996, "rlm": 1051, "rm": [113, 179, 390, 394, 418], "rmse": [43, 52, 114, 155, 325, 758, 1000, 1052], "rmse_": 325, "rmse_test_mean": 325, "rmse_test_scor": 325, "rmse_test_std": 325, "rmse_train_mean": 325, "rmse_train_scor": 325, "rmse_train_std": 325, "rmsle": [759, 1000], "rmtree": [89, 106, 417], "rna": 398, "rnd": 320, "rng": [44, 58, 59, 67, 70, 72, 79, 85, 97, 114, 118, 125, 127, 132, 140, 152, 155, 156, 157, 159, 176, 177, 180, 182, 183, 185, 187, 188, 191, 194, 199, 200, 201, 202, 204, 209, 214, 221, 222, 227, 234, 247, 253, 254, 256, 263, 273, 281, 284, 289, 290, 314, 323, 326, 329, 330, 332, 334, 335, 338, 339, 343, 352, 366, 367, 369, 374, 388, 391, 407, 429, 478, 482, 483, 484, 486, 487, 488, 489, 651, 657, 678, 680, 686, 695, 820, 847, 848, 849, 851, 852, 853, 857, 860, 862, 863, 864, 889, 901, 904, 905, 907, 908, 909, 918, 1025], "ro": 63, "road": 398, "rob": [227, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1053, 1056], "robert": [0, 83, 106, 174, 208, 296, 383, 406, 421, 536, 543, 636, 664, 729, 731, 732, 743, 878, 990, 996, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1051, 1056], "robertlayton": 83, "roberto": [416, 450], "robertson": 1054, "robin": [187, 188, 635, 990, 1047, 1050, 1055, 1056], "robinson": 1054, "robl": 1048, "robson": 1051, "robust": [2, 48, 70, 96, 98, 110, 112, 150, 152, 174, 188, 189, 192, 193, 198, 210, 222, 224, 237, 247, 257, 293, 319, 334, 375, 383, 388, 394, 416, 423, 424, 454, 456, 477, 478, 481, 482, 483, 484, 532, 542, 567, 568, 657, 665, 678, 679, 686, 687, 758, 842, 873, 887, 889, 890, 901, 907, 947, 1000, 1004, 1006, 1010, 1013, 1014, 1019, 1021, 1022, 1024, 1035, 1036, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1057], "robust_contour": 113, "robust_cov": 113, "robust_mah": 113, "robust_scal": [2, 890, 901, 1049], "robustli": [8, 223], "robustscal": [2, 257, 889, 902, 990, 1010, 1046, 1047, 1049, 1051, 1052, 1053, 1057], "roc": [2, 50, 62, 144, 174, 189, 246, 248, 257, 258, 270, 272, 273, 280, 335, 336, 393, 414, 415, 420, 512, 518, 572, 666, 710, 714, 715, 716, 735, 750, 790, 796, 797, 827, 838, 841, 879, 917, 1006, 1021, 1038, 1043, 1044, 1046, 1047, 1051, 1053, 1057], "roc_auc": [50, 174, 278, 282, 287, 288, 393, 642, 710, 741, 1000, 1038], "roc_auc_ovo": [1000, 1051], "roc_auc_ovo_weight": [1000, 1051], "roc_auc_ovr": [1000, 1051], "roc_auc_ovr_weight": [1000, 1051], "roc_auc_scor": [2, 62, 174, 278, 287, 328, 335, 710, 714, 715, 716, 797, 1000, 1043, 1044, 1049, 1051, 1055, 1056], "roc_curv": [2, 50, 248, 275, 287, 710, 714, 735, 790, 796, 1000, 1041, 1042, 1043, 1046, 1047, 1049, 1054, 1057, 1059], "roc_displai": 248, "rocchio": [360, 859], "rocco": [1054, 1055, 1056], "roccurvedisplai": [2, 144, 257, 260, 272, 275, 287, 288, 328, 393, 796, 797, 1006, 1038, 1051, 1057, 1058, 1059], "rock": 114, "rocklin": [385, 391], "rocktalu": 100, "roddi": [1050, 1051], "rodent": [50, 312, 381, 506], "roderick": 990, "rodion": 1054, "rodrigo": [1049, 1059], "rodrigu": [1048, 1049, 1054], "rodr\u00edguez": 325, "roeder": 1051, "roehr": [1057, 1058], "roei": 1053, "roeschk": 1050, "roger": [731, 1048, 1049, 1053], "rogerstanimoto": [458, 465, 707, 786, 787, 788, 1003], "rogerstanimotodist": 707, "rohan": [1046, 1047, 1049, 1050, 1054], "rohit": [1044, 1045, 1049, 1050], "roi": [1041, 1055], "roi_siz": 89, "roic": 1056, "rok": 1051, "rokem": [1041, 1047], "rokhlin": [543, 549, 949], "roland": [1043, 1044], "rolando": [1042, 1043], "role": [0, 287, 373, 385, 421], "roll": [2, 102, 189, 239, 240, 245, 389, 416, 538, 700, 701, 943, 1021, 1024, 1051, 1056], "rolling_max": 52, "rolling_mean": 52, "rolling_min": 52, "romain": [1048, 1053], "roman": [0, 405, 635, 926, 1043, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058], "roman4oo": 1056, "romaniuk": 1045, "romero": 1059, "romijnd": 1053, "romuald": 1050, "ron": [0, 265, 406, 1041], "ronald": [381, 1004, 1044, 1054], "ronan": [1041, 1044, 1049], "ronchetti": [657, 996], "rong": 1015, "ronrubin": [672, 693, 694, 996], "ronsin": [1049, 1050, 1058], "ronweiss": 265, "room": [319, 381, 391, 416, 1023], "roopam": [1049, 1050], "root": [2, 43, 113, 155, 174, 201, 368, 383, 386, 394, 416, 450, 509, 549, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 647, 758, 759, 798, 799, 920, 921, 922, 923, 924, 926, 1000, 1006, 1016, 1043, 1049, 1050, 1051, 1052, 1055, 1056], "root_": 450, "root_mean_squared_error": [2, 52, 155, 758, 1000, 1058], "root_mean_squared_log_error": [2, 759, 1000, 1058], "rope": 278, "rope_interv": 278, "rope_prob": 278, "rori": 1052, "rosa": 1056, "rosal": 420, "rose": 381, "rosenberg": [416, 725, 745, 803], "rosenfeld": 1049, "ross": [542, 615, 616, 1016, 1055, 1056], "rosset": [139, 423, 527, 561], "rossi": 1044, "rosslimlinyang_ijcv": 542, "rostamizadeh": 989, "rostomyan": 1049, "rotat": [47, 75, 124, 127, 130, 132, 151, 162, 189, 195, 243, 289, 290, 298, 349, 355, 419, 421, 426, 428, 512, 540, 549, 558, 622, 705, 892, 924, 996, 1021, 1052, 1053], "rotation_mod": 289, "rotations_": 558, "roth": [92, 1046, 1049, 1056], "rough": [25, 1006, 1027], "roughli": [139, 152, 209, 269, 288, 299, 324, 373, 400, 421, 424, 527, 997, 1041], "rouli": 1044, "round": [46, 48, 62, 117, 145, 155, 187, 188, 227, 238, 278, 284, 321, 323, 360, 400, 458, 464, 465, 572, 573, 601, 602, 605, 635, 700, 721, 810, 820, 877, 909, 924, 926, 990, 1004, 1016, 1043, 1045, 1047, 1049, 1050, 1052, 1054, 1055, 1057, 1058], "rounded_list": 820, "rouseeuw1984": 482, "rousseeuw": [113, 114, 416, 418, 477, 482, 800, 801, 1006], "rousseuw": [113, 114], "rout": [2, 47, 91, 137, 184, 189, 201, 246, 272, 336, 430, 433, 436, 439, 440, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 833, 834, 835, 836, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 957, 958, 959, 960, 984, 1021, 1036, 1055, 1057], "route_param": [254, 957], "routed_param": [254, 960], "routemappingpair": 957, "router": [2, 254, 400, 407, 957, 958, 959, 960], "routerconsumerclassifi": 254, "routerconsumerclassifierifittedrouterconsumerclassifi": 254, "routin": [335, 375, 380, 383, 386, 387, 388, 389, 394, 398, 400, 425, 680, 682, 695, 855, 914, 915, 916, 917, 918, 997, 1003, 1010, 1011, 1014, 1019, 1024, 1041, 1055, 1056, 1057], "routing_info": 957, "routlei": 1047, "rouvinen": 1046, "roux": [666, 996, 1013], "row": [2, 43, 57, 58, 59, 62, 64, 70, 79, 95, 109, 121, 123, 145, 148, 158, 161, 187, 220, 221, 222, 248, 251, 257, 258, 272, 321, 368, 373, 381, 388, 395, 399, 400, 413, 416, 419, 424, 431, 450, 451, 455, 457, 458, 459, 461, 464, 465, 467, 472, 476, 496, 498, 499, 500, 501, 502, 503, 508, 509, 510, 512, 513, 518, 519, 521, 534, 542, 550, 556, 559, 598, 599, 628, 640, 651, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 700, 704, 705, 718, 726, 727, 733, 766, 767, 771, 774, 776, 777, 778, 779, 781, 782, 784, 786, 787, 788, 789, 805, 806, 841, 847, 848, 849, 850, 851, 857, 860, 861, 862, 863, 864, 867, 878, 882, 884, 885, 887, 897, 898, 899, 902, 903, 906, 910, 928, 932, 933, 949, 971, 974, 978, 980, 982, 983, 986, 987, 989, 990, 992, 994, 996, 998, 1000, 1001, 1003, 1010, 1011, 1014, 1015, 1020, 1048, 1049, 1050, 1051, 1056], "row_compl": 57, "row_id_attribut": 380, "row_idx": [59, 220], "row_idx_shuffl": 58, "row_ind": [431, 459, 461], "row_indic": 155, "row_labels_": [57, 58, 59, 413, 459, 461], "row_norm": 266, "rowan": 1056, "rowei": [697, 701, 861, 997, 1003], "rows_": [57, 413, 431, 459, 461], "royal": [549, 635, 888, 900, 1014], "rp": 251, "rpath": 384, "rr2007": 992, "rragundez": 1049, "rrr": 390, "rrrcn": 390, "rsalakhu": 652, "rsh": [290, 330], "rskf": 824, "rsme": 1000, "rsnegrin": 1055, "rsplit": [45, 55, 279, 1030], "rst": [374, 386, 390, 394, 1034, 1041], "rstride": 193, "rt": 144, "rt_model": 144, "rtn": 51, "rtol": [388, 852, 853, 857], "ru": 222, "ruben": 1056, "rubi": 1053, "rubia": 1044, "rubial": 1054, "rubin": 990, "rubinstein": [672, 693, 694], "rubric": 997, "ruchitagard": 1051, "rudi": 1047, "rudresh": 1056, "ruff": [386, 404, 409], "ruifeng": [1047, 1048, 1053], "ruin": 386, "ruiter": 1056, "rule": [2, 13, 27, 43, 64, 145, 197, 272, 365, 368, 369, 373, 383, 386, 387, 388, 398, 400, 401, 411, 414, 415, 416, 420, 421, 423, 425, 544, 557, 558, 559, 560, 561, 569, 570, 577, 578, 602, 610, 642, 653, 666, 667, 674, 675, 676, 681, 683, 684, 685, 686, 714, 715, 719, 808, 811, 812, 814, 822, 830, 831, 834, 835, 836, 837, 839, 861, 912, 925, 989, 994, 1002, 1003, 1014, 1016, 1020, 1025, 1032, 1036, 1043, 1046, 1053, 1058], "ruleset": 1016, "rumelhart": 1004, "rumsfeld": [45, 381], "run": [43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 384, 386, 387, 388, 390, 391, 392, 393, 394, 398, 400, 401, 404, 410, 412, 416, 418, 420, 423, 426, 427, 428, 445, 451, 452, 454, 455, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 470, 472, 475, 476, 479, 480, 539, 540, 541, 542, 543, 545, 547, 549, 550, 551, 553, 554, 556, 563, 564, 565, 566, 571, 572, 573, 574, 575, 576, 577, 578, 590, 600, 602, 603, 604, 606, 607, 608, 610, 618, 619, 638, 642, 648, 654, 655, 657, 659, 660, 661, 663, 664, 668, 669, 670, 671, 690, 691, 696, 697, 698, 699, 700, 701, 702, 789, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 844, 845, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 869, 870, 871, 874, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 943, 944, 971, 974, 989, 999, 1001, 1004, 1013, 1015, 1016, 1019, 1020, 1024, 1025, 1032, 1034, 1041, 1044, 1046, 1048, 1049, 1050, 1051, 1055, 1056, 1057], "run_histori": 47, "run_id": 96, "run_tim": [235, 236], "rung": 1010, "runnabl": [54, 390, 391], "runtim": [30, 47, 49, 93, 139, 206, 235, 237, 252, 317, 321, 374, 388, 389, 398, 400, 410, 416, 423, 458, 571, 687, 822, 912, 913, 914, 915, 916, 917, 918, 1014, 1015, 1044, 1048, 1049, 1055, 1056, 1058, 1059], "runtime_histori": 47, "runxfail": 394, "rupesh": 1044, "rush": [43, 52, 386], "rushabh": 1052, "rushil": [1056, 1057], "russ": [636, 990], "russel": [1047, 1048], "russellrao": [458, 465, 707, 786, 787, 788, 1003], "russellraodist": 707, "russian": 424, "rust": 1019, "ruth": 1051, "rutter": 1054, "ruusmann": 1047, "rv": [0, 282, 319, 812, 820, 822, 989, 1041, 1042, 1045, 1046, 1047, 1048, 1049], "rv_discrete_frozen": 290, "rvd": [477, 482], "rvdriessen": [477, 482], "rvraghav93": [282, 319], "rw2006": [426, 618, 619], "ryad": 1047, "ryan": [1044, 1047, 1049, 1050], "ryb": 365, "ryder": 51, "ryotaro": 1053, "r\u00e9my": 1047, "r\u00fcdiger": [1049, 1050, 1052], "s1": [126, 174, 184, 208, 209, 383, 1033], "s2": [126, 174, 184, 208, 209, 383, 558, 1033], "s22": 506, "s3": [57, 126, 174, 208, 209, 383, 1033], "s4": [174, 208, 209, 383], "s5": [174, 208, 209, 383, 1008], "s6": [174, 208, 209, 383], "s_": [126, 282, 996, 997, 1008, 1010, 1033], "s__p": 872, "s_color": 240, "s_hessian": 240, "s_i": [416, 996, 1010], "s_ica_": 127, "s_isomap": 240, "s_j": 416, "s_ltsa": 240, "s_mod": 240, "s_pca_": 127, "s_point": 240, "s_scale": 240, "s_spectral": 240, "s_standard": 240, "s_t_sne": 240, "sa": [381, 500], "saaba": 1046, "saad": 1059, "sabharw": 1051, "sabri": 1056, "sach": 51, "sachdev": 1056, "sachdeva": 1048, "sachin": [1048, 1049, 1055], "sackei": 1051, "saclai": 0, "sacr": 1019, "sad": [826, 827], "sadak": 1053, "sadhana": 1049, "sadli": 152, "sadra": 1057, "sad\u0142ocha": 1054, "saeed": 1000, "saeger": [1046, 1047, 1048], "safari": 1010, "safe": [2, 72, 192, 209, 272, 361, 386, 388, 416, 417, 441, 516, 517, 575, 576, 605, 782, 786, 836, 871, 906, 966, 972, 1003, 1047, 1048, 1049, 1054, 1055], "safe_copi": 1048, "safe_index": [395, 1051], "safe_mask": [2, 395], "safe_realloc": 1044, "safe_sparse_dot": [2, 395, 1051], "safe_sqr": [2, 395], "safeguard": 410, "safer": [361, 369, 384, 416, 420, 1041], "safest": [220, 238, 369, 380], "safeti": [104, 398, 417, 966, 1020, 1051], "safikh": 1056, "safiuddin": 1056, "sag": [212, 227, 666, 667, 680, 682, 695, 996, 1014, 1019, 1046, 1047, 1048, 1050, 1051], "sag_solv": 1050, "saga": [66, 211, 235, 236, 666, 667, 680, 682, 695, 822, 996, 1048, 1050], "sagar": 1051, "sagnik": 1049, "saha": 1055, "sahil": 1057, "sahin": 1051, "sahu": 1053, "sai": [206, 247, 356, 360, 361, 386, 414, 416, 417, 421, 423, 424, 454, 455, 508, 512, 518, 685, 989, 1006, 1013, 1024, 1031, 1032, 1034, 1058, 1059], "said": [155, 192, 247, 279, 381, 386, 800, 998, 1006, 1025, 1032], "saihttam": 1047, "sailesh": [1048, 1049], "saint": 1047, "saito": [421, 546, 548, 555, 1048], "saiw": 1047, "sake": [43, 64, 152, 155, 188, 192, 220, 324, 353, 360, 362, 394, 398, 678], "saket": [1045, 1046, 1053], "sakinaouisrani": 1055, "salahuddin": 1056, "salakhutdinov": [652, 861, 1003], "salamin": 1045, "sale": [149, 257, 278, 1000, 1024], "saleem": 1051, "salerno": 383, "salim": [1058, 1059], "sallisaw": [417, 474], "salman": [0, 405, 1056, 1057, 1058, 1059, 1060], "salmon": 1025, "salt": [67, 252, 321, 1055], "salvator": [1041, 1055, 1056, 1058, 1059], "salz": 1048, "salzmann": [220, 238], "sam": [1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1055, 1056], "sambhav": 1052, "same": [2, 25, 43, 46, 47, 52, 58, 63, 70, 72, 75, 79, 88, 90, 92, 93, 99, 104, 105, 106, 123, 125, 127, 130, 132, 134, 140, 142, 146, 149, 152, 153, 155, 158, 174, 176, 192, 193, 195, 206, 208, 209, 214, 220, 221, 222, 228, 238, 254, 258, 268, 272, 273, 274, 275, 276, 278, 279, 281, 283, 284, 286, 291, 292, 299, 302, 304, 316, 319, 320, 322, 324, 325, 328, 330, 341, 349, 360, 361, 362, 368, 369, 373, 374, 375, 380, 381, 383, 385, 386, 388, 390, 392, 395, 398, 399, 400, 401, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 437, 441, 446, 447, 454, 458, 464, 473, 477, 478, 479, 480, 481, 482, 483, 484, 486, 501, 503, 504, 506, 512, 516, 517, 539, 540, 543, 544, 545, 546, 547, 548, 551, 555, 557, 559, 560, 561, 562, 565, 567, 568, 569, 570, 572, 573, 575, 576, 597, 598, 610, 611, 614, 618, 619, 621, 630, 635, 636, 637, 640, 641, 654, 657, 660, 661, 663, 666, 667, 671, 674, 675, 676, 680, 681, 682, 683, 684, 685, 686, 692, 695, 707, 712, 713, 720, 721, 723, 725, 734, 739, 740, 744, 750, 763, 764, 765, 786, 787, 788, 794, 796, 800, 802, 803, 805, 806, 808, 809, 811, 812, 814, 816, 817, 822, 826, 827, 830, 831, 833, 834, 835, 836, 837, 838, 839, 854, 855, 856, 860, 862, 863, 864, 875, 876, 877, 881, 882, 884, 886, 887, 888, 889, 890, 891, 892, 894, 901, 912, 913, 920, 922, 934, 938, 949, 966, 971, 974, 975, 985, 989, 990, 992, 994, 996, 997, 998, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1014, 1015, 1016, 1019, 1020, 1029, 1034, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "same_kind": 1058, "samesh": [1051, 1052], "samm": [67, 139, 141, 148, 423, 561, 1057, 1058], "samoocha": 1049, "sampl": [2, 27, 30, 37, 43, 44, 47, 50, 53, 61, 62, 63, 64, 68, 69, 70, 72, 74, 76, 77, 78, 81, 83, 84, 88, 91, 92, 93, 94, 95, 100, 113, 114, 115, 118, 121, 123, 125, 129, 130, 133, 134, 139, 140, 141, 142, 143, 144, 145, 148, 149, 151, 152, 153, 155, 156, 161, 162, 163, 167, 171, 173, 174, 176, 180, 181, 182, 183, 185, 187, 189, 192, 193, 197, 198, 204, 206, 208, 209, 220, 222, 224, 227, 228, 230, 231, 232, 234, 236, 237, 238, 240, 247, 251, 252, 254, 255, 257, 263, 264, 266, 267, 268, 269, 270, 272, 273, 277, 278, 280, 281, 282, 284, 286, 290, 292, 293, 298, 299, 303, 304, 305, 306, 308, 309, 310, 317, 319, 321, 322, 323, 324, 326, 328, 330, 331, 333, 335, 336, 338, 340, 341, 342, 343, 344, 345, 347, 349, 351, 353, 354, 356, 357, 360, 361, 365, 368, 373, 379, 381, 382, 385, 386, 388, 389, 398, 399, 407, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 424, 425, 426, 427, 428, 433, 434, 435, 438, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 462, 464, 465, 466, 469, 470, 471, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 505, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 615, 616, 618, 619, 635, 636, 637, 638, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 695, 696, 699, 700, 701, 703, 704, 705, 706, 707, 708, 709, 710, 711, 713, 715, 716, 717, 718, 720, 721, 722, 723, 724, 726, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 742, 743, 744, 745, 746, 747, 748, 749, 751, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 768, 769, 771, 772, 776, 777, 778, 779, 781, 782, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 872, 875, 876, 877, 878, 881, 882, 883, 884, 885, 886, 887, 889, 890, 891, 892, 893, 897, 898, 899, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 928, 932, 933, 937, 938, 949, 953, 969, 971, 974, 975, 978, 981, 989, 990, 992, 993, 994, 995, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1021, 1023, 1025, 1031, 1032, 1033, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "sample_i": [185, 426, 619, 1055], "sample_id": [368, 381, 505], "sample_interv": 646, "sample_interval_": 1057, "sample_posterior": [188, 635, 990], "sample_s": [93, 252, 361, 801], "sample_score_mean": 282, "sample_score_std": 282, "sample_silhouette_valu": 95, "sample_step": 646, "sample_weight": [61, 201, 220, 233, 238, 254, 329, 334, 335, 358, 386, 400, 407, 416, 423, 427, 433, 439, 445, 451, 452, 455, 457, 467, 468, 473, 477, 490, 491, 492, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 618, 619, 640, 641, 642, 643, 645, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 705, 706, 708, 710, 711, 715, 716, 717, 720, 721, 724, 726, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 742, 743, 746, 747, 748, 749, 751, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 764, 790, 791, 792, 793, 795, 796, 797, 798, 799, 802, 804, 807, 808, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 877, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 960, 988, 1000, 1014, 1015, 1016, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1059], "sample_weight1": 254, "sample_weight2": 254, "sample_weight_const": 358, "sample_weight_last_ten": 358, "sample_weight_vect": 938, "sample_without_replac": [2, 395, 1047], "samples_weight": 233, "samplewis": [762, 1000], "samson": 1048, "samuel": [704, 1024, 1044, 1045, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058], "samuela": 1044, "samu\u00ebl": 1048, "san": [174, 383, 424, 1012], "sanchez": [197, 1049, 1050], "sandbox": 410, "sandeep": 1053, "sander": [416, 427, 452, 454, 458, 465, 858, 1006, 1050, 1051], "sandi": 1054, "sandip": [1058, 1059], "sandra": [1050, 1056], "sandro": [1049, 1056], "sandrocasagrand": [1049, 1050], "sandrovskii": 1048, "sangam": 1056, "sangamswadik": 1056, "sangeeth": 1050, "saniti": [389, 876, 1000, 1041, 1042], "sanjabi": 1051, "sanjai": 1055, "sanjai_3": [1056, 1057], "sanjoi": [906, 1012], "sano": 1055, "sanofi": 51, "santa": [184, 1056], "santana": [1052, 1055], "santhanam": 1049, "santhosh": 1052, "santhoshbala18": 1052, "santi": [1046, 1048, 1049], "santiago": 1052, "sap": 51, "sapiro": [421, 539, 545], "saqib": 1049, "sara": 1054, "sarah": [1048, 1050, 1053], "sarahremu": [1056, 1059], "sarajpoor": 1056, "sarat": 1052, "sarawagi": 791, "sarra": 1051, "sartaj": 1047, "sasank": 1047, "sashka": [1056, 1057], "sass": [386, 404, 409], "sassenhagen": [135, 1053, 1058], "sat": [43, 155, 193, 424], "satellit": 1003, "satisfi": [416, 658, 662, 707, 725, 744, 745, 852, 853], "satish": 1049, "sato": 1044, "satrajit": [0, 406, 1041, 1042], "satur": [72, 192, 319], "sauerbrei": 1010, "sauerkraut": 424, "saul": [697, 701, 997, 1048, 1049, 1051], "saurabh": [1045, 1046, 1047, 1048, 1049, 1053], "sauvignon": 325, "saval": 1050, "savard": 1041, "save": [88, 104, 106, 257, 317, 385, 386, 390, 392, 393, 394, 400, 410, 420, 428, 476, 542, 543, 635, 852, 853, 910, 996, 1000, 1010, 1016, 1024, 1034, 1041, 1044, 1048, 1051, 1059], "saver": 1019, "savings_statu": 272, "savkomax": 1056, "saw": [126, 221, 224, 1033], "sawtooth": [126, 1033], "say_hello": 961, "sc": [380, 416], "scaja": 1058, "scala": 1020, "scalabl": [77, 79, 97, 189, 196, 252, 270, 333, 361, 386, 416, 423, 424, 456, 499, 510, 597, 648, 814, 825, 836, 838, 850, 873, 882, 884, 912, 914, 917, 918, 992, 995, 997, 1000, 1013, 1015, 1021, 1024, 1041, 1044, 1045, 1051, 1052, 1055, 1056], "scalar": [2, 125, 331, 336, 392, 400, 412, 417, 426, 428, 472, 475, 532, 541, 623, 624, 625, 630, 631, 635, 636, 638, 746, 750, 928, 936, 992, 1004, 1006, 1010, 1014, 1019, 1051, 1052, 1055, 1057], "scalarmapp": 66, "scale": [2, 36, 43, 44, 51, 62, 64, 72, 75, 78, 81, 82, 91, 93, 96, 105, 106, 112, 115, 118, 127, 130, 150, 157, 174, 176, 177, 178, 181, 182, 183, 185, 189, 193, 197, 200, 201, 208, 211, 220, 222, 224, 234, 235, 236, 238, 239, 242, 247, 253, 257, 268, 275, 278, 279, 280, 281, 285, 302, 304, 315, 316, 317, 318, 319, 329, 332, 334, 335, 343, 344, 346, 349, 353, 369, 372, 373, 378, 379, 380, 383, 386, 391, 395, 398, 399, 400, 416, 417, 421, 423, 424, 425, 426, 454, 455, 458, 459, 465, 472, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 509, 518, 522, 523, 532, 542, 546, 548, 549, 555, 557, 558, 569, 570, 590, 598, 599, 605, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 639, 640, 649, 652, 653, 654, 655, 657, 660, 666, 667, 668, 669, 670, 680, 682, 684, 685, 686, 689, 695, 696, 697, 698, 700, 702, 707, 711, 724, 749, 755, 765, 767, 777, 783, 785, 822, 825, 838, 839, 840, 852, 853, 854, 869, 870, 873, 876, 881, 882, 884, 887, 889, 890, 892, 897, 898, 899, 901, 902, 904, 905, 912, 913, 914, 915, 916, 917, 918, 975, 976, 977, 978, 981, 989, 992, 993, 996, 1000, 1001, 1002, 1003, 1004, 1008, 1014, 1015, 1020, 1021, 1024, 1025, 1032, 1033, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "scale_": [657, 881, 882, 890, 892, 902, 1010, 1046], "scaled_clf": 324, "scaled_pca": 324, "scaled_x_train": 324, "scaler": [45, 105, 107, 172, 189, 236, 237, 252, 257, 259, 261, 292, 302, 307, 318, 323, 324, 333, 349, 352, 369, 391, 417, 420, 498, 666, 667, 680, 682, 695, 872, 881, 882, 884, 888, 889, 890, 892, 897, 898, 899, 900, 901, 902, 903, 1004, 1010, 1014, 1021, 1030, 1041, 1046, 1049, 1054], "scaler2": 261, "scalewai": 394, "scaling_": 558, "scalings_": [557, 558], "scanpi": 1058, "scatter": [43, 48, 50, 51, 61, 66, 67, 70, 73, 74, 77, 78, 79, 80, 84, 87, 91, 92, 93, 94, 95, 97, 102, 113, 118, 122, 123, 127, 129, 130, 131, 133, 140, 141, 145, 148, 156, 158, 159, 161, 167, 169, 176, 177, 178, 180, 182, 183, 184, 185, 191, 192, 197, 200, 203, 210, 212, 216, 217, 218, 221, 222, 223, 229, 232, 233, 234, 237, 240, 241, 242, 243, 244, 245, 247, 252, 253, 255, 263, 264, 265, 266, 267, 268, 269, 273, 279, 281, 293, 299, 302, 305, 306, 307, 308, 309, 310, 311, 314, 319, 321, 322, 324, 332, 340, 343, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 357, 358, 360, 365, 366, 367, 418, 639, 709, 994, 996, 1032, 1033], "scatter_": 709, "scatter_fig": 145, "scatter_kwarg": [43, 52, 109, 160, 192, 709], "scatter_trac": 145, "scatterplot": [117, 199, 278], "scatterpoint": [129, 133, 243, 265, 340], "scenario": [92, 104, 155, 176, 197, 224, 281, 369, 393, 404, 415, 420, 423, 545, 551, 553, 554, 994, 1000, 1010, 1051], "scene": [383, 394, 1003, 1005, 1054], "schapir": [50, 296, 312, 381, 423, 506, 561, 562], "schedul": [155, 315, 374, 684, 685, 686, 869, 870, 1014, 1024, 1048], "scheidegg": 1041, "scheme": [287, 304, 325, 326, 381, 400, 416, 420, 422, 424, 574, 598, 666, 667, 713, 821, 879, 880, 883, 885, 889, 893, 896, 901, 912, 917, 989, 996, 1010, 1014, 1041, 1049, 1052, 1053, 1058, 1059], "scherer": 1047, "scheubrein": 1053, "schloss": 1000, "schl\u00fcter": [1041, 1049], "schmerler": 1056, "schmid": [766, 767, 998], "schmidt": [666, 996, 1044], "schmitt": [1051, 1052], "schmitz": 1058, "schneider": [360, 1054], "schoelkopf": 908, "schoentgen": [1049, 1050], "schofield": 1041, "schole": 1053, "scholkopf1997": 421, "scholkopf1998": 1010, "scholz": 1059, "school": [104, 181, 192, 383, 416, 796, 1000], "schreiber": [0, 406, 1046, 1047, 1048], "schroeder": [45, 381], "schubert": [416, 427, 452, 458, 1045, 1046, 1049, 1050, 1052, 1053, 1054, 1055, 1059], "schucker": 1047, "schuder": [1049, 1050, 1051], "schuetz": [847, 851], "schuldt": 1045, "schult": 55, "schulz": 1041, "schumach": [1044, 1045, 1046], "schut": 1041, "schwardt": 1041, "schwartz": [1041, 1043, 1055], "schwetlick": [1052, 1053], "sch\u00f6lkopf": [44, 421, 543, 878, 1006, 1010, 1015], "sch\u00f6nberger": [1043, 1044], "sch\u00fctze": [421, 598, 998, 1000, 1002], "sci": [57, 104, 360, 361, 362, 381, 398, 496, 697, 701, 883, 997, 1010, 1034], "scibol": 1052, "scienc": [0, 73, 113, 174, 184, 192, 296, 380, 383, 398, 416, 448, 462, 546, 548, 555, 696, 697, 701, 859, 990, 992, 996, 997, 1000, 1003, 1012, 1020, 1024, 1028, 1049], "scientif": [0, 68, 165, 166, 167, 252, 380, 384, 398, 404, 416, 460, 470, 509, 1024, 1026], "scientifiqu": 0, "scientist": [990, 1024], "scikera": 1019, "scikit": [2, 15, 30, 45, 47, 49, 51, 52, 54, 55, 67, 68, 85, 90, 104, 105, 137, 143, 144, 145, 155, 157, 160, 171, 174, 185, 187, 188, 189, 192, 193, 194, 195, 197, 208, 209, 220, 221, 222, 238, 246, 249, 257, 259, 260, 261, 270, 272, 275, 283, 290, 292, 296, 299, 301, 304, 306, 325, 327, 341, 353, 360, 361, 364, 365, 368, 369, 374, 375, 378, 380, 381, 382, 383, 385, 386, 389, 392, 393, 394, 395, 399, 400, 407, 409, 410, 412, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 430, 431, 433, 434, 435, 436, 438, 439, 440, 446, 451, 454, 455, 458, 465, 472, 473, 475, 476, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511, 512, 520, 523, 529, 532, 546, 549, 569, 570, 572, 573, 575, 584, 589, 590, 591, 597, 607, 610, 619, 634, 636, 638, 640, 642, 646, 648, 654, 656, 660, 666, 677, 688, 696, 705, 708, 709, 710, 725, 726, 740, 750, 756, 786, 787, 788, 796, 803, 807, 808, 809, 810, 811, 812, 813, 814, 822, 825, 826, 827, 828, 829, 830, 831, 834, 835, 838, 840, 841, 854, 856, 872, 873, 875, 877, 879, 882, 884, 885, 886, 887, 891, 892, 893, 896, 909, 910, 912, 917, 920, 921, 943, 944, 966, 967, 989, 990, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1010, 1013, 1014, 1015, 1016, 1018, 1021, 1023, 1027, 1028, 1029, 1030, 1032, 1033, 1036, 1038, 1039, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "scikit_learn": 1019, "scikit_learn_data": [381, 494, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507], "scipi": [0, 2, 45, 53, 55, 57, 76, 81, 82, 88, 89, 111, 112, 115, 126, 128, 132, 151, 176, 192, 195, 206, 210, 222, 264, 268, 269, 275, 278, 286, 290, 299, 304, 309, 317, 329, 330, 335, 336, 338, 339, 373, 380, 381, 384, 386, 388, 392, 394, 395, 398, 399, 400, 404, 409, 410, 416, 421, 424, 458, 459, 460, 461, 465, 470, 471, 504, 511, 516, 540, 542, 543, 549, 552, 589, 590, 593, 594, 596, 597, 618, 619, 656, 657, 661, 665, 666, 667, 671, 674, 675, 676, 677, 678, 680, 682, 684, 685, 686, 688, 692, 695, 699, 700, 703, 768, 771, 786, 787, 788, 789, 800, 801, 812, 820, 822, 838, 852, 853, 854, 855, 856, 857, 858, 860, 861, 862, 863, 864, 865, 866, 867, 869, 875, 884, 885, 890, 891, 892, 895, 899, 902, 903, 912, 914, 915, 917, 918, 946, 950, 951, 955, 971, 972, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 986, 989, 990, 996, 998, 1001, 1003, 1004, 1010, 1014, 1015, 1018, 1020, 1028, 1030, 1033, 1034, 1043, 1045, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057], "sckit": 1057, "scls19fr": 1046, "scognamiglio": 423, "scope": [45, 57, 272, 373, 375, 386, 398, 424, 1019, 1020, 1030], "score": [2, 13, 27, 43, 45, 47, 50, 52, 58, 59, 61, 62, 63, 64, 67, 68, 69, 72, 93, 95, 104, 105, 106, 107, 108, 109, 111, 115, 118, 132, 137, 139, 141, 148, 149, 150, 151, 152, 155, 156, 159, 160, 166, 169, 170, 171, 174, 187, 189, 191, 192, 193, 194, 195, 197, 204, 211, 212, 215, 220, 222, 226, 228, 236, 238, 247, 252, 253, 254, 257, 261, 267, 270, 272, 276, 278, 279, 280, 281, 282, 283, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 306, 307, 308, 314, 315, 316, 317, 321, 323, 324, 325, 326, 328, 329, 330, 331, 335, 336, 338, 339, 341, 342, 349, 356, 360, 361, 364, 369, 381, 386, 388, 391, 399, 400, 410, 411, 412, 413, 414, 415, 417, 419, 421, 423, 425, 433, 435, 439, 445, 451, 455, 457, 460, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 510, 512, 540, 544, 549, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 576, 577, 578, 600, 601, 602, 603, 604, 606, 607, 608, 610, 611, 612, 614, 617, 618, 619, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 706, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 721, 723, 724, 725, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 744, 745, 746, 747, 748, 750, 763, 764, 765, 790, 791, 792, 793, 794, 795, 796, 797, 802, 803, 804, 805, 806, 807, 808, 811, 812, 814, 822, 827, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 858, 859, 861, 862, 863, 868, 869, 870, 872, 892, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 951, 989, 992, 996, 998, 1003, 1006, 1008, 1010, 1014, 1020, 1021, 1028, 1030, 1032, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "score_clf1": 69, "score_clf2": 69, "score_clf3": 69, "score_df": 62, "score_differ": 283, "score_estim": [220, 238], "score_full_data": 187, "score_func": [72, 105, 106, 425, 600, 603, 604, 606, 607, 608, 750, 1041, 1043, 1058], "score_iri": 284, "score_iterative_imput": 187, "score_label": [238, 284], "score_mean": 352, "score_nam": [62, 72, 253, 280, 294, 334, 361, 814, 831], "score_param": [667, 1058], "score_rand": 284, "score_sampl": [267, 304, 305, 306, 312, 400, 422, 477, 540, 549, 571, 685, 805, 806, 808, 811, 812, 822, 857, 858, 868, 872, 916, 1006, 1044, 1049, 1051, 1053], "score_simple_imput": 187, "score_std": 352, "score_tim": [280, 420, 835, 836], "score_times_nb": 280, "score_times_svm": 280, "score_typ": [253, 280, 294, 334, 814, 831, 1057], "score_valu": 361, "scorer": [2, 155, 160, 238, 254, 272, 282, 335, 388, 400, 407, 415, 420, 423, 425, 569, 570, 602, 610, 642, 667, 681, 683, 719, 740, 741, 750, 808, 811, 812, 814, 822, 830, 831, 834, 835, 836, 839, 958, 989, 996, 1000, 1008, 1020, 1045, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "scorer1_nam": 420, "scorer2_nam": 420, "scorer_": [808, 811, 812, 822], "scorer_nam": [282, 808, 822], "scores_": [199, 200, 600, 603, 604, 606, 607, 608, 652, 653, 667, 1041, 1051], "scores_df": 52, "scores_glm_pure_premium": 238, "scores_matrix": 289, "scores_max": 55, "scores_product_model": 238, "scores_std": [165, 1029], "scoring_cal": 719, "scoring_inner_cv": 335, "scoring_on_bootstrap": 281, "scoring_weight": 407, "scott": [422, 857, 1041, 1042, 1047, 1049, 1050, 1051, 1056, 1057], "scratch": [387, 450, 1000, 1043], "screen": [48, 1054], "screenporch": 149, "screenshot": 384, "script": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 374, 386, 387, 388, 389, 390, 392, 398, 400, 404, 410, 424, 1020, 1023, 1034], "scroll": 1027, "scrollbar": 391, "scrutin": 287, "scsi": 57, "scullei": 416, "sd345": 1034, "sdca": 1019, "sdenton4": 1044, "sdg_param": 342, "se": [174, 242, 383, 404], "seabold": [1044, 1046, 1047], "seaborn": [72, 140, 155, 191, 192, 199, 204, 268, 278, 386, 404, 409, 1019], "seagreen": 214, "seal": 1047, "seamu": 1043, "sean": [1053, 1054, 1056], "seanpwilliam": 1048, "sear": 1047, "search": [2, 45, 64, 81, 89, 105, 106, 107, 108, 152, 169, 171, 173, 174, 176, 189, 238, 253, 254, 268, 270, 272, 277, 279, 282, 283, 285, 290, 298, 299, 301, 303, 317, 321, 333, 349, 355, 360, 369, 383, 384, 386, 388, 398, 400, 411, 416, 417, 420, 423, 424, 425, 427, 451, 456, 458, 460, 465, 466, 469, 472, 479, 480, 486, 510, 523, 530, 565, 566, 567, 568, 572, 573, 574, 587, 607, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 636, 661, 684, 696, 697, 700, 701, 721, 736, 793, 796, 808, 811, 812, 819, 820, 822, 824, 838, 839, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 872, 917, 920, 921, 922, 923, 954, 988, 993, 995, 997, 1000, 1003, 1004, 1014, 1016, 1019, 1020, 1021, 1025, 1026, 1028, 1030, 1036, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1055, 1056, 1058], "search_05p": 152, "search_95p": 152, "search_cv": 105, "searchcv": [399, 1056], "searcher": 1034, "searchforpass": 1057, "searchgrid": 1020, "searchsort": 50, "season": [43, 52, 181, 193, 221, 385], "seasonal_kernel": 181, "seasoncountstru32": 52, "sebastian": [324, 1042, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058], "sebastianraschka": 324, "sebastien": 1049, "sebastin": [1048, 1049], "sebasti\u00e1n": 1047, "seberg": 1042, "sec": [49, 228, 242, 245, 299], "sec65": 1056, "secant": 650, "second": [43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 381, 388, 390, 392, 400, 413, 415, 416, 420, 421, 423, 424, 426, 472, 475, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 510, 512, 518, 561, 591, 596, 597, 598, 599, 629, 632, 639, 640, 707, 720, 724, 766, 767, 771, 772, 774, 775, 782, 783, 784, 785, 786, 789, 808, 811, 812, 822, 836, 842, 843, 846, 849, 860, 862, 863, 864, 869, 870, 989, 990, 994, 995, 996, 997, 1000, 1001, 1002, 1003, 1004, 1007, 1010, 1011, 1016, 1025, 1031, 1033, 1056], "secondari": [643, 1045], "secondli": [384, 398, 416, 423, 665, 996, 1034], "sect": 44, "section": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 72, 125, 130, 142, 150, 155, 160, 165, 166, 167, 181, 185, 191, 192, 193, 195, 199, 204, 208, 209, 222, 244, 248, 254, 257, 259, 272, 276, 278, 281, 287, 324, 325, 326, 330, 360, 361, 362, 369, 379, 381, 384, 386, 387, 388, 390, 391, 392, 393, 394, 401, 407, 414, 415, 417, 419, 420, 421, 423, 424, 425, 426, 447, 451, 467, 542, 622, 627, 630, 645, 653, 796, 806, 914, 917, 989, 994, 996, 1000, 1001, 1003, 1004, 1006, 1007, 1014, 1015, 1017, 1018, 1032, 1034, 1041, 1043, 1044, 1045, 1048], "sector": 192, "sector_construct": 192, "sector_manufactur": 192, "sector_oth": 192, "secur": [390, 400, 1019, 1020, 1024, 1036], "sed": [390, 1041], "sedamaki": 1055, "sedykh": 1056, "see": [0, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 52, 58, 61, 62, 64, 72, 79, 84, 85, 88, 90, 92, 93, 97, 99, 100, 102, 103, 113, 118, 120, 121, 125, 130, 131, 135, 139, 140, 141, 142, 145, 146, 147, 148, 149, 151, 152, 153, 155, 157, 160, 165, 170, 171, 172, 174, 176, 181, 182, 183, 187, 189, 192, 193, 195, 197, 199, 200, 201, 204, 211, 221, 222, 223, 224, 226, 237, 238, 240, 242, 249, 251, 254, 257, 258, 259, 261, 264, 265, 266, 271, 272, 273, 275, 277, 278, 279, 280, 281, 283, 285, 287, 288, 289, 292, 293, 294, 296, 299, 305, 306, 308, 312, 319, 325, 326, 328, 329, 330, 331, 332, 333, 334, 340, 349, 353, 356, 360, 361, 362, 364, 365, 366, 367, 369, 373, 374, 375, 378, 379, 380, 381, 383, 384, 385, 386, 388, 390, 392, 393, 394, 398, 399, 400, 410, 412, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 440, 445, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 468, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 496, 499, 500, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 592, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 617, 618, 619, 622, 627, 630, 631, 635, 636, 637, 638, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 707, 709, 714, 716, 719, 721, 751, 771, 782, 786, 787, 788, 789, 796, 800, 801, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 819, 820, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 948, 949, 969, 971, 974, 984, 989, 990, 992, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1020, 1024, 1025, 1027, 1032, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "seed": [2, 46, 50, 63, 64, 70, 74, 75, 79, 80, 87, 89, 92, 94, 95, 99, 100, 105, 111, 112, 113, 123, 126, 131, 142, 148, 167, 169, 194, 210, 215, 218, 223, 226, 229, 233, 237, 243, 264, 266, 267, 268, 269, 281, 284, 293, 304, 305, 306, 311, 353, 354, 358, 361, 369, 374, 388, 395, 398, 400, 416, 420, 421, 451, 455, 456, 458, 460, 465, 467, 468, 469, 470, 479, 480, 481, 544, 552, 561, 562, 563, 564, 567, 568, 635, 654, 655, 660, 661, 668, 669, 670, 671, 685, 697, 699, 701, 703, 805, 806, 812, 843, 846, 861, 915, 935, 948, 949, 965, 969, 989, 990, 995, 997, 1032, 1033, 1045, 1046, 1050, 1051, 1057], "seeger": [647, 992], "seek": [240, 242, 244, 385, 386, 398, 401, 516, 517, 997, 1026, 1028], "seel": 1055, "seem": [43, 48, 52, 81, 90, 152, 155, 193, 220, 244, 247, 279, 296, 315, 323, 356, 360, 361, 385, 386, 391, 415, 420, 509, 996, 1000], "seemingli": [238, 369, 398], "seen": [55, 62, 75, 90, 101, 115, 128, 134, 146, 152, 155, 192, 193, 216, 244, 250, 254, 315, 319, 349, 360, 381, 388, 390, 399, 400, 414, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 432, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 529, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 631, 635, 636, 637, 638, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 975, 981, 989, 995, 1000, 1003, 1004, 1010, 1016, 1024, 1029, 1030, 1032, 1033, 1053, 1054, 1055, 1056, 1057, 1058], "segfault": [374, 387, 1041, 1049, 1054], "seglearn": 1019, "segment": [51, 53, 55, 59, 71, 82, 83, 189, 243, 250, 381, 394, 416, 424, 460, 470, 516, 517, 699, 868, 1000, 1019, 1021, 1024, 1049, 1051, 1053], "seguin": 1046, "sei": 424, "seismic_r": [199, 204], "sejourn": 1050, "sel": [407, 425], "seladu": 1057, "seldom": 912, "sele": [1055, 1056], "selecci\u00f3n": 325, "select": [2, 18, 29, 43, 46, 48, 49, 52, 58, 70, 71, 79, 82, 90, 92, 97, 103, 105, 108, 115, 123, 124, 125, 134, 135, 139, 141, 147, 149, 152, 155, 160, 169, 171, 181, 183, 192, 193, 195, 197, 198, 200, 202, 204, 206, 207, 219, 224, 228, 235, 238, 241, 247, 251, 253, 257, 262, 263, 264, 265, 272, 276, 277, 278, 279, 283, 291, 292, 303, 319, 324, 325, 330, 334, 336, 338, 339, 342, 344, 349, 356, 360, 361, 362, 369, 373, 374, 381, 383, 384, 386, 388, 394, 399, 400, 413, 416, 417, 418, 421, 423, 424, 426, 451, 453, 454, 455, 457, 459, 461, 466, 467, 468, 472, 474, 475, 480, 481, 484, 496, 497, 500, 501, 504, 505, 508, 509, 510, 512, 520, 523, 540, 542, 543, 548, 549, 552, 557, 559, 566, 567, 568, 571, 573, 589, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 619, 635, 639, 640, 653, 654, 655, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 679, 681, 684, 686, 690, 691, 699, 700, 705, 720, 724, 726, 762, 796, 800, 801, 805, 806, 808, 811, 812, 813, 814, 822, 834, 835, 836, 838, 840, 854, 855, 856, 858, 860, 862, 863, 864, 872, 873, 877, 882, 888, 892, 909, 912, 913, 917, 920, 921, 922, 923, 928, 969, 970, 994, 995, 997, 999, 1000, 1001, 1003, 1004, 1006, 1010, 1013, 1014, 1015, 1016, 1017, 1019, 1020, 1021, 1022, 1024, 1025, 1026, 1028, 1032, 1033, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1058, 1059], "select__k": 989, "select_dtyp": [109, 149, 333, 474], "selected_featur": 195, "selected_features_nam": 195, "selectfdr": [2, 425, 600, 604, 606, 607, 608, 614, 1045, 1047, 1048, 1057], "selectfpr": [2, 386, 425, 600, 603, 606, 607, 608, 614, 1057], "selectfrommodel": [2, 174, 400, 407, 601, 610, 611, 1022, 1036, 1046, 1047, 1048, 1049, 1051, 1053, 1054, 1055, 1057, 1058], "selectfw": [2, 425, 600, 603, 604, 607, 608, 614, 1057], "selectkbest": [2, 106, 108, 170, 171, 332, 369, 386, 407, 417, 425, 589, 600, 603, 604, 606, 608, 614, 989, 1042, 1047, 1057, 1058], "selectkbestselectkbest": [171, 332], "selector": [2, 52, 105, 170, 171, 257, 356, 394, 424, 425, 474, 589, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 1043, 1051, 1053, 1057], "selectormixin": [2, 1052], "selectpercentil": [2, 89, 105, 261, 352, 425, 600, 603, 604, 606, 607, 611, 614, 1042, 1047, 1057, 1058], "selectpercentileselectpercentil": [105, 261], "self": [2, 47, 57, 62, 64, 91, 100, 137, 184, 189, 254, 292, 299, 337, 343, 349, 360, 380, 386, 387, 388, 391, 392, 393, 394, 416, 424, 426, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 508, 516, 517, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 711, 805, 806, 807, 808, 809, 810, 811, 812, 815, 817, 822, 826, 827, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 957, 958, 960, 961, 966, 974, 1003, 1020, 1021, 1022, 1024, 1036, 1043, 1048, 1055], "self_request": 254, "self_training_clf": 341, "self_training_model": [330, 909], "selftrain": 342, "selftrainingclassifi": [2, 330, 341, 342, 343, 407, 1013, 1053, 1058], "selftrainingclassifierifittedselftrainingclassifi": 330, "seljak": 1056, "sell": 109, "selvan": 1053, "semant": [54, 360, 361, 400, 552, 1034, 1035, 1036, 1043], "semi": [2, 38, 57, 67, 167, 178, 252, 255, 321, 330, 346, 349, 353, 362, 381, 400, 496, 512, 543, 596, 598, 684, 737, 838, 872, 876, 907, 908, 909, 917, 998, 1003, 1006, 1021, 1022, 1036, 1041, 1053, 1056], "semi_supervis": [2, 189, 330, 332, 337, 338, 339, 340, 341, 342, 343, 407, 907, 908, 909, 1001, 1013, 1021, 1042, 1047, 1048, 1055, 1056], "semiconductor": 1024, "semidefinit": [1010, 1015], "semilogi": 251, "semilogx": [165, 209, 291, 1029], "semin": 423, "seminar": 1000, "semisupervis": [338, 400], "sen": [2, 189, 198, 223, 226, 319, 657, 665, 679, 686, 687, 1021], "send": [386, 416, 428, 541], "sender": [360, 381], "sendyk": 1050, "seng": 1053, "senger": [0, 1057, 1058, 1059, 1060], "senior": [1010, 1024], "sens": [42, 43, 52, 55, 62, 90, 101, 182, 189, 192, 197, 251, 319, 325, 339, 349, 360, 369, 373, 386, 387, 400, 416, 418, 420, 425, 470, 477, 478, 479, 480, 481, 482, 483, 484, 660, 663, 664, 680, 809, 819, 909, 994, 996, 1003, 1004, 1006, 1010, 1013, 1021], "sensibl": [87, 187, 296, 361, 388, 996, 1010], "sensit": [43, 79, 90, 113, 114, 142, 152, 189, 193, 222, 223, 224, 247, 248, 257, 270, 282, 285, 292, 319, 336, 349, 374, 375, 401, 415, 418, 423, 460, 470, 504, 559, 569, 666, 700, 708, 710, 720, 721, 726, 750, 792, 795, 796, 807, 808, 830, 838, 873, 892, 910, 995, 996, 997, 999, 1000, 1004, 1006, 1014, 1015, 1021, 1025, 1033, 1045, 1059], "sensor": 204, "sent": [155, 416, 841], "sentenc": [104, 360, 362, 381, 401, 424], "sentiment": 1026, "seoeun": 1057, "sep": [123, 287], "sepal": [80, 121, 133, 135, 148, 178, 203, 261, 302, 330, 333, 346, 383, 1010, 1031, 1032], "sepal_col": 333, "separ": [52, 53, 61, 62, 66, 67, 75, 90, 95, 97, 101, 107, 113, 122, 124, 125, 127, 130, 139, 141, 144, 147, 158, 174, 179, 188, 189, 193, 194, 197, 198, 219, 221, 241, 255, 265, 278, 281, 287, 288, 319, 321, 324, 330, 341, 344, 345, 347, 348, 349, 353, 354, 360, 369, 373, 382, 383, 388, 391, 394, 398, 400, 410, 414, 416, 417, 418, 421, 423, 424, 426, 472, 520, 527, 541, 546, 548, 549, 555, 557, 589, 596, 597, 599, 618, 639, 646, 654, 655, 681, 684, 685, 698, 702, 733, 740, 753, 754, 756, 761, 800, 827, 844, 845, 871, 872, 914, 916, 917, 922, 923, 989, 990, 992, 994, 996, 997, 999, 1006, 1007, 1010, 1014, 1015, 1021, 1030, 1032, 1033, 1041, 1044, 1046, 1047, 1051, 1053, 1054, 1057, 1058], "seper": 561, "septemb": [742, 1000, 1041, 1044, 1047, 1049, 1054, 1057], "seq": 641, "seq_dataset": [1041, 1051], "seqlearn": 398, "sequenc": [2, 51, 139, 148, 208, 243, 388, 400, 417, 420, 421, 423, 424, 511, 520, 561, 562, 569, 570, 577, 578, 589, 590, 596, 597, 599, 654, 808, 811, 819, 838, 872, 896, 952, 953, 963, 971, 974, 1019, 1041, 1044, 1046, 1047], "sequencekernel": 184, "sequenti": [2, 52, 148, 168, 171, 189, 214, 279, 330, 384, 421, 423, 424, 508, 509, 542, 601, 605, 610, 611, 613, 614, 654, 655, 660, 661, 666, 668, 669, 670, 671, 681, 796, 872, 873, 892, 990, 1008, 1014, 1019, 1021, 1022, 1036, 1041, 1050, 1053], "sequentialfeatureselector": [2, 174, 407, 425, 601, 605, 611, 1053, 1054, 1055, 1056, 1057], "sergei": [416, 1043, 1047, 1048, 1049, 1050, 1051], "sergeyf": 1043, "sergio": [1041, 1043, 1044, 1053, 1056], "sergiodsr": 1052, "sergul": [1048, 1049, 1052], "seri": [2, 42, 43, 51, 58, 115, 146, 152, 155, 189, 191, 194, 195, 202, 220, 222, 224, 238, 240, 261, 283, 292, 326, 332, 338, 378, 381, 391, 400, 416, 497, 498, 499, 500, 504, 508, 509, 510, 512, 513, 518, 549, 570, 698, 702, 709, 750, 753, 754, 756, 798, 829, 834, 835, 838, 928, 991, 996, 997, 1001, 1003, 1014, 1019, 1021, 1044, 1047, 1048, 1049, 1053, 1056, 1058, 1059], "serial": [400, 410, 430, 956, 1019, 1020, 1041, 1049, 1053, 1058], "serializetostr": 410, "serious": 1002, "serum": [174, 383], "serv": [104, 129, 139, 182, 272, 281, 353, 417, 559, 992, 1036, 1055], "server": [0, 174, 373, 383, 384, 386, 504, 1023, 1049], "servic": [0, 43, 248, 257, 386, 390, 410, 1024, 1049], "sess": 410, "session": [388, 392, 398, 404, 1018, 1024, 1034], "set": [2, 3, 8, 19, 27, 37, 42, 43, 44, 45, 46, 47, 50, 52, 53, 58, 62, 63, 64, 66, 67, 70, 72, 76, 77, 79, 80, 81, 84, 85, 88, 89, 90, 92, 93, 95, 97, 99, 100, 101, 104, 105, 107, 113, 114, 115, 118, 121, 124, 125, 129, 130, 133, 137, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 162, 165, 170, 171, 174, 176, 182, 183, 184, 185, 189, 191, 192, 193, 194, 195, 199, 204, 205, 208, 209, 211, 213, 215, 216, 217, 219, 220, 221, 222, 225, 228, 233, 234, 238, 240, 241, 242, 247, 248, 249, 250, 252, 253, 254, 257, 261, 263, 265, 267, 268, 271, 273, 276, 278, 279, 280, 281, 282, 283, 286, 287, 288, 289, 293, 296, 298, 301, 305, 306, 307, 308, 309, 312, 315, 316, 317, 319, 321, 323, 324, 325, 326, 328, 330, 331, 335, 338, 339, 342, 343, 346, 348, 351, 353, 356, 360, 361, 362, 366, 367, 368, 369, 373, 374, 375, 378, 379, 381, 383, 384, 386, 388, 390, 391, 393, 394, 399, 400, 401, 404, 407, 410, 412, 413, 414, 416, 417, 418, 419, 421, 422, 423, 424, 425, 426, 427, 428, 430, 433, 440, 441, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 469, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 496, 497, 501, 503, 504, 505, 507, 510, 511, 512, 516, 517, 518, 523, 531, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 587, 588, 589, 590, 591, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 613, 614, 615, 616, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 702, 705, 706, 707, 708, 709, 710, 711, 719, 721, 722, 727, 729, 731, 734, 735, 736, 737, 738, 739, 742, 746, 748, 753, 754, 756, 758, 759, 761, 764, 787, 788, 790, 791, 792, 793, 795, 797, 798, 799, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 897, 898, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 926, 927, 932, 933, 943, 944, 949, 953, 956, 957, 969, 970, 971, 974, 975, 981, 984, 989, 990, 991, 992, 993, 994, 995, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1019, 1020, 1021, 1026, 1028, 1029, 1030, 1033, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "set1": [278, 308, 309], "set_": [254, 407, 1059], "set_alpha": [70, 263, 264, 265, 268, 269], "set_arrai": [51, 243, 250], "set_aspect": [43, 179, 231, 265, 357], "set_autoscaley_on": 77, "set_axis_bgcolor": 115, "set_axis_off": 68, "set_axisbelow": 49, "set_box_aspect": 70, "set_clim": 303, "set_clip_box": [70, 263, 264, 265, 268, 269], "set_color": [46, 231], "set_config": [2, 254, 259, 261, 272, 326, 329, 335, 373, 374, 407, 417, 445, 451, 452, 455, 457, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 598, 599, 602, 605, 618, 619, 634, 635, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 807, 809, 810, 815, 817, 826, 830, 833, 834, 835, 836, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 1050, 1052, 1055, 1057], "set_constrained_layout_pad": 125, "set_edgecolor": 125, "set_facecolor": [115, 263], "set_fit_request": [254, 335, 407, 445, 451, 452, 455, 457, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 596, 599, 602, 643, 651, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 688, 698, 844, 845, 847, 848, 849, 850, 851, 857, 877, 878, 891, 892, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923], "set_fmt_str_length": 52, "set_i": 92, "set_index": [62, 139, 152, 209, 238, 278, 325, 361], "set_inverse_transform_request": [541, 589, 879, 892], "set_label": [75, 179, 251], "set_label_posit": 46, "set_linewidth": [51, 243, 250], "set_major_formatt": [240, 242, 245, 299, 304], "set_major_loc": [240, 304], "set_output": [189, 193, 246, 259, 324, 325, 389, 440, 450, 451, 453, 455, 457, 472, 476, 490, 491, 492, 493, 504, 512, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 574, 575, 576, 577, 578, 589, 590, 591, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 666, 696, 697, 700, 838, 856, 861, 864, 868, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 910, 1021, 1056, 1057, 1058], "set_param": [128, 135, 143, 149, 152, 193, 194, 200, 208, 209, 213, 224, 228, 252, 257, 272, 291, 302, 328, 352, 361, 389, 400, 416, 417, 423, 426, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 990, 1006, 1025, 1032, 1033, 1041, 1047, 1048, 1049, 1054, 1055], "set_partial_fit_request": [457, 542, 674, 675, 676, 684, 685, 686, 840, 841, 844, 845, 847, 848, 849, 850, 851, 869, 892], "set_path_effect": 75, "set_posit": [102, 131, 231, 319], "set_predict_proba_request": [920, 922], "set_predict_request": [254, 490, 491, 492, 560, 619, 643, 652, 653, 920, 921, 922, 923], "set_printopt": 271, "set_prop_cycl": 221, "set_score_request": [254, 272, 335, 407, 445, 451, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 577, 578, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 686, 687, 688, 807, 830, 840, 841, 842, 843, 845, 846, 847, 848, 849, 850, 851, 854, 855, 859, 862, 863, 869, 870, 872, 907, 908, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 1000], "set_siz": 306, "set_size_inch": [95, 165, 258], "set_split_request": [809, 810, 815, 817, 826], "set_start_method": 398, "set_stat": 989, "set_tick_param": 263, "set_ticklabel": [80, 121, 131, 217, 360], "set_titl": [47, 49, 54, 62, 64, 66, 67, 68, 70, 77, 78, 80, 88, 90, 92, 95, 99, 100, 106, 109, 113, 121, 123, 130, 135, 139, 144, 146, 150, 156, 158, 160, 161, 185, 187, 188, 191, 192, 193, 194, 195, 199, 200, 209, 211, 218, 220, 221, 222, 228, 240, 241, 244, 245, 250, 252, 253, 257, 258, 263, 271, 272, 273, 274, 275, 278, 280, 281, 285, 289, 290, 292, 294, 296, 298, 299, 302, 303, 304, 309, 314, 315, 319, 320, 321, 322, 323, 324, 328, 332, 338, 339, 346, 353, 356, 357, 358, 360, 364], "set_transform_request": [254, 490, 491, 492, 541, 590, 596, 598, 599, 643, 875, 878, 884, 892], "set_vis": [54, 70, 303, 309, 319], "set_xlabel": [46, 49, 80, 88, 95, 106, 107, 109, 121, 123, 130, 150, 185, 187, 188, 191, 193, 194, 195, 197, 209, 215, 217, 218, 220, 222, 235, 236, 252, 272, 278, 280, 284, 289, 290, 292, 294, 296, 304, 319, 320, 324, 341, 361, 362, 364], "set_xlim": [67, 77, 95, 109, 113, 123, 144, 158, 188, 193, 218, 220, 225, 252, 263, 282, 284, 296, 304, 314, 319, 321, 322, 323, 324, 329, 335, 357], "set_xscal": [209, 225], "set_xtick": [43, 47, 49, 67, 78, 95, 99, 135, 158, 162, 193, 195, 211, 236, 252, 263, 289, 290, 298, 314, 316, 321, 322, 346], "set_xticklabel": [47, 49, 113, 135, 162, 179, 193, 195, 289, 290, 298], "set_ylabel": [46, 47, 49, 66, 70, 80, 88, 95, 100, 106, 107, 109, 113, 121, 123, 130, 135, 139, 146, 150, 185, 193, 197, 209, 211, 215, 217, 218, 220, 222, 224, 235, 252, 263, 272, 278, 280, 284, 289, 290, 292, 298, 304, 319, 320, 324, 328, 341, 356, 361, 364, 1030], "set_ylim": [47, 49, 67, 77, 95, 106, 123, 144, 157, 158, 185, 193, 200, 218, 220, 221, 252, 263, 282, 294, 298, 304, 314, 319, 321, 322, 324, 329, 335, 341, 357], "set_yscal": [150, 220], "set_ytick": [43, 67, 78, 95, 99, 135, 158, 187, 188, 195, 211, 236, 263, 289, 314, 316, 321, 322, 346, 362], "set_yticklabel": [135, 179, 187, 188, 195, 289, 362], "set_zlabel": [80, 121, 217], "set_zord": 127, "setattr": 388, "setdefault": [55, 927], "setdiff1d": 355, "seth": 1047, "sethdandridg": 1045, "setminu": 1016, "setosa": [80, 121, 131, 133, 287, 288, 383, 512, 1025, 1032], "setp": [47, 49, 289, 293], "settabl": 1000, "settingwithcopywarn": 193, "setup": [285, 287, 373, 384, 388, 392, 394, 1003, 1026], "setuptool": [384, 1059], "seuclidean": [458, 465, 707, 786, 787, 788, 1003, 1049, 1052, 1053], "seuclideandist": 707, "seung": 421, "seven": [381, 993], "seventh": [519, 1012], "sever": [0, 43, 48, 51, 52, 62, 64, 67, 70, 72, 90, 91, 92, 96, 108, 122, 142, 155, 158, 160, 163, 171, 174, 176, 181, 182, 189, 192, 197, 204, 209, 220, 224, 239, 240, 243, 244, 245, 251, 265, 273, 278, 283, 292, 301, 315, 319, 331, 356, 360, 361, 373, 380, 381, 383, 386, 388, 391, 394, 398, 400, 413, 416, 417, 420, 422, 423, 424, 426, 455, 457, 472, 495, 507, 516, 517, 546, 563, 564, 567, 568, 571, 572, 573, 578, 596, 597, 599, 618, 653, 654, 660, 696, 697, 698, 699, 700, 701, 805, 806, 808, 811, 812, 822, 840, 841, 847, 848, 849, 850, 851, 871, 872, 879, 896, 920, 921, 922, 923, 935, 989, 992, 997, 1000, 1001, 1003, 1008, 1010, 1014, 1016, 1017, 1018, 1019, 1021, 1023, 1024, 1025, 1032, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1050, 1054, 1057, 1058], "sevin": 1049, "sewook": 1051, "sex": [105, 174, 192, 194, 208, 209, 261, 333, 335, 383, 504, 1008, 1032], "sex_mal": 192, "seyedsaman": 1055, "sf": [174, 278, 330, 381, 425, 500, 610], "sfm": 174, "sfs_backward": 174, "sfs_forward": 174, "sfu": [416, 450], "sgd": [2, 46, 47, 50, 122, 134, 141, 151, 152, 161, 167, 179, 180, 189, 198, 201, 205, 211, 212, 227, 234, 247, 267, 286, 315, 316, 331, 350, 351, 354, 358, 360, 365, 369, 375, 512, 520, 639, 657, 674, 675, 676, 679, 684, 685, 686, 687, 869, 870, 989, 1004, 1021, 1022, 1036, 1041, 1044, 1045, 1046, 1048, 1052, 1054], "sgdclassifi": [2, 25, 46, 47, 227, 228, 229, 230, 231, 232, 233, 252, 286, 342, 351, 360, 369, 373, 375, 392, 400, 414, 424, 646, 648, 649, 650, 654, 666, 674, 676, 912, 917, 992, 996, 1001, 1014, 1015, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1054, 1055, 1056, 1057, 1058, 1059], "sgdoneclasssvm": [2, 234, 247, 331, 916, 1006, 1014, 1054, 1056, 1057, 1058, 1059], "sgdregressor": [2, 25, 49, 231, 373, 375, 398, 654, 657, 675, 679, 684, 687, 870, 913, 918, 996, 1014, 1043, 1045, 1047, 1048, 1049, 1052, 1054, 1055, 1056, 1057, 1059], "sgi": 360, "sgkf": [420, 826], "sgm": 47, "sgml": [47, 373], "sh": [289, 390, 394, 989], "sh_color": 244, "sh_err": 244, "sh_lle": 244, "sh_point": 244, "sh_tsne": 244, "sha256": [47, 1056], "shack": [1051, 1052, 1053], "shade": [58, 88, 172, 203, 302, 307, 345, 421], "shader": 412, "shadi": [1056, 1057], "shadow": [129, 133, 134, 243, 340, 355, 362, 424], "shafer": 104, "shagun": 1047, "shah": [1045, 1046, 1047, 1053, 1059], "shaharyar": 1059, "shahebaz": 1049, "shahriar": 1043, "shaikh": [0, 371, 376, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1059], "shail": 1053, "shakerimoff": 1055, "shalev": [674, 675, 996, 1014], "shalil": 1049, "shall": 181, "shallow": [392, 423, 569, 570, 927], "shamsi": 1049, "shandeng123": 1055, "shane": [100, 1050, 1053, 1056], "shanghai": [697, 701, 997], "shangwu": [1049, 1050], "shankar": 1051, "shanmuga": 1047, "shanno": 996, "shannon": [565, 572, 920, 922, 997, 1016], "shantanu": 791, "shao": [1053, 1054, 1055], "shape": [2, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 76, 81, 82, 83, 86, 87, 88, 89, 90, 93, 95, 96, 101, 104, 108, 109, 113, 125, 126, 128, 140, 145, 146, 147, 148, 149, 152, 153, 154, 155, 158, 159, 167, 170, 172, 177, 178, 180, 181, 182, 183, 187, 188, 189, 193, 194, 208, 209, 220, 222, 227, 229, 232, 233, 234, 235, 236, 239, 241, 242, 243, 247, 250, 251, 252, 253, 254, 256, 257, 263, 265, 267, 268, 269, 276, 278, 280, 281, 284, 285, 287, 288, 299, 304, 305, 309, 312, 314, 316, 321, 322, 328, 330, 333, 334, 335, 340, 341, 343, 346, 349, 352, 353, 354, 357, 358, 360, 361, 368, 373, 379, 380, 381, 386, 388, 400, 413, 414, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 437, 438, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 508, 509, 510, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 720, 721, 722, 723, 724, 725, 726, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 929, 934, 937, 938, 943, 947, 949, 951, 954, 962, 964, 969, 971, 975, 976, 977, 978, 979, 980, 981, 982, 983, 990, 995, 996, 1000, 1001, 1002, 1003, 1004, 1006, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1021, 1030, 1031, 1033, 1034, 1041, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1055, 1057, 1058], "shape_fit_": [914, 915, 916, 917, 918], "shape_img": 593, "sharad": 1049, "sharan": [1048, 1049], "share": [70, 117, 158, 192, 268, 360, 368, 369, 373, 374, 388, 394, 410, 416, 421, 424, 557, 676, 712, 716, 805, 806, 811, 812, 994, 1007, 1023, 1041, 1043, 1049, 1051, 1053, 1056], "shared_yax": 145, "sharedmem": 1049, "sharei": [43, 52, 70, 109, 123, 130, 135, 161, 185, 193, 220, 222, 228, 280, 289, 292, 304, 320, 325, 355, 356, 361], "sharex": [43, 46, 54, 70, 107, 123, 130, 161, 185, 193, 222, 280, 292, 304, 341, 1030], "sharma": [1045, 1047, 1049, 1050, 1052, 1053, 1055, 1058, 1059], "sharmadharmp": 1055, "sharon": [45, 381], "sharova": 1048, "sharp": [43, 193, 1007, 1010], "sharper": 734, "shashank": [1047, 1053], "shaun": 1042, "shawpan": 1047, "shaymernaturalint": 1055, "she": [386, 902, 903, 1051], "shea": [1049, 1050], "shebanov": [1049, 1050], "sheep": 1024, "sheer": [386, 1024], "sheerman": 1041, "sheet": 1043, "sheetscikit": 1027, "shekhar": 1047, "shell": [387, 394, 398, 1025, 1034], "shellyfung": 1056, "shen": 1054, "sheng": 1051, "shengxiduan": 1047, "shenhanc78": 1049, "sheni": 1053, "shenk": 1049, "shenoi": 1048, "sherlock": [636, 990], "sheth": 1049, "shetti": 1054, "shi": [416, 460, 470, 699], "shibata": 1051, "shiebler": 1047, "shield": 400, "shift": [2, 52, 71, 73, 79, 84, 99, 189, 199, 243, 268, 304, 317, 319, 353, 418, 422, 448, 456, 466, 469, 477, 520, 523, 697, 701, 858, 881, 1010, 1021, 1035, 1036, 1041, 1045, 1049], "shifted_gaussian": 267, "shifted_opposite_lof_scor": 858, "shih": [849, 1002], "shiki": 1052, "shilt": 1044, "shinehid": 1054, "shinitski": 1058, "shinnar": 1054, "shinsuk": 1056, "ship": [57, 160, 188, 365, 374, 384, 404, 424, 996, 1041, 1050], "shiqiao": [0, 406, 1041, 1042], "shirsat": 1056, "shiva": [1056, 1057], "shivam": [1049, 1050, 1051], "shivamgargsya": [1048, 1052, 1054], "shivan": 1046, "shivram": 1049, "shiyu": 1050, "shleifer": [1047, 1048], "shmelkov": 1046, "shoaib": 1056, "shoemak": 1052, "shogo": [1056, 1057], "shooter23": [1053, 1054], "shop": 1024, "short": [44, 121, 149, 156, 211, 276, 316, 360, 386, 394, 420, 424, 428, 996, 997, 1003, 1023, 1046, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "short_nam": 55, "shortcom": 996, "shortcut": [394, 410, 426], "shorten": [386, 1015, 1054], "shorten_param": 279, "shorter": [43, 182, 266, 398, 416, 421, 458, 465, 571, 705, 1002, 1006, 1034, 1052], "shortest": [2, 74, 391, 395, 696, 954, 997, 1054], "shortest_path": 1054, "shorthand": [93, 400, 417, 475, 569, 570, 873, 874, 1044], "shortlog": 390, "shortname_slic": 55, "shota": 1047, "should": [43, 44, 45, 47, 48, 52, 54, 55, 62, 64, 67, 72, 88, 137, 139, 142, 145, 149, 152, 155, 174, 187, 192, 197, 199, 200, 204, 220, 222, 238, 247, 252, 253, 254, 257, 272, 278, 281, 284, 285, 287, 292, 296, 299, 320, 321, 326, 340, 349, 356, 361, 369, 373, 374, 375, 381, 384, 385, 386, 388, 390, 391, 393, 394, 395, 399, 400, 404, 407, 410, 412, 414, 415, 416, 418, 420, 421, 423, 424, 425, 426, 427, 428, 430, 433, 439, 445, 448, 450, 451, 452, 453, 455, 457, 458, 460, 462, 465, 466, 467, 470, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 504, 511, 516, 517, 524, 529, 531, 532, 535, 540, 541, 542, 544, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 597, 598, 599, 601, 602, 605, 610, 615, 616, 618, 619, 628, 635, 636, 637, 639, 640, 641, 643, 646, 647, 648, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 692, 695, 697, 698, 699, 700, 701, 702, 703, 704, 709, 717, 735, 736, 750, 774, 779, 782, 786, 787, 788, 789, 790, 793, 796, 797, 800, 807, 809, 810, 815, 816, 817, 818, 825, 826, 827, 828, 830, 834, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 862, 863, 869, 870, 872, 875, 876, 877, 878, 879, 880, 881, 883, 884, 885, 886, 891, 892, 893, 895, 899, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 932, 936, 938, 941, 949, 957, 961, 966, 969, 971, 974, 975, 976, 977, 978, 979, 980, 981, 989, 990, 994, 995, 996, 997, 1000, 1001, 1003, 1005, 1006, 1007, 1010, 1013, 1014, 1015, 1016, 1020, 1023, 1024, 1030, 1034, 1038, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "shouldn": [264, 269, 386], "show": [2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 167, 169, 170, 171, 172, 173, 174, 177, 178, 179, 180, 181, 182, 184, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 335, 338, 339, 340, 341, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 364, 365, 366, 367, 368, 374, 375, 386, 392, 398, 399, 404, 407, 413, 414, 415, 418, 420, 421, 422, 423, 425, 426, 446, 510, 567, 601, 602, 639, 640, 705, 706, 708, 709, 710, 721, 814, 831, 854, 872, 924, 925, 926, 989, 992, 994, 995, 997, 999, 1000, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1014, 1015, 1020, 1029, 1030, 1034, 1043, 1045, 1046, 1048, 1050, 1051, 1052, 1053, 1055, 1057, 1058, 1059], "show_top10": 381, "show_vers": [2, 373, 384, 386, 394, 404, 1049], "show_weight": 925, "show_with_diff": 128, "showcas": [137, 140, 145, 149, 152, 153, 155, 189, 388], "shown": [62, 83, 92, 120, 137, 141, 145, 152, 185, 191, 193, 204, 210, 218, 238, 245, 247, 252, 257, 265, 278, 281, 284, 287, 296, 304, 315, 316, 319, 320, 321, 338, 356, 360, 361, 386, 391, 401, 414, 416, 417, 420, 421, 422, 424, 426, 446, 468, 640, 706, 708, 709, 710, 721, 808, 822, 924, 926, 995, 996, 997, 1000, 1003, 1010, 1014, 1015, 1016, 1034, 1045, 1050, 1051, 1052, 1055], "shown_imag": 241, "shrankhla": 1056, "shreesha": [1057, 1058], "shreya": 1051, "shrink": [63, 115, 125, 153, 193, 204, 215, 218, 224, 240, 267, 319, 356, 421, 567, 568, 684, 686, 859, 869, 870, 914, 915, 916, 917, 918, 1003, 1015, 1032], "shrink_threshold": [310, 859, 1003, 1041, 1053], "shrinkag": [2, 69, 110, 112, 115, 132, 154, 189, 310, 429, 477, 478, 481, 482, 483, 484, 485, 487, 488, 489, 547, 551, 557, 569, 570, 808, 996, 1010, 1021, 1022, 1036, 1041, 1045, 1046, 1048], "shrinkage_": [111, 112, 481, 483], "shrinkage_coeffici": 488, "shrunk": [2, 111, 132, 319, 326, 334, 429, 481, 483, 484, 487, 488, 489, 557, 893, 994, 1014, 1035, 1036], "shrunk_cov": [429, 487, 489], "shrunk_cov_scor": 132, "shrunk_covari": [2, 418, 1058], "shrunkcovari": [2, 111, 132, 418, 477, 478, 481, 482, 483], "shrunken": [859, 1041], "shu": [1042, 1045, 1049], "shuangchi": [1055, 1056], "shubernetskii": 1043, "shubh": 1052, "shubhal": 1058, "shubham": [1048, 1051, 1059], "shubhanshu": 1053, "shubhraneel": 1055, "shuckle16": 1047, "shuffl": [2, 49, 52, 54, 58, 59, 61, 64, 68, 83, 95, 96, 125, 145, 146, 148, 155, 160, 188, 204, 228, 229, 234, 247, 279, 283, 284, 291, 299, 326, 338, 339, 340, 341, 351, 360, 361, 369, 381, 395, 400, 411, 477, 482, 496, 497, 499, 500, 503, 505, 511, 519, 520, 521, 522, 523, 527, 530, 532, 539, 545, 547, 548, 554, 555, 561, 562, 563, 564, 572, 573, 575, 576, 610, 613, 615, 666, 667, 674, 675, 676, 680, 682, 684, 685, 686, 695, 808, 810, 811, 812, 813, 814, 822, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 842, 869, 870, 893, 912, 913, 914, 917, 948, 949, 969, 971, 995, 996, 1001, 1008, 1014, 1015, 1029, 1034, 1036, 1041, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1052], "shuffle_param": 356, "shuffled_arrai": 974, "shufflesplit": [2, 273, 280, 356, 420, 810, 816, 818, 828, 838, 1029, 1041, 1042, 1044, 1046, 1047], "shuhei": 1054, "shuhua": 1053, "shutil": [89, 106, 417], "shuttl": 361, "shuzh": 1051, "shwartz": [674, 675, 996, 1014], "shwed": 1049, "shyam": 1054, "si": 104, "siam": [416, 420, 460, 468, 470, 543, 549], "siang": 1044, "siavash": 1054, "siavrez": 1055, "sibsp": [194, 333], "sid": 1048, "siddharth": [1048, 1052], "siddiqui": 1059, "side": [43, 64, 94, 152, 213, 224, 238, 242, 250, 272, 319, 353, 360, 369, 381, 398, 414, 417, 420, 421, 424, 433, 439, 523, 996, 997, 1000, 1002, 1015, 1050], "sidhpura": 1056, "siebert": 1049, "sierra": [539, 545], "sievert": 1051, "siftikha": 1049, "sig": 126, "sigh": 360, "sigkdd": [380, 381, 519, 684, 893, 1010, 1012], "sigma": [53, 81, 82, 89, 113, 132, 152, 276, 278, 413, 418, 421, 423, 622, 657, 994, 996, 998, 1002, 1005, 1033], "sigma2": [542, 549], "sigma_": [418, 652, 653, 1054, 1058], "sigma_0": [179, 180, 185, 426, 622], "sigma_0_bound": [185, 622], "sigma_i": [1002, 1010], "sigma_k": [421, 994], "sigmod": [416, 458, 465, 858, 1006], "sigmoid": [2, 61, 62, 63, 64, 378, 423, 445, 460, 543, 569, 628, 647, 651, 773, 782, 785, 869, 870, 914, 915, 916, 917, 918, 1005, 1015, 1036, 1054, 1058], "sigmoid_kernel": [2, 773, 998], "sign": [75, 112, 118, 126, 129, 141, 204, 268, 314, 356, 386, 416, 421, 424, 552, 590, 597, 614, 643, 644, 666, 667, 674, 676, 682, 683, 684, 685, 743, 750, 912, 916, 947, 949, 965, 996, 1000, 1005, 1010, 1014, 1015, 1033, 1041, 1045, 1050, 1054, 1056, 1059], "signal": [2, 11, 53, 114, 125, 126, 127, 134, 150, 152, 176, 181, 182, 189, 191, 198, 199, 205, 206, 208, 209, 214, 215, 219, 221, 269, 331, 416, 418, 424, 425, 426, 429, 483, 511, 529, 534, 539, 542, 545, 549, 553, 554, 633, 652, 653, 654, 655, 660, 661, 671, 672, 680, 692, 693, 694, 793, 829, 838, 886, 996, 1000, 1017, 1021, 1024, 1028, 1035, 1036], "signatur": [254, 360, 361, 381, 496, 497, 565, 566, 572, 573, 602, 618, 619, 667, 681, 683, 719, 750, 814, 831, 834, 836, 839, 885, 960, 989, 1048, 1054, 1058], "signif": [45, 992, 1030], "signifi": [388, 416, 589, 819, 1005], "signific": [2, 43, 90, 145, 152, 169, 170, 172, 189, 224, 238, 270, 278, 298, 299, 323, 360, 369, 380, 381, 398, 416, 419, 420, 423, 512, 540, 542, 557, 558, 635, 666, 667, 674, 675, 676, 684, 685, 686, 827, 837, 912, 914, 915, 916, 917, 918, 999, 1000, 1003, 1021, 1041, 1043, 1044, 1045, 1049], "significantli": [43, 61, 62, 64, 72, 111, 112, 139, 145, 150, 152, 155, 174, 192, 193, 194, 220, 224, 228, 236, 238, 272, 278, 299, 329, 330, 361, 362, 369, 374, 390, 416, 421, 423, 424, 429, 477, 482, 487, 488, 546, 548, 555, 566, 573, 654, 655, 660, 661, 668, 669, 670, 671, 692, 700, 852, 853, 992, 996, 997, 1003, 1008, 1015, 1041, 1043, 1044, 1048, 1049, 1054, 1055, 1056], "sijaranamu": 1047, "silenc": 254, "silent": [254, 424, 589, 868, 1010, 1046, 1047, 1049, 1050, 1054, 1055], "silhouett": [2, 58, 71, 73, 84, 92, 93, 189, 361, 455, 520, 800, 801, 1021, 1041, 1045], "silhouette_avg": 95, "silhouette_sampl": [2, 95, 801, 1045, 1047, 1049, 1057], "silhouette_scor": [2, 73, 84, 93, 95, 361, 386, 416, 1041, 1045, 1047, 1049, 1051, 1055], "silicon": 384, "silk": 1055, "sillanp\u00e4\u00e4": 1041, "silva": [414, 696, 997, 1052, 1054, 1059], "silverman": [857, 1056], "silvermann": 422, "silverthorn": 1041, "silvestrin": 1058, "sim": [421, 1032], "sim4n6": 1056, "simd": [400, 1056], "similar": [2, 43, 44, 46, 51, 55, 58, 62, 63, 70, 72, 84, 86, 92, 95, 109, 118, 125, 129, 139, 152, 173, 176, 183, 191, 192, 193, 194, 204, 220, 222, 234, 240, 242, 243, 244, 247, 253, 254, 269, 272, 275, 278, 281, 284, 285, 286, 296, 298, 299, 319, 331, 348, 353, 356, 361, 362, 369, 373, 378, 380, 382, 385, 386, 388, 391, 392, 394, 395, 398, 400, 410, 413, 414, 416, 419, 420, 421, 423, 424, 425, 426, 427, 448, 451, 452, 458, 460, 462, 463, 511, 516, 517, 544, 590, 597, 598, 599, 618, 685, 700, 703, 711, 713, 723, 727, 733, 736, 737, 739, 742, 746, 748, 763, 768, 769, 794, 800, 801, 804, 805, 806, 834, 839, 884, 905, 908, 912, 913, 914, 915, 933, 989, 992, 993, 995, 996, 997, 999, 1001, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1025, 1033, 1036, 1041, 1045, 1046, 1047, 1049, 1053, 1054], "similarli": [43, 51, 72, 90, 123, 156, 193, 195, 204, 209, 220, 248, 257, 272, 278, 314, 319, 334, 336, 349, 369, 374, 382, 384, 388, 391, 400, 410, 412, 413, 419, 420, 424, 737, 738, 746, 791, 792, 795, 830, 995, 997, 998, 1000, 1007, 1014, 1015, 1017, 1025, 1029, 1049, 1055, 1057], "simmon": 1024, "simon": [996, 1024, 1044, 1045, 1054, 1055, 1056, 1057], "simona": [1052, 1053, 1054], "simonamaggio": [1052, 1053, 1054], "simoncw": 1051, "simonpl": 1046, "simpl": [2, 13, 37, 43, 64, 90, 105, 109, 111, 117, 118, 125, 145, 150, 183, 189, 193, 204, 221, 237, 260, 279, 296, 300, 303, 312, 332, 345, 360, 362, 365, 369, 384, 386, 388, 389, 390, 391, 393, 398, 399, 400, 401, 407, 413, 416, 417, 418, 420, 421, 422, 423, 424, 425, 430, 437, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 470, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 522, 530, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 794, 796, 805, 806, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 956, 992, 994, 995, 996, 997, 999, 1000, 1003, 1010, 1012, 1014, 1016, 1020, 1021, 1024, 1025, 1034, 1038, 1041], "simplefilt": 410, "simpleimput": [2, 105, 160, 187, 188, 194, 249, 259, 261, 329, 332, 369, 400, 635, 636, 637, 990, 1010, 1049, 1050, 1052, 1053, 1055, 1056, 1057, 1058, 1059], "simpleimputersimpleimput": [105, 160, 194, 249, 259, 329, 332], "simplepipelin": 254, "simpler": [238, 349, 373, 385, 416, 421, 996, 1001, 1032, 1046], "simplest": [88, 420, 997, 1032, 1033], "simplex": [63, 678, 805, 887], "simpli": [74, 118, 158, 176, 184, 244, 255, 257, 287, 312, 330, 331, 373, 381, 386, 388, 391, 398, 400, 418, 419, 420, 421, 423, 424, 493, 703, 770, 773, 879, 951, 992, 1000, 1001, 1002, 1003, 1014, 1026, 1034, 1048, 1049, 1050], "simplic": [43, 53, 67, 204, 353, 360, 362, 400, 422, 1003, 1004, 1005, 1015], "simplif": [382, 385, 391, 1041, 1047], "simplifi": [43, 105, 208, 254, 349, 385, 387, 391, 416, 419, 523, 570, 871, 872, 1000, 1002, 1010], "simplist": [220, 424], "simul": [112, 127, 155, 192, 214, 255, 278, 1024], "simultan": [58, 90, 126, 282, 286, 334, 356, 367, 378, 413, 416, 989, 1000, 1001, 1016, 1024, 1048], "sin": [43, 53, 57, 74, 126, 140, 151, 152, 157, 159, 169, 176, 182, 183, 185, 199, 200, 204, 214, 221, 226, 242, 253, 269, 311, 320, 329, 335, 355, 366, 367, 426, 524, 623, 707, 772, 1033], "sin_transform": 43, "sina": [320, 1054], "sinayev": 1043, "sinc": [0, 43, 44, 50, 52, 62, 70, 72, 84, 88, 90, 101, 104, 105, 106, 126, 149, 165, 171, 174, 176, 181, 192, 193, 195, 197, 202, 220, 222, 224, 237, 248, 252, 253, 254, 265, 268, 272, 274, 278, 280, 281, 287, 288, 292, 296, 298, 299, 301, 302, 325, 331, 332, 343, 346, 349, 356, 360, 361, 362, 369, 374, 381, 384, 386, 387, 388, 390, 391, 394, 398, 399, 400, 404, 407, 410, 414, 416, 417, 418, 419, 420, 421, 423, 424, 426, 433, 445, 449, 453, 454, 458, 461, 464, 477, 490, 491, 492, 493, 504, 535, 544, 545, 546, 547, 548, 554, 555, 557, 558, 559, 560, 561, 563, 565, 567, 569, 570, 571, 572, 575, 577, 596, 597, 599, 618, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 640, 641, 646, 659, 663, 666, 667, 674, 676, 681, 682, 683, 684, 685, 687, 700, 715, 717, 743, 750, 758, 759, 790, 797, 807, 808, 811, 812, 822, 830, 833, 834, 835, 836, 840, 841, 842, 843, 847, 848, 849, 850, 851, 854, 859, 862, 869, 870, 872, 877, 902, 903, 907, 908, 912, 914, 917, 920, 922, 949, 957, 989, 992, 993, 994, 996, 997, 1001, 1002, 1003, 1004, 1006, 1008, 1010, 1014, 1015, 1016, 1024, 1025, 1034, 1041, 1042, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "sinclert": 1049, "sind": 424, "sine": [2, 43, 176, 181, 182, 189, 214, 226, 262, 263, 264, 265, 267, 268, 366, 382, 623, 805, 806, 999, 1016, 1021], "singer": [296, 674, 675, 743, 996, 1000, 1014, 1015], "singh": [1047, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "singl": [2, 30, 31, 70, 74, 83, 87, 88, 90, 93, 96, 97, 106, 127, 138, 139, 140, 148, 149, 159, 174, 176, 182, 187, 189, 193, 195, 197, 204, 220, 222, 224, 258, 260, 268, 272, 274, 287, 296, 316, 332, 334, 349, 360, 361, 362, 365, 367, 369, 373, 374, 380, 381, 386, 391, 393, 394, 395, 398, 399, 400, 407, 414, 415, 417, 419, 420, 421, 423, 424, 425, 441, 445, 448, 449, 453, 454, 455, 457, 462, 472, 474, 475, 501, 502, 504, 514, 517, 542, 561, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 590, 600, 607, 608, 610, 614, 635, 640, 642, 651, 674, 675, 681, 684, 685, 686, 698, 700, 702, 718, 719, 729, 730, 731, 732, 733, 744, 745, 746, 749, 782, 793, 805, 806, 808, 811, 812, 822, 829, 830, 834, 835, 837, 838, 841, 849, 852, 853, 857, 869, 870, 871, 881, 882, 885, 886, 887, 892, 893, 907, 908, 920, 921, 922, 923, 928, 964, 987, 989, 995, 996, 997, 1000, 1001, 1003, 1005, 1007, 1008, 1010, 1014, 1015, 1016, 1019, 1021, 1024, 1025, 1032, 1034, 1041, 1042, 1043, 1045, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "single_prior": 185, "single_source_shortest_path_length": [2, 395], "singleton": [374, 816, 935, 1054, 1057], "singular": [2, 125, 395, 413, 416, 419, 459, 461, 490, 491, 492, 493, 529, 532, 542, 546, 548, 549, 552, 555, 557, 558, 665, 680, 681, 682, 695, 949, 996, 997, 999, 1035, 1036, 1047, 1048, 1059], "singular_": 665, "singular_values_": [542, 549, 552, 1048], "sinha": [1049, 1058, 1059], "sinhrk": [1045, 1046], "sink": [649, 992], "sinoisoid": 152, "sinusoid": [126, 140, 152, 204, 253, 653, 993, 1033], "sio": 410, "siola": [1056, 1057], "sip\u0151cz": [1051, 1052, 1053, 1057], "siqi": 1055, "siqueira": 1051, "sir": 383, "sister": 1019, "site": [384, 386, 389, 394, 404, 423, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 1024, 1049], "situat": [62, 79, 92, 106, 191, 192, 226, 247, 281, 386, 394, 410, 418, 420, 421, 423, 476, 536, 542, 590, 885, 888, 900, 910, 994, 996, 1002, 1003, 1013, 1016, 1049], "situp": 383, "sivamani": 1051, "sivaprasad": [1044, 1045], "six": [174, 221, 241, 323, 383, 1050], "sixteenth": 1012, "sixth": 381, "size": [37, 42, 43, 44, 45, 47, 50, 51, 52, 53, 61, 64, 67, 69, 72, 74, 75, 77, 79, 81, 82, 87, 89, 90, 92, 93, 95, 96, 97, 101, 102, 107, 111, 112, 113, 114, 115, 117, 118, 123, 125, 126, 127, 128, 129, 132, 134, 142, 151, 152, 155, 156, 157, 170, 176, 178, 179, 182, 183, 189, 191, 193, 194, 199, 200, 201, 202, 206, 210, 215, 218, 221, 222, 223, 226, 233, 234, 240, 245, 247, 250, 251, 252, 253, 254, 256, 257, 265, 271, 274, 276, 278, 280, 281, 283, 284, 285, 296, 305, 306, 307, 314, 317, 320, 321, 322, 323, 326, 329, 332, 334, 335, 339, 343, 345, 347, 348, 349, 356, 358, 360, 361, 362, 364, 373, 374, 375, 381, 382, 386, 391, 395, 398, 399, 400, 404, 407, 413, 414, 416, 418, 420, 421, 424, 426, 427, 429, 452, 453, 454, 456, 457, 458, 465, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 501, 502, 503, 523, 535, 542, 544, 546, 548, 555, 565, 566, 567, 568, 569, 570, 572, 573, 591, 595, 596, 602, 640, 641, 651, 665, 674, 675, 687, 691, 700, 703, 713, 727, 746, 748, 751, 789, 801, 810, 813, 814, 818, 825, 828, 829, 830, 833, 836, 838, 847, 848, 849, 851, 854, 855, 856, 857, 858, 860, 862, 863, 864, 869, 870, 887, 889, 901, 906, 910, 914, 915, 916, 917, 918, 920, 921, 922, 923, 926, 948, 952, 953, 963, 964, 966, 969, 975, 990, 992, 993, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1007, 1010, 1012, 1014, 1015, 1016, 1023, 1024, 1028, 1030, 1032, 1033, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1056, 1057], "size_cluster_i": 95, "size_mb": 360, "sizeabl": [825, 828], "skaft": 1055, "skeleton": [1034, 1044], "sketch": [2, 23, 197, 375, 378, 395, 647, 648, 649, 965, 1036, 1053], "skew": [2, 48, 152, 223, 251, 257, 319, 334, 378, 420, 647, 648, 649, 650, 888, 900, 996, 1010, 1036, 1044, 1048, 1057], "skewed": [650, 1048], "skewedchi2sampl": [2, 646, 647, 648, 649, 992, 1048, 1055, 1056], "skf": [265, 420, 827], "skfold": 341, "skforecast": 1019, "skill": 1000, "skimag": [81, 82, 380, 1033], "skip": [374, 386, 388, 395, 412, 424, 476, 576, 654, 655, 660, 668, 669, 670, 679, 689, 910, 1034, 1045, 1048, 1051, 1053, 1055, 1057], "skip_complet": 635, "skip_comput": 1051, "skip_parameter_valid": [476, 910, 1057], "skipper": [1044, 1046, 1047], "skiptestwarn": 388, "skl2onnx": 410, "sklear": 387, "sklearn": [2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 373, 374, 375, 379, 380, 381, 384, 385, 386, 387, 388, 390, 391, 392, 394, 395, 398, 399, 400, 403, 404, 407, 410, 412, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 992, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1025, 1029, 1030, 1031, 1032, 1033, 1034, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048], "sklearn2pmml": 1019, "sklearn_api": 0, "sklearn_assume_finit": 373, "sklearn_cache_": 328, "sklearn_enable_debug_cython_direct": 387, "sklearn_fail_no_openmp": 384, "sklearn_graph_cache_": 301, "sklearn_is_fit": [137, 1021], "sklearn_panda": 1019, "sklearn_run_float32_test": 386, "sklearn_site_joblib": 1049, "sklearn_tut_workspac": 1034, "sklearn_warning_as_error": 374, "sklearn_xarrai": 1019, "sklearnex": 404, "skop": [1019, 1036], "skorch": 1019, "sktime": [52, 1019], "sl": 220, "slack": 1014, "slai": 360, "slama": [1051, 1053], "slep": [386, 400], "slep000": 401, "slep009": [1052, 1054, 1055], "slep010": [388, 1052], "slep011": 1020, "slep018": [261, 388, 1056], "slep020": 401, "slice": [2, 43, 52, 55, 148, 155, 229, 242, 245, 252, 307, 310, 331, 332, 345, 381, 387, 388, 395, 417, 472, 475, 501, 502, 516, 554, 647, 782, 786, 789, 928, 952, 953, 971, 1053, 1055, 1059], "slice_": [501, 502, 1056], "sliceabl": 955, "slide": [279, 652, 996, 1018, 1019], "slight": [149, 225, 330, 410, 423, 457, 1051], "slightli": [43, 62, 64, 99, 115, 142, 145, 149, 152, 156, 160, 174, 176, 177, 178, 194, 199, 220, 238, 243, 245, 254, 257, 286, 292, 299, 328, 346, 362, 385, 386, 414, 416, 423, 424, 426, 428, 454, 596, 597, 599, 646, 666, 811, 812, 912, 914, 917, 948, 949, 989, 996, 1010, 1014, 1015, 1050, 1054, 1055, 1057, 1059], "slishak": 1055, "sloan": 0, "slogdet": 947, "slope": [193, 218, 222, 237, 416, 499, 731, 756, 998, 1000], "sloppili": 424, "sloth": [50, 312, 381, 506], "slow": [301, 319, 360, 373, 380, 384, 386, 421, 424, 455, 707, 886, 887, 891, 914, 917, 949, 997, 1003, 1020, 1033, 1048], "slower": [106, 128, 145, 149, 187, 253, 287, 362, 400, 423, 424, 425, 454, 459, 461, 546, 548, 555, 563, 564, 565, 566, 571, 572, 573, 574, 596, 597, 599, 639, 640, 641, 651, 667, 680, 682, 695, 700, 712, 840, 844, 845, 993, 997, 998, 999, 1001, 1003, 1016, 1034, 1045, 1052], "slowest": [149, 948, 949], "slowli": [398, 400, 552, 949], "slug": 104, "smacof": [2, 698, 1056], "small": [37, 38, 41, 44, 50, 52, 59, 64, 74, 83, 84, 88, 90, 104, 111, 115, 118, 122, 130, 140, 142, 149, 151, 152, 181, 183, 192, 193, 200, 206, 210, 211, 221, 224, 226, 235, 237, 238, 265, 272, 278, 285, 290, 292, 301, 312, 315, 317, 319, 321, 323, 330, 338, 343, 349, 354, 356, 360, 361, 375, 379, 381, 383, 386, 389, 395, 398, 400, 410, 413, 414, 416, 418, 419, 420, 421, 422, 423, 424, 425, 429, 449, 451, 453, 454, 455, 457, 466, 467, 471, 483, 504, 506, 546, 548, 549, 555, 563, 564, 565, 569, 570, 572, 590, 597, 598, 610, 615, 616, 658, 662, 663, 664, 666, 667, 687, 690, 691, 754, 811, 812, 826, 837, 840, 869, 870, 877, 905, 914, 917, 949, 989, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1007, 1008, 1010, 1012, 1013, 1016, 1020, 1024, 1032, 1033, 1041, 1042, 1044, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1055, 1056, 1057, 1058, 1059, 1060], "smaller": [2, 37, 47, 61, 75, 81, 90, 115, 139, 155, 174, 181, 182, 185, 187, 205, 209, 211, 224, 251, 296, 305, 306, 314, 319, 336, 349, 356, 361, 386, 413, 416, 418, 420, 421, 423, 425, 447, 448, 454, 458, 462, 464, 522, 542, 543, 565, 566, 567, 568, 569, 570, 572, 573, 601, 618, 627, 641, 654, 655, 657, 658, 660, 661, 662, 664, 666, 667, 668, 669, 670, 671, 680, 682, 690, 691, 700, 717, 805, 811, 812, 858, 861, 885, 886, 904, 905, 912, 920, 921, 922, 923, 949, 994, 996, 997, 999, 1000, 1001, 1003, 1004, 1006, 1010, 1012, 1014, 1015, 1016, 1020, 1034, 1049, 1054, 1058], "smallest": [113, 114, 220, 299, 336, 364, 381, 416, 418, 425, 535, 549, 638, 662, 663, 664, 690, 691, 698, 702, 703, 808, 811, 812, 822, 827, 882, 929, 1016, 1054], "smallest_ab": 336, "smallest_coef": [115, 535], "smari": [1050, 1051, 1052], "smart": [254, 451, 467, 468, 598], "smartphon": 1024, "smedbergm": 1047, "smedemark": 1051, "smile": [109, 381, 1055], "sminchisescu": [650, 992], "smirnov": 1053, "smith": [1047, 1048, 1049, 1050, 1051, 1053], "sml": [868, 1005], "smo": [912, 913], "smola": [421, 424, 543, 878, 1010, 1015], "smolskii": 1056, "smooth": [43, 81, 82, 89, 174, 181, 213, 221, 236, 325, 349, 383, 401, 416, 422, 423, 426, 456, 457, 545, 546, 547, 554, 565, 566, 567, 568, 572, 573, 574, 598, 599, 627, 630, 684, 847, 848, 849, 851, 889, 893, 901, 920, 921, 922, 923, 996, 1002, 1010, 1014, 1015, 1016, 1034], "smooth_idf": [424, 598, 599], "smoothened_coin": [81, 82], "smoother": [43, 44, 152, 193, 316, 422], "smoothli": 380, "smt": 1057, "smtp": [381, 500], "smujjiga": 1051, "sn": [72, 140, 155, 191, 192, 199, 204, 268, 278], "snake": [332, 334, 590, 893, 1010], "snapshot": [410, 567, 568, 1020], "sne": [51, 189, 239, 240, 241, 242, 244, 299, 522, 533, 700, 1021, 1035, 1036], "snippet": [137, 369, 386, 391, 394, 398, 412, 423, 424, 425, 990, 1010, 1023, 1054], "snowhit": 1052, "snr": 89, "snuderl": 1045, "sny": 51, "snyder": [700, 997], "so": [30, 37, 43, 48, 51, 52, 55, 64, 77, 83, 90, 91, 96, 100, 114, 145, 148, 149, 150, 151, 155, 159, 176, 181, 192, 194, 197, 200, 220, 221, 247, 254, 257, 272, 278, 296, 299, 305, 306, 309, 315, 316, 320, 325, 326, 329, 341, 349, 360, 362, 368, 369, 373, 374, 375, 380, 381, 384, 385, 386, 388, 390, 391, 392, 394, 395, 400, 407, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 423, 424, 425, 426, 429, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 464, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 504, 516, 517, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 612, 615, 616, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 703, 713, 716, 724, 734, 764, 786, 796, 805, 806, 807, 808, 811, 812, 814, 815, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 902, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 949, 966, 975, 989, 990, 992, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1010, 1012, 1013, 1014, 1015, 1019, 1020, 1024, 1032, 1033, 1034, 1041, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1057, 1058], "soar": 1056, "sobkevich": 1053, "sobolev": 1045, "soc": [57, 381, 1034], "socastro": [1051, 1057], "socg2006": 455, "social": [192, 401, 416, 1024], "societi": [174, 383, 416, 418, 477, 482, 549, 635, 888, 900, 996, 1014], "sodhani": 1047, "soft": [2, 134, 161, 162, 386, 400, 577, 578, 908, 916, 1014, 1024, 1046], "softmax": [423, 569, 666, 667, 996, 1003, 1004], "softw": 996, "softwar": [0, 174, 373, 383, 386, 394, 398, 400, 410, 424, 635, 643, 666, 990, 1024], "soil_typ": 257, "sokalmichen": [458, 465, 707, 786, 787, 788, 1003], "sokalmichenerdist": 707, "sokalsneath": [458, 465, 707, 786, 787, 788, 1003], "sokalsneathdist": 707, "sok\u00f3\u0142": [1058, 1059], "sole": [102, 398, 416], "soledad": 1053, "soler": [0, 406], "solid": [50, 67, 69, 151, 179, 232, 233, 247, 257, 312, 321, 1024], "solntz": 360, "solosil": 1054, "solut": [81, 199, 204, 209, 211, 225, 234, 247, 253, 331, 349, 384, 388, 400, 410, 413, 415, 416, 418, 420, 421, 424, 425, 457, 459, 461, 539, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 557, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 618, 654, 656, 658, 660, 662, 663, 664, 666, 668, 670, 672, 673, 674, 675, 676, 677, 680, 682, 684, 685, 686, 687, 688, 690, 691, 693, 694, 695, 805, 806, 822, 861, 869, 870, 993, 994, 996, 997, 999, 1004, 1006, 1014, 1015, 1018, 1024, 1029, 1032, 1034, 1041, 1044, 1054, 1055, 1056], "solutu": 1049, "solutusimmensu": 1049, "solv": [2, 44, 45, 101, 176, 209, 252, 278, 298, 385, 386, 387, 388, 391, 398, 416, 418, 420, 421, 426, 455, 461, 470, 486, 539, 545, 546, 547, 551, 553, 554, 555, 556, 643, 645, 654, 660, 662, 663, 672, 673, 678, 680, 682, 685, 693, 694, 695, 842, 912, 913, 916, 949, 991, 994, 996, 997, 1000, 1001, 1014, 1015, 1016, 1018, 1019, 1024, 1027, 1030, 1034, 1047, 1051, 1054], "solvabl": 416, "solver": [54, 66, 69, 70, 81, 101, 189, 198, 209, 211, 212, 213, 220, 222, 228, 235, 236, 238, 314, 315, 316, 317, 326, 335, 336, 360, 392, 398, 400, 404, 412, 416, 428, 460, 470, 479, 480, 486, 510, 541, 543, 548, 549, 552, 555, 557, 654, 655, 656, 660, 661, 666, 667, 668, 669, 670, 671, 674, 676, 677, 678, 680, 682, 684, 688, 689, 692, 695, 696, 697, 699, 701, 703, 796, 822, 838, 843, 846, 869, 870, 914, 915, 916, 917, 918, 994, 997, 1000, 1001, 1004, 1014, 1015, 1019, 1021, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "solver_": [680, 682], "solver_opt": 678, "somani": 1053, "some": [0, 42, 43, 44, 47, 48, 52, 57, 61, 62, 64, 72, 79, 85, 88, 90, 91, 93, 97, 102, 105, 108, 111, 113, 114, 118, 125, 140, 141, 145, 149, 152, 153, 155, 156, 157, 160, 161, 170, 176, 178, 181, 182, 183, 184, 185, 187, 188, 189, 192, 193, 194, 195, 197, 199, 201, 203, 204, 208, 209, 210, 214, 215, 220, 221, 224, 228, 229, 234, 237, 238, 240, 242, 247, 251, 254, 257, 264, 265, 266, 271, 272, 273, 278, 279, 280, 281, 284, 286, 292, 296, 298, 302, 305, 310, 315, 316, 319, 324, 329, 330, 331, 332, 333, 334, 335, 336, 345, 346, 348, 349, 356, 358, 360, 361, 362, 368, 369, 373, 374, 375, 379, 380, 381, 383, 384, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 404, 407, 410, 412, 413, 414, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 439, 445, 451, 452, 455, 457, 459, 461, 467, 471, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 504, 507, 516, 517, 523, 531, 532, 541, 542, 544, 549, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 582, 589, 590, 596, 598, 599, 602, 614, 617, 618, 619, 640, 641, 643, 647, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 697, 698, 700, 701, 705, 706, 708, 709, 710, 715, 716, 723, 728, 734, 735, 746, 747, 748, 754, 762, 764, 765, 771, 790, 792, 795, 796, 797, 802, 805, 807, 809, 810, 815, 817, 826, 827, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 932, 933, 957, 989, 990, 992, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1023, 1024, 1025, 1030, 1032, 1033, 1034, 1038, 1041, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "some_funct": [386, 939], "some_integ": 420, "some_iter": 386, "some_param": 386, "somebodi": 401, "someestim": 385, "somehow": 193, "someon": [386, 390, 400, 1041], "someth": [192, 241, 296, 360, 386, 388, 389, 390, 394, 424, 1000, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "sometim": [106, 160, 191, 272, 278, 316, 361, 369, 374, 375, 386, 388, 390, 392, 399, 400, 416, 418, 421, 423, 424, 457, 542, 543, 546, 548, 549, 877, 878, 879, 927, 995, 996, 997, 1000, 1005, 1010, 1011, 1015, 1025, 1033, 1038, 1042, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1057], "somewhat": [356, 369, 375, 386, 388, 421, 423, 914, 917, 996, 1015, 1016], "somewher": [392, 1000, 1034], "sommer": 1059, "somya": 1049, "son": [383, 990], "song": 997, "soni": [51, 1051, 1053], "sonni": 1046, "sonniv": [1056, 1057], "sonoiya": 1051, "sonoma": 325, "soon": [114, 400, 1032], "sooner": 1058, "sophist": [990, 1002], "sorbaro": 1046, "sorensen": 421, "soriano": 1050, "sornarajah": 1046, "sorri": 1049, "sorro": 1050, "sorski": [1055, 1056], "sort": [2, 43, 47, 49, 51, 57, 58, 61, 95, 104, 107, 137, 142, 149, 152, 159, 174, 181, 199, 204, 220, 221, 238, 256, 278, 279, 282, 293, 311, 355, 360, 366, 367, 386, 390, 394, 395, 400, 420, 423, 424, 426, 542, 549, 563, 574, 589, 602, 618, 625, 705, 720, 726, 737, 738, 746, 762, 791, 792, 795, 797, 808, 835, 847, 848, 849, 850, 851, 852, 853, 860, 862, 863, 864, 867, 877, 883, 885, 886, 889, 891, 893, 901, 914, 917, 949, 954, 996, 1003, 1006, 1010, 1024, 1034, 1041, 1045, 1051, 1052, 1053, 1055, 1056, 1059], "sort_graph_by_row_valu": [2, 395, 1056], "sort_index": 296, "sort_result": [852, 853, 860, 862, 863, 864, 1053], "sort_valu": [105, 194, 195, 261, 268, 278, 289, 325, 326], "sort_whats_new": 390, "sorted_idx": [153, 328], "sorted_importances_idx": 194, "sortofamudkip": [1056, 1057], "sought": 789, "soumirai": 1051, "sound": [174, 369], "sounder": 1047, "sourav": [1048, 1051], "sourc": [0, 2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 380, 383, 385, 386, 387, 389, 390, 392, 394, 395, 398, 399, 404, 410, 413, 417, 421, 423, 424, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 966, 967, 968, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 984, 985, 986, 987, 988, 997, 1010, 1016, 1019, 1021, 1024, 1033, 1034, 1051, 1055, 1059], "south": [50, 155, 192, 312, 381, 422], "south_y": 192, "sp": [43, 192, 335, 990, 1033], "sp_version": [222, 678], "space": [2, 37, 43, 47, 49, 57, 67, 81, 83, 88, 92, 93, 95, 96, 98, 100, 104, 105, 108, 118, 125, 127, 133, 135, 144, 148, 152, 158, 171, 174, 176, 182, 197, 204, 221, 240, 241, 242, 244, 251, 252, 253, 257, 258, 264, 269, 286, 289, 290, 299, 308, 309, 321, 330, 353, 360, 361, 362, 368, 369, 373, 378, 381, 382, 383, 386, 393, 398, 399, 400, 413, 416, 419, 421, 422, 423, 424, 426, 451, 455, 456, 457, 460, 470, 472, 473, 474, 475, 490, 491, 492, 496, 506, 540, 542, 543, 546, 547, 548, 549, 551, 552, 557, 581, 590, 596, 597, 599, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 640, 641, 646, 648, 649, 650, 651, 696, 697, 698, 700, 701, 702, 704, 707, 808, 811, 812, 814, 822, 831, 842, 852, 853, 860, 861, 862, 863, 872, 877, 878, 884, 889, 904, 905, 906, 925, 953, 992, 993, 994, 995, 996, 998, 1000, 1001, 1003, 1004, 1005, 1006, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1019, 1020, 1025, 1032, 1034, 1035, 1036, 1041, 1042, 1044, 1049, 1050, 1051, 1055, 1056, 1057], "spacek": 1046, "spain": 325, "spam": [589, 717, 749, 847, 1000, 1002, 1024], "span": [52, 90, 111, 152, 252, 272, 275, 381, 416, 424, 557, 644, 808, 811, 1000, 1033], "spanish": 1019, "spannbauer": 1053, "sparciti": 361, "spare": [380, 682, 683], "spark": [381, 1020], "sparrai": 1058, "spars": [2, 25, 45, 46, 51, 53, 55, 57, 66, 74, 75, 89, 90, 92, 104, 110, 111, 112, 124, 126, 144, 158, 189, 191, 198, 199, 205, 208, 209, 212, 214, 215, 219, 236, 251, 253, 279, 285, 299, 317, 329, 333, 336, 342, 359, 362, 368, 373, 378, 380, 381, 382, 386, 388, 389, 390, 391, 398, 399, 400, 410, 416, 417, 423, 424, 426, 427, 431, 438, 446, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 460, 461, 465, 467, 468, 470, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 495, 496, 497, 504, 505, 511, 516, 531, 532, 534, 535, 536, 537, 539, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 559, 561, 562, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 593, 594, 596, 597, 598, 599, 601, 602, 611, 612, 613, 614, 615, 616, 617, 637, 638, 639, 641, 646, 648, 649, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 699, 700, 701, 703, 704, 705, 706, 708, 709, 710, 711, 720, 721, 722, 737, 738, 739, 742, 746, 747, 748, 762, 763, 768, 769, 771, 772, 774, 775, 776, 778, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 791, 792, 793, 795, 800, 801, 804, 807, 808, 811, 812, 822, 829, 830, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 851, 854, 855, 856, 858, 859, 860, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 875, 876, 877, 879, 881, 882, 883, 884, 885, 887, 889, 890, 891, 892, 894, 895, 896, 897, 899, 901, 902, 903, 904, 905, 906, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 928, 930, 931, 932, 933, 938, 946, 949, 950, 953, 954, 955, 963, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 986, 990, 993, 996, 997, 998, 1000, 1001, 1003, 1013, 1015, 1016, 1020, 1021, 1022, 1032, 1033, 1034, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "sparse_cg": [360, 680, 682, 695, 996, 1042, 1048, 1050, 1051, 1055, 1057], "sparse_coef_": [654, 660, 668, 670, 1041], "sparse_encod": [2, 550, 658, 659, 660, 661, 662, 663, 664, 671, 672, 673, 690, 691, 692, 693, 694, 1041, 1048, 1049, 1051, 1055], "sparse_encode_parallel": 1041, "sparse_format": [535, 1058], "sparse_func": [1047, 1053], "sparse_input_": 879, "sparse_lasso": 206, "sparse_output": [43, 149, 261, 325, 332, 335, 574, 879, 883, 885, 891, 896, 1010, 1056, 1057], "sparse_output_": [472, 559], "sparse_symmetric_arrai": 986, "sparse_threshold": [193, 472, 475, 1049], "sparsearrai": 1052, "sparsecod": [2, 134, 421, 539, 545, 548, 556, 1048, 1049, 1051, 1053, 1055], "sparsecodingmixin": 1041, "sparsefunc": [2, 395, 975, 976, 977, 978, 979, 980, 981, 1054], "sparsefuncs_fast": [2, 395, 982, 983], "sparsepca": [2, 125, 539, 541, 542, 543, 545, 547, 548, 549, 550, 553, 554, 1041, 1048, 1049, 1051, 1052, 1054, 1055, 1056, 1059], "sparser": [90, 199, 211, 421, 479, 486, 547, 551, 996, 1003, 1014], "sparserandomproject": [2, 241, 251, 904, 1012, 1042, 1047, 1055, 1057, 1058], "sparsetool": 1048, "sparsifi": [46, 204, 373, 666, 667, 674, 675, 676, 684, 685, 686, 912, 984, 1043], "sparsiti": [2, 53, 66, 80, 115, 131, 189, 198, 204, 205, 213, 231, 235, 236, 253, 356, 361, 373, 400, 418, 421, 423, 425, 509, 510, 535, 539, 545, 546, 547, 548, 551, 553, 554, 555, 654, 660, 665, 666, 684, 686, 729, 731, 732, 881, 887, 892, 897, 993, 996, 1003, 1010, 1021, 1028, 1033, 1043], "sparsity_en_lr": 211, "sparsity_l1_lr": 211, "sparsity_l2_lr": 211, "sparsity_ratio": 373, "spatial": [82, 84, 90, 195, 204, 237, 316, 381, 400, 416, 427, 452, 454, 458, 460, 465, 687, 700, 768, 771, 786, 787, 788, 789, 800, 801, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 865, 866, 996, 1003, 1010, 1043, 1047, 1054, 1057], "spawn": [373, 398, 808, 822, 833, 834, 835, 1052], "speak": [361, 373, 386, 1014], "spearman": [195, 643, 644, 991], "spearmanr": 195, "spec": [1056, 1057], "speci": [2, 42, 121, 189, 257, 300, 360, 379, 422, 506, 714, 797, 857, 916, 927, 1000, 1006, 1021, 1036, 1041], "special": [151, 192, 210, 238, 296, 309, 325, 349, 380, 382, 388, 392, 398, 400, 416, 419, 421, 472, 475, 561, 563, 567, 833, 924, 989, 994, 996, 998, 999, 1000, 1001, 1003, 1016, 1048, 1051, 1053, 1055], "special_charact": [924, 1016], "species_nam": [50, 312], "specif": [2, 43, 50, 51, 58, 64, 70, 79, 90, 97, 100, 104, 106, 145, 155, 160, 181, 184, 189, 192, 193, 197, 224, 238, 272, 273, 278, 296, 319, 328, 329, 333, 336, 353, 360, 361, 362, 369, 373, 374, 381, 386, 389, 391, 392, 394, 398, 400, 404, 410, 412, 416, 417, 420, 421, 423, 424, 425, 426, 440, 504, 511, 542, 559, 565, 572, 575, 576, 577, 578, 582, 596, 599, 601, 620, 621, 622, 623, 625, 626, 627, 628, 630, 631, 633, 648, 651, 654, 655, 660, 666, 680, 695, 705, 707, 720, 721, 754, 808, 809, 810, 815, 816, 817, 822, 835, 848, 941, 943, 944, 963, 976, 977, 978, 994, 996, 997, 999, 1000, 1002, 1003, 1005, 1007, 1008, 1010, 1014, 1016, 1017, 1018, 1023, 1034, 1041, 1045, 1049, 1050, 1051, 1052, 1055, 1056, 1058], "specifi": [2, 43, 58, 64, 90, 125, 149, 150, 155, 177, 180, 182, 183, 184, 209, 221, 228, 263, 272, 286, 373, 374, 380, 384, 386, 388, 395, 399, 400, 407, 410, 414, 416, 417, 420, 421, 423, 425, 426, 428, 430, 436, 445, 449, 453, 458, 460, 471, 472, 475, 477, 478, 480, 481, 482, 483, 484, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 511, 523, 535, 539, 541, 545, 546, 548, 549, 554, 555, 560, 565, 567, 568, 569, 570, 572, 575, 576, 591, 592, 601, 602, 605, 610, 618, 619, 628, 639, 640, 641, 646, 651, 654, 655, 656, 659, 660, 661, 663, 664, 666, 667, 668, 669, 670, 671, 673, 676, 677, 680, 681, 682, 683, 684, 685, 688, 689, 690, 691, 692, 695, 699, 706, 708, 710, 717, 719, 737, 738, 746, 750, 762, 779, 787, 788, 791, 792, 795, 808, 810, 811, 812, 814, 815, 817, 821, 822, 825, 830, 831, 832, 833, 834, 835, 836, 837, 839, 843, 846, 847, 848, 850, 851, 852, 853, 857, 862, 885, 886, 887, 890, 891, 893, 908, 912, 913, 914, 915, 916, 917, 918, 919, 920, 922, 944, 951, 984, 990, 996, 997, 999, 1000, 1003, 1007, 1008, 1010, 1013, 1014, 1015, 1029, 1033, 1041, 1047, 1048, 1049, 1050, 1052, 1053, 1055, 1056, 1057, 1058, 1059, 1060], "spector": 420, "spectral": [2, 53, 56, 71, 79, 81, 84, 90, 104, 189, 241, 242, 340, 342, 360, 361, 362, 386, 424, 457, 459, 460, 461, 470, 477, 478, 479, 480, 481, 482, 483, 484, 496, 519, 521, 599, 696, 697, 698, 699, 700, 703, 727, 803, 1003, 1013, 1021, 1035, 1036, 1041, 1042], "spectral_clust": [2, 81, 101, 1049, 1051, 1053, 1054, 1055, 1056, 1058], "spectral_embed": [2, 400, 997, 1042, 1045, 1047, 1049, 1051, 1054, 1055, 1056, 1058], "spectralbiclust": [2, 413, 461, 1043, 1047, 1048, 1052], "spectralclust": [2, 79, 332, 416, 448, 1003, 1041, 1042, 1051, 1053, 1054, 1055, 1056, 1057, 1058], "spectralcoclust": [2, 57, 59, 413, 459, 1043, 1048, 1052], "spectralembed": [2, 87, 240, 241, 242, 696, 697, 698, 700, 997, 1042, 1047, 1051, 1055, 1056, 1058], "spectrum": [107, 532, 552, 703, 949, 1024, 1030, 1049], "speech": [424, 1000], "speed": [81, 82, 92, 104, 128, 137, 145, 188, 193, 206, 209, 213, 257, 299, 330, 339, 360, 362, 375, 386, 389, 395, 398, 400, 412, 414, 416, 421, 423, 424, 427, 451, 452, 455, 456, 457, 458, 460, 465, 467, 468, 469, 470, 539, 540, 618, 635, 640, 641, 642, 647, 654, 655, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 672, 689, 692, 700, 805, 806, 814, 836, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 887, 949, 989, 992, 997, 999, 1001, 1014, 1024, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "speedi": 373, "speedup": [335, 373, 421, 423, 658, 662, 665, 1041, 1042, 1043, 1044, 1056], "speer": 1043, "spell": 424, "spend": 424, "spent": [299, 325, 387, 392, 836, 1056], "sperret6": 1059, "sphere": [139, 189, 239, 240, 243, 244, 245, 361, 422, 527, 597, 696, 697, 698, 699, 700, 772, 935, 994, 998, 1003, 1021], "sphere_data": 242, "sphereclust": 1019, "spheric": [70, 92, 117, 156, 242, 265, 267, 268, 312, 382, 772, 805, 806, 996, 999, 1003, 1019], "sphinx": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 374, 390, 400, 404, 409, 1034, 1041, 1048], "sphinxcontrib": [386, 404, 409], "sphinxext": [386, 404, 409], "sphx_glr_auto_examples_mlcomp_sparse_document_classif": 1041, "spidlen": [700, 997], "spie": [174, 383], "spielman": 1051, "spike": 193, "spikebh": 1055, "spikhalskii": 1046, "spiki": 43, "spin": 394, "spine": [46, 54, 70, 231, 319], "spirit": 421, "spite": 1002, "spline": [2, 189, 198, 199, 293, 304, 524, 525, 526, 680, 873, 887, 891, 1019, 1021, 1054], "spline_": 43, "splines_df": 43, "splinetransform": [2, 43, 221, 257, 331, 887, 1010, 1054, 1056, 1057], "split": [2, 43, 44, 45, 50, 52, 54, 55, 61, 63, 64, 67, 68, 104, 130, 139, 144, 145, 146, 148, 150, 151, 152, 153, 154, 155, 156, 165, 170, 191, 192, 195, 204, 215, 216, 220, 223, 228, 238, 248, 257, 264, 265, 271, 272, 273, 276, 278, 283, 285, 288, 292, 296, 302, 308, 314, 316, 320, 321, 326, 332, 334, 341, 349, 360, 362, 368, 381, 393, 399, 400, 404, 407, 414, 415, 416, 421, 423, 424, 425, 445, 450, 451, 480, 481, 487, 488, 505, 539, 545, 547, 550, 554, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 596, 597, 599, 602, 610, 655, 659, 661, 663, 669, 671, 673, 681, 683, 703, 712, 713, 725, 739, 745, 765, 803, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 843, 846, 852, 853, 869, 870, 893, 897, 898, 900, 901, 902, 903, 920, 921, 922, 923, 971, 989, 992, 996, 997, 1003, 1006, 1007, 1008, 1010, 1014, 1016, 1020, 1025, 1029, 1030, 1032, 1033, 1034, 1036, 1041, 1044, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "split0_test_precis": [808, 822], "split0_test_scor": [808, 822, 1047], "split0_train_scor": [808, 822, 1047], "split1_test_scor": [808, 822], "split1_train_scor": [808, 822], "split2_test_scor": 808, "split_cod": 421, "split_sign": [539, 545, 550], "splitter": [43, 254, 334, 335, 400, 407, 420, 445, 480, 572, 573, 575, 576, 602, 610, 655, 659, 661, 663, 667, 669, 671, 673, 681, 683, 808, 810, 811, 812, 813, 814, 822, 823, 824, 827, 828, 831, 832, 833, 834, 835, 836, 837, 839, 843, 846, 920, 921, 922, 923, 1016, 1020, 1047, 1048, 1049, 1050, 1057, 1058, 1059, 1060], "splot": [264, 269], "splt": 221, "sply88": 1055, "spmatrix": 1058, "spolski": 424, "sport": [57, 381], "spot": [88, 249, 416], "spottabl": 392, "spread": [43, 75, 242, 279, 319, 338, 339, 340, 343, 356, 373, 386, 416, 460, 470, 523, 889, 901, 909, 1000], "spring": [43, 52, 193], "springer": [142, 143, 154, 181, 277, 414, 416, 420, 421, 423, 528, 543, 567, 568, 698, 702, 704, 713, 728, 734, 748, 749, 764, 805, 920, 921, 997, 1000, 1001, 1007, 1016], "sprint": [385, 386, 1041], "spuriou": [349, 394, 1010, 1054, 1055, 1056], "spy": 214, "sq": 777, "sqeuclidean": [73, 458, 465, 786, 787, 788], "sqft": 257, "sql": 380, "sqr": 75, "sqrt": [51, 113, 114, 115, 128, 134, 143, 165, 195, 199, 201, 243, 245, 259, 263, 264, 265, 268, 269, 278, 354, 356, 416, 423, 424, 426, 471, 477, 478, 479, 480, 481, 482, 483, 484, 546, 548, 555, 565, 566, 567, 568, 572, 573, 627, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 707, 739, 771, 772, 777, 892, 905, 920, 921, 922, 923, 992, 996, 997, 1000, 1002, 1012, 1055], "squar": [2, 43, 44, 52, 96, 105, 112, 113, 114, 116, 117, 126, 127, 135, 142, 153, 155, 156, 174, 176, 181, 189, 191, 192, 198, 199, 201, 202, 204, 209, 210, 216, 220, 222, 225, 230, 237, 238, 250, 251, 253, 266, 293, 323, 330, 331, 333, 346, 360, 378, 383, 386, 392, 395, 400, 416, 418, 419, 421, 422, 423, 427, 428, 439, 448, 450, 451, 452, 454, 455, 457, 458, 462, 465, 467, 468, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 509, 539, 545, 547, 549, 551, 553, 554, 555, 557, 560, 562, 564, 566, 567, 568, 570, 573, 576, 578, 598, 599, 600, 603, 604, 606, 607, 608, 612, 613, 614, 617, 619, 623, 630, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 677, 678, 679, 680, 681, 682, 683, 684, 686, 687, 688, 690, 691, 693, 694, 695, 696, 698, 700, 702, 704, 717, 729, 730, 731, 732, 758, 759, 766, 767, 771, 777, 778, 793, 798, 799, 838, 845, 846, 854, 855, 858, 859, 860, 862, 863, 870, 873, 892, 912, 913, 915, 917, 918, 919, 921, 923, 947, 973, 986, 991, 993, 994, 1003, 1004, 1008, 1014, 1016, 1021, 1022, 1032, 1033, 1036, 1041, 1044, 1046, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1057, 1058], "square_dist": 1053, "squared_epsilon_insensit": [675, 684, 686, 913, 996, 1047], "squared_error": [46, 52, 134, 152, 153, 331, 423, 566, 567, 568, 570, 573, 679, 684, 686, 701, 921, 923, 1014, 1016, 1054, 1057, 1058], "squared_hing": [227, 356, 674, 684, 912, 919, 996, 1015], "squared_loss": [398, 1054], "squareform": 195, "squash": [257, 390, 426, 539, 545, 550, 556], "squeez": [109, 182, 183, 257, 299, 319, 1033], "sr": 1024, "sr_color": 244, "sr_err": 244, "sr_lle": 244, "sr_point": 244, "sr_tsne": 244, "srajan": 1049, "sre": 1056, "srebro": 1014, "srep30750": 416, "sri": [679, 996, 1048, 1049], "sridharan": 1046, "sriharsha": [1049, 1050], "srikantan": 996, "srimukh": 1053, "srinath": [1055, 1056], "srinivasan": [1049, 1052], "sripada": 1053, "srivastava": [1044, 1056, 1059], "srivatsan": [1047, 1048, 1051], "srvanrel": 1047, "ss": 420, "sse": 451, "sseg": 1046, "ssrn": [220, 238], "sss": 828, "ssvm": 398, "st": [82, 102, 278, 333, 1044, 1047, 1049], "st30": 343, "st50": 343, "st_pipelin": 342, "sta4273": 652, "stabil": [72, 143, 150, 192, 241, 283, 319, 356, 361, 400, 413, 454, 658, 662, 678, 850, 869, 870, 888, 900, 948, 990, 996, 999, 1010, 1020, 1025, 1041, 1045, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056], "stabilis": 199, "stabl": [43, 64, 185, 192, 214, 218, 222, 299, 329, 356, 361, 384, 386, 390, 392, 395, 400, 404, 420, 424, 428, 479, 480, 486, 541, 549, 663, 680, 682, 695, 700, 732, 760, 948, 949, 996, 1002, 1003, 1010, 1020, 1037, 1041, 1042, 1047, 1052, 1054, 1058], "stack": [2, 14, 109, 138, 149, 163, 187, 189, 220, 249, 304, 368, 385, 394, 398, 400, 422, 472, 474, 475, 504, 523, 570, 573, 575, 576, 620, 635, 636, 638, 661, 681, 709, 833, 835, 873, 877, 885, 886, 892, 974, 990, 1019, 1020, 1021, 1022, 1023, 1036, 1041, 1044, 1048, 1049, 1050, 1051, 1052], "stack_method": [423, 575], "stack_method_": [423, 575, 576], "stacking_regressor": 160, "stackingclassifi": [2, 328, 369, 400, 407, 423, 576, 990, 1051, 1052, 1053, 1054, 1055, 1056, 1058, 1060], "stackingregressor": [2, 160, 328, 400, 407, 423, 575, 990, 1051, 1052, 1053, 1054, 1055, 1058, 1060], "stackingregressorinot": 160, "stackoverflow": [391, 394, 398], "stade": 1045, "stage": [0, 46, 63, 106, 139, 144, 150, 153, 272, 384, 390, 400, 412, 416, 423, 456, 561, 562, 567, 568, 569, 570, 596, 597, 599, 610, 997, 1010, 1018, 1049, 1053], "staged_decision_funct": [561, 567, 569], "staged_predict": [139, 150, 153, 423, 561, 562, 567, 568, 569, 570, 1041, 1053], "staged_predict_proba": [151, 154, 561, 567, 569, 1041], "staged_scor": [561, 562], "stagewis": 139, "stagg": 1054, "stai": [43, 52, 63, 72, 134, 192, 361, 385, 386, 390, 400, 401, 1005, 1023, 1047], "stairstep": 285, "stalei": [1050, 1051], "stall": [385, 389], "stallei": 1053, "stan": [850, 1058], "stand": [281, 362, 390, 398, 421, 539, 545, 553, 554, 604, 617, 686, 713, 725, 744, 745, 765, 794, 796, 803, 999, 1000, 1006], "standalon": [392, 666, 912], "standard": [2, 50, 51, 52, 58, 63, 68, 70, 90, 96, 104, 105, 107, 113, 114, 118, 126, 139, 142, 144, 145, 146, 147, 148, 156, 160, 174, 176, 181, 183, 185, 192, 199, 205, 209, 218, 220, 229, 240, 241, 242, 252, 257, 268, 272, 273, 276, 277, 278, 279, 281, 319, 324, 347, 360, 373, 374, 378, 379, 380, 382, 383, 384, 386, 388, 389, 391, 392, 395, 398, 400, 404, 410, 412, 416, 418, 419, 420, 424, 426, 454, 476, 480, 496, 504, 509, 518, 519, 520, 521, 522, 524, 525, 526, 527, 528, 530, 532, 533, 538, 540, 543, 549, 560, 598, 602, 619, 642, 652, 653, 680, 681, 682, 683, 684, 686, 695, 697, 701, 796, 814, 829, 831, 849, 852, 853, 854, 855, 856, 858, 860, 861, 862, 863, 864, 865, 866, 876, 881, 882, 885, 888, 889, 890, 892, 900, 901, 902, 903, 910, 912, 913, 932, 989, 992, 996, 997, 1000, 1002, 1003, 1004, 1006, 1014, 1015, 1020, 1024, 1025, 1030, 1032, 1033, 1034, 1036, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1059], "standard_coef_": 1052, "standard_intercept_": 1052, "standard_norm": [369, 695], "standard_scal": 259, "standard_t": 127, "standardscal": [2, 45, 49, 67, 79, 84, 90, 93, 97, 105, 107, 118, 135, 160, 174, 192, 199, 208, 209, 211, 220, 236, 238, 248, 249, 257, 258, 259, 261, 272, 275, 285, 292, 302, 307, 308, 314, 321, 324, 328, 329, 331, 332, 333, 335, 336, 349, 352, 369, 375, 386, 388, 391, 395, 399, 417, 420, 437, 474, 475, 575, 684, 686, 872, 873, 876, 889, 903, 912, 913, 914, 915, 917, 918, 990, 997, 1004, 1010, 1014, 1015, 1017, 1030, 1043, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1057], "standardscalerifittedstandardscal": 261, "standardscalerstandardscal": [105, 160, 192, 248, 249, 258, 259, 261, 272, 285, 292, 329, 332], "standpoint": 85, "stanford": [174, 383, 657, 690, 691, 847, 850, 851, 905, 998], "stanislav": [1056, 1057], "stanlei": [1055, 1056, 1057], "stap": 1049, "stapl": 1045, "star": [70, 123, 163, 386], "stareh": 1052, "start": [0, 43, 46, 49, 51, 52, 58, 63, 88, 93, 99, 102, 108, 118, 128, 144, 150, 152, 171, 174, 181, 183, 193, 197, 200, 201, 209, 220, 221, 222, 228, 238, 240, 244, 252, 254, 266, 272, 278, 286, 299, 332, 334, 339, 360, 368, 369, 373, 374, 375, 379, 386, 387, 388, 390, 391, 392, 398, 400, 404, 413, 416, 420, 421, 425, 426, 448, 450, 458, 462, 464, 546, 618, 625, 640, 653, 661, 667, 674, 675, 676, 684, 685, 686, 698, 702, 789, 790, 797, 805, 806, 808, 811, 812, 822, 854, 855, 856, 858, 860, 868, 954, 984, 989, 996, 999, 1004, 1005, 1014, 1020, 1024, 1025, 1033, 1034, 1044, 1046, 1049, 1051, 1053, 1054, 1055, 1056, 1057], "start_": 47, "start_bodi": 47, "start_d": 47, "start_idx": [51, 243], "start_reut": 47, "start_tim": [46, 49, 57, 146, 147, 150, 160, 176, 209, 241], "start_titl": 47, "start_top": 47, "startstart": 1027, "startswith": [52, 104, 241, 312], "startup": 1024, "stat": [2, 45, 47, 49, 104, 113, 174, 176, 195, 275, 278, 286, 290, 304, 330, 338, 339, 383, 395, 399, 418, 482, 600, 603, 604, 606, 607, 608, 612, 613, 614, 617, 690, 691, 812, 820, 822, 920, 921, 951, 989, 996, 1010, 1030, 1048, 1050, 1054], "state": [37, 88, 92, 104, 106, 113, 155, 222, 251, 259, 264, 272, 284, 330, 369, 374, 375, 386, 388, 392, 394, 398, 400, 401, 415, 423, 424, 429, 448, 451, 455, 457, 462, 467, 483, 552, 597, 687, 811, 812, 820, 822, 824, 852, 853, 859, 907, 908, 935, 989, 990, 996, 1002, 1005, 1012, 1019, 1020, 1024, 1043, 1045, 1047, 1049, 1051, 1054, 1057], "state_to_print": 387, "stateless": [104, 361, 375, 388, 400, 424, 590, 591, 597, 646, 875, 876, 884, 1010, 1057], "statement": [192, 388, 391, 394, 398, 400, 421, 1034], "static": [386, 388, 392, 394, 654, 655, 660, 661, 668, 669, 670, 671], "station": 181, "stationari": [180, 426, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633], "statist": [2, 47, 52, 114, 139, 142, 143, 154, 165, 166, 167, 169, 173, 174, 189, 191, 192, 193, 194, 204, 208, 224, 270, 272, 275, 277, 280, 287, 296, 298, 319, 325, 330, 369, 379, 381, 383, 386, 392, 400, 414, 415, 416, 417, 418, 420, 421, 423, 425, 441, 477, 482, 501, 502, 524, 525, 526, 528, 530, 549, 561, 567, 568, 570, 612, 613, 614, 617, 635, 638, 642, 643, 652, 657, 664, 698, 702, 704, 718, 724, 729, 731, 732, 739, 751, 796, 808, 824, 842, 869, 870, 888, 889, 890, 892, 897, 900, 901, 903, 917, 920, 921, 975, 989, 990, 994, 996, 997, 999, 1000, 1001, 1002, 1007, 1008, 1010, 1014, 1015, 1016, 1017, 1018, 1021, 1026, 1032, 1033, 1046, 1049, 1052, 1053, 1055, 1056, 1059], "statistician": [400, 892], "statistics_": 638, "statisticyearmonthhourweekdaytempfeel_temphumiditywindspeedcountstrf64f64f64f64f64f64f64f64f64": 52, "statlearnspars": [729, 731, 732], "statlib": 381, "statnikov": 1000, "statsmodel": [996, 1019], "statu": [137, 185, 335, 380, 390, 404, 504, 852, 853, 1059], "statweb": [657, 690, 691], "staub": 1047, "staubda": 1044, "std": [43, 50, 51, 52, 72, 81, 85, 89, 96, 101, 112, 114, 115, 126, 127, 128, 146, 148, 149, 155, 160, 185, 187, 188, 192, 200, 205, 229, 251, 276, 277, 278, 280, 281, 283, 286, 288, 292, 293, 325, 341, 352, 361, 369, 400, 416, 420, 423, 523, 614, 617, 837, 892, 903, 1010, 1029, 1033, 1049, 1053], "std_": [282, 1046], "std_auc": 288, "std_display_styl": [253, 280, 814, 831], "std_error": 165, "std_fit_tim": [145, 301, 808, 822], "std_i": 192, "std_precis": 276, "std_predict": 183, "std_predictions_gpr": 176, "std_recal": 276, "std_scaler": 336, "std_score": [361, 1054], "std_score_tim": [145, 279, 808, 822], "std_test_precis": 276, "std_test_recal": 276, "std_test_scor": [105, 107, 145, 165, 173, 277, 278, 279, 286, 301, 480, 602, 808, 822, 1047, 1054], "std_time": 1047, "std_tpr": 288, "std_train_scor": [808, 822, 1047], "std_y_pr": 181, "stderr": [51, 841], "stdin": [394, 1034], "stdout": [47, 125, 228, 841, 861, 869, 870], "stds_california": 188, "stds_diabet": 188, "steadi": [907, 908], "steelblu": [126, 127, 162], "steep": [2, 177, 193, 287, 288, 416, 420, 426, 458, 464], "stef": [635, 990], "stefan": [1044, 1045, 1049, 1051], "stefani": [0, 1054, 1056, 1057, 1058, 1059, 1060], "stefanini": 1055, "stefano": 1043, "stehl": [1055, 1056], "stein": 1047, "steinbach": [416, 1056, 1058], "steinfurt": [1051, 1053], "steingold": [1048, 1049], "steinlei": [416, 713], "steinley2004": 713, "stella": [416, 460, 470], "stellalin7": 1056, "stem": [142, 150, 194, 219, 269, 420, 424, 992, 1002], "step": [58, 63, 69, 77, 89, 90, 93, 102, 104, 105, 106, 107, 108, 114, 118, 128, 132, 139, 144, 148, 149, 150, 160, 171, 172, 173, 178, 181, 192, 194, 220, 228, 238, 248, 249, 252, 258, 261, 269, 272, 276, 279, 285, 287, 292, 299, 301, 302, 307, 314, 317, 321, 324, 325, 329, 332, 343, 345, 349, 361, 362, 364, 369, 373, 381, 384, 385, 386, 388, 390, 391, 394, 398, 400, 410, 413, 414, 416, 418, 419, 421, 423, 424, 425, 450, 455, 457, 544, 545, 546, 547, 554, 571, 596, 597, 599, 601, 602, 605, 614, 635, 652, 656, 674, 675, 677, 684, 686, 687, 688, 702, 708, 805, 806, 808, 811, 812, 822, 843, 844, 845, 846, 868, 869, 870, 872, 873, 875, 912, 913, 914, 915, 917, 918, 948, 949, 971, 975, 990, 996, 999, 1004, 1005, 1010, 1014, 1016, 1017, 1019, 1023, 1030, 1034, 1041, 1045, 1046, 1048, 1049, 1050, 1052, 1053, 1054, 1057, 1059], "stephan": [716, 1044, 1050, 1051, 1053], "stephani": 1052, "stephen": [1024, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1054], "stepwis": [155, 643, 662, 663, 664, 690, 691, 996], "stern": [796, 1000], "steve": [1043, 1045, 1049, 1054, 1056], "steven": [1043, 1044, 1046, 1048, 1049, 1054, 1056, 1057, 1059], "steward": 1048, "stewart": [1046, 1051, 1054, 1056, 1059], "stick": [48, 805, 999], "stijn": 1048, "stikhin": 1051, "still": [43, 52, 64, 68, 79, 88, 90, 92, 97, 115, 121, 129, 147, 152, 155, 160, 176, 182, 191, 192, 194, 195, 199, 204, 220, 222, 238, 252, 281, 287, 319, 330, 331, 334, 360, 361, 369, 375, 380, 385, 386, 388, 390, 391, 392, 394, 400, 416, 420, 423, 424, 427, 448, 452, 462, 482, 504, 635, 640, 643, 645, 666, 667, 725, 764, 786, 789, 800, 801, 811, 812, 825, 828, 890, 892, 912, 930, 989, 990, 994, 996, 999, 1000, 1003, 1006, 1008, 1015, 1016, 1018, 1020, 1023, 1024, 1041, 1043, 1046, 1047, 1049, 1050, 1051, 1054, 1055, 1056, 1057, 1059, 1060], "stine": [1049, 1050], "stochast": [2, 46, 93, 150, 151, 154, 166, 189, 197, 198, 208, 242, 244, 247, 252, 305, 307, 308, 313, 316, 331, 348, 416, 421, 423, 470, 496, 504, 510, 511, 512, 522, 530, 544, 552, 567, 568, 612, 635, 639, 647, 666, 667, 676, 680, 682, 684, 685, 686, 687, 695, 696, 697, 698, 700, 838, 861, 868, 869, 870, 873, 882, 916, 948, 949, 974, 989, 1003, 1004, 1006, 1021, 1022, 1035, 1036, 1041, 1042, 1045, 1046, 1048, 1050, 1052], "stochastic_gradi": [1043, 1044, 1050], "stock": [42, 81, 189, 240, 241, 416, 418, 462, 480, 697, 1021, 1028], "stogbauer": [615, 616], "stojanov": [1055, 1056], "stolbunov": 1046, "stone": [386, 920, 921, 1016], "stop": [43, 46, 51, 55, 79, 97, 138, 139, 145, 181, 183, 189, 193, 198, 208, 222, 323, 329, 386, 388, 394, 395, 400, 416, 421, 423, 425, 448, 449, 451, 453, 455, 457, 460, 462, 470, 471, 479, 480, 486, 490, 491, 492, 498, 504, 516, 517, 540, 544, 545, 546, 547, 548, 551, 553, 554, 555, 561, 562, 565, 566, 567, 568, 569, 570, 572, 573, 596, 597, 599, 610, 625, 635, 652, 653, 654, 656, 657, 660, 664, 666, 667, 674, 675, 676, 677, 679, 684, 685, 686, 688, 699, 700, 703, 722, 758, 805, 806, 838, 869, 870, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 954, 974, 989, 996, 1004, 1005, 1015, 1016, 1020, 1021, 1022, 1024, 1036, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1055, 1056, 1057, 1058], "stop_n_inli": [679, 996], "stop_prob": 679, "stop_scor": [679, 996], "stop_word": [54, 57, 360, 361, 424, 596, 597, 599], "stop_words_": 1059, "stopiter": 1053, "stopword": [497, 1034], "storag": [0, 362, 400, 666, 667, 674, 675, 676, 684, 685, 686, 912, 1003, 1015, 1044, 1049], "storch": 1050, "store": [2, 68, 88, 89, 104, 106, 114, 121, 171, 184, 197, 206, 209, 224, 241, 248, 258, 268, 272, 283, 287, 338, 362, 368, 373, 380, 381, 386, 388, 393, 394, 395, 398, 400, 410, 412, 417, 419, 421, 423, 424, 426, 427, 446, 448, 452, 454, 458, 465, 472, 475, 477, 478, 481, 482, 483, 484, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 511, 516, 542, 543, 549, 557, 558, 563, 564, 565, 566, 571, 572, 573, 574, 577, 578, 597, 618, 619, 635, 639, 640, 643, 657, 658, 662, 668, 669, 670, 671, 674, 675, 681, 683, 684, 685, 686, 696, 697, 698, 700, 705, 706, 708, 709, 710, 789, 805, 806, 808, 814, 822, 830, 831, 852, 853, 854, 855, 856, 858, 860, 861, 862, 863, 864, 867, 883, 890, 892, 893, 907, 908, 909, 932, 933, 957, 958, 971, 974, 986, 990, 992, 996, 1003, 1012, 1015, 1016, 1019, 1025, 1034, 1038, 1041, 1042, 1043, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "store_cent": [454, 1058], "store_covari": [70, 557, 558, 1046, 1048], "store_cv_result": [272, 681, 683, 830, 1059], "store_cv_valu": [681, 683, 1049, 1052, 1059], "store_precis": [69, 112, 477, 478, 481, 482, 483, 484], "stori": [191, 278, 296, 381, 999], "stork": 994, "stott": 1049, "stoyanov": [1049, 1050], "str": [47, 49, 52, 93, 95, 133, 135, 148, 172, 238, 257, 278, 290, 299, 309, 347, 360, 380, 381, 395, 424, 427, 428, 432, 437, 445, 446, 447, 449, 450, 451, 452, 453, 454, 455, 457, 458, 460, 465, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 535, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 584, 589, 590, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 625, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 700, 704, 705, 706, 707, 708, 710, 715, 717, 719, 721, 735, 737, 738, 740, 741, 746, 750, 779, 782, 786, 787, 788, 789, 790, 791, 792, 795, 797, 800, 801, 807, 808, 809, 810, 811, 812, 814, 815, 817, 819, 820, 822, 826, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 928, 931, 932, 933, 936, 939, 941, 945, 956, 957, 958, 960, 963, 984, 985, 988, 1056], "strai": 1005, "straight": [130, 210, 216, 218, 275, 353, 373], "straightforward": [320, 385, 415, 421, 1024], "straka": 1053, "strateg": 401, "strategi": [2, 30, 43, 52, 87, 89, 93, 96, 105, 149, 154, 155, 160, 166, 171, 173, 187, 188, 189, 194, 204, 209, 220, 228, 238, 249, 257, 259, 270, 272, 277, 279, 281, 282, 283, 285, 286, 287, 288, 290, 292, 298, 313, 316, 318, 320, 321, 325, 326, 328, 329, 332, 362, 372, 388, 392, 399, 400, 410, 415, 420, 423, 424, 425, 428, 445, 446, 447, 455, 460, 470, 480, 510, 512, 520, 522, 530, 541, 546, 559, 560, 569, 570, 572, 573, 575, 576, 596, 597, 599, 600, 602, 610, 635, 636, 638, 642, 653, 655, 659, 661, 663, 669, 671, 673, 681, 683, 699, 703, 712, 719, 721, 740, 763, 765, 803, 808, 811, 812, 814, 822, 825, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 844, 845, 869, 870, 877, 882, 893, 907, 912, 914, 917, 920, 921, 922, 923, 971, 989, 990, 999, 1001, 1002, 1003, 1004, 1006, 1008, 1010, 1014, 1015, 1016, 1019, 1021, 1029, 1034, 1036, 1044, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1059], "stratif": [809, 810, 816, 817, 826, 827, 828, 971, 1050], "stratifi": [2, 44, 130, 146, 156, 170, 194, 235, 248, 257, 261, 272, 273, 278, 281, 287, 302, 307, 308, 328, 388, 400, 415, 559, 567, 575, 576, 610, 667, 674, 676, 684, 807, 808, 811, 812, 814, 822, 823, 824, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 843, 846, 861, 869, 971, 1000, 1003, 1029, 1046, 1047, 1048, 1050, 1051, 1054], "stratifiedgroupkfold": [2, 273, 1054], "stratifiedkfold": [2, 173, 265, 273, 284, 288, 341, 420, 445, 575, 576, 602, 610, 667, 681, 808, 809, 811, 812, 813, 814, 816, 818, 822, 826, 828, 831, 832, 833, 834, 835, 836, 837, 839, 893, 1029, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1054], "stratifiedshufflesplit": [2, 273, 349, 420, 1029, 1041, 1042, 1047, 1048, 1054], "stream": [47, 416, 421, 424, 470, 597, 881, 882, 892, 992, 1019, 1049, 1052], "stream_reuters_docu": 47, "streamhandl": 1052, "streamlin": 996, "street": [160, 174, 383], "strehl": 416, "strength": [51, 160, 183, 220, 224, 279, 328, 373, 419, 423, 454, 575, 576, 651, 656, 657, 660, 666, 667, 677, 680, 681, 682, 683, 684, 686, 688, 695, 791, 869, 870, 912, 913, 917, 918, 989, 996, 1003, 1006, 1014, 1015], "stress": [698, 702, 997, 1056], "stress_": 698, "stretch": [244, 267], "stretched_gaussian": 267, "strickland": 1047, "strict": [369, 384, 400, 412, 421, 511, 543, 596, 597, 599, 996, 1041, 1050, 1053, 1059], "stricter": 187, "strictli": [64, 220, 238, 254, 319, 334, 361, 391, 400, 414, 419, 421, 424, 516, 517, 543, 549, 552, 569, 570, 596, 599, 650, 678, 679, 681, 683, 703, 708, 747, 774, 808, 811, 812, 818, 822, 835, 861, 888, 900, 904, 905, 907, 908, 912, 913, 917, 918, 947, 989, 991, 996, 1000, 1010, 1014, 1042, 1052, 1057], "striebel": [1047, 1048], "strife": 997, "strike": [150, 193, 224], "string": [2, 47, 105, 148, 184, 238, 249, 272, 282, 331, 336, 362, 373, 380, 381, 386, 387, 388, 392, 400, 417, 420, 423, 424, 425, 427, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 497, 498, 504, 513, 535, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 589, 590, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 625, 628, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 707, 717, 719, 727, 740, 770, 773, 779, 782, 786, 787, 788, 789, 800, 801, 805, 806, 808, 811, 812, 814, 822, 830, 831, 835, 840, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 930, 932, 933, 940, 941, 942, 964, 984, 985, 989, 990, 1000, 1013, 1015, 1025, 1032, 1041, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "strip": [54, 238, 361, 373, 380, 381, 504], "strip_acc": [596, 597, 599], "strip_accents_unicod": 1051, "stripe": 322, "stripplot": 192, "strive": [385, 401, 1024], "strong": [32, 43, 52, 89, 176, 189, 191, 192, 198, 213, 217, 218, 224, 225, 226, 253, 298, 326, 356, 414, 421, 423, 532, 657, 680, 993, 994, 996, 997, 999, 1007, 1015, 1021, 1032], "stronger": [279, 651, 660, 666, 667, 680, 681, 682, 683, 684, 686, 695], "strongest": [55, 213], "strongli": [62, 64, 115, 118, 128, 149, 153, 192, 202, 235, 254, 284, 360, 386, 403, 404, 414, 423, 666, 744, 803, 996, 997, 1036, 1050, 1057], "stroudsburg": [909, 1013], "strubel": 1054, "struct": [384, 400, 1044], "structur": [0, 2, 42, 47, 48, 52, 53, 54, 55, 58, 59, 71, 75, 76, 78, 79, 81, 87, 88, 89, 90, 91, 97, 101, 115, 135, 137, 156, 175, 189, 240, 241, 244, 249, 254, 269, 273, 284, 304, 324, 329, 332, 337, 349, 353, 363, 364, 365, 373, 381, 383, 386, 388, 391, 398, 400, 401, 404, 413, 416, 418, 419, 420, 421, 423, 424, 425, 426, 449, 450, 453, 454, 458, 459, 460, 461, 462, 465, 470, 471, 480, 504, 511, 512, 516, 519, 521, 522, 529, 538, 543, 549, 552, 571, 618, 619, 620, 624, 625, 626, 697, 704, 717, 721, 838, 860, 865, 892, 904, 905, 908, 920, 921, 922, 923, 926, 948, 949, 971, 974, 997, 999, 1000, 1003, 1005, 1006, 1010, 1013, 1016, 1019, 1020, 1021, 1028, 1033, 1034, 1041, 1042, 1044, 1045, 1047, 1051], "struggl": [385, 401, 416], "stuck": [96, 700, 997], "student": [0, 127, 278, 997, 1020, 1024], "studi": [43, 64, 95, 152, 220, 238, 281, 284, 285, 292, 360, 381, 383, 420, 425, 704, 716, 766, 767, 837, 998, 1000, 1014, 1025], "studio": [384, 1024], "study_135": 380, "study_14": 380, "study_34": 380, "study_98": 380, "study_99": 380, "stuff": 1024, "stump": [141, 423, 567, 1052], "stupp": [1047, 1048], "stupperich": 1053, "sturla": 1043, "style": [61, 63, 114, 152, 209, 228, 238, 282, 386, 393, 416, 424, 451, 455, 467, 708, 814, 831, 932, 933, 945, 1041, 1044, 1055], "st\u00e9fan": 387, "st\u00e9phan": 1051, "st\u00e9phane": [1050, 1051, 1055, 1056], "su": [729, 731, 732], "sub": [47, 72, 83, 88, 90, 92, 95, 104, 134, 254, 256, 263, 330, 338, 339, 346, 349, 357, 381, 386, 388, 392, 400, 417, 423, 424, 445, 451, 452, 455, 457, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 541, 542, 544, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 596, 598, 599, 602, 605, 618, 619, 635, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 807, 809, 810, 815, 817, 826, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 871, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 958, 996, 1000, 1014, 1034, 1051, 1055, 1057, 1058], "sub_sampl": 544, "subclass": [137, 388, 426, 582, 966, 1046, 1049, 1054, 1058], "subclust": [416, 450], "subcluster_centers_": [77, 450], "subcluster_labels_": 450, "subcompon": [125, 421], "subdirectori": 386, "subdivid": [381, 426], "subestim": 388, "subestimator__c": 388, "subestimator__class_weight": 388, "subestimator__du": 388, "subestimator__fit_intercept": 388, "subestimator__intercept_sc": 388, "subestimator__l1_ratio": 388, "subestimator__max_it": 388, "subestimator__multi_class": 388, "subestimator__n_job": 388, "subestimator__penalti": 388, "subestimator__random_st": 388, "subestimator__solv": 388, "subestimator__tol": 388, "subestimator__verbos": 388, "subestimator__warm_start": 388, "subexpress": 52, "subfold": [2, 384, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 511, 1054], "subgraph": 413, "subhash": 1055, "subhodeep": [1041, 1042, 1043], "subi": [1050, 1051, 1056], "subject": [16, 104, 157, 269, 281, 360, 381, 386, 388, 390, 398, 400, 401, 414, 418, 420, 421, 503, 666, 667, 693, 830, 875, 970, 991, 996, 1015, 1018, 1034, 1050, 1051, 1054, 1056], "subject_body_extractor": 104, "subject_body_transform": 104, "subjectbodi": 104, "subjectbodyextractor": 104, "sublinear": [421, 598, 599], "sublinear_tf": [360, 421, 424, 598, 599], "submatric": 413, "submatrix": [413, 431, 459, 461], "submit": [383, 384, 385, 388, 389, 390, 391, 394, 400, 401, 404], "submitt": 385, "submodel": 420, "submodul": [390, 392, 992, 998, 1041], "subobject": [430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 811, 812, 822, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923], "suboptim": [420, 708, 710, 790, 797, 1003, 1049, 1057], "subpackag": [386, 390, 1045, 1050], "subplot": [43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 66, 67, 68, 70, 74, 78, 79, 85, 86, 88, 89, 90, 91, 92, 95, 97, 100, 101, 107, 109, 112, 113, 114, 115, 117, 118, 121, 122, 123, 125, 126, 127, 128, 130, 134, 135, 139, 141, 142, 144, 145, 146, 148, 149, 150, 153, 155, 157, 158, 160, 161, 162, 169, 178, 180, 185, 187, 188, 192, 193, 195, 197, 200, 203, 211, 212, 214, 215, 218, 219, 220, 221, 222, 224, 228, 233, 234, 236, 238, 240, 241, 244, 245, 247, 248, 250, 252, 253, 255, 256, 257, 258, 263, 264, 265, 266, 268, 269, 272, 273, 274, 275, 278, 280, 281, 283, 284, 285, 287, 288, 289, 291, 292, 293, 298, 299, 301, 302, 303, 304, 307, 308, 310, 311, 312, 314, 315, 316, 317, 320, 321, 322, 323, 324, 325, 328, 332, 333, 341, 343, 346, 347, 348, 349, 353, 355, 356, 357, 358, 360, 361, 362, 364, 365, 393, 1030], "subplot_kw": [240, 303], "subplot_spec": 393, "subplot_titl": 145, "subplots_adjust": [45, 46, 53, 54, 74, 77, 79, 80, 85, 86, 89, 97, 99, 113, 115, 122, 123, 127, 128, 134, 141, 142, 160, 192, 219, 220, 235, 238, 247, 255, 263, 265, 266, 269, 273, 289, 291, 304, 312, 314, 317, 321, 330, 339, 346, 349, 1030], "subpopul": [237, 687, 996], "subproblem": 1046, "subrahmanyam": [1041, 1044], "subramaniam": [1056, 1057, 1058], "subramaniyan": 1053, "subramanyam": 1048, "subrat": 1053, "subrat93": 1053, "subsampl": [134, 151, 154, 193, 237, 274, 326, 330, 466, 567, 568, 569, 570, 571, 640, 687, 709, 811, 812, 838, 877, 889, 901, 928, 938, 992, 996, 1020, 1041, 1051, 1055, 1057, 1058, 1059], "subscrib": 1039, "subscript": [374, 1054], "subsect": [25, 374, 386], "subsembl": 1019, "subsequ": [46, 68, 93, 109, 128, 139, 171, 208, 222, 280, 283, 299, 301, 349, 369, 386, 388, 392, 400, 412, 416, 417, 423, 426, 445, 504, 516, 561, 562, 567, 569, 570, 674, 676, 684, 811, 812, 840, 841, 844, 847, 848, 849, 850, 851, 869, 887, 891, 990, 999, 1001, 1050, 1051, 1055, 1057, 1059], "subset": [2, 46, 57, 58, 63, 64, 68, 104, 105, 113, 114, 146, 148, 149, 150, 165, 171, 174, 193, 195, 209, 221, 235, 236, 237, 238, 250, 252, 256, 257, 272, 276, 279, 281, 287, 288, 290, 296, 324, 325, 330, 338, 342, 360, 361, 362, 369, 381, 386, 394, 398, 400, 413, 414, 416, 417, 420, 423, 424, 426, 433, 445, 457, 472, 474, 475, 477, 496, 497, 500, 501, 505, 516, 557, 558, 559, 561, 563, 564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 575, 577, 610, 618, 637, 647, 648, 649, 650, 659, 663, 666, 674, 675, 676, 679, 682, 683, 684, 685, 686, 687, 705, 711, 712, 719, 721, 724, 726, 739, 742, 763, 765, 801, 804, 807, 810, 830, 836, 838, 840, 841, 842, 843, 847, 848, 849, 850, 851, 854, 859, 862, 869, 878, 907, 908, 912, 914, 917, 920, 922, 928, 969, 989, 996, 1000, 1001, 1011, 1013, 1015, 1016, 1034, 1044, 1049, 1050, 1052, 1054, 1059, 1060], "subset_featur": 105, "subset_label": 238, "subset_mask": 294, "subsidi": 192, "subspac": [132, 419, 423, 460, 523, 563, 564, 699, 703, 949, 994, 1003, 1006, 1012, 1024, 1033], "substanti": [165, 301, 305, 306, 320, 386, 858, 1006, 1045, 1048], "substitut": [407, 984, 1020, 1047], "subtl": [358, 369, 999, 1020], "subtleti": 1036, "subtract": [181, 192, 257, 419, 421, 451, 455, 467, 542, 652, 653, 1048, 1058], "subtre": [565, 566, 567, 568, 572, 573, 920, 921, 922, 923, 1016], "subwindow": 1016, "succe": [132, 155, 204, 292], "succeed": 386, "success": [2, 85, 169, 189, 270, 282, 285, 286, 355, 369, 411, 416, 420, 421, 423, 523, 572, 587, 808, 811, 812, 829, 917, 1003, 1021, 1024, 1029, 1033, 1036, 1053], "successfulli": [43, 53, 323, 385, 390, 410, 416, 424, 1014], "successor": [458, 464, 1016, 1019], "suchak": 1054, "sudo": [384, 404], "suen": 1004, "suffer": [118, 147, 194, 299, 319, 361, 373, 416, 423, 552, 771, 995, 996, 1000, 1003, 1033, 1050], "suffic": [92, 93, 388, 1034], "suffici": [2, 64, 90, 160, 228, 293, 349, 373, 400, 416, 425, 540, 665, 690, 691, 827, 828, 1001, 1003, 1020, 1050, 1056, 1057], "suffix": [390, 404, 835, 1000, 1051], "suganthan": 383, "sugar": [174, 383], "suggest": [113, 128, 142, 146, 192, 195, 278, 349, 373, 385, 386, 393, 400, 420, 421, 423, 477, 482, 573, 653, 837, 994, 996, 997, 1005, 1008, 1015, 1034, 1045, 1052, 1055, 1058], "suh": 1049, "suha": 1059, "suit": [58, 125, 158, 192, 220, 221, 247, 268, 331, 332, 334, 360, 374, 386, 388, 391, 392, 394, 404, 410, 419, 421, 423, 458, 460, 511, 685, 849, 893, 943, 989, 992, 997, 1000, 1002, 1003, 1014, 1019, 1020, 1024, 1027, 1048, 1055], "suitabl": [143, 152, 204, 206, 224, 315, 362, 380, 381, 392, 395, 410, 416, 421, 424, 460, 470, 476, 495, 513, 516, 635, 643, 847, 848, 851, 886, 887, 910, 965, 969, 994, 996, 999, 1010, 1012, 1014, 1019, 1034, 1055, 1056], "sullivan": [1044, 1045, 1046], "sultan": 1055, "sum": [2, 30, 47, 55, 57, 63, 96, 114, 123, 128, 134, 151, 152, 170, 174, 184, 192, 201, 207, 216, 220, 224, 235, 238, 241, 243, 257, 272, 287, 299, 306, 309, 332, 336, 342, 353, 354, 356, 360, 361, 362, 368, 383, 392, 400, 413, 414, 416, 418, 419, 421, 422, 423, 424, 426, 439, 450, 451, 455, 457, 467, 472, 473, 490, 491, 492, 523, 528, 531, 539, 542, 544, 545, 549, 552, 553, 554, 557, 558, 560, 562, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 576, 577, 578, 598, 599, 619, 621, 631, 633, 643, 649, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 678, 680, 681, 684, 685, 686, 687, 689, 692, 698, 702, 704, 707, 717, 718, 727, 734, 749, 764, 766, 767, 771, 796, 840, 841, 845, 846, 855, 859, 863, 870, 871, 891, 892, 912, 913, 915, 918, 920, 921, 922, 923, 951, 975, 981, 986, 996, 1000, 1001, 1002, 1003, 1015, 1016, 1032, 1044, 1045, 1047, 1049, 1050, 1052, 1057, 1058], "sum_": [278, 287, 356, 413, 414, 416, 421, 422, 423, 546, 548, 555, 704, 763, 994, 996, 997, 1000, 1002, 1004, 1005, 1007, 1008, 1010, 1014, 1015, 1016], "sum_gradi": 423, "sum_h": 1005, "sum_hessian": 423, "sum_i": [331, 423, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 991, 992, 996, 998, 1000, 1005], "sum_j": [654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 996, 1000, 1005], "sum_k": [423, 557, 1016], "sum_m": 423, "sum_n": [285, 715, 1000], "sum_n_compon": [472, 871], "sum_over_featur": [1041, 1056], "sum_weight": 981, "sumit": 1055, "summar": [220, 269, 285, 287, 362, 386, 388, 403, 423, 529, 666, 702, 714, 715, 996, 997, 1000, 1006, 1036], "summari": [52, 174, 332, 368, 369, 383, 398, 700, 721, 796, 925, 998, 1001, 1019, 1034], "summaris": [249, 329], "summat": [1002, 1004], "summer": [0, 43, 52, 83, 181, 1041], "sun": [43, 155, 193, 1049, 1054, 1055], "sundai": 43, "sundaramahalingam": 1058, "sung": 1052, "sunglok": 996, "sunita": 791, "sunitha": 1053, "sunmi": 1052, "super": [57, 62, 64, 388, 424, 1049], "superflu": 421, "superimpos": 421, "superior": 423, "superposit": 204, "supersed": [385, 1046], "superset": [420, 829, 1000], "supervis": [2, 27, 32, 34, 38, 57, 62, 64, 67, 72, 84, 89, 93, 118, 133, 144, 155, 166, 167, 178, 241, 252, 255, 265, 278, 308, 330, 341, 346, 349, 353, 361, 362, 373, 381, 388, 399, 400, 414, 416, 419, 420, 421, 423, 424, 426, 445, 447, 472, 496, 511, 512, 561, 596, 598, 601, 602, 642, 684, 737, 809, 810, 813, 815, 816, 817, 818, 823, 824, 825, 826, 827, 828, 832, 833, 834, 835, 837, 838, 861, 871, 872, 876, 886, 893, 907, 908, 909, 917, 994, 997, 1000, 1002, 1003, 1006, 1010, 1011, 1015, 1016, 1017, 1019, 1020, 1021, 1023, 1025, 1026, 1028, 1034, 1036, 1041, 1047, 1053], "supp": 394, "suppli": [155, 398, 416, 654, 932, 933, 1003, 1024, 1045, 1047, 1049, 1054], "support": [2, 39, 43, 45, 46, 47, 48, 49, 52, 61, 66, 68, 81, 104, 105, 106, 138, 143, 159, 160, 170, 171, 181, 193, 221, 230, 231, 232, 238, 252, 253, 254, 260, 271, 276, 283, 285, 296, 299, 317, 319, 323, 332, 336, 338, 339, 342, 343, 345, 346, 349, 350, 351, 352, 353, 354, 356, 373, 374, 375, 380, 384, 386, 388, 390, 391, 392, 393, 395, 396, 399, 400, 401, 410, 416, 420, 421, 424, 425, 426, 445, 448, 458, 460, 461, 472, 473, 474, 475, 477, 482, 495, 504, 520, 546, 548, 549, 552, 555, 557, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 621, 622, 623, 625, 627, 628, 630, 631, 633, 635, 639, 640, 641, 651, 653, 665, 666, 667, 678, 679, 680, 682, 683, 684, 685, 686, 695, 698, 702, 707, 715, 721, 737, 738, 746, 751, 786, 787, 788, 791, 792, 795, 796, 808, 811, 812, 814, 822, 830, 835, 836, 844, 845, 850, 852, 853, 856, 858, 864, 872, 873, 877, 883, 885, 886, 888, 892, 900, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 928, 938, 943, 944, 988, 989, 990, 992, 993, 994, 996, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1011, 1014, 1019, 1020, 1021, 1022, 1024, 1025, 1028, 1030, 1034, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "support_": [253, 355, 477, 482, 601, 602, 610, 914, 915, 916, 917, 918, 1015], "support_fract": [48, 477, 482], "support_reweight": [477, 482], "support_vector": [347, 353], "support_vector_indic": 347, "support_vectors_": [46, 49, 350, 353, 354, 914, 915, 916, 917, 918, 1015], "suppos": [254, 281, 338, 373, 374, 386, 388, 392, 418, 423, 424, 425, 565, 569, 572, 666, 667, 674, 676, 682, 683, 684, 750, 858, 912, 914, 917, 920, 922, 938, 1004, 1050, 1052, 1058], "suppress": [192, 373, 394, 700, 1003, 1048], "suptitl": [43, 44, 52, 54, 68, 69, 70, 74, 75, 85, 88, 92, 95, 102, 109, 125, 128, 135, 139, 148, 149, 157, 160, 185, 192, 193, 195, 214, 219, 235, 236, 240, 241, 242, 256, 266, 272, 274, 292, 317, 319, 321, 328, 330, 338, 339, 343, 355, 356, 365], "surac": 1051, "sure": [2, 63, 91, 213, 226, 254, 255, 272, 369, 373, 374, 380, 384, 385, 386, 387, 388, 390, 391, 394, 398, 404, 414, 417, 424, 501, 531, 657, 932, 933, 943, 986, 990, 997, 1014, 1019, 1020, 1048, 1049, 1051, 1056], "suresh": 1055, "surf": 193, "surfac": [67, 129, 138, 139, 140, 141, 143, 161, 189, 203, 212, 229, 284, 302, 345, 346, 363, 364, 366, 367, 368, 423, 512, 561, 565, 572, 639, 772, 920, 926, 994, 999, 1014, 1015, 1016, 1021], "surface_": 639, "surgan12": 1050, "surpass": [139, 353, 869, 870], "surplu": 420, "surpris": [88, 193, 384, 996, 1019, 1043], "surprisingli": [238, 381, 424], "surrend": 57, "surrog": 1024, "surround": [255, 386, 858, 1006], "survei": [192, 419], "surviv": [105, 194, 989, 1019], "surya": [1054, 1055], "suscept": 410, "susik": 1045, "suspect": 43, "suspici": 381, "sustain": 0, "sutherland": [1043, 1045, 1046, 1048, 1049, 1050, 1051], "sutiono": 1052, "suzuki": [1052, 1053], "sv": 1015, "sv_ind": 253, "sv_ratio": 253, "svc": [2, 45, 62, 64, 66, 67, 68, 104, 108, 150, 161, 167, 177, 189, 197, 211, 224, 252, 255, 259, 271, 276, 278, 280, 283, 284, 285, 288, 289, 294, 321, 324, 328, 330, 341, 343, 344, 345, 346, 347, 349, 350, 351, 352, 354, 357, 358, 360, 373, 388, 392, 400, 414, 417, 420, 423, 442, 443, 444, 445, 476, 523, 563, 705, 706, 708, 710, 808, 825, 839, 841, 872, 909, 910, 912, 914, 915, 918, 988, 989, 995, 998, 1000, 1001, 1010, 1021, 1025, 1029, 1030, 1032, 1038, 1041, 1042, 1043, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055], "svc__c": [321, 872], "svc_disp": [260, 328, 1038], "svc_isoton": 62, "svc_sigmoid": 62, "svcifittedsvc": 260, "svcsvc": [259, 276, 278, 330], "svd": [2, 70, 132, 158, 241, 361, 395, 412, 419, 428, 459, 461, 490, 491, 493, 529, 540, 541, 542, 543, 547, 548, 549, 552, 554, 557, 558, 672, 680, 681, 682, 693, 694, 695, 871, 949, 994, 1034, 1043, 1047, 1048, 1054, 1056, 1059], "svd__n_compon": 871, "svd_lapack_driv": 949, "svd_method": [57, 459, 461, 540, 1044], "svd_solver": [45, 104, 125, 132, 335, 336, 412, 421, 543, 549, 1030, 1047, 1059], "sven": [1055, 1056], "svg": [0, 1027], "svm": [2, 42, 46, 48, 49, 50, 54, 62, 64, 66, 67, 68, 104, 106, 108, 125, 148, 158, 161, 164, 166, 168, 173, 174, 178, 180, 189, 198, 201, 203, 212, 213, 230, 231, 232, 233, 247, 253, 255, 256, 259, 260, 271, 275, 276, 277, 278, 280, 281, 283, 284, 285, 286, 288, 289, 293, 294, 305, 310, 311, 314, 321, 322, 328, 330, 337, 341, 342, 344, 347, 355, 356, 360, 373, 381, 388, 392, 400, 417, 420, 421, 423, 425, 442, 443, 444, 445, 502, 512, 520, 523, 549, 563, 564, 571, 575, 576, 585, 601, 602, 607, 608, 613, 639, 647, 651, 676, 684, 685, 686, 697, 705, 706, 708, 710, 721, 743, 750, 769, 808, 822, 828, 834, 835, 838, 840, 841, 858, 872, 873, 885, 887, 892, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 988, 989, 992, 995, 997, 998, 1000, 1001, 1005, 1013, 1015, 1017, 1021, 1022, 1025, 1028, 1029, 1030, 1034, 1036, 1038, 1041, 1042, 1043, 1045, 1046, 1047, 1048], "svm1": 417, "svm2": 417, "svm__c": 108, "svm_weight": 170, "svm_weights_select": 170, "svmlight": [2, 379, 495, 516, 517, 1036, 1041, 1042, 1048, 1050], "svmlight_file_test": 517, "svmlight_file_train": 517, "svmsgd": 1014, "svr": [2, 46, 49, 189, 246, 328, 344, 373, 442, 443, 444, 564, 575, 576, 601, 602, 651, 686, 808, 814, 913, 915, 917, 993, 1021, 1027, 1032, 1041, 1043, 1045, 1046, 1049, 1051, 1052, 1053, 1054, 1055, 1056], "svr_fit": 253, "svr_lin": 355, "svr_poli": 355, "svr_predict": 253, "svr_rbf": 355, "svrg": 1019, "sw": 299, "sw_test": [61, 329], "sw_train": [61, 329], "swap": [2, 416, 421, 724, 744, 979, 980, 1041], "swapnil": 1055, "swart": 55, "sweep": 868, "swier": [1052, 1053], "swiss": [2, 102, 189, 239, 240, 245, 416, 538, 700, 701, 1021, 1055], "switch": [372, 686, 712, 725, 745, 763, 765, 803, 852, 853, 948, 949, 1000, 1003, 1036, 1041], "swpeas": 1054, "swu": 1045, "sy": [47, 51, 57, 228, 251, 299, 342, 362, 381, 398, 625], "syd": 1056, "sydnei": 0, "syhw": [1042, 1043], "sylvain": [0, 376, 1045, 1050, 1051, 1052, 1053, 1054, 1055], "sylvainlan": [1049, 1050, 1051, 1052, 1053], "symbol": [51, 362, 374, 388, 392, 418, 424, 507, 590, 596, 597, 599, 924, 926, 1019], "symbol_dict": 51, "symlink": 390, "symlognorm": [199, 204], "symmetr": [2, 79, 152, 195, 222, 400, 414, 416, 460, 470, 471, 482, 527, 535, 537, 698, 702, 703, 712, 713, 723, 724, 725, 730, 732, 736, 744, 745, 763, 765, 771, 793, 803, 805, 806, 986, 989, 996, 1000, 1003, 1057], "symmetri": [174, 383, 707, 885, 888, 900, 998], "symmetric_arrai": 986, "symposium": [174, 383, 416, 468], "symptomat": 272, "sync": 390, "synchron": [386, 424], "syndrom": 380, "synnaev": 317, "synonym": [400, 854, 855, 856, 862, 863, 864], "synonymi": 421, "syntax": [374, 386, 391, 394, 417, 476, 871, 872, 910, 989, 1025, 1052, 1054], "synthet": [43, 53, 62, 64, 67, 70, 72, 77, 84, 146, 152, 158, 176, 181, 183, 193, 210, 222, 237, 314, 321, 356, 369, 373, 379, 389, 401, 416, 418, 425, 666, 667, 912, 913, 919, 994, 1032, 1033, 1047], "synthetic_feature_weight": [666, 667], "syonekura": 1049, "sysconfig": 384, "system": [44, 130, 204, 278, 285, 336, 369, 373, 374, 375, 381, 383, 386, 387, 388, 389, 394, 398, 404, 410, 416, 421, 423, 427, 452, 479, 480, 486, 543, 547, 551, 558, 647, 653, 658, 659, 662, 663, 664, 690, 691, 734, 764, 777, 805, 861, 907, 908, 996, 1000, 1003, 1012, 1019, 1020, 1024, 1034, 1041, 1049, 1050], "systemat": [43, 155, 278, 388, 720, 736, 1000, 1056], "sysuresh": 1055, "szabo": [1043, 1044], "szepieniec": 1047, "szlam": [421, 948, 949], "szpak": [1048, 1051], "szyma\u0144ski": [1049, 1050], "s\u00e1nchez": 1053, "s\u00e3o": 1059, "s\u00e4ger": [1044, 1047], "s\u00e9bastien": [1024, 1047, 1049], "s\u00f6nke": 1051, "s\u00f8ren": 1058, "s\u0142apek": 1052, "t": [2, 16, 47, 50, 51, 55, 63, 64, 70, 74, 75, 77, 78, 79, 87, 89, 93, 104, 106, 111, 112, 113, 115, 117, 123, 126, 127, 132, 134, 135, 139, 142, 143, 151, 152, 153, 154, 155, 159, 160, 174, 177, 179, 180, 181, 184, 185, 189, 192, 193, 194, 195, 199, 201, 204, 207, 214, 217, 218, 219, 220, 221, 238, 239, 241, 242, 243, 244, 254, 255, 264, 267, 269, 272, 277, 278, 292, 298, 299, 311, 312, 316, 328, 331, 332, 334, 338, 339, 341, 345, 346, 349, 350, 354, 360, 361, 362, 367, 368, 369, 373, 374, 380, 381, 383, 386, 388, 390, 392, 394, 399, 400, 404, 407, 410, 414, 415, 416, 417, 419, 420, 421, 423, 424, 425, 429, 433, 439, 441, 445, 455, 456, 458, 464, 471, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 503, 504, 521, 522, 523, 527, 528, 533, 538, 540, 542, 549, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 577, 578, 598, 599, 602, 615, 616, 618, 619, 635, 636, 638, 639, 640, 641, 643, 647, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 698, 700, 703, 704, 712, 718, 724, 725, 734, 744, 745, 763, 764, 765, 775, 796, 797, 802, 803, 807, 808, 811, 812, 822, 830, 836, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 858, 859, 862, 863, 868, 869, 870, 878, 881, 882, 883, 885, 886, 892, 893, 905, 907, 908, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 949, 950, 964, 989, 992, 994, 996, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1014, 1015, 1016, 1021, 1025, 1032, 1033, 1034, 1035, 1036, 1042, 1044, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "t0": [45, 47, 50, 54, 55, 74, 77, 79, 81, 83, 85, 87, 93, 97, 99, 128, 204, 206, 235, 236, 237, 242, 245, 247, 251, 253, 279, 335, 360, 361, 362, 684, 685, 686, 1030], "t1": [79, 81, 97, 235, 242, 245, 247], "t15h": 1048, "t_": [674, 675, 676, 684, 685, 686, 869, 870, 1014], "t_0": 1014, "t_batch": 99, "t_i": 1002, "t_k": [423, 1000, 1016], "t_m": 1016, "t_mini_batch": [77, 99], "t_p": 285, "t_post": 278, "t_sne": [240, 1049], "t_stat": 278, "t_stat_uncorrect": 278, "t_t": 1016, "taa": 184, "taac": 184, "tab": [46, 48, 70, 88, 113, 139, 155, 157, 160, 176, 181, 183, 208, 209, 272, 329, 335, 417, 1048], "tab10": [252, 268], "tab20b": 43, "tabea": [1056, 1057], "tabibian": 1047, "tabl": [93, 238, 278, 386, 387, 390, 395, 416, 424, 590, 666, 688, 808, 822, 849, 965, 996, 1000, 1001, 1006, 1019, 1042], "tabular": [43, 52, 193, 388, 423, 1008], "tacit": 400, "tacitli": 1043, "tackl": [153, 278, 374, 386, 416, 849, 1002, 1024, 1028], "tadej": [1042, 1043], "tae": 1053, "taehoon": [1048, 1049], "taemin": 996, "tag": [47, 84, 105, 247, 340, 380, 385, 389, 390, 394, 398, 400, 412, 424, 433, 439, 504, 840, 1020, 1023, 1046, 1050, 1051, 1052, 1055, 1056, 1057, 1058], "tahar": 1048, "tahiri": 1053, "taifi": 1047, "tail": [52, 152, 188, 192, 220, 222, 278, 319, 529, 532, 996], "tail_strength": [336, 529, 532], "takanori": 1049, "take": [2, 44, 47, 52, 58, 66, 81, 88, 90, 92, 101, 109, 113, 123, 125, 139, 148, 176, 178, 181, 185, 192, 197, 203, 224, 228, 229, 244, 254, 265, 266, 272, 273, 279, 283, 287, 288, 298, 299, 302, 305, 306, 307, 309, 310, 319, 332, 336, 341, 345, 346, 349, 358, 361, 362, 365, 373, 374, 375, 380, 381, 384, 386, 388, 391, 392, 393, 394, 398, 400, 401, 407, 414, 415, 416, 417, 419, 420, 421, 423, 424, 425, 426, 428, 445, 451, 454, 455, 457, 458, 460, 465, 466, 467, 469, 471, 477, 527, 541, 546, 547, 548, 554, 555, 589, 600, 603, 604, 606, 607, 608, 618, 619, 624, 628, 629, 632, 640, 651, 657, 679, 681, 682, 683, 684, 687, 699, 700, 707, 713, 715, 717, 727, 737, 738, 746, 750, 751, 764, 779, 782, 786, 787, 788, 789, 791, 792, 795, 796, 808, 809, 813, 814, 822, 826, 836, 854, 855, 856, 858, 860, 861, 862, 863, 864, 876, 886, 907, 908, 912, 913, 914, 915, 916, 917, 918, 936, 970, 989, 992, 996, 997, 999, 1000, 1001, 1003, 1005, 1006, 1007, 1010, 1015, 1016, 1024, 1025, 1029, 1031, 1038, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058, 1059], "takeawai": 298, "taken": [37, 43, 46, 67, 77, 88, 90, 154, 174, 181, 192, 251, 252, 266, 284, 296, 321, 381, 383, 385, 386, 390, 400, 416, 420, 424, 428, 448, 541, 569, 570, 591, 592, 654, 655, 658, 660, 661, 662, 666, 667, 668, 669, 670, 671, 685, 687, 689, 692, 703, 885, 886, 906, 909, 915, 916, 959, 1000, 1002, 1010, 1012, 1047, 1050, 1053, 1054], "takeshi": [1049, 1054, 1055, 1056], "takeuchi": 381, "takingitcasu": [1049, 1050], "talbot": 283, "talgatomarov": 1052, "talk": [57, 104, 279, 360, 361, 362, 381, 400, 410, 1024, 1026, 1034], "talli": 422, "tallott": 1049, "talwalkar": 989, "tamara": [381, 1058], "tamer": 1056, "tami": 93, "tamir": [1052, 1055], "tamirlan1": 1052, "tamper": 47, "tampermonkei": 394, "tan": [869, 870, 1004, 1048], "tandfonlin": 416, "tang": [383, 1051, 1052, 1053], "tangent": [240, 353, 697, 701, 998, 1035, 1036], "tanh": [353, 785, 869, 870, 998, 1015], "tanjina": 1058, "tann": [1049, 1054], "tao": [1057, 1058], "tar": [47, 390], "taranjeet": 1047, "tarashanski": 1058, "tarbal": [390, 1056], "tarcusx": 1049, "tarfil": 47, "target": [2, 43, 45, 52, 55, 57, 63, 66, 68, 69, 80, 87, 103, 105, 107, 108, 118, 121, 129, 131, 133, 140, 147, 148, 149, 150, 152, 153, 155, 157, 159, 160, 161, 163, 167, 169, 172, 174, 176, 178, 181, 182, 188, 189, 191, 192, 193, 194, 199, 203, 204, 213, 216, 220, 222, 224, 225, 228, 229, 241, 248, 250, 251, 252, 253, 256, 257, 258, 265, 271, 272, 274, 276, 279, 281, 283, 284, 287, 288, 292, 296, 298, 299, 302, 307, 310, 311, 315, 318, 319, 329, 330, 332, 334, 338, 339, 342, 343, 345, 346, 349, 353, 355, 360, 361, 365, 366, 367, 368, 369, 373, 375, 378, 379, 380, 381, 382, 383, 386, 388, 390, 391, 394, 395, 399, 403, 410, 416, 419, 420, 423, 426, 440, 445, 446, 447, 450, 453, 472, 473, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 508, 509, 510, 511, 512, 513, 516, 518, 528, 532, 539, 540, 542, 544, 545, 547, 550, 551, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 577, 578, 581, 590, 591, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 635, 636, 638, 639, 640, 641, 642, 643, 644, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 687, 688, 689, 690, 692, 693, 694, 695, 705, 706, 708, 709, 710, 715, 716, 717, 720, 721, 726, 728, 729, 731, 732, 734, 735, 736, 737, 738, 743, 746, 747, 748, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 764, 790, 791, 792, 793, 795, 796, 797, 798, 799, 802, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 822, 823, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 859, 861, 862, 863, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 884, 885, 886, 887, 889, 890, 891, 892, 893, 896, 901, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 932, 962, 963, 964, 991, 992, 993, 996, 997, 1000, 1004, 1007, 1008, 1014, 1015, 1016, 1020, 1021, 1023, 1024, 1025, 1030, 1032, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "target_class": 324, "target_column": [497, 498, 504], "target_encod": 326, "target_filenam": [509, 513], "target_gener": 182, "target_idx": 640, "target_mean_": [893, 1010], "target_nam": [45, 57, 66, 87, 121, 129, 133, 191, 229, 241, 265, 271, 279, 287, 288, 302, 325, 342, 360, 365, 379, 381, 496, 497, 499, 500, 501, 502, 504, 505, 508, 510, 511, 512, 513, 518, 721, 1000, 1016, 1025, 1030, 1034, 1051], "target_opset": 410, "target_test": [272, 517], "target_train": [272, 517], "target_typ": [325, 893, 936, 963, 1058], "target_type_": 893, "targetencod": [2, 325, 326, 400, 885, 886, 990, 1010, 1019, 1057, 1058], "targetencodertargetencod": 325, "targets_test": 252, "targets_train": 252, "tari": 93, "tashai": [1049, 1050], "task": [2, 38, 43, 46, 128, 146, 147, 153, 155, 173, 184, 189, 198, 204, 206, 207, 209, 219, 220, 236, 240, 257, 272, 275, 292, 298, 353, 362, 373, 375, 381, 383, 385, 386, 390, 391, 392, 395, 398, 399, 400, 421, 423, 424, 425, 426, 456, 469, 501, 513, 523, 600, 603, 604, 606, 607, 608, 612, 613, 614, 617, 640, 641, 654, 655, 660, 661, 668, 669, 670, 671, 682, 689, 692, 735, 737, 738, 762, 790, 792, 795, 797, 809, 813, 826, 832, 966, 967, 997, 1000, 1001, 1002, 1003, 1011, 1013, 1015, 1016, 1018, 1020, 1021, 1022, 1023, 1024, 1025, 1032, 1033, 1034, 1036, 1041, 1046, 1050, 1056], "tast": 1041, "tata": 1058, "tau": 1010, "tau_0": 544, "tavenard": 1053, "tax": 0, "taxonom": 383, "taxonomist": 1033, "taylor": [423, 1049, 1051, 1052, 1055], "tb": 394, "tc": [174, 383, 401], "tcg": 184, "tch": [174, 383], "tcompl": 93, "tcpdump": 381, "tda": 1019, "teach": 386, "teacher": 104, "teal": [221, 230, 285], "team": [381, 389, 398, 400, 401, 1019, 1024, 1041], "teas": 192, "tech": [51, 383, 850], "technic": [184, 192, 221, 241, 332, 381, 383, 386, 400, 423, 660, 672, 693, 694, 907, 996, 997, 1003], "technion": [672, 693, 694, 996], "techniqu": [11, 26, 51, 56, 104, 106, 127, 135, 140, 150, 166, 173, 174, 188, 189, 191, 228, 242, 244, 283, 296, 303, 331, 339, 353, 364, 375, 383, 398, 400, 410, 414, 416, 420, 421, 422, 423, 424, 425, 455, 456, 457, 458, 542, 562, 685, 697, 701, 702, 734, 764, 992, 996, 997, 999, 1000, 1003, 1006, 1008, 1012, 1014, 1016, 1020, 1024, 1028, 1033, 1034, 1054], "technolog": 383, "technologi": [174, 383, 416, 1019, 1024], "technometr": [383, 418, 477, 482, 1006], "tediou": [160, 272], "teen": 1010, "teevan": [849, 1002], "teh": [868, 1005], "tejesh95": 1045, "telecom": [61, 62, 77, 247, 1024], "telenczuk": [46, 153, 160, 174, 188, 1050, 1053, 1054, 1056], "tell": [176, 192, 193, 254, 278, 349, 354, 374, 381, 416, 424, 571, 587, 989, 994, 1007, 1034], "temp": [43, 193], "temp_fold": 966, "temperatur": [193, 424, 1007], "tempfil": [89, 301, 328, 417, 1003], "templat": [386, 390, 391, 400, 401, 565, 566, 571, 572, 573, 574, 1019], "templateclassifi": 388, "tempor": [52, 155, 204, 1019, 1020], "temporari": [89, 104, 106, 373, 476, 695, 789, 910, 1003, 1044, 1045, 1048, 1054, 1055], "temporarili": [416, 1046], "temporarydirectori": [301, 328], "tempt": 192, "temptat": [369, 386], "ten": [54, 57, 139, 145, 155, 174, 241, 269, 381, 383, 423, 528, 917, 1050], "tenavi": 1055, "tend": [43, 51, 64, 72, 74, 78, 87, 90, 92, 172, 174, 192, 193, 209, 220, 225, 238, 257, 263, 266, 275, 279, 298, 317, 353, 362, 373, 375, 386, 388, 400, 414, 416, 418, 421, 423, 425, 445, 456, 661, 858, 889, 901, 949, 996, 997, 1003, 1016, 1034], "tendenc": [155, 245, 996, 997, 999, 1002, 1005], "tenenbaum": [696, 997], "tenenhau": 383, "tensor": [2, 197, 378, 412, 421, 546, 548, 555, 647, 648, 649, 1036, 1053, 1059], "tensorflow": [45, 398, 1019, 1030], "tensorsketch": 992, "tent": 392, "tenur": 1024, "teon": 1053, "terenc": [1053, 1054], "term": [2, 43, 53, 54, 62, 68, 93, 130, 142, 145, 149, 152, 181, 191, 204, 208, 209, 220, 222, 224, 234, 237, 238, 257, 272, 276, 280, 299, 314, 331, 353, 356, 360, 362, 375, 386, 388, 390, 398, 414, 416, 418, 420, 421, 423, 451, 455, 457, 460, 467, 470, 532, 543, 546, 548, 552, 555, 557, 596, 597, 598, 599, 612, 615, 616, 640, 641, 648, 650, 652, 653, 654, 655, 656, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 676, 677, 678, 680, 681, 682, 683, 684, 686, 688, 695, 703, 738, 746, 791, 792, 795, 869, 870, 887, 891, 894, 912, 913, 914, 915, 916, 917, 918, 989, 991, 992, 994, 995, 996, 997, 1000, 1001, 1002, 1004, 1005, 1010, 1014, 1015, 1025, 1034, 1049, 1055, 1056, 1057], "term1": 424, "term2": 424, "term3": 424, "termin": [374, 391, 392, 394, 404, 416, 430, 456, 469, 561, 562, 566, 567, 568, 571, 573, 674, 675, 676, 684, 686, 869, 870, 921, 923, 1006, 1016], "terminalipythonapp": 392, "terminalpdb": 394, "termination_condition_": 909, "terminologi": [400, 1049], "terraza": 1053, "terri": [104, 1045], "terrycojon": 1045, "tesson": 416, "test": [2, 43, 45, 47, 49, 50, 52, 61, 62, 63, 64, 67, 68, 69, 89, 104, 105, 117, 130, 139, 142, 144, 145, 146, 147, 151, 152, 153, 154, 155, 165, 167, 168, 170, 173, 176, 177, 189, 191, 192, 193, 194, 195, 197, 204, 209, 215, 216, 219, 220, 221, 222, 224, 227, 228, 235, 236, 238, 244, 248, 253, 254, 256, 265, 270, 271, 272, 273, 276, 277, 278, 279, 280, 282, 283, 285, 286, 288, 289, 290, 292, 298, 302, 307, 308, 314, 316, 321, 323, 324, 325, 326, 335, 342, 349, 356, 362, 369, 373, 374, 380, 381, 383, 389, 390, 391, 392, 398, 399, 400, 403, 404, 409, 411, 412, 414, 415, 417, 418, 421, 423, 424, 425, 426, 433, 435, 439, 442, 443, 444, 445, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 496, 497, 501, 505, 506, 510, 512, 532, 539, 545, 547, 551, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 577, 578, 600, 602, 603, 604, 606, 607, 608, 610, 612, 613, 614, 616, 617, 618, 619, 635, 636, 638, 643, 644, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 720, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 859, 862, 863, 869, 870, 872, 897, 898, 900, 901, 902, 903, 907, 908, 910, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 931, 941, 943, 944, 995, 996, 999, 1000, 1003, 1004, 1008, 1010, 1014, 1015, 1016, 1019, 1020, 1021, 1023, 1024, 1026, 1029, 1030, 1036, 1041, 1042, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1060], "test_": [52, 160, 420], "test_0": 43, "test_4": 43, "test_accuraci": [265, 279, 292], "test_auc": 835, "test_ax": 130, "test_balanced_accuraci": 292, "test_best_it": 151, "test_check_estim": 944, "test_color": 151, "test_common": [386, 394], "test_dataset": 380, "test_devi": 154, "test_enable_hist_gradient_boost": 390, "test_error": 291, "test_fn": 1000, "test_fold": [420, 821], "test_fract": 1041, "test_idx": [52, 400], "test_import": 194, "test_index": [265, 341, 420, 809, 810, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829], "test_indic": 1029, "test_indx": 420, "test_lin": 151, "test_logist": [386, 394], "test_ms": 335, "test_neg_mean_absolute_error": [43, 222], "test_neg_mean_squared_error": [222, 835], "test_neg_root_mean_squared_error": 43, "test_negative_likelihood_ratio": 281, "test_positive_likelihood_ratio": 281, "test_prec_macro": 420, "test_precision_macro": 420, "test_r2": 835, "test_rec_macro": 420, "test_recall_macro": 420, "test_requiring_mpl_fixtur": 386, "test_result": 194, "test_scor": [149, 151, 153, 155, 228, 277, 280, 296, 325, 356, 364, 399, 420, 814, 831, 835, 836, 839], "test_scores_nb": 280, "test_scores_svm": 280, "test_set": 414, "test_siz": [43, 44, 45, 49, 52, 61, 62, 64, 67, 68, 105, 144, 150, 151, 153, 154, 155, 159, 191, 197, 204, 215, 220, 227, 228, 235, 236, 272, 275, 276, 280, 285, 287, 291, 298, 307, 308, 314, 316, 317, 321, 323, 324, 330, 349, 356, 369, 391, 420, 706, 810, 825, 828, 829, 838, 840, 861, 990, 1002, 1003, 1029, 1030, 1041, 1042, 1047, 1048, 1053], "test_sklearn_compatible_estim": [328, 944], "test_sparsifi": 394, "test_stat": 47, "test_tim": [253, 360], "test_tp": 1000, "test_val": 387, "test_your_test_nam": 374, "tested_neg": 292, "tested_posit": 292, "testpypi": 390, "teunp": 1055, "texa": [51, 104], "text": [2, 42, 45, 46, 49, 50, 51, 54, 57, 67, 68, 72, 75, 79, 88, 91, 92, 93, 95, 96, 97, 99, 104, 113, 114, 137, 145, 150, 172, 184, 195, 200, 214, 215, 247, 251, 254, 258, 259, 263, 265, 270, 277, 278, 284, 285, 289, 304, 307, 309, 314, 321, 331, 337, 339, 355, 364, 373, 375, 378, 379, 380, 386, 391, 398, 400, 414, 416, 417, 419, 420, 421, 423, 426, 455, 457, 472, 476, 495, 496, 497, 507, 511, 516, 529, 544, 552, 572, 596, 597, 598, 599, 623, 633, 660, 666, 674, 676, 682, 684, 705, 711, 713, 715, 721, 725, 737, 738, 745, 801, 803, 808, 822, 838, 847, 849, 851, 854, 859, 872, 873, 875, 876, 884, 908, 909, 910, 912, 924, 925, 926, 946, 989, 992, 996, 998, 1000, 1001, 1002, 1004, 1007, 1010, 1012, 1014, 1015, 1018, 1020, 1021, 1024, 1026, 1027, 1036, 1041, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "text1": 424, "text2": 424, "text2d": 244, "text3": 424, "text3d": [80, 131], "text_": 705, "text_analyt": 1034, "text_clf": 1034, "text_kw": [705, 1056], "text_preprocess": 472, "text_stat": 104, "text_stats_transform": 104, "textbook": [424, 598], "textcoord": [48, 197], "textrm": [1015, 1032], "texttt": 1000, "textual": [421, 430, 1016, 1050], "textur": [174, 383, 766, 767, 998], "tf": [2, 54, 57, 251, 360, 361, 362, 381, 421, 529, 552, 596, 597, 598, 599, 851, 859, 884, 989, 998, 1002, 1010, 1019, 1034], "tf_feature_nam": 54, "tf_transform": 1034, "tf_vector": 54, "tfid": 598, "tfidf": [54, 104, 342, 424, 599, 1034], "tfidf__use_idf": 1034, "tfidf_feature_nam": 54, "tfidf_transform": 1034, "tfidf_vector": 54, "tfidftransform": [2, 342, 361, 362, 424, 497, 599, 1034, 1048, 1049, 1055, 1057, 1058, 1059], "tfidfvector": [2, 54, 57, 104, 279, 360, 381, 421, 424, 497, 596, 597, 598, 1034, 1041, 1043, 1049, 1050, 1051, 1054, 1055, 1059], "tfidfvectorizertfidfvector": 279, "tfifi": 1054, "tfrac": 426, "tgct": 184, "tgz": [45, 1030], "th": [139, 257, 331, 368, 399, 416, 420, 423, 431, 449, 453, 459, 461, 467, 471, 480, 565, 566, 567, 568, 569, 570, 572, 573, 574, 601, 602, 640, 656, 657, 677, 679, 688, 704, 726, 788, 829, 893, 937, 990, 996, 1000, 1004, 1007, 1014, 1015, 1056], "th0rwa": [1051, 1052], "thakur": [1044, 1045], "thaler": 1047, "than": [2, 25, 43, 44, 46, 50, 51, 53, 57, 64, 66, 67, 75, 79, 82, 88, 90, 106, 109, 113, 115, 118, 123, 125, 128, 130, 132, 139, 141, 142, 144, 145, 146, 148, 149, 152, 155, 172, 174, 176, 182, 185, 187, 192, 193, 194, 197, 199, 204, 206, 209, 220, 222, 226, 236, 237, 238, 244, 247, 253, 254, 255, 257, 264, 272, 275, 276, 278, 279, 280, 281, 284, 287, 292, 296, 298, 299, 305, 306, 317, 319, 323, 324, 325, 326, 330, 332, 334, 336, 339, 353, 360, 361, 362, 369, 373, 374, 375, 380, 381, 382, 384, 385, 386, 388, 391, 392, 394, 400, 401, 410, 412, 413, 414, 415, 416, 418, 419, 420, 421, 423, 424, 425, 426, 447, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 460, 462, 465, 468, 471, 472, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 501, 502, 504, 517, 522, 523, 531, 539, 542, 543, 544, 545, 546, 548, 549, 550, 552, 555, 556, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 581, 589, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 635, 636, 638, 642, 648, 650, 651, 652, 654, 655, 660, 661, 663, 666, 667, 668, 669, 670, 671, 674, 675, 676, 679, 680, 682, 684, 685, 686, 687, 690, 695, 700, 702, 704, 712, 713, 720, 728, 729, 730, 731, 732, 743, 744, 747, 772, 787, 788, 789, 791, 793, 803, 805, 806, 808, 811, 812, 818, 822, 827, 829, 830, 833, 834, 835, 836, 837, 840, 842, 843, 845, 846, 847, 848, 849, 851, 852, 853, 854, 855, 856, 858, 860, 861, 862, 863, 864, 866, 869, 870, 875, 885, 886, 887, 889, 890, 892, 895, 901, 902, 906, 909, 912, 913, 914, 917, 918, 920, 921, 922, 923, 924, 938, 949, 951, 952, 957, 963, 969, 971, 974, 989, 990, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1014, 1015, 1016, 1019, 1020, 1023, 1025, 1029, 1032, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "thanh": 1059, "thank": [0, 43, 55, 62, 90, 118, 194, 197, 220, 287, 360, 361, 385, 394, 1019, 1024, 1041, 1045, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "tharak": 1058, "thebabush": [1058, 1059], "thedevpanda": 1056, "thei": [0, 8, 25, 30, 31, 43, 52, 63, 72, 85, 92, 115, 127, 137, 140, 146, 147, 149, 151, 153, 155, 156, 170, 173, 174, 176, 177, 181, 192, 193, 204, 206, 209, 215, 220, 221, 238, 241, 244, 247, 253, 254, 257, 271, 275, 278, 279, 281, 287, 292, 296, 299, 301, 315, 319, 324, 330, 332, 353, 360, 361, 366, 367, 369, 373, 374, 375, 379, 381, 382, 383, 384, 385, 386, 387, 388, 390, 394, 395, 398, 399, 400, 401, 407, 410, 413, 415, 416, 417, 418, 419, 421, 423, 425, 426, 428, 448, 450, 454, 461, 462, 475, 504, 516, 517, 541, 543, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 605, 618, 627, 637, 651, 654, 655, 660, 666, 667, 668, 669, 670, 678, 680, 684, 686, 689, 695, 770, 771, 773, 776, 782, 797, 808, 822, 841, 847, 848, 849, 850, 851, 869, 872, 874, 880, 891, 892, 914, 917, 920, 921, 922, 923, 927, 989, 990, 992, 994, 996, 999, 1000, 1001, 1002, 1003, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1024, 1025, 1029, 1031, 1032, 1034, 1041, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057], "theil": [2, 189, 198, 223, 226, 319, 657, 665, 679, 686, 687, 1021], "theilsen": 226, "theilsenregressor": [2, 226, 237, 657, 679, 686, 996, 1045, 1053, 1055, 1060], "theirs": 360, "them": [16, 43, 44, 47, 68, 74, 75, 84, 88, 90, 91, 95, 100, 101, 104, 105, 118, 125, 127, 130, 140, 156, 169, 174, 176, 187, 188, 192, 193, 194, 197, 199, 204, 215, 221, 222, 224, 238, 251, 254, 257, 258, 272, 276, 278, 279, 281, 287, 296, 301, 319, 324, 326, 331, 342, 349, 362, 368, 373, 375, 381, 384, 386, 387, 388, 389, 390, 394, 398, 400, 401, 403, 407, 410, 414, 415, 416, 417, 420, 421, 423, 424, 426, 452, 455, 457, 458, 465, 472, 475, 501, 502, 516, 575, 576, 577, 578, 615, 616, 624, 628, 629, 632, 640, 647, 672, 700, 776, 779, 782, 786, 787, 788, 789, 797, 808, 822, 829, 837, 872, 876, 881, 882, 886, 890, 892, 893, 902, 903, 909, 920, 921, 957, 966, 989, 990, 996, 999, 1000, 1001, 1003, 1004, 1005, 1010, 1015, 1016, 1018, 1019, 1023, 1024, 1025, 1032, 1033, 1034, 1041, 1042, 1047, 1048, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "themat": 400, "theme": [381, 386, 404, 409, 1041], "themrmax": [1047, 1048], "themselv": [64, 192, 319, 382, 388, 394, 400, 407, 413, 416, 423, 424, 426, 454, 623, 800, 1016, 1034, 1051], "theodor": 1046, "theofilo": 1048, "theoptip": [1051, 1052], "theorem": [32, 176, 356, 1002], "theoret": [37, 72, 92, 176, 272, 416, 423, 561, 562, 647, 712, 734, 764, 912, 989, 996, 997, 999, 1000, 1002, 1012, 1014, 1015, 1024], "theori": [8, 149, 253, 268, 356, 383, 416, 420, 423, 698, 702, 734, 764, 904, 905, 949, 989, 996, 997, 999, 1000, 1001, 1015, 1016], "theotheo": 1051, "thereaft": [192, 199], "therebi": [43, 192, 420, 423, 992, 1051], "therefor": [43, 48, 53, 58, 61, 64, 70, 72, 87, 88, 105, 106, 109, 113, 118, 130, 134, 139, 142, 144, 152, 155, 158, 160, 173, 191, 194, 220, 224, 236, 237, 263, 268, 269, 272, 279, 281, 292, 296, 298, 302, 316, 319, 324, 338, 349, 356, 357, 360, 361, 368, 373, 380, 384, 391, 398, 407, 410, 412, 416, 417, 418, 420, 421, 423, 424, 445, 543, 549, 557, 559, 561, 562, 567, 568, 572, 573, 612, 614, 666, 667, 673, 676, 679, 684, 686, 687, 709, 720, 743, 765, 805, 872, 873, 885, 889, 893, 901, 990, 994, 996, 997, 1000, 1002, 1003, 1004, 1005, 1008, 1010, 1015, 1016, 1020, 1025, 1032, 1033, 1034, 1050, 1051, 1054, 1055, 1056, 1057, 1058], "therein": 676, "thereof": 400, "theriley106": 1049, "thesi": [0, 383, 416, 423], "theta": [177, 178, 180, 182, 184, 185, 255, 421, 426, 531, 544, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 700, 1002, 1016], "theta0": 177, "theta1": 177, "theta_": [850, 1002], "theta_c": [255, 531], "theta_d": 421, "theta_i": 1002, "theta_l": 426, "theta_opt": [618, 619], "thi": [0, 2, 7, 11, 30, 31, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 375, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 403, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 440, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 490, 491, 492, 493, 495, 497, 498, 501, 502, 504, 505, 506, 507, 509, 510, 511, 513, 516, 517, 523, 524, 525, 526, 527, 528, 529, 531, 532, 534, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 581, 582, 583, 585, 587, 588, 589, 590, 591, 592, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 614, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 705, 707, 708, 709, 710, 711, 712, 714, 715, 717, 719, 720, 721, 722, 724, 725, 726, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 740, 744, 745, 746, 747, 748, 749, 750, 751, 756, 762, 763, 764, 765, 766, 767, 769, 770, 771, 773, 776, 777, 782, 786, 787, 788, 789, 790, 791, 792, 793, 795, 796, 797, 800, 801, 802, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 927, 928, 932, 933, 938, 939, 941, 943, 944, 949, 951, 956, 957, 958, 959, 960, 961, 963, 966, 967, 970, 971, 974, 975, 984, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1023, 1024, 1025, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1038, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "thibault": 1050, "thibaut": 1055, "thibsej": 1050, "thick": [95, 309, 1003], "thierno": 1051, "thierri": [0, 263, 265, 1024, 1047, 1048, 1055], "thij": [1053, 1056, 1057], "thin": [242, 628], "thing": [48, 70, 241, 273, 360, 374, 375, 381, 385, 386, 388, 398, 401, 416, 418, 424, 567, 568, 996, 1010, 1024, 1047], "think": [44, 72, 192, 193, 360, 361, 386, 422, 999, 1020, 1024, 1025], "thinner": 102, "third": [70, 148, 153, 169, 174, 184, 238, 247, 269, 296, 304, 321, 334, 374, 381, 385, 398, 401, 410, 424, 542, 596, 597, 598, 599, 810, 811, 812, 817, 854, 855, 856, 858, 860, 890, 902, 989, 1011, 1041, 1052, 1057, 1058], "thirion": [0, 405, 1041, 1047, 1048, 1054], "thirteen": 383, "thirti": 1018, "thiruvenkadam": 1055, "this_centroid": 77, "this_cov": 115, "this_cv": 273, "this_di": 51, "this_dx": 51, "this_i": [61, 226], "this_max_it": 235, "this_p": 63, "this_prec": 115, "this_scor": [352, 1029], "this_sw": 61, "this_x": [61, 218, 226, 1032], "thoma": [0, 132, 247, 319, 374, 376, 401, 405, 908, 996, 1010, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "thomas9292": 1053, "thomaz": 1052, "thomo": 93, "thompson": [1044, 1056, 1057], "thorben": 1053, "thorough": 1024, "thoroughli": 1005, "thorsten": 1024, "those": [43, 46, 51, 55, 57, 90, 95, 105, 140, 152, 155, 172, 174, 185, 191, 192, 193, 194, 195, 220, 222, 224, 238, 245, 251, 254, 256, 257, 269, 271, 272, 278, 281, 284, 296, 315, 319, 324, 336, 346, 349, 360, 361, 362, 373, 374, 380, 386, 388, 390, 391, 392, 393, 398, 400, 401, 404, 413, 414, 415, 416, 420, 421, 423, 424, 426, 456, 458, 469, 472, 476, 502, 503, 504, 511, 565, 566, 572, 573, 577, 578, 589, 700, 705, 720, 726, 744, 808, 811, 812, 820, 822, 829, 854, 855, 856, 858, 860, 861, 862, 863, 864, 912, 913, 914, 917, 920, 921, 922, 923, 960, 989, 992, 996, 999, 1000, 1002, 1003, 1004, 1007, 1010, 1016, 1018, 1019, 1024, 1025, 1034, 1041, 1044, 1047, 1048, 1049, 1054, 1055, 1056, 1057, 1058, 1059], "though": [80, 90, 145, 174, 197, 199, 257, 284, 304, 321, 323, 361, 362, 369, 373, 380, 383, 386, 388, 399, 400, 416, 421, 422, 423, 424, 425, 707, 815, 817, 912, 989, 990, 992, 997, 1000, 1003, 1008, 1010, 1014, 1034, 1049], "thought": [240, 304, 400, 416, 454, 997, 1001], "thoui": [0, 406, 1041], "thousand": [77, 145, 155, 251, 253, 323, 361, 381, 416, 423, 869, 870, 917, 997, 1034, 1050, 1052], "thread": [299, 329, 332, 384, 398, 400, 416, 423, 844, 845, 966, 967, 1044, 1046, 1048, 1049, 1050, 1051, 1052, 1054, 1056, 1057, 1058], "threadpoolctl": [374, 384, 404, 409], "threadsaf": 1054, "three": [43, 46, 63, 70, 75, 76, 80, 81, 90, 93, 111, 121, 122, 139, 144, 146, 149, 150, 151, 161, 162, 163, 171, 174, 184, 192, 204, 212, 217, 220, 222, 229, 231, 253, 254, 263, 266, 298, 325, 326, 329, 374, 379, 383, 390, 404, 410, 413, 416, 420, 421, 422, 424, 459, 470, 506, 717, 951, 993, 995, 996, 997, 1000, 1003, 1010, 1014, 1015, 1018, 1025, 1033, 1041], "thresh": 1045, "threshold": [2, 50, 62, 77, 100, 128, 134, 174, 189, 193, 195, 215, 248, 250, 270, 275, 276, 277, 282, 285, 298, 334, 335, 337, 365, 368, 400, 411, 416, 421, 423, 425, 449, 450, 453, 454, 477, 504, 508, 516, 517, 539, 545, 550, 556, 557, 558, 559, 569, 571, 596, 599, 601, 605, 610, 611, 652, 666, 675, 679, 684, 686, 700, 706, 708, 710, 711, 714, 715, 726, 728, 734, 735, 747, 748, 750, 764, 790, 792, 795, 796, 797, 802, 805, 806, 807, 808, 827, 830, 838, 847, 858, 859, 873, 875, 877, 879, 892, 895, 907, 908, 909, 910, 917, 924, 926, 974, 996, 1000, 1003, 1004, 1006, 1010, 1013, 1015, 1016, 1020, 1021, 1036, 1041, 1045, 1046, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1057, 1058, 1059], "threshold_": [605, 1048], "threshold_lambda": 652, "threshold_sign": 368, "thriller": [424, 883], "thrive": [0, 386], "throat": [50, 312, 381, 506], "through": [0, 2, 46, 52, 70, 144, 174, 184, 192, 224, 240, 252, 273, 278, 281, 304, 323, 324, 347, 354, 362, 368, 383, 384, 386, 388, 393, 395, 400, 401, 404, 407, 415, 416, 419, 421, 423, 425, 426, 433, 439, 454, 472, 475, 480, 543, 549, 565, 566, 569, 572, 573, 574, 589, 601, 602, 605, 655, 659, 661, 663, 666, 667, 669, 671, 673, 676, 684, 685, 696, 699, 728, 814, 831, 888, 900, 904, 905, 920, 921, 922, 923, 955, 958, 989, 990, 997, 1000, 1002, 1003, 1004, 1006, 1008, 1010, 1014, 1015, 1016, 1024, 1025, 1032, 1034, 1041, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1056, 1057, 1058, 1059], "throughout": [334, 369, 400, 635, 809, 869, 870, 1025, 1044, 1049], "throughput": [372, 1019, 1036, 1044], "throw": [2, 316, 395, 931, 1045, 1048, 1049, 1050, 1051, 1055], "thrown": [719, 1050, 1051], "thu": [43, 44, 61, 62, 63, 64, 75, 88, 90, 95, 111, 115, 128, 130, 142, 144, 145, 147, 149, 155, 170, 176, 181, 182, 193, 204, 208, 209, 220, 222, 238, 247, 253, 258, 265, 272, 276, 278, 283, 284, 285, 292, 302, 326, 328, 331, 364, 369, 373, 374, 381, 388, 392, 398, 400, 407, 414, 415, 416, 420, 421, 423, 424, 426, 427, 445, 447, 471, 523, 535, 561, 562, 563, 564, 565, 566, 571, 572, 573, 574, 611, 614, 618, 630, 635, 640, 641, 651, 653, 666, 685, 713, 726, 733, 796, 803, 810, 815, 817, 829, 843, 846, 881, 912, 991, 992, 993, 994, 995, 996, 997, 1000, 1001, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1020, 1024, 1041, 1043, 1047, 1049, 1050, 1051, 1053, 1057], "thuan": 1052, "thukarama": 1056, "thumb": [13, 145, 197, 373, 386, 387, 398, 416, 666, 667, 674, 675, 676, 684, 685, 686, 912, 1000], "thumbnail": 1041, "th\u00e9ophil": 1057, "ti": [104, 220, 265, 268, 276, 357, 373, 414, 416, 607, 608, 643, 728, 734, 764, 805, 806, 914, 917, 920, 999, 1000, 1015, 1042, 1044, 1045, 1049, 1051, 1055, 1056, 1057], "tiago": [1042, 1046], "tialo": [1058, 1059], "tian": [416, 450, 1046, 1047, 1048], "tianqi": 423, "tiao": [1046, 1047], "tib": [690, 691], "tibshirani": [142, 143, 154, 174, 208, 277, 383, 420, 423, 528, 567, 568, 636, 664, 729, 731, 732, 842, 859, 920, 921, 990, 994, 996, 1001, 1007, 1016], "tic": [174, 193, 257, 289, 1002], "tic_bwd": 174, "tic_fwd": 174, "ticconi": 1047, "tick": [47, 78, 95, 179, 258, 289, 640, 836], "tick_bottom": 319, "tick_left": 319, "tick_param": [46, 54, 163, 263, 278, 323, 341], "tick_right": 46, "ticker": [240, 242, 245, 299], "ticket": [333, 386], "tidelift": 0, "tie": [189, 212, 344, 398, 423, 520, 840, 917, 1001, 1015, 1016, 1021, 1042, 1057], "tieleman": [868, 1005], "tien": 1046, "tiernei": [1049, 1050, 1051], "tight": [75, 134, 141, 148, 167, 170, 205, 207, 212, 213, 214, 225, 229, 232, 237, 242, 245, 267, 299, 305, 306, 310, 311, 345, 349, 352, 354, 365, 590, 700, 1053], "tight_layout": [45, 47, 62, 64, 67, 75, 87, 90, 100, 107, 109, 118, 125, 126, 127, 135, 139, 141, 146, 148, 150, 153, 158, 160, 162, 178, 180, 185, 187, 191, 192, 194, 195, 199, 200, 204, 210, 218, 220, 228, 231, 235, 238, 240, 252, 257, 273, 274, 290, 298, 299, 301, 311, 320, 321, 322, 323, 324, 328, 332, 347, 361, 364, 365, 1030], "tightli": 1028, "tijanajovanov": 1053, "tikhonov": [183, 426, 680], "tild": [878, 1008, 1010], "tilen": 1051, "till": [416, 450, 796, 1000], "tim": [0, 144, 159, 405, 1041, 1046, 1047, 1050, 1051, 1052, 1054, 1056, 1057, 1058, 1059], "time": [0, 2, 37, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 375, 380, 381, 383, 384, 385, 386, 387, 388, 390, 391, 392, 394, 398, 400, 401, 407, 410, 412, 413, 414, 416, 418, 419, 421, 423, 424, 427, 445, 449, 451, 452, 453, 454, 455, 458, 460, 463, 465, 466, 467, 469, 470, 471, 472, 473, 475, 476, 480, 504, 507, 509, 527, 531, 542, 544, 546, 548, 549, 555, 570, 575, 576, 577, 578, 598, 618, 627, 635, 636, 637, 638, 642, 647, 648, 651, 654, 658, 660, 662, 668, 670, 672, 674, 675, 680, 681, 682, 684, 685, 686, 693, 694, 698, 700, 702, 709, 750, 753, 754, 756, 798, 802, 805, 806, 808, 810, 811, 812, 813, 815, 817, 822, 823, 824, 827, 829, 833, 834, 835, 836, 837, 838, 840, 842, 847, 848, 849, 850, 851, 852, 853, 860, 862, 863, 864, 868, 869, 870, 871, 872, 873, 874, 876, 877, 879, 882, 885, 887, 891, 896, 904, 905, 909, 910, 914, 917, 918, 926, 951, 966, 989, 990, 992, 993, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1019, 1024, 1025, 1030, 1032, 1033, 1034, 1041, 1043, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "time_dens": 335, "time_spars": 335, "time_step": [204, 870], "timeit": [235, 266, 392], "timeout": [504, 966, 1055], "timer": [266, 392], "times_init": 266, "timescal": 252, "timeseri": 43, "timeseriessplit": [2, 43, 52, 155, 204, 273, 420, 1047, 1048, 1053], "timo": 1053, "timofei": 1056, "timotheemathieu": 1054, "timothi": [1046, 1054], "timsaur": 1051, "tinertia": 93, "ting": [571, 1006, 1049, 1050], "tingshan": 1054, "tini": [1043, 1056, 1059], "tinoco": 1058, "tinta": 325, "tinyclu": 0, "tip": [369, 372, 386, 389, 392, 411, 424, 542, 549, 653, 700, 996, 1022, 1023, 1035, 1036, 1044], "tiphain": 1052, "tirth": [1051, 1052], "titan": [105, 194, 261, 328, 332, 333, 1008], "titl": [0, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 58, 59, 61, 62, 63, 64, 66, 68, 72, 73, 74, 76, 79, 80, 81, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 111, 112, 114, 115, 117, 118, 121, 122, 125, 126, 127, 128, 129, 132, 133, 134, 140, 141, 142, 145, 147, 148, 149, 152, 153, 155, 156, 159, 162, 163, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 192, 199, 200, 202, 204, 205, 207, 208, 209, 212, 213, 219, 220, 222, 224, 225, 226, 228, 229, 234, 237, 238, 240, 241, 242, 247, 251, 252, 253, 255, 256, 257, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 277, 278, 279, 281, 282, 283, 287, 288, 293, 301, 302, 305, 306, 307, 308, 310, 311, 312, 319, 323, 324, 325, 326, 340, 343, 345, 346, 347, 348, 349, 352, 353, 357, 358, 360, 365, 366, 367, 385, 386, 390, 394, 417, 1000, 1023, 1030], "title_bow": 417, "titles_opt": 271, "titov": [1049, 1051, 1054, 1055], "titu": 1052, "tiwari": 1053, "tiziano": 1041, "tjoa": 1045, "tkammi": 1047, "tkdd": 571, "tliu68": 1054, "tm": [51, 1003], "tmp": 390, "tmpdir": [301, 328], "tn": [272, 336, 720, 726, 1000], "tn_c": 287, "tnr": 272, "tnwei": 1053, "to_british": 424, "to_fram": 109, "to_list": 195, "to_numpi": [52, 181, 272], "to_onnx": 410, "to_replac": [43, 193], "toarrai": [46, 335, 342, 368, 417, 424, 574, 590, 596, 598, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 885, 902, 903, 950, 971, 972, 974, 982, 983, 990, 1003, 1010, 1058], "toastedcornflak": [1047, 1048], "toastedyeast": [1055, 1056], "tobia": [1049, 1054, 1056], "tobychees": [1048, 1049], "toc": [174, 257], "toc_bwd": 174, "toc_fwd": 174, "toccac": 1051, "tocsc": 206, "tocsr": 55, "toctre": [386, 404, 409], "tod": [416, 427, 452], "todai": [181, 1034], "todens": [975, 976, 977, 978, 979, 980, 981], "todo": [81, 251, 390, 394, 416, 1059, 1060], "toeplitz": 112, "togeth": [43, 51, 86, 95, 105, 148, 160, 176, 182, 192, 201, 241, 244, 257, 274, 325, 332, 352, 365, 369, 388, 390, 398, 399, 400, 416, 423, 424, 425, 431, 459, 461, 575, 576, 602, 697, 723, 808, 822, 872, 873, 886, 996, 997, 1000, 1001, 1007, 1010, 1016, 1017, 1024, 1026, 1028, 1047, 1058], "toi": [48, 71, 74, 75, 76, 77, 82, 84, 87, 88, 90, 92, 102, 113, 118, 129, 142, 156, 161, 162, 189, 202, 210, 224, 234, 246, 257, 263, 305, 306, 315, 346, 355, 379, 392, 398, 416, 423, 424, 448, 449, 450, 452, 454, 456, 457, 458, 460, 466, 477, 520, 522, 530, 571, 647, 685, 734, 764, 806, 858, 865, 873, 892, 916, 997, 999, 1000, 1006, 1010, 1021, 1036], "tok": [362, 424], "token": [2, 57, 362, 373, 381, 390, 424, 544, 596, 597, 598, 599, 1041, 1049, 1053, 1059], "token_featur": 424, "token_freq": 362, "token_pattern": [362, 424, 596, 597, 599], "tokoroten": 1046, "tokyo": [880, 1011], "tol": [46, 49, 55, 107, 125, 150, 155, 174, 187, 200, 211, 213, 227, 228, 234, 236, 247, 258, 264, 266, 317, 331, 356, 360, 388, 392, 423, 428, 451, 455, 457, 460, 467, 470, 479, 480, 486, 490, 491, 492, 539, 540, 541, 543, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 557, 558, 567, 568, 569, 570, 610, 635, 646, 648, 649, 650, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 674, 675, 676, 677, 680, 682, 684, 685, 686, 687, 688, 690, 691, 693, 694, 695, 696, 697, 699, 701, 703, 805, 806, 822, 861, 869, 870, 907, 908, 912, 913, 914, 915, 916, 917, 918, 986, 996, 1014, 1015, 1030, 1034, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1058, 1059], "tola": 1051, "told": 424, "toledano": 1049, "toler": [81, 107, 155, 187, 211, 213, 236, 237, 353, 362, 381, 388, 395, 416, 428, 451, 455, 460, 467, 470, 479, 480, 486, 490, 491, 492, 539, 540, 541, 543, 544, 548, 549, 550, 551, 552, 553, 555, 556, 567, 568, 569, 570, 635, 654, 655, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 684, 686, 687, 689, 690, 691, 692, 696, 697, 698, 699, 701, 702, 703, 852, 853, 857, 861, 869, 870, 907, 908, 912, 913, 914, 915, 916, 917, 918, 986, 996, 1000, 1014, 1015, 1030, 1053, 1054, 1055, 1056], "toleranbc": 1050, "tolist": [43, 151, 187, 277, 330, 381], "tom": [0, 212, 228, 299, 301, 321, 322, 405, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "tom1092": 1054, "toma": 1045, "tomasz": 1054, "tomato": 221, "tomatti": 1056, "tomdlt": 1047, "tomiock": [1056, 1057], "toml": 390, "tommaso": 1054, "tommi": [1048, 1049, 1050], "tomographi": [42, 55, 101, 189, 660, 680, 996, 1021], "tomohiro": 1054, "tomorrow": 415, "tom\u00e1": [1054, 1055], "tongyu": 1058, "toni": [45, 381, 571, 892, 1006, 1054, 1055], "tonk": 1048, "tony_blair": 1030, "too": [43, 46, 51, 52, 55, 64, 79, 85, 90, 92, 97, 104, 108, 115, 129, 152, 155, 187, 192, 194, 204, 221, 224, 241, 251, 257, 264, 271, 272, 276, 285, 294, 316, 325, 349, 360, 366, 367, 373, 383, 386, 392, 394, 398, 400, 414, 416, 418, 420, 423, 424, 425, 428, 445, 457, 546, 687, 700, 715, 847, 848, 849, 850, 851, 877, 890, 892, 995, 997, 999, 1000, 1002, 1003, 1007, 1032, 1042, 1045, 1048, 1049, 1050, 1051, 1053, 1059], "took": [0, 43, 77, 286], "tool": [21, 29, 41, 48, 50, 150, 192, 254, 272, 276, 281, 369, 379, 380, 381, 384, 386, 388, 389, 390, 391, 392, 393, 394, 399, 400, 401, 403, 404, 407, 410, 416, 417, 418, 495, 700, 709, 989, 995, 996, 1000, 1006, 1010, 1015, 1017, 1019, 1020, 1024, 1025, 1034, 1048, 1051, 1054, 1055, 1056], "toolbox": [398, 1019, 1024], "toolchain": 384, "toolkit": [373, 1019, 1024], "toolset": 1024, "tooth": [126, 1033], "tootoonian": 1054, "top": [2, 45, 51, 53, 54, 55, 70, 72, 74, 76, 77, 78, 79, 80, 86, 97, 99, 105, 122, 127, 137, 144, 145, 148, 155, 160, 163, 192, 220, 222, 231, 235, 247, 257, 258, 263, 265, 266, 269, 275, 279, 287, 288, 304, 319, 321, 325, 329, 335, 338, 339, 349, 353, 360, 369, 386, 388, 392, 398, 413, 414, 416, 421, 422, 423, 495, 595, 596, 599, 607, 734, 764, 802, 924, 926, 989, 992, 996, 998, 1008, 1019, 1024, 1030, 1033, 1034, 1055], "top10": 381, "top5": 360, "top_featur": 54, "top_features_ind": 54, "top_indic": 360, "top_k_accuraci": 1000, "top_k_accuracy_scor": [2, 1000, 1053, 1055], "tophat": [304, 422, 852, 853, 857], "topic": [42, 45, 46, 47, 104, 189, 360, 361, 362, 381, 382, 420, 421, 424, 496, 505, 544, 546, 548, 555, 596, 599, 996, 1001, 1019, 1020, 1021, 1034, 1046, 1048], "topic_d": 47, "topic_idx": 54, "topic_word_prior": [421, 544], "topic_word_prior_": 544, "topisan": 1051, "toplak": 1057, "topolog": [471, 1019], "topologi": [244, 245], "torch": [412, 1059], "torgo": 380, "toro": 325, "toronto": [542, 652, 868], "torr": 1050, "torrella": [1050, 1051, 1057], "tortois": 996, "tosequ": 1059, "toshihiro": [1047, 1048, 1054], "toshniw": 1053, "tot": 51, "total": [2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 365, 366, 367, 368, 374, 380, 381, 383, 392, 400, 413, 416, 422, 424, 427, 439, 452, 473, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 508, 509, 510, 512, 513, 518, 520, 522, 523, 527, 530, 531, 544, 552, 560, 561, 562, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 576, 578, 591, 592, 598, 602, 604, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 674, 675, 678, 679, 680, 681, 684, 685, 686, 687, 705, 712, 713, 721, 737, 738, 739, 742, 746, 747, 765, 777, 791, 792, 795, 802, 803, 804, 808, 822, 833, 834, 835, 845, 846, 847, 848, 855, 857, 863, 870, 887, 891, 913, 915, 918, 920, 921, 922, 923, 949, 989, 996, 997, 1000, 1001, 1002, 1003, 1010, 1014, 1015, 1016, 1021, 1030, 1034, 1042, 1047, 1049, 1057], "total_cel": 155, "total_fit_tim": 47, "total_sampl": [341, 544], "total_sz_mb": 47, "total_vect_tim": 47, "totalbsmtsf": 160, "totrmsabvgrd": 149, "tottim": 392, "tour": [0, 212, 228, 299, 301, 321, 322, 405, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "tournament": 989, "toward": [0, 63, 64, 98, 115, 146, 152, 159, 176, 194, 199, 224, 225, 245, 257, 356, 386, 400, 416, 456, 460, 470, 684, 686, 703, 886, 999, 1014, 1016, 1018, 1020], "toyota": 51, "tp": [336, 416, 720, 726, 737, 738, 739, 790, 791, 792, 795, 924, 1000], "tp_c": 287, "tpng": 924, "tpot": 1019, "tpr": [50, 248, 257, 272, 275, 287, 288, 393, 710, 714, 797, 1000, 1038, 1041, 1057], "tpr_a": 287, "tpr_b": 287, "tpr_score": 272, "tprs_lower": 288, "tprs_upper": 288, "tr": [273, 383, 390, 416, 418, 477, 478, 479, 480, 481, 482, 483, 484, 850], "trace": [394, 416, 429, 481, 483, 484, 487, 488, 489, 697, 701, 997, 1052], "traceback": [386, 391, 394, 398, 476, 719, 1023, 1058], "traceord": 145, "tracer0tong": 1047, "trach": 1041, "track": [137, 143, 151, 339, 386, 389, 390, 412, 542, 969, 1001, 1019, 1020, 1048, 1051], "tracker": [385, 389, 394, 398, 401, 404, 410, 1020], "tracking_select": 969, "tractabl": [43, 420, 549, 642, 1019, 1054], "trade": [37, 96, 111, 145, 155, 194, 224, 277, 279, 280, 349, 360, 400, 415, 416, 418, 561, 562, 567, 568, 642, 664, 700, 808, 811, 812, 822, 835, 997, 1004, 1012, 1014, 1015, 1020], "tradeoff": [90, 142, 189, 252, 260, 270, 285, 286, 287, 288, 360, 373, 386, 394, 422, 523, 572, 706, 710, 735, 797, 838, 873, 892, 912, 997, 1021, 1032, 1050, 1053], "tradit": [55, 90, 220, 235, 361, 375, 414, 423, 424, 640, 702, 996, 999, 1010, 1019, 1024], "tradition": 1016, "traffic": 1024, "trail": [388, 984], "train": [2, 43, 44, 45, 46, 47, 49, 50, 52, 61, 63, 64, 66, 67, 68, 69, 89, 91, 93, 99, 100, 104, 105, 109, 117, 118, 125, 128, 129, 130, 137, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 155, 157, 160, 161, 162, 165, 171, 176, 177, 178, 181, 182, 183, 184, 185, 189, 191, 192, 193, 194, 195, 197, 203, 204, 206, 208, 209, 211, 212, 213, 215, 216, 219, 220, 221, 222, 227, 228, 229, 232, 234, 235, 238, 247, 250, 252, 256, 265, 267, 270, 271, 272, 273, 274, 276, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 292, 293, 294, 295, 298, 299, 302, 305, 306, 307, 308, 310, 312, 314, 315, 316, 319, 321, 323, 324, 328, 331, 335, 337, 338, 339, 342, 343, 345, 346, 348, 355, 356, 362, 363, 366, 367, 369, 373, 374, 375, 378, 381, 383, 388, 391, 398, 399, 400, 412, 414, 415, 416, 417, 418, 419, 421, 423, 424, 425, 426, 428, 445, 448, 449, 451, 452, 455, 457, 459, 460, 461, 462, 467, 473, 477, 478, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 496, 497, 501, 504, 505, 506, 508, 512, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 635, 636, 638, 639, 641, 642, 643, 644, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 692, 695, 696, 697, 699, 700, 704, 711, 749, 796, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 872, 877, 878, 881, 882, 885, 886, 890, 891, 892, 893, 897, 898, 900, 901, 902, 903, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 926, 974, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1004, 1005, 1006, 1007, 1008, 1010, 1014, 1015, 1016, 1019, 1020, 1021, 1022, 1024, 1026, 1029, 1030, 1036, 1038, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "train_0": 43, "train_4": 43, "train_accuraci": [265, 292], "train_auc": 835, "train_ax": 130, "train_balanced_accuraci": 292, "train_cover_std": 50, "train_dataset": [192, 380], "train_error": 291, "train_errors_with": 150, "train_errors_without": 150, "train_fract": 1041, "train_idx": [52, 192, 400], "train_import": 194, "train_index": [265, 341, 420, 809, 810, 813, 815, 816, 817, 818, 821, 823, 824, 825, 826, 827, 828, 829], "train_indic": 1029, "train_indx": 420, "train_pr": 150, "train_prec_macro": 420, "train_r2": 835, "train_rec_macro": 420, "train_result": 194, "train_sampl": [64, 235, 236], "train_scor": [228, 325, 356, 364, 814, 831, 835, 836, 839, 995], "train_score_": [153, 423, 567, 568, 569, 570], "train_set": 414, "train_siz": [44, 46, 49, 139, 159, 177, 197, 236, 253, 257, 280, 291, 330, 333, 356, 810, 814, 825, 828, 836, 838, 995, 1029, 1041, 1042, 1047, 1048], "train_size_ab": 836, "train_size_idx": 356, "train_sizes_ab": 836, "train_test_s": 253, "train_test_split": [2, 44, 45, 46, 49, 52, 61, 62, 64, 67, 68, 105, 109, 118, 130, 139, 144, 146, 150, 151, 152, 153, 154, 155, 156, 159, 170, 171, 191, 192, 194, 195, 197, 204, 215, 220, 227, 228, 235, 236, 238, 248, 257, 260, 261, 271, 272, 275, 276, 281, 285, 287, 291, 298, 302, 307, 308, 314, 316, 317, 321, 323, 324, 326, 328, 329, 330, 335, 336, 342, 364, 368, 369, 391, 399, 412, 417, 420, 423, 445, 446, 566, 568, 575, 576, 705, 706, 708, 710, 807, 808, 830, 840, 843, 861, 869, 870, 872, 922, 923, 989, 990, 1000, 1002, 1003, 1008, 1010, 1015, 1030, 1038, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1050, 1054, 1058, 1059], "train_tim": [235, 253, 360, 361], "trainabl": 388, "traine": 1024, "training_data": 176, "training_data_": 1051, "training_idx": 184, "training_indic": 183, "training_noisy_target": 176, "training_sample_indic": 176, "training_tim": [150, 360], "training_time_early_stop": 150, "training_time_ful": 150, "trajectori": 143, "tran": 112, "trans_data": 242, "transact": [98, 272, 336, 383, 416, 418, 427, 429, 452, 456, 483, 542, 546, 548, 555, 571, 652, 672, 693, 694, 733, 734, 764, 777, 996, 1000], "transax": [79, 97, 244, 247, 265, 307, 321], "transcript": 386, "transcriptom": 700, "transduc": 339, "transduct": [400, 416, 907, 908, 1020], "transduction_": [338, 339, 340, 907, 908, 909], "transfer": [155, 407, 412, 996, 1020], "transform": [2, 7, 20, 23, 35, 37, 43, 44, 45, 47, 49, 53, 62, 79, 81, 82, 83, 86, 89, 92, 97, 103, 107, 108, 118, 120, 121, 127, 128, 130, 131, 133, 134, 138, 143, 145, 149, 159, 160, 171, 182, 188, 189, 192, 193, 194, 197, 212, 220, 221, 228, 234, 236, 238, 241, 244, 247, 249, 250, 252, 254, 255, 257, 261, 265, 274, 275, 276, 279, 287, 299, 301, 307, 308, 309, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 333, 335, 336, 349, 352, 353, 360, 362, 369, 380, 381, 382, 383, 386, 388, 391, 395, 400, 407, 410, 412, 414, 416, 418, 419, 420, 421, 423, 424, 425, 426, 432, 437, 440, 445, 449, 450, 451, 453, 455, 457, 460, 472, 473, 474, 475, 476, 490, 491, 492, 493, 496, 497, 504, 511, 516, 517, 522, 523, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 558, 565, 567, 569, 572, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 644, 646, 647, 648, 649, 650, 661, 666, 671, 681, 684, 692, 696, 697, 698, 699, 700, 702, 709, 710, 721, 761, 762, 793, 808, 811, 812, 822, 838, 841, 847, 856, 861, 864, 868, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 910, 912, 914, 917, 918, 941, 943, 989, 990, 992, 994, 996, 997, 1000, 1001, 1004, 1014, 1015, 1017, 1019, 1020, 1021, 1022, 1025, 1030, 1031, 1034, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "transform_algorithm": [128, 134, 539, 545, 550, 1057], "transform_alpha": [128, 134, 539, 545, 550, 1054], "transform_dur": 299, "transform_func": 279, "transform_list": 871, "transform_max_it": [539, 545, 546, 550, 1051], "transform_method": 421, "transform_n_nonzero_coef": [128, 134, 539, 545, 550], "transform_n_nozero_coef": 134, "transform_output": [261, 272, 326, 476, 910, 1056, 1057], "transformed_grid": 158, "transformedtargetregressor": [2, 109, 192, 220, 398, 407, 417, 601, 602, 605, 1001, 1049, 1051, 1054, 1059], "transformedtargetregressortransformedtargetregressor": 192, "transformer_": [254, 473], "transformer_list": [108, 417, 871, 874, 990, 1052, 1053], "transformer_nam": 299, "transformer_weight": [104, 472, 475, 871, 1046, 1053], "transformermixin": [2, 254, 299, 388, 400, 473, 1049, 1056, 1057, 1058], "transformers_": [472, 475, 1058, 1059], "transfus": 248, "transit": [55, 356, 390, 410, 1052], "transitive_target": 55, "translat": [109, 388, 426, 535, 622, 881, 882, 898, 997, 1000, 1024], "transluc": 165, "transpar": [67, 321, 985, 1024], "transpil": 1019, "transpos": [62, 278, 428, 546, 548, 555, 668, 669, 670, 671, 796, 949, 986, 992, 1000, 1012, 1033, 1041, 1055], "transposit": 949, "trapezoid": [2, 285, 714, 715, 1000], "travel": 0, "travers": [368, 1003, 1007, 1059], "travi": [1041, 1049], "treat": [43, 45, 105, 149, 160, 187, 192, 220, 287, 325, 330, 335, 341, 369, 386, 398, 400, 413, 423, 424, 450, 569, 570, 596, 597, 599, 615, 616, 640, 646, 653, 679, 682, 737, 738, 746, 762, 791, 792, 795, 796, 881, 882, 888, 889, 892, 893, 897, 900, 901, 903, 912, 913, 957, 990, 992, 996, 1000, 1001, 1007, 1010, 1014, 1016, 1030, 1045, 1053, 1057, 1058], "treatment": [114, 191, 380, 415, 421, 477, 482], "tree": [2, 43, 46, 52, 63, 64, 67, 76, 79, 90, 97, 129, 138, 141, 142, 143, 145, 149, 150, 151, 152, 153, 156, 157, 159, 160, 161, 163, 174, 184, 187, 193, 195, 203, 228, 229, 241, 254, 255, 256, 257, 258, 275, 282, 284, 296, 299, 302, 304, 312, 319, 320, 324, 329, 330, 332, 346, 369, 373, 381, 383, 392, 399, 400, 403, 414, 415, 416, 422, 427, 445, 449, 450, 451, 452, 453, 454, 456, 458, 465, 471, 503, 504, 508, 512, 522, 523, 527, 552, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 639, 640, 641, 642, 666, 696, 700, 710, 711, 719, 750, 756, 796, 798, 814, 829, 835, 836, 838, 847, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 873, 876, 885, 920, 921, 922, 923, 924, 925, 926, 944, 990, 997, 1000, 1001, 1006, 1007, 1019, 1020, 1021, 1022, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048], "tree_": [328, 364, 368, 857, 920, 921, 922, 923], "tree_copi": [852, 853], "tree_disp": 258, "tree_importance_sorted_idx": 195, "tree_indic": 195, "tree_optim": 296, "tree_preprocessor": [160, 220], "tree_stat": [852, 853], "treelit": 1019, "trein": 1044, "tremend": [325, 423], "trend": [157, 181, 193, 250, 315, 1024, 1048], "trent": [1024, 1047], "trevor": [174, 208, 333, 383, 636, 664, 729, 731, 732, 990, 996, 1012, 1045, 1046, 1049, 1050, 1051, 1053], "trevorstephen": [1045, 1047], "tri": [101, 133, 240, 308, 353, 374, 388, 391, 398, 401, 414, 457, 459, 461, 639, 640, 641, 678, 700, 706, 708, 710, 822, 1005, 1025, 1043, 1049, 1053, 1059], "triag": [0, 386, 389, 401], "trial": [43, 283, 455, 457, 468, 679, 805, 806, 996, 1047], "triangl": [400, 421, 451, 455, 467, 707, 998, 1003], "triangular": [416, 471, 619, 997], "tribe": 381, "trick": [2, 176, 253, 309, 353, 362, 372, 375, 389, 398, 417, 590, 597, 651, 680, 992, 993, 1004, 1014, 1015, 1032, 1033, 1036, 1042, 1050, 1058], "tricki": [414, 997], "trickiest": 386, "trigg": 574, "trigger": [105, 106, 390, 400, 410, 417, 869, 870, 872, 873, 932, 933, 949, 996, 1034, 1049, 1055, 1056], "triglycerid": [174, 383], "trim": [235, 416, 852, 853], "trimeta": 1052, "trinh": 1056, "tripl": 391, "triplet": 517, "tripramudya": 1057, "trishnendu": 1049, "tristan": 996, "triu": 51, "trivial": [48, 222, 272, 364, 386, 416, 826, 914, 917, 997, 1020, 1041], "troillard": [1057, 1058], "tropp": [543, 549], "troubl": [66, 424], "troubleshoot": 424, "troyanskaya": [636, 990], "true": [2, 43, 44, 45, 46, 47, 49, 50, 52, 54, 55, 57, 63, 64, 66, 68, 70, 72, 79, 84, 85, 88, 89, 90, 92, 93, 95, 98, 104, 105, 106, 107, 109, 111, 112, 113, 114, 115, 117, 123, 125, 126, 127, 128, 130, 135, 137, 139, 143, 145, 149, 151, 152, 154, 155, 156, 157, 160, 161, 163, 165, 166, 170, 173, 176, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 204, 205, 207, 208, 209, 211, 213, 215, 216, 217, 220, 222, 223, 224, 227, 228, 234, 235, 236, 238, 240, 243, 244, 247, 248, 251, 253, 254, 255, 256, 257, 260, 261, 263, 266, 268, 271, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 304, 305, 308, 312, 314, 315, 316, 317, 320, 324, 325, 326, 328, 330, 332, 333, 334, 335, 336, 339, 341, 342, 343, 352, 353, 355, 356, 357, 360, 361, 362, 364, 365, 368, 369, 373, 374, 379, 381, 382, 384, 386, 387, 388, 391, 392, 393, 395, 399, 400, 403, 407, 410, 412, 413, 414, 415, 416, 417, 418, 420, 421, 423, 424, 425, 426, 428, 429, 430, 431, 433, 435, 436, 438, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 467, 469, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 516, 517, 518, 519, 520, 521, 522, 523, 527, 530, 531, 532, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 593, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 705, 706, 707, 708, 709, 710, 711, 713, 715, 716, 717, 719, 720, 721, 722, 723, 726, 727, 728, 732, 734, 735, 736, 737, 738, 739, 741, 742, 743, 746, 747, 748, 749, 750, 751, 758, 759, 760, 762, 764, 769, 775, 777, 786, 790, 791, 792, 793, 794, 795, 796, 797, 802, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 819, 820, 822, 826, 827, 830, 832, 833, 834, 835, 836, 837, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 930, 931, 932, 933, 943, 949, 950, 961, 962, 965, 966, 970, 971, 972, 973, 981, 986, 988, 989, 990, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1019, 1025, 1029, 1030, 1032, 1033, 1034, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "true_coef": [191, 204, 215, 654, 655, 660, 668, 669, 670, 689, 690, 691], "true_cov": [477, 479, 480, 486], "true_den": 304, "true_fac": 256, "true_fun": 293, "true_h": 332, "true_k": 361, "true_label": [334, 338, 339], "true_nam": [45, 1030], "true_relev": [734, 764], "true_w": 332, "true_weight": 199, "trujillo": [1055, 1056], "truli": [281, 285, 375, 720, 1000], "truncat": [2, 107, 158, 241, 395, 542, 543, 547, 548, 549, 552, 684, 686, 734, 764, 805, 861, 925, 949, 989, 999, 1000, 1014, 1030, 1034, 1035, 1036, 1047, 1049], "truncate_mod": 76, "truncatedsvd": [2, 158, 241, 361, 421, 542, 543, 547, 548, 549, 700, 871, 874, 1043, 1048, 1052, 1053, 1055, 1059], "truong": 1047, "trust": [51, 63, 105, 106, 114, 139, 144, 146, 147, 156, 157, 160, 163, 171, 181, 192, 193, 194, 195, 201, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 333, 335, 340, 368, 390, 401, 410, 414, 1029, 1055], "trustworthi": [2, 332, 1049, 1050, 1055, 1056, 1057, 1058], "truth": [2, 27, 58, 68, 75, 80, 84, 92, 93, 96, 111, 115, 118, 128, 132, 156, 184, 204, 214, 220, 221, 257, 269, 281, 361, 400, 416, 711, 712, 713, 716, 720, 721, 722, 723, 725, 726, 729, 731, 732, 734, 736, 737, 738, 742, 744, 745, 746, 747, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 791, 792, 793, 794, 795, 798, 799, 803, 804, 1000, 1025, 1033, 1049, 1055], "truthi": [2, 961], "try": [43, 45, 50, 51, 52, 54, 62, 63, 74, 88, 105, 106, 128, 139, 144, 145, 146, 147, 148, 155, 156, 157, 160, 163, 171, 176, 181, 188, 191, 192, 193, 194, 197, 199, 201, 209, 248, 249, 250, 254, 258, 259, 260, 261, 264, 265, 268, 272, 276, 278, 279, 285, 290, 292, 296, 299, 312, 317, 325, 329, 330, 332, 333, 335, 340, 351, 356, 360, 361, 368, 381, 384, 385, 386, 388, 391, 392, 394, 398, 400, 404, 407, 410, 416, 419, 420, 423, 424, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 511, 575, 585, 597, 666, 681, 683, 697, 701, 807, 808, 811, 812, 820, 822, 830, 833, 834, 835, 837, 890, 892, 895, 897, 898, 899, 900, 901, 902, 903, 912, 931, 984, 989, 996, 997, 1006, 1015, 1016, 1020, 1023, 1024, 1025, 1027, 1030, 1032, 1033, 1034, 1043, 1044, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058], "tr\u00e9segni": [0, 1043], "ts_cv": [43, 52, 155], "tscv": [420, 829], "tseng": 416, "tsetogl": 1056, "tsilhouett": 93, "tslearn": 1019, "tsne": [2, 189, 240, 241, 242, 244, 245, 300, 301, 332, 400, 430, 440, 504, 696, 697, 698, 856, 860, 873, 974, 997, 1003, 1021, 1044, 1046, 1047, 1048, 1049, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "tsne_param": 299, "tsoumaka": [728, 742, 748, 1000], "tspeng": [1056, 1057], "tsuga": 1054, "tsujii": 1014, "tsukada": 1053, "tsuruoka": 1014, "tsutomu": 1052, "tt": [161, 273, 473], "ttang131": 1051, "ttime": 93, "tttthomasssss": 1045, "tube": [918, 1015], "tue": [43, 155, 193, 1047], "tuft": 457, "tuhin": 1059, "tuk": 1059, "tulio": [1049, 1050], "tulken": 1051, "tulloch": [1044, 1045], "tumor": [174, 383, 415], "tune": [2, 43, 64, 79, 90, 105, 130, 139, 145, 155, 173, 174, 176, 187, 189, 193, 209, 224, 225, 237, 244, 248, 257, 270, 271, 281, 282, 283, 285, 296, 301, 320, 341, 349, 353, 356, 360, 369, 373, 374, 375, 399, 400, 411, 414, 416, 420, 423, 425, 426, 460, 470, 504, 559, 567, 568, 569, 602, 621, 622, 623, 625, 627, 628, 630, 631, 633, 651, 666, 667, 698, 702, 708, 710, 726, 750, 792, 795, 807, 808, 824, 830, 835, 838, 868, 873, 892, 910, 917, 994, 995, 996, 997, 999, 1000, 1003, 1004, 1006, 1014, 1015, 1021, 1026, 1036, 1041, 1055, 1057, 1059], "tuned_classifi": 336, "tuned_model": [272, 292], "tuned_model_coef": 292, "tuned_param": 46, "tuned_paramet": [111, 165, 276], "tunedthresholdclassifiercv": [2, 272, 292, 415, 807, 1059], "tunedthresholdclassifiercvifittedtunedthresholdclassifiercv": 272, "tupl": [47, 83, 84, 90, 134, 193, 238, 379, 380, 381, 388, 400, 420, 428, 441, 459, 461, 472, 475, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 508, 509, 510, 512, 513, 516, 518, 519, 520, 521, 522, 530, 541, 569, 570, 575, 576, 577, 578, 590, 591, 592, 595, 596, 597, 599, 635, 640, 641, 642, 719, 720, 727, 750, 789, 791, 805, 808, 822, 835, 852, 853, 871, 872, 882, 883, 887, 890, 898, 902, 914, 915, 916, 917, 918, 927, 933, 934, 936, 940, 941, 942, 943, 958, 966, 967, 984, 1007, 1047, 1048, 1052, 1053, 1054, 1059], "tur": 1059, "turn": [2, 30, 43, 68, 111, 187, 188, 192, 204, 235, 236, 252, 278, 303, 336, 362, 373, 374, 375, 381, 398, 400, 401, 416, 417, 419, 421, 424, 425, 426, 589, 590, 597, 615, 616, 841, 845, 914, 917, 935, 990, 994, 1002, 1005, 1010, 1024, 1034, 1046, 1048, 1049, 1054], "turquois": [129, 133, 134, 154, 226, 237, 243, 265, 266, 285], "tutori": [114, 165, 166, 167, 209, 222, 238, 278, 386, 387, 392, 394, 399, 410, 416, 460, 470, 699, 1015, 1032, 1044], "tutorial_hom": 1034, "tuveri": 1056, "tuzova": 1049, "tv": 93, "tw": [197, 380, 495, 516, 517, 666, 1015], "tweak": [2, 115, 254, 420, 966, 999, 1034, 1052], "tweedi": [2, 189, 198, 220, 472, 504, 560, 656, 677, 688, 714, 732, 753, 755, 757, 758, 760, 838, 873, 876, 877, 885, 892, 996, 1021, 1051, 1052, 1054], "tweedie_pow": 238, "tweedieregressor": [2, 43, 329, 332, 656, 677, 996, 1052, 1055, 1056], "tweet": 1024, "twelfth": 704, "twenti": [57, 251, 383, 413, 416, 1034], "twenty_test": 1034, "twenty_train": 1034, "twice": [64, 272, 290, 292, 360, 362, 388, 426, 627, 738, 740, 951, 1050, 1058], "twine": 390, "twinx": 341, "twister": 1052, "twitter": 390, "two": [2, 37, 43, 46, 48, 50, 54, 58, 61, 63, 66, 70, 72, 74, 75, 78, 90, 95, 99, 104, 105, 109, 113, 117, 118, 121, 122, 123, 125, 127, 128, 130, 133, 138, 139, 140, 147, 148, 149, 150, 152, 155, 156, 157, 158, 161, 171, 174, 176, 177, 178, 179, 182, 183, 187, 188, 189, 192, 193, 194, 199, 203, 204, 208, 209, 210, 211, 216, 220, 221, 222, 228, 229, 232, 237, 238, 242, 244, 245, 247, 252, 254, 255, 257, 263, 264, 265, 267, 268, 269, 272, 273, 275, 279, 285, 296, 302, 304, 307, 308, 310, 312, 319, 321, 324, 328, 329, 331, 332, 336, 340, 345, 346, 349, 350, 351, 353, 357, 360, 361, 362, 365, 369, 379, 380, 381, 382, 383, 384, 386, 388, 390, 392, 393, 394, 398, 400, 401, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 449, 450, 451, 452, 453, 455, 458, 459, 460, 461, 465, 467, 472, 477, 478, 479, 480, 481, 482, 483, 484, 496, 498, 499, 500, 501, 502, 504, 506, 508, 509, 510, 511, 512, 513, 515, 518, 522, 527, 530, 544, 546, 548, 552, 555, 557, 558, 561, 568, 578, 589, 592, 598, 599, 600, 603, 604, 606, 607, 608, 609, 610, 611, 614, 615, 616, 618, 619, 628, 629, 632, 636, 639, 640, 647, 651, 653, 678, 679, 681, 700, 707, 711, 712, 713, 720, 723, 724, 727, 729, 730, 731, 732, 739, 740, 743, 744, 746, 749, 751, 762, 763, 765, 771, 772, 779, 782, 785, 786, 787, 788, 789, 793, 794, 802, 803, 804, 805, 841, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 869, 870, 876, 877, 884, 885, 886, 887, 906, 907, 908, 912, 913, 920, 922, 923, 963, 979, 980, 986, 989, 990, 992, 994, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1017, 1021, 1025, 1029, 1032, 1033, 1034, 1038, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "two_mean": 79, "two_point_correl": [852, 853], "twoclass_output": 141, "twosigmajab": 1049, "twx": 51, "tx": 419, "tx_k": [419, 994], "txn": 51, "txt": [360, 380, 501, 511], "txt_sentoken": 1034, "ty": 419, "ty_k": 419, "tyagi": 1055, "tygert": [543, 549, 949], "tyler": [324, 1048, 1054, 1055, 1056], "tylerlanigan": 324, "type": [2, 46, 88, 89, 100, 103, 104, 114, 121, 123, 134, 148, 149, 151, 181, 188, 189, 191, 192, 193, 197, 204, 220, 222, 249, 254, 259, 261, 262, 264, 265, 268, 269, 272, 273, 279, 284, 285, 287, 288, 289, 292, 296, 309, 325, 335, 353, 360, 362, 368, 369, 374, 379, 380, 381, 383, 386, 389, 390, 391, 392, 398, 399, 404, 410, 413, 417, 424, 440, 472, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 504, 516, 517, 523, 575, 580, 589, 590, 596, 597, 599, 608, 612, 625, 635, 637, 638, 646, 664, 666, 680, 682, 687, 695, 697, 700, 701, 707, 709, 715, 722, 724, 737, 738, 741, 746, 791, 792, 795, 796, 805, 806, 808, 814, 822, 831, 836, 838, 839, 854, 855, 856, 858, 859, 860, 862, 863, 864, 865, 866, 872, 873, 874, 877, 879, 885, 886, 892, 893, 910, 914, 915, 916, 917, 918, 928, 930, 932, 933, 936, 940, 941, 963, 964, 971, 974, 986, 987, 990, 992, 997, 999, 1000, 1001, 1002, 1003, 1004, 1010, 1012, 1016, 1021, 1023, 1024, 1027, 1032, 1033, 1034, 1041, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "type_check": 390, "type_filt": 941, "type_of_target": [2, 400, 879, 893, 1001, 1055, 1056, 1058, 1059], "type_of_target_": 893, "typed_ndarrai": 386, "typeerror": [254, 331, 391, 719, 936, 957, 984, 1048, 1049, 1052, 1054, 1058], "typic": [25, 62, 64, 129, 137, 150, 197, 204, 220, 224, 238, 253, 280, 281, 285, 287, 288, 305, 306, 330, 349, 361, 373, 379, 380, 381, 384, 388, 389, 390, 395, 399, 400, 410, 412, 414, 416, 417, 420, 421, 423, 424, 426, 451, 455, 457, 504, 549, 559, 561, 563, 564, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 637, 646, 648, 651, 662, 663, 664, 679, 690, 691, 720, 879, 886, 890, 893, 948, 949, 957, 960, 985, 989, 993, 996, 997, 999, 1000, 1001, 1002, 1006, 1008, 1024, 1034, 1050, 1054, 1057, 1058], "typo": [386, 401, 407, 1041], "tzu": 1045, "t\u00e9l\u00e9com": 0, "u": [43, 49, 50, 51, 52, 55, 70, 85, 87, 91, 121, 125, 132, 149, 150, 155, 176, 185, 191, 192, 193, 217, 221, 224, 228, 238, 241, 244, 251, 254, 260, 261, 264, 265, 269, 272, 273, 278, 281, 285, 292, 323, 325, 353, 360, 368, 374, 381, 386, 390, 392, 394, 398, 404, 407, 413, 416, 419, 421, 423, 424, 439, 471, 473, 490, 491, 492, 539, 545, 553, 554, 558, 560, 562, 564, 566, 568, 570, 573, 576, 578, 596, 597, 599, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 689, 692, 697, 701, 712, 728, 748, 763, 845, 846, 855, 863, 870, 892, 906, 913, 915, 918, 921, 923, 949, 992, 994, 999, 1000, 1007, 1010, 1024, 1034, 1038, 1051], "u2uwz2": [174, 383], "u_": [413, 490, 491, 492], "u_1": [413, 992], "u_2": [413, 992], "u_i": [416, 490, 491, 492, 763], "u_init": 551, "u_k": [419, 421], "uai": 1012, "ubuntu": [373, 384, 392, 394], "ucdenv": 81, "uchida": [200, 1051], "uci": [47, 174, 272, 324, 380, 383, 508, 510, 512, 518], "ucl": 1013, "ucla": [277, 996], "udi": 1041, "udit": 1055, "ufmay": 1053, "ufunc": [192, 1058], "ugli": [229, 307, 310, 345], "ugo": 1055, "ugurcaliskan": 1045, "ugurthemast": [1044, 1045], "uhmann": 1054, "uieda": 1054, "uint": 1052, "uint32": [381, 505], "uint8": [88, 128, 380, 505, 514, 515, 1053], "uk": [1013, 1034], "ulloa": 1047, "ulrik": [416, 460, 470, 699], "ulterior": 52, "ultim": [90, 244, 387], "umar": [1049, 1050], "umass": [45, 57, 381, 1030], "umberto": 1053, "umbrella": 415, "umpi": 424, "un": [51, 386, 414, 424, 428, 541, 597, 803, 875, 884, 895, 899, 1050], "unabl": [51, 63, 105, 106, 144, 146, 147, 156, 157, 160, 163, 171, 181, 191, 192, 193, 194, 201, 204, 220, 248, 249, 250, 254, 258, 259, 260, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 333, 335, 340, 368, 375, 892, 1010, 1050], "unadjust": [416, 1000, 1053], "unaffect": 1003, "unalt": 1000, "unambigu": [287, 1001, 1047], "unanim": 401, "unavail": [400, 666, 667, 961, 1048, 1054], "unbalanc": [2, 189, 281, 344, 347, 350, 420, 520, 639, 917, 937, 938, 989, 1014, 1021], "unbias": [111, 414, 418, 421, 445, 558, 664, 680, 682, 695, 996, 1029], "unbound": [72, 999, 1055, 1059], "uncalibr": [61, 62, 63, 445], "uncent": 201, "uncertain": [278, 339, 385], "uncertainti": [62, 155, 176, 183, 199, 280, 414, 416, 575, 576, 651, 872, 990, 1012], "uncertainty_index": [338, 339], "unchang": [192, 238, 285, 423, 440, 445, 450, 451, 452, 453, 454, 455, 457, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 618, 619, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 700, 771, 807, 809, 810, 815, 817, 826, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 859, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 1003, 1025, 1049, 1055, 1057], "unclaim": 389, "unclear": [385, 386, 509], "unclust": 454, "uncommon": [418, 666, 912, 1015], "uncompress": [47, 516, 517, 1034], "unconstrain": [155, 157, 193, 329, 335, 381, 1014], "uncorrect": [278, 603, 606], "uncorrel": [2, 284, 382, 536, 542, 549, 1000, 1032], "uncorrupt": 44, "uncov": [135, 703], "undefin": [52, 281, 400, 720, 737, 746, 791, 969, 1000, 1049, 1053, 1057], "undefinedmetricwarn": [2, 317, 737, 738, 791, 792, 795, 1050], "under": [2, 43, 46, 50, 61, 62, 64, 76, 102, 111, 112, 132, 149, 152, 193, 220, 247, 257, 278, 285, 287, 288, 320, 334, 380, 386, 388, 390, 392, 394, 400, 404, 410, 414, 416, 418, 420, 421, 424, 425, 454, 459, 461, 478, 479, 480, 481, 482, 483, 484, 540, 547, 549, 551, 662, 663, 664, 710, 714, 715, 716, 723, 750, 762, 796, 797, 805, 806, 857, 956, 996, 997, 998, 1000, 1003, 1010, 1014, 1015, 1016, 1019, 1020, 1034, 1041, 1043, 1044, 1046, 1049, 1053], "underdetermin": 204, "underestim": [52, 152, 193, 220, 238, 278, 386], "underfit": [43, 70, 152, 176, 189, 194, 221, 224, 270, 294, 314, 325, 356, 423, 665, 808, 811, 812, 822, 834, 835, 872, 887, 995, 996, 1021], "underflow": [1049, 1054], "undergo": 284, "undergrad": 1024, "underli": [64, 91, 113, 159, 174, 192, 195, 221, 223, 224, 254, 272, 283, 303, 304, 353, 367, 374, 386, 398, 400, 403, 407, 412, 414, 416, 418, 420, 421, 422, 423, 425, 426, 445, 459, 460, 461, 470, 472, 473, 479, 480, 486, 532, 563, 564, 572, 573, 575, 576, 577, 578, 601, 602, 605, 610, 666, 667, 673, 676, 681, 683, 688, 699, 703, 807, 808, 811, 812, 822, 830, 833, 834, 835, 840, 841, 842, 843, 844, 845, 846, 855, 857, 912, 920, 921, 922, 923, 965, 996, 997, 1001, 1006, 1013, 1015, 1043, 1045, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1057, 1058, 1059, 1060], "underrepres": 386, "underscor": [362, 388, 400, 984, 1031, 1041, 1051, 1054], "underset": [421, 996, 1003, 1016], "understand": [43, 48, 52, 76, 139, 181, 189, 193, 254, 272, 273, 276, 292, 330, 331, 346, 353, 360, 363, 364, 369, 385, 386, 387, 392, 398, 403, 416, 423, 424, 512, 838, 869, 870, 920, 921, 922, 923, 926, 989, 990, 997, 999, 1016, 1018, 1019, 1021, 1024, 1041, 1055], "understood": [279, 386, 416, 957, 1031], "undertak": 398, "undesir": [92, 177, 426, 830], "undistinguish": 420, "undistort": 128, "undo": [279, 882, 1045], "undocu": 1048, "unequ": [92, 1049], "uneth": 191, "uneven": [87, 273, 416, 420], "unevenli": [92, 220, 273], "unexpect": [92, 254, 369, 386, 391, 394, 404, 410, 543, 704, 1000, 1015, 1043, 1049, 1050, 1053, 1055, 1057], "unexpectedli": [400, 1049], "unfair": 369, "unfinish": [385, 386], "unfit": [2, 91, 417, 441, 472, 577, 578, 610, 619, 1049, 1051, 1058], "unfold": [130, 389, 997], "unfortun": [152, 191, 192, 238, 394, 398, 423, 516, 517], "unhandl": 1050, "unhelp": 386, "uni": [61, 62, 63, 64, 108, 143, 176, 177, 179, 180, 181, 182, 183, 185, 211, 252, 253, 340, 356], "unicod": [362, 424, 495, 511, 590, 596, 597, 599, 965, 1041, 1049, 1053], "unicodedata": [596, 597, 599], "unicodedecodeerror": [424, 596, 597, 599], "unifi": [296, 387, 395, 398, 399, 423, 645, 1019, 1041], "unifom": 302, "uniform": [2, 58, 67, 72, 88, 151, 152, 156, 170, 177, 182, 185, 199, 200, 234, 245, 247, 250, 286, 302, 305, 306, 311, 314, 320, 322, 323, 326, 332, 334, 348, 388, 391, 410, 416, 446, 447, 559, 577, 578, 618, 619, 636, 647, 657, 658, 662, 676, 684, 685, 686, 707, 729, 731, 736, 753, 754, 756, 758, 759, 761, 793, 798, 799, 812, 820, 822, 847, 848, 851, 854, 855, 862, 863, 877, 889, 891, 901, 937, 951, 989, 990, 999, 1000, 1003, 1047, 1049, 1051, 1055, 1057], "uniform_averag": [439, 473, 490, 491, 492, 562, 564, 566, 568, 570, 573, 576, 578, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 729, 731, 736, 753, 754, 756, 758, 759, 761, 793, 798, 799, 845, 846, 855, 863, 870, 913, 915, 918, 921, 923, 1000, 1050], "uniform_labelings_scor": 72, "uniformli": [72, 145, 152, 169, 247, 263, 328, 388, 524, 525, 526, 559, 650, 812, 820, 822, 891, 989, 990, 1000, 1003, 1010, 1045, 1050], "unigram": [279, 381, 424, 596, 597, 599, 1048], "unilev": 51, "unimod": [247, 482], "unimport": [425, 1008], "uninform": [62, 64, 326, 382, 391, 424, 989, 996, 1049], "uniniti": 394, "uninstal": 384, "unintention": 1010, "unintuit": 92, "union": [104, 192, 417, 746, 762, 871, 1048], "union_not_memb": 192, "uniqu": [2, 43, 61, 66, 77, 82, 83, 92, 93, 98, 102, 107, 146, 147, 153, 154, 155, 192, 194, 204, 235, 238, 265, 287, 308, 325, 326, 334, 341, 360, 361, 362, 380, 388, 395, 400, 416, 417, 420, 423, 424, 448, 458, 462, 464, 472, 475, 504, 557, 558, 559, 561, 562, 565, 566, 567, 568, 569, 570, 572, 573, 574, 618, 641, 642, 643, 674, 676, 684, 705, 717, 719, 762, 790, 808, 810, 822, 835, 840, 841, 844, 850, 859, 862, 864, 869, 871, 883, 885, 886, 893, 896, 912, 914, 920, 921, 922, 923, 937, 949, 963, 964, 996, 1001, 1010, 1024, 1032, 1049, 1052, 1053, 1055, 1056, 1057, 1058, 1059], "unique_label": [2, 84, 90, 361, 388, 395], "unit": [2, 63, 104, 113, 192, 197, 220, 238, 304, 316, 319, 336, 361, 381, 386, 387, 388, 392, 394, 395, 421, 424, 428, 472, 497, 498, 527, 532, 540, 541, 542, 549, 550, 597, 598, 599, 615, 616, 619, 666, 667, 684, 693, 707, 778, 859, 868, 869, 870, 876, 882, 884, 888, 890, 892, 898, 899, 900, 902, 903, 912, 913, 996, 998, 999, 1000, 1005, 1010, 1016, 1019, 1032, 1045, 1049, 1055, 1056], "unit_eig_vec": 263, "unit_vari": [890, 902, 1053], "unitari": 949, "uniti": 30, "univ": [697, 701, 997], "univ_select": 108, "univari": [2, 18, 48, 49, 71, 82, 106, 108, 168, 169, 171, 189, 202, 219, 235, 291, 344, 378, 416, 417, 424, 453, 512, 533, 538, 600, 603, 604, 606, 607, 608, 610, 613, 614, 615, 616, 617, 635, 636, 637, 638, 653, 808, 813, 834, 838, 872, 873, 882, 887, 891, 892, 912, 917, 996, 1015, 1017, 1021, 1022, 1033, 1036, 1041, 1047], "univers": [0, 184, 192, 360, 381, 383, 389, 416, 421, 424, 598, 796, 847, 851, 907, 996, 998, 1000, 1002], "unix": 424, "unknown": [52, 91, 192, 254, 278, 338, 340, 375, 381, 400, 410, 413, 424, 879, 885, 886, 963, 999, 1010, 1025, 1045, 1049, 1053, 1054], "unknown_typ": 410, "unknown_v": 160, "unknown_valu": [149, 160, 194, 257, 325, 886, 1010, 1053, 1055, 1056], "unlabel": [38, 45, 255, 330, 338, 339, 340, 342, 343, 400, 416, 907, 908, 909, 999, 1025, 1028, 1030, 1032, 1053], "unlabeled_indic": 339, "unlabeled_set": 338, "unless": [191, 254, 264, 269, 386, 388, 389, 398, 400, 410, 414, 416, 419, 427, 445, 452, 454, 456, 458, 460, 465, 466, 469, 472, 475, 480, 497, 504, 516, 517, 539, 543, 544, 545, 547, 550, 551, 553, 554, 555, 556, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 575, 576, 577, 578, 602, 610, 615, 616, 618, 619, 640, 642, 647, 654, 655, 659, 660, 661, 663, 665, 666, 667, 669, 671, 673, 674, 676, 684, 687, 696, 697, 698, 699, 700, 701, 702, 717, 722, 782, 786, 789, 808, 811, 812, 814, 822, 830, 831, 833, 834, 835, 836, 837, 839, 840, 841, 842, 844, 845, 854, 855, 858, 860, 862, 863, 865, 866, 869, 870, 871, 874, 893, 897, 898, 900, 901, 902, 903, 907, 908, 920, 921, 922, 923, 928, 932, 933, 949, 996, 999, 1001, 1041, 1043, 1047, 1049, 1052, 1053, 1058, 1059], "unlik": [90, 91, 145, 192, 193, 240, 242, 268, 319, 347, 386, 388, 392, 398, 400, 407, 410, 418, 420, 421, 424, 454, 458, 543, 658, 659, 662, 663, 664, 690, 691, 793, 829, 852, 853, 892, 903, 915, 996, 999, 1000, 1007, 1015, 1041, 1047], "unlimit": [565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923], "unlucki": 369, "unmaintain": 1041, "unmarri": 192, "unmeaning": 1048, "unmix": [126, 428, 541], "unmixing_matrix": 541, "unmodifi": [388, 400], "unnecessari": [145, 263, 391, 451, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 713, 1003, 1010, 1020, 1024, 1044, 1046, 1051, 1052, 1054, 1057], "unnecessarili": [244, 1048, 1051], "unnorm": [400, 544, 997, 1047, 1048], "unobserv": [155, 191, 192, 421], "unord": [416, 423, 1010], "unpack": 388, "unpen": [414, 656, 677, 688, 996], "unpickl": [2, 400, 584, 852, 853, 1047, 1053, 1057], "unpleas": 1043, "unpract": 999, "unprefix": 1047, "unprocess": [458, 596, 597, 599], "unprotect": 966, "unprun": [565, 566, 572, 573, 920, 921, 922, 923], "unquot": 238, "unrealist": 381, "unreason": [238, 420], "unreg": 354, "unregular": [885, 908, 1032, 1050], "unrel": [325, 374, 391, 394, 424, 523], "unreli": [272, 417], "unrepresent": 927, "unrestrict": 501, "unrol": 244, "unrot": 135, "unsaf": 542, "unsampl": 992, "unscal": [319, 324, 996, 1000, 1049, 1055], "unscaled_clf": 324, "unseen": [111, 150, 171, 209, 224, 228, 291, 305, 353, 375, 378, 388, 399, 400, 416, 420, 858, 889, 901, 991, 1000, 1006, 1008, 1010, 1016, 1025, 1044, 1049, 1053], "unseen_featur": [424, 589], "unset": [374, 400, 1049], "unsetmetadatapassederror": 407, "unshad": 421, "unshifft": 685, "unshift": 916, "unsign": [88, 129, 381, 590, 965], "unsmooth": 422, "unsort": [1003, 1042, 1045, 1049], "unspecifi": [607, 608, 810, 997], "unstabl": [74, 101, 192, 416, 418, 419, 697, 701, 948, 949, 1016, 1045, 1046, 1048, 1053, 1055, 1057], "unstack": [238, 281], "unstructur": [53, 71, 74, 75, 76, 82, 189, 244, 316, 416, 449, 453, 471, 511, 538, 865, 1012, 1021, 1024, 1045], "unsuccess": 50, "unsupervis": [2, 6, 27, 34, 45, 51, 72, 84, 106, 107, 118, 125, 144, 158, 247, 255, 305, 306, 348, 360, 361, 369, 378, 381, 388, 399, 400, 416, 419, 421, 422, 423, 424, 425, 440, 450, 453, 540, 542, 544, 545, 547, 550, 551, 557, 571, 574, 575, 577, 578, 590, 591, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 636, 638, 642, 643, 646, 647, 648, 649, 650, 685, 808, 811, 812, 814, 822, 831, 836, 839, 854, 855, 858, 860, 861, 862, 863, 868, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 889, 890, 891, 892, 893, 904, 905, 909, 916, 997, 1000, 1006, 1013, 1022, 1025, 1026, 1028, 1030, 1036, 1041, 1044, 1054, 1058], "unsupport": [407, 410, 501, 1049, 1054], "unsur": 913, "untangl": 130, "untar": 47, "unterthin": [319, 1044, 1045, 1046], "until": [90, 174, 228, 290, 330, 332, 391, 400, 401, 413, 416, 420, 425, 516, 517, 565, 566, 567, 568, 572, 573, 574, 601, 654, 655, 660, 661, 666, 667, 668, 669, 670, 671, 674, 675, 676, 679, 684, 685, 686, 702, 805, 806, 811, 812, 869, 870, 909, 912, 920, 921, 922, 923, 975, 989, 996, 997, 1005, 1013, 1016, 1034, 1044, 1048, 1049, 1055], "untransform": [353, 472, 475, 1011], "untru": 1000, "untrust": 410, "untun": [152, 336], "unus": [121, 131, 193, 217, 240, 242, 471, 587, 771, 779, 989, 997, 1041, 1049, 1051, 1052, 1054, 1056], "unusu": [64, 413, 1006, 1010, 1049], "unveil": 1047, "unvendor": 1049, "unwant": [221, 360], "unweight": [188, 233, 471, 655, 661, 686, 715, 721, 737, 738, 746, 791, 792, 795, 796, 847, 848, 849, 850, 851, 990], "unwieldi": 883, "uoa": 905, "up": [2, 47, 50, 72, 79, 81, 82, 83, 87, 90, 92, 97, 104, 113, 114, 120, 123, 137, 144, 155, 188, 192, 193, 199, 204, 213, 221, 236, 237, 265, 272, 280, 283, 299, 312, 317, 320, 325, 332, 336, 339, 346, 353, 356, 360, 362, 375, 380, 381, 386, 390, 392, 393, 394, 395, 398, 400, 401, 414, 416, 421, 423, 424, 451, 455, 456, 457, 458, 460, 464, 467, 468, 469, 516, 517, 544, 557, 558, 565, 566, 567, 568, 569, 570, 572, 573, 574, 618, 635, 640, 641, 647, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 668, 669, 670, 671, 672, 689, 690, 691, 692, 700, 713, 777, 805, 806, 810, 811, 812, 814, 836, 886, 887, 890, 902, 920, 921, 922, 923, 926, 949, 952, 953, 989, 992, 996, 997, 1000, 1003, 1010, 1014, 1015, 1020, 1023, 1024, 1033, 1034, 1041, 1042, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1058, 1059], "upadhyai": [1047, 1048, 1049, 1050], "upcast": [1051, 1055], "upcom": [181, 384], "updat": [47, 79, 97, 139, 145, 154, 252, 328, 362, 385, 386, 390, 394, 400, 410, 416, 421, 423, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 471, 473, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 805, 806, 807, 808, 809, 810, 811, 812, 815, 817, 822, 826, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 927, 975, 996, 1003, 1004, 1005, 1014, 1023, 1024, 1042, 1048, 1049, 1050, 1052, 1054, 1056, 1057, 1059, 1060], "update_from": 306, "update_func": 306, "update_h": 555, "update_layout": [145, 279], "update_legend_marker_s": 306, "update_terminal_region": 1050, "upgrad": [328, 329, 330, 331, 332, 333, 334, 335, 336, 404, 1020, 1041, 1046, 1049], "upload": [380, 384, 390, 398, 679], "upload_d": 380, "upon": [238, 245, 254, 312, 381, 386, 398, 400, 410, 569, 570, 635, 638, 679, 797, 805, 806, 852, 853, 989, 996, 1016, 1025, 1034, 1055], "upper": [43, 46, 48, 61, 106, 109, 112, 113, 114, 141, 142, 143, 151, 152, 153, 154, 160, 162, 170, 180, 182, 185, 192, 214, 220, 226, 227, 230, 234, 237, 238, 251, 255, 256, 277, 278, 279, 292, 304, 305, 315, 324, 341, 348, 351, 353, 355, 416, 422, 471, 596, 597, 599, 603, 621, 622, 623, 625, 627, 628, 630, 631, 633, 640, 641, 643, 645, 658, 662, 685, 743, 796, 885, 886, 914, 915, 916, 936, 999, 1000, 1003, 1010, 1014, 1015, 1016, 1049], "upperbound": 742, "uppercas": [400, 1054], "uppercase_initi": 424, "upperlimit": 712, "upright": 381, "upstream": [373, 386, 390, 394, 398, 1010, 1050], "upward": [458, 464], "ur": 1052, "urbanowicz": 1000, "urbanowicz2015": 1000, "urcrnrlat": [50, 312], "urcrnrlon": [50, 312], "uri": 55, "url": [51, 55, 174, 380, 383, 388, 390], "urllib": [47, 55], "urlopen": 55, "urlretriev": 47, "urlu": 1059, "urvang": [1049, 1051], "us": [0, 2, 15, 16, 19, 25, 27, 30, 37, 42, 43, 46, 47, 48, 50, 52, 53, 54, 57, 58, 59, 61, 62, 63, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 118, 121, 122, 123, 124, 127, 129, 130, 132, 133, 134, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 159, 161, 162, 163, 165, 166, 167, 170, 171, 172, 173, 175, 176, 177, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 204, 205, 206, 208, 209, 210, 211, 213, 214, 216, 218, 219, 220, 221, 222, 224, 225, 226, 228, 229, 232, 235, 237, 238, 240, 241, 242, 243, 245, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 264, 265, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 279, 280, 281, 283, 284, 285, 286, 288, 289, 290, 291, 292, 293, 296, 297, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 315, 316, 317, 318, 319, 321, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 336, 338, 339, 342, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 356, 359, 362, 364, 366, 367, 372, 373, 374, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 390, 393, 395, 399, 400, 401, 403, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 422, 423, 426, 427, 428, 429, 430, 432, 434, 435, 437, 438, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 496, 497, 498, 501, 502, 504, 506, 507, 509, 511, 514, 516, 517, 519, 522, 523, 524, 527, 528, 530, 531, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 582, 583, 585, 586, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 614, 615, 616, 617, 618, 619, 621, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 717, 719, 720, 721, 722, 723, 724, 725, 726, 727, 729, 731, 732, 734, 735, 736, 737, 738, 740, 743, 744, 745, 746, 747, 749, 750, 751, 753, 754, 756, 758, 759, 761, 763, 764, 765, 766, 767, 771, 772, 774, 775, 776, 777, 779, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 819, 820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 927, 928, 931, 932, 933, 935, 938, 939, 944, 946, 948, 949, 953, 956, 957, 958, 960, 963, 967, 969, 971, 972, 974, 976, 977, 978, 984, 989, 990, 992, 993, 995, 998, 999, 1001, 1002, 1003, 1005, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1033, 1035, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "usa": [277, 381, 909, 990, 997, 1012, 1013], "usabl": [155, 380, 386, 388, 400, 410, 424, 808, 1041, 1048, 1055, 1056], "usag": [41, 77, 88, 105, 108, 117, 129, 137, 171, 192, 193, 248, 252, 254, 271, 272, 308, 310, 316, 345, 362, 373, 381, 385, 386, 388, 389, 393, 394, 396, 400, 401, 404, 410, 416, 420, 421, 426, 427, 452, 454, 458, 472, 497, 502, 504, 520, 523, 527, 531, 542, 543, 549, 557, 569, 570, 599, 617, 648, 656, 666, 667, 668, 674, 675, 676, 677, 684, 685, 686, 687, 688, 698, 786, 789, 800, 801, 868, 869, 871, 912, 920, 921, 922, 923, 949, 989, 990, 992, 999, 1000, 1001, 1003, 1015, 1022, 1023, 1025, 1029, 1036, 1042, 1043, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1059], "usal": 197, "usd": 257, "use_encoded_valu": [149, 160, 194, 257, 325, 886, 1010, 1053], "use_group": 273, "use_idf": [421, 424, 598, 599, 1034], "usecas": [329, 332, 334, 416, 570], "useless": [54, 148, 281, 392, 425, 523, 536, 666, 720, 996, 1010, 1050], "user": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 52, 62, 64, 90, 103, 125, 145, 185, 189, 192, 208, 240, 254, 268, 275, 285, 287, 296, 299, 305, 306, 309, 325, 328, 329, 330, 331, 332, 333, 334, 335, 336, 369, 373, 374, 380, 384, 385, 386, 388, 390, 392, 393, 394, 398, 399, 400, 404, 407, 410, 414, 416, 417, 418, 420, 421, 423, 424, 425, 427, 428, 429, 430, 433, 439, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 467, 468, 469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 582, 589, 590, 591, 592, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 621, 622, 623, 624, 627, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 703, 705, 706, 707, 708, 710, 711, 712, 713, 715, 716, 717, 718, 719, 720, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 765, 766, 767, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 926, 945, 949, 989, 990, 996, 997, 999, 1000, 1001, 1003, 1010, 1014, 1019, 1020, 1024, 1027, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "user_guid": 43, "user_r": 417, "userguid": 1048, "usernam": 404, "userscript": 394, "userwarn": [79, 97, 141, 185, 354, 391, 720, 1010, 1047, 1049, 1054], "ushtanit": [1053, 1054], "usp": 44, "usr": 384, "usual": [43, 52, 75, 111, 112, 114, 151, 152, 154, 160, 191, 193, 206, 220, 221, 271, 272, 275, 278, 287, 288, 292, 320, 331, 349, 369, 373, 374, 384, 386, 388, 394, 398, 399, 400, 404, 407, 413, 416, 417, 420, 421, 423, 424, 425, 458, 464, 546, 548, 550, 555, 567, 568, 615, 616, 638, 648, 666, 667, 674, 675, 676, 684, 685, 686, 700, 734, 766, 814, 836, 840, 912, 949, 989, 990, 992, 995, 996, 997, 999, 1000, 1001, 1004, 1005, 1006, 1007, 1010, 1014, 1015, 1016, 1025, 1031, 1032, 1056], "utc": 1000, "utf": [360, 362, 424, 495, 511, 590, 596, 597, 599], "util": [2, 4, 10, 17, 35, 38, 47, 49, 50, 83, 90, 91, 96, 120, 137, 139, 160, 220, 222, 228, 236, 242, 250, 254, 256, 266, 284, 286, 299, 321, 328, 341, 349, 353, 360, 374, 380, 381, 386, 387, 388, 389, 398, 399, 400, 412, 415, 416, 417, 420, 421, 424, 445, 451, 452, 455, 457, 461, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 541, 542, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 585, 589, 590, 596, 598, 599, 602, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 698, 807, 808, 809, 810, 815, 817, 826, 830, 832, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 857, 859, 862, 863, 869, 870, 872, 875, 877, 878, 879, 884, 891, 892, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 995, 998, 1000, 1001, 1010, 1011, 1019, 1024, 1026, 1036, 1041, 1042, 1044, 1045, 1047, 1048], "utilis": 1047, "utkarsh": [1047, 1048, 1049, 1050], "utl": 425, "utstat": 652, "uttam": 1054, "uv": [125, 421], "uw": [174, 383, 1053], "uwha": [1054, 1055], "v": [0, 2, 30, 43, 48, 52, 53, 55, 57, 64, 66, 69, 70, 71, 72, 73, 74, 75, 76, 82, 84, 90, 93, 104, 109, 110, 113, 115, 116, 117, 125, 127, 128, 132, 143, 145, 146, 147, 152, 153, 154, 165, 170, 176, 189, 190, 195, 198, 209, 218, 219, 220, 221, 224, 225, 229, 235, 244, 251, 264, 265, 268, 269, 270, 274, 294, 296, 298, 310, 326, 328, 346, 357, 361, 369, 374, 378, 383, 386, 392, 394, 400, 412, 413, 414, 418, 419, 421, 424, 439, 449, 453, 460, 470, 471, 472, 473, 478, 481, 482, 483, 484, 485, 490, 491, 492, 504, 520, 532, 538, 539, 545, 549, 553, 554, 558, 560, 562, 564, 566, 568, 570, 572, 573, 576, 578, 589, 597, 601, 602, 608, 614, 619, 638, 639, 642, 643, 647, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 684, 686, 687, 696, 703, 707, 709, 712, 725, 744, 745, 747, 762, 763, 765, 796, 803, 808, 813, 820, 822, 834, 838, 840, 841, 842, 845, 846, 847, 855, 863, 865, 868, 870, 872, 873, 876, 879, 885, 886, 887, 892, 893, 896, 906, 912, 913, 914, 915, 917, 918, 921, 923, 927, 994, 995, 996, 997, 1000, 1001, 1002, 1005, 1008, 1010, 1014, 1015, 1017, 1021, 1036, 1041, 1044, 1045, 1046, 1049, 1051, 1052, 1055, 1056, 1059], "v0": [390, 479, 480, 486, 520, 596, 597, 599, 808, 822, 871, 874, 1042, 1049, 1050, 1051], "v1": [272, 333, 380, 404, 569, 570, 805, 806, 1053, 1056, 1057, 1058, 1059], "v10": 272, "v11": 272, "v12": 272, "v13": 272, "v14": 272, "v15": 272, "v16": 272, "v17": 272, "v18": 272, "v19": 272, "v2": [272, 381, 505, 672, 693, 694, 996], "v20": 272, "v21": 272, "v22": 272, "v23": 272, "v24": 272, "v25": 272, "v26": 272, "v27": 272, "v28": 272, "v3": 272, "v4": 272, "v5": [272, 1049], "v6": 272, "v7": 272, "v8": 272, "v9": 272, "v_": [413, 424], "v_1": 413, "v_2": 413, "v_i": 1005, "v_ih_j": 1005, "v_init": 551, "v_j": [416, 763, 1005], "v_k": [419, 421, 539, 545, 553, 554], "v_measur": [744, 803], "v_measure_scor": [2, 57, 72, 73, 84, 93, 334, 361, 416, 725, 744, 745, 765, 1000, 1050], "v_new": 868, "va": [47, 150, 172, 289, 307, 309, 355], "vac": 296, "vacaliuc": [1049, 1050], "vacat": 381, "vachan": 1052, "vadim": [1049, 1053, 1054], "vaerenbergh": [1056, 1057], "vaggi": [1043, 1044], "vaillant": 1053, "val": [107, 232, 278, 951], "val_errors_with": 150, "val_errors_without": 150, "val_pr": 150, "val_scor": 151, "vale": 1051, "valencia": [1055, 1057], "valentin": [1044, 1046, 1056, 1057], "valero": 51, "valgrind": 389, "valid": [2, 47, 52, 53, 63, 64, 89, 90, 91, 92, 105, 106, 108, 109, 111, 115, 132, 137, 143, 145, 148, 149, 150, 151, 152, 155, 156, 164, 168, 171, 172, 174, 184, 189, 192, 194, 198, 204, 206, 208, 214, 220, 222, 228, 238, 254, 256, 260, 265, 268, 270, 275, 278, 279, 280, 282, 284, 285, 286, 287, 290, 291, 292, 293, 296, 303, 317, 320, 325, 328, 330, 335, 341, 349, 356, 364, 374, 381, 386, 389, 398, 399, 400, 410, 411, 414, 416, 417, 418, 421, 422, 423, 424, 425, 430, 432, 445, 450, 451, 453, 454, 455, 457, 458, 465, 471, 472, 476, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 501, 509, 510, 512, 523, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 555, 557, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 580, 583, 585, 590, 591, 597, 601, 602, 605, 610, 640, 642, 646, 647, 648, 649, 650, 651, 654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 679, 680, 681, 682, 683, 684, 685, 686, 687, 689, 690, 691, 692, 693, 694, 696, 697, 700, 707, 709, 710, 714, 721, 736, 770, 773, 782, 786, 787, 788, 793, 800, 801, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 843, 846, 852, 853, 854, 855, 856, 857, 858, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 875, 876, 878, 884, 892, 904, 905, 907, 908, 910, 912, 914, 917, 919, 920, 921, 922, 923, 932, 933, 934, 935, 936, 943, 955, 957, 960, 984, 985, 986, 987, 988, 990, 999, 1000, 1001, 1003, 1004, 1008, 1010, 1012, 1014, 1015, 1016, 1019, 1020, 1021, 1024, 1025, 1028, 1036, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "valid_metr": [852, 853, 1003, 1057], "valid_scor": 995, "validate_metadata": [254, 957], "validation_curv": [2, 334, 356, 407, 831, 995, 1048, 1049, 1050, 1053, 1057], "validation_fract": [150, 155, 228, 331, 423, 567, 568, 569, 570, 674, 675, 676, 684, 686, 869, 870, 1014, 1049, 1055], "validation_score_": [155, 569, 570], "validation_scores_": [869, 870, 1056], "validationcurvedisplai": [2, 294, 995, 1057], "validationerror": 1055, "vallei": 325, "vall\u00e9": 1048, "valu": [2, 20, 27, 43, 44, 46, 50, 51, 52, 53, 55, 57, 58, 59, 63, 64, 68, 72, 75, 77, 79, 81, 88, 90, 95, 96, 97, 101, 105, 107, 109, 111, 113, 115, 125, 128, 135, 137, 139, 141, 143, 144, 145, 146, 147, 149, 152, 153, 156, 157, 159, 160, 169, 170, 172, 173, 176, 179, 180, 182, 184, 191, 192, 193, 194, 195, 197, 199, 200, 202, 204, 206, 208, 209, 210, 211, 213, 218, 220, 221, 222, 224, 226, 235, 238, 239, 242, 243, 247, 248, 249, 250, 251, 252, 253, 257, 260, 261, 263, 269, 271, 272, 274, 276, 278, 279, 281, 283, 284, 285, 287, 289, 290, 291, 292, 294, 299, 302, 312, 314, 315, 317, 319, 320, 321, 322, 323, 324, 325, 326, 330, 336, 341, 349, 353, 354, 356, 360, 361, 362, 364, 369, 373, 374, 375, 378, 379, 380, 381, 383, 387, 388, 389, 391, 392, 393, 395, 398, 399, 400, 403, 404, 407, 413, 414, 416, 417, 418, 419, 420, 424, 425, 426, 427, 428, 429, 430, 439, 440, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 495, 498, 499, 501, 504, 505, 506, 509, 516, 517, 519, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 594, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 702, 703, 705, 706, 707, 708, 709, 710, 712, 713, 715, 716, 717, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 743, 744, 745, 746, 747, 748, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 777, 779, 782, 786, 787, 788, 789, 790, 791, 792, 793, 795, 796, 797, 798, 799, 800, 801, 802, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 817, 819, 820, 822, 825, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 926, 927, 929, 930, 931, 932, 933, 936, 937, 938, 939, 941, 949, 951, 957, 960, 961, 962, 963, 964, 976, 977, 978, 989, 992, 993, 994, 995, 996, 997, 999, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1011, 1013, 1014, 1015, 1021, 1022, 1024, 1025, 1030, 1032, 1033, 1034, 1035, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "valuabl": [150, 272, 386, 990, 1024], "valuat": 423, "value_count": [43, 52, 193, 272, 292, 296], "value_kei": [398, 927], "value_typ": [426, 625], "valueerror": [2, 254, 255, 388, 392, 407, 476, 585, 611, 625, 643, 679, 722, 844, 862, 871, 877, 891, 931, 935, 936, 985, 986, 987, 1010, 1043, 1044, 1045, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059], "values_format": [705, 1051], "vamsi": 1056, "van": [0, 380, 405, 418, 477, 482, 542, 635, 700, 704, 990, 997, 1000, 1006, 1024, 1042, 1043, 1044, 1045, 1048, 1049, 1050, 1052, 1053, 1054, 1056, 1057], "vandana": 1052, "vander": 200, "vandermond": [221, 1010], "vanderpla": [0, 50, 183, 221, 240, 266, 304, 312, 406, 1018, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049], "vang": 1054, "vanilla": [220, 412, 415, 416, 455, 457, 468, 637], "vanilla_model": 272, "vanilla_model_coef": 292, "vanrel": 1047, "vanschoren": [380, 1053], "vapnik": [601, 602], "var": [117, 118, 142, 174, 200, 278, 383, 387, 425, 649, 653, 914, 915, 916, 917, 918, 1000, 1049], "var_": [542, 850, 892, 1054], "var_smooth": [850, 1049], "varanasi": [1041, 1044], "vardhan": 1045, "varepsilon": [416, 1014, 1015], "vari": [46, 52, 64, 67, 70, 79, 81, 90, 97, 100, 109, 145, 146, 148, 158, 167, 173, 178, 180, 189, 192, 193, 209, 211, 214, 218, 227, 245, 252, 257, 268, 274, 278, 281, 292, 313, 319, 321, 322, 324, 334, 337, 343, 349, 352, 354, 358, 369, 373, 375, 381, 400, 410, 449, 453, 454, 508, 516, 522, 523, 530, 567, 568, 572, 573, 654, 655, 658, 659, 660, 661, 662, 663, 668, 669, 670, 671, 689, 692, 711, 771, 827, 831, 836, 838, 839, 869, 873, 877, 892, 909, 917, 920, 921, 974, 992, 995, 996, 1000, 1003, 1004, 1013, 1016, 1021, 1024, 1048, 1049, 1057], "variabl": [2, 43, 48, 50, 51, 52, 72, 104, 142, 146, 149, 152, 153, 155, 166, 167, 169, 174, 183, 184, 187, 188, 193, 194, 197, 204, 209, 220, 224, 225, 238, 242, 254, 257, 269, 272, 278, 281, 288, 296, 298, 324, 325, 326, 369, 373, 375, 381, 383, 384, 386, 388, 390, 391, 394, 400, 407, 412, 416, 417, 418, 419, 421, 423, 424, 425, 458, 490, 491, 492, 495, 507, 509, 516, 523, 540, 542, 544, 549, 552, 561, 567, 568, 612, 614, 615, 616, 648, 658, 659, 662, 663, 669, 690, 691, 703, 717, 755, 809, 810, 813, 815, 816, 817, 818, 823, 824, 825, 826, 827, 828, 832, 833, 834, 835, 837, 840, 844, 845, 875, 886, 889, 893, 901, 913, 989, 990, 992, 996, 999, 1000, 1001, 1002, 1003, 1005, 1007, 1008, 1010, 1014, 1016, 1019, 1020, 1025, 1026, 1028, 1030, 1041, 1046, 1049, 1051, 1054, 1056], "varianc": [2, 37, 43, 44, 52, 64, 79, 90, 92, 97, 107, 111, 113, 117, 118, 121, 125, 126, 127, 130, 132, 133, 135, 138, 154, 155, 183, 185, 189, 192, 198, 200, 202, 204, 209, 210, 216, 220, 222, 225, 238, 268, 272, 275, 278, 281, 287, 288, 291, 292, 308, 314, 319, 324, 336, 361, 369, 378, 382, 395, 413, 414, 416, 418, 419, 420, 421, 422, 423, 428, 449, 453, 457, 471, 529, 532, 540, 541, 542, 549, 552, 557, 558, 563, 564, 566, 567, 568, 573, 611, 615, 616, 619, 633, 651, 652, 653, 660, 664, 665, 668, 670, 680, 681, 682, 683, 684, 695, 718, 736, 793, 805, 806, 850, 861, 876, 882, 888, 890, 892, 898, 900, 902, 903, 921, 923, 975, 976, 977, 981, 994, 995, 996, 998, 1003, 1004, 1005, 1008, 1012, 1014, 1015, 1016, 1017, 1021, 1022, 1030, 1032, 1033, 1036, 1041, 1049, 1051, 1052, 1053, 1054, 1055, 1056], "variance_weight": [736, 793, 1000], "variances_": 611, "variancethreshold": [2, 425, 877, 990, 1044, 1051, 1054, 1057], "variant": [2, 64, 78, 125, 186, 188, 189, 278, 331, 332, 361, 362, 392, 416, 419, 421, 424, 426, 457, 468, 498, 501, 502, 520, 523, 551, 567, 568, 573, 623, 627, 630, 631, 635, 638, 646, 647, 649, 653, 680, 712, 809, 813, 815, 816, 817, 826, 834, 855, 873, 909, 990, 996, 997, 998, 999, 1000, 1002, 1003, 1014, 1020, 1021, 1034, 1041, 1049], "variat": [2, 43, 46, 51, 72, 100, 123, 157, 174, 181, 182, 188, 189, 192, 225, 262, 264, 269, 275, 289, 298, 309, 329, 349, 383, 410, 420, 421, 451, 455, 467, 544, 651, 680, 682, 683, 805, 806, 826, 827, 829, 989, 1000, 1010, 1013, 1016, 1019, 1021, 1030, 1032, 1035, 1036, 1044, 1046, 1047], "variegatu": [50, 312, 381, 506], "variet": 325, "varieti": [25, 62, 187, 265, 325, 349, 394, 416, 418, 424, 651, 1003, 1016, 1019, 1024, 1043, 1056, 1057], "varimax": [135, 421, 540, 1053], "variou": [4, 41, 43, 51, 71, 72, 74, 90, 93, 95, 96, 97, 114, 117, 120, 128, 189, 192, 198, 228, 230, 239, 240, 241, 242, 251, 296, 299, 315, 323, 329, 338, 339, 360, 362, 368, 369, 373, 380, 381, 382, 383, 386, 388, 391, 399, 401, 414, 416, 418, 445, 449, 480, 510, 522, 523, 533, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 577, 578, 602, 610, 655, 659, 661, 663, 666, 669, 671, 673, 674, 676, 681, 683, 684, 699, 700, 707, 808, 811, 812, 814, 822, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 872, 912, 913, 989, 990, 997, 1000, 1003, 1007, 1010, 1014, 1016, 1019, 1021, 1023, 1024, 1033, 1034, 1041, 1044, 1045, 1058], "varma": 1050, "varoquaux": [0, 51, 67, 68, 74, 75, 80, 81, 86, 87, 88, 101, 102, 107, 115, 120, 121, 127, 131, 203, 209, 210, 217, 218, 241, 243, 250, 252, 265, 321, 353, 354, 401, 405, 1018, 1024, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "varun": [1047, 1048, 1049, 1055, 1056], "varunchaduvula": 1059, "vasani": 1052, "vasilei": [1024, 1048], "vasileva": 1055, "vasiloudi": 1046, "vassard": 1055, "vassilvitskii": [416, 455, 468], "vast": [272, 386], "vastli": 324, "vathsala": [1048, 1049, 1050, 1051], "vatsan": 1047, "vavrova": 1048, "vazelh": [1049, 1050, 1051], "vazirgianni": 416, "vb": 544, "vbgmm": [1041, 1045, 1047], "vc": 384, "vcvarsal": 384, "vd": 1059, "ve": [361, 386, 424, 1024, 1034, 1048], "veal": 57, "veb2009": 416, "veb2010": 416, "vec": [125, 424, 546, 548, 555], "veclib": [373, 398], "vect": [47, 104, 279, 342, 424, 1034], "vect__": 279, "vect__max_df": 279, "vect__min_df": 279, "vect__ngram_rang": [279, 1034], "vect__norm": 279, "vector": [2, 17, 39, 46, 47, 48, 49, 51, 54, 57, 58, 63, 66, 68, 71, 75, 83, 106, 120, 125, 127, 128, 170, 176, 184, 201, 207, 224, 225, 232, 236, 252, 253, 260, 276, 278, 279, 283, 305, 317, 319, 336, 343, 345, 346, 349, 350, 351, 352, 353, 354, 356, 358, 361, 373, 375, 381, 391, 392, 395, 398, 400, 413, 414, 416, 418, 419, 420, 421, 423, 426, 427, 428, 445, 451, 452, 453, 455, 457, 458, 459, 461, 472, 473, 475, 476, 490, 491, 492, 493, 495, 497, 505, 517, 520, 529, 532, 539, 542, 543, 545, 546, 547, 548, 549, 550, 551, 552, 553, 557, 558, 559, 560, 575, 576, 577, 578, 589, 590, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 621, 622, 623, 625, 626, 627, 628, 630, 631, 633, 639, 646, 648, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 676, 680, 681, 682, 683, 684, 685, 686, 694, 695, 696, 697, 699, 700, 701, 703, 707, 727, 743, 771, 776, 777, 778, 779, 781, 782, 783, 785, 786, 807, 808, 811, 812, 822, 830, 836, 839, 840, 841, 847, 848, 849, 850, 851, 854, 855, 856, 858, 859, 860, 862, 863, 864, 869, 870, 877, 879, 884, 892, 896, 899, 910, 912, 913, 914, 915, 916, 917, 918, 919, 932, 946, 948, 949, 963, 969, 989, 992, 993, 994, 996, 997, 998, 1000, 1001, 1002, 1004, 1005, 1006, 1010, 1014, 1016, 1021, 1022, 1025, 1028, 1031, 1034, 1036, 1038, 1041, 1042, 1043, 1044, 1045, 1047, 1049, 1050, 1052, 1054, 1059], "vectori": [400, 1051], "vectorizer2": 596, "vectorizer_param": 342, "vectorizermixin": 1051, "vectorizing_tim": 47, "vectors_test": 381, "ved": 1058, "vedaldi": [646, 992], "veenhui": [1056, 1057, 1058, 1059, 1060], "veerkhar": 1056, "veerlosar": 1051, "veghit": 1057, "vehag": [220, 238], "vehbrand": [220, 238], "vehga": [220, 238], "vehicl": [220, 238], "vehpow": [220, 238], "vel": 383, "velkov": 1043, "veloc": 386, "vembu": 414, "vempati": 992, "vendor": [254, 1046, 1049, 1050], "venezuela": [50, 312, 381, 506], "venkat": [0, 406], "venkatachalam": [1051, 1052, 1053, 1054, 1055, 1058, 1059], "venkatesh": 1051, "venna": 704, "venthur": 1049, "venu": 400, "venv": [384, 404], "vera": [1055, 1056], "verbos": [49, 77, 85, 89, 99, 104, 106, 108, 160, 207, 279, 316, 317, 319, 331, 342, 360, 384, 390, 400, 448, 451, 455, 457, 460, 462, 467, 470, 472, 475, 479, 480, 486, 539, 544, 545, 546, 547, 548, 551, 553, 554, 555, 556, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 601, 602, 635, 640, 652, 653, 654, 655, 656, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 677, 684, 685, 686, 687, 688, 689, 690, 691, 692, 695, 698, 700, 702, 773, 786, 805, 806, 808, 811, 812, 814, 822, 831, 833, 834, 835, 836, 837, 839, 841, 843, 846, 861, 868, 869, 870, 871, 872, 873, 874, 909, 912, 913, 914, 915, 916, 917, 918, 966, 1020, 1043, 1044, 1046, 1048, 1049, 1050, 1052, 1053, 1055, 1056, 1059], "verbose_feature_names_out": [149, 192, 193, 194, 261, 325, 331, 332, 333, 335, 417, 472, 475, 871, 1054, 1058, 1059], "verbose_interv": [805, 806], "veri": [43, 52, 62, 64, 74, 75, 77, 79, 85, 87, 95, 97, 113, 114, 115, 117, 123, 128, 152, 158, 165, 181, 187, 192, 193, 194, 209, 220, 221, 222, 225, 228, 238, 244, 247, 253, 254, 257, 263, 272, 280, 281, 284, 285, 287, 288, 294, 299, 316, 319, 331, 338, 341, 349, 353, 358, 360, 362, 369, 373, 381, 385, 386, 388, 391, 392, 394, 398, 399, 400, 410, 414, 415, 416, 418, 420, 421, 422, 423, 424, 425, 426, 450, 455, 460, 470, 479, 480, 486, 508, 512, 518, 549, 565, 566, 569, 570, 572, 573, 575, 576, 597, 598, 630, 658, 659, 662, 663, 664, 672, 690, 691, 693, 699, 700, 703, 713, 751, 754, 800, 805, 808, 816, 818, 822, 825, 828, 852, 853, 877, 881, 882, 883, 892, 904, 905, 914, 917, 920, 921, 922, 923, 949, 989, 992, 993, 995, 996, 997, 998, 999, 1000, 1003, 1004, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1024, 1032, 1033, 1041, 1046, 1047, 1049, 1052, 1054, 1056, 1057, 1058], "verif": [381, 1000, 1024], "verifi": [88, 95, 137, 155, 192, 220, 386, 391, 410, 412, 984, 1003], "verlag": 704, "vermeil": 1049, "veronda": 1042, "verrier": 1056, "versa": [192, 275, 360, 416, 426, 450, 615, 616, 841, 1045], "versatil": [426, 1015, 1024], "versicolor": [121, 287, 288, 512], "versicolour": [80, 121, 131, 133, 383, 1032], "version": [2, 7, 43, 52, 66, 81, 88, 90, 105, 125, 130, 139, 155, 178, 188, 193, 194, 197, 204, 218, 221, 222, 228, 234, 236, 254, 257, 261, 298, 316, 324, 328, 329, 330, 331, 333, 334, 335, 336, 349, 360, 373, 381, 385, 387, 388, 389, 392, 394, 395, 398, 400, 401, 404, 407, 409, 410, 416, 417, 419, 421, 423, 424, 426, 427, 428, 434, 438, 439, 440, 441, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 467, 468, 469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512, 513, 516, 517, 518, 520, 522, 530, 531, 535, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 696, 697, 698, 699, 700, 702, 703, 704, 705, 706, 708, 709, 710, 712, 715, 716, 717, 719, 721, 722, 726, 729, 730, 731, 732, 733, 735, 736, 737, 738, 739, 742, 747, 748, 749, 750, 751, 754, 758, 759, 761, 762, 765, 766, 767, 769, 774, 775, 777, 786, 790, 791, 792, 793, 795, 797, 798, 799, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 817, 821, 822, 826, 827, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 867, 868, 869, 870, 871, 872, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 898, 900, 901, 902, 904, 905, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 930, 932, 933, 943, 944, 948, 949, 956, 957, 958, 959, 960, 963, 966, 967, 970, 975, 981, 986, 987, 989, 992, 994, 997, 1000, 1002, 1004, 1006, 1008, 1013, 1014, 1016, 1019, 1020, 1023, 1033, 1037, 1039], "versionad": [808, 811, 812, 822], "versionchang": 386, "versionwarn": 390, "versu": [67, 127, 138, 160, 167, 178, 189, 192, 198, 229, 235, 247, 252, 253, 266, 270, 273, 296, 305, 307, 337, 342, 346, 348, 349, 353, 416, 420, 423, 426, 512, 542, 564, 618, 639, 647, 666, 667, 674, 676, 682, 683, 684, 685, 791, 808, 813, 834, 844, 873, 908, 909, 916, 917, 921, 989, 996, 1000, 1001, 1006, 1013, 1014, 1015, 1021, 1032, 1049], "vert": [153, 194, 195, 328, 1014], "vertex": [55, 63, 416, 461, 1054], "vertic": [45, 55, 95, 151, 195, 209, 251, 252, 282, 298, 319, 322, 354, 355, 400, 413, 416, 421, 523, 705, 789, 1030], "verticalalign": [51, 63, 74, 75], "vese": 1053, "vesteghem": 1051, "veto": 401, "vettigli": 1050, "vga": 57, "vh": 949, "vi": [45, 47, 381, 707, 1030, 1049, 1052], "via": [0, 2, 43, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 378, 383, 384, 387, 388, 390, 394, 398, 399, 400, 401, 404, 407, 413, 414, 416, 417, 419, 420, 421, 425, 426, 445, 509, 543, 547, 549, 551, 554, 567, 568, 575, 576, 605, 619, 624, 629, 632, 635, 646, 647, 648, 649, 664, 674, 676, 679, 681, 684, 695, 697, 700, 701, 717, 808, 832, 833, 834, 835, 836, 840, 841, 842, 844, 850, 858, 869, 871, 872, 873, 892, 893, 989, 994, 996, 997, 999, 1000, 1001, 1007, 1008, 1014, 1015, 1020, 1021, 1024, 1025, 1036, 1041, 1045, 1046, 1049, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "viacheslav": 1047, "viard": 1052, "vibrantabhi19": 1048, "vicdemand": 155, "vice": [192, 275, 360, 416, 426, 450, 615, 616, 841, 1045], "vicent": [1054, 1055, 1056], "vicpric": 155, "victoireloui": 1055, "victor": [416, 460, 470, 1048, 1051], "victoria": 155, "video": [333, 380, 389, 511, 1001, 1024, 1026], "vie": 1047, "viega": 1000, "view": [43, 77, 81, 111, 127, 155, 193, 217, 259, 373, 375, 386, 416, 424, 544, 653, 665, 852, 853, 927, 996, 997], "view_init": [193, 240, 242, 244], "viewabl": 386, "vighnesh": [1046, 1047, 1049], "vignesh": 1057, "vigni": 1058, "vijai": [1024, 1044], "vijalapuram": 1049, "vijeth": [1057, 1058], "vijitbenjaronk": [1048, 1049], "vika": [1053, 1055], "vikram": [1047, 1056, 1057], "vikrant": 1055, "vila": [1051, 1053], "vilhelm": [1048, 1049], "villalba": [1046, 1049, 1053], "villanova": [1053, 1054], "villaz\u00f3n": 1053, "villu": 1047, "vil\u00e9m": 1054, "vinayak": [1045, 1046, 1047, 1049, 1050, 1056, 1057], "vincent": [0, 82, 102, 179, 183, 406, 1024, 1041, 1043, 1045, 1046, 1048, 1051, 1056, 1057, 1058], "vineet": 1059, "vineyard": 325, "vinh": [416, 712], "vinh10a": 416, "viniciu": [1053, 1054], "vinit": 1049, "vink": [1052, 1054], "vinod": 1049, "vin\u00edciu": 1049, "viola": [381, 1049], "violat": [62, 349, 394, 398, 400, 643, 936, 1007, 1014, 1016], "violet": [132, 1057], "violeta": 1053, "vipin": 416, "viraj": 1049, "virchan": 1059, "virgil": [0, 48, 406, 1041, 1042, 1044], "virgilefritsch": 1041, "virginica": [80, 121, 131, 133, 287, 288, 383, 512, 1000, 1032], "viridi": [66, 73, 299, 705], "viridis_r": 279, "virshup": 1058, "virtanen": 1046, "virtual": [387, 404, 420, 1024], "virtualenv": [384, 386], "visag": 1024, "visconti": 1045, "vishaal": [1049, 1050], "vishal": 1056, "vishwakarma": 1055, "visibl": [52, 192, 193, 222, 358, 380, 386, 416, 868, 1005, 1046, 1056], "vision": [542, 766, 767, 992, 996, 998, 1016, 1019, 1024, 1042], "visit": [368, 386, 1007, 1023], "visual": [2, 27, 42, 43, 48, 52, 58, 62, 66, 68, 78, 81, 84, 87, 92, 95, 96, 113, 122, 124, 127, 129, 132, 134, 144, 145, 153, 155, 156, 158, 162, 163, 172, 184, 188, 189, 193, 195, 204, 211, 220, 222, 238, 240, 241, 245, 246, 249, 252, 258, 259, 268, 270, 271, 274, 275, 279, 280, 283, 285, 287, 288, 304, 308, 309, 313, 315, 319, 323, 324, 328, 330, 339, 353, 378, 382, 384, 392, 393, 413, 418, 420, 421, 422, 423, 446, 449, 453, 454, 462, 480, 504, 510, 512, 515, 518, 522, 530, 540, 542, 549, 572, 574, 639, 641, 653, 666, 697, 700, 705, 706, 708, 709, 710, 726, 735, 790, 797, 809, 810, 813, 814, 825, 826, 827, 828, 829, 831, 838, 869, 873, 877, 881, 882, 884, 888, 889, 890, 892, 912, 914, 915, 917, 918, 926, 945, 995, 997, 998, 1003, 1004, 1006, 1007, 1010, 1016, 1019, 1021, 1025, 1036, 1044, 1051, 1052, 1053, 1055], "visualis": [125, 128, 135, 255, 552, 809, 810, 813, 825, 826, 827, 828, 829, 1003, 1020], "visualize_group": 273, "vitor": 1056, "vivek": [1048, 1049, 1050, 1058], "viz": [288, 393], "vjacheslav": 1045, "vlad": [0, 125, 255, 317, 405, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1050], "vladimir": [543, 949, 996, 1051, 1055, 1058], "vlahava": [728, 748, 1000], "vlajic": [1052, 1053, 1059], "vlasio": [1024, 1048], "vlasovet": 1054, "vlb": 57, "vliet": 1053, "vline": [111, 127, 207, 208, 209, 221, 278, 291, 320], "vlines_": 640, "vlo": 51, "vmax": [66, 86, 115, 125, 128, 135, 179, 182, 199, 204, 211, 236, 252, 267, 273, 316, 349], "vmin": [66, 75, 115, 125, 128, 135, 179, 182, 199, 204, 211, 236, 252, 267, 273, 316, 349], "vnherdeiro": 1051, "vo": [1047, 1055], "voc": 1000, "vocabulari": [123, 235, 360, 361, 398, 424, 596, 597, 598, 599, 1002, 1025, 1034, 1041, 1043, 1046, 1049, 1052, 1054], "vocabulary_": [362, 424, 589, 596, 599, 1034, 1041], "void": 387, "vol": [64, 184, 204, 272, 284, 383, 416, 482, 567, 568, 636, 643, 653, 672, 693, 694, 805, 837, 849, 990, 1002, 1003], "voltag": 57, "volum": [0, 101, 112, 174, 181, 381, 383, 416, 418, 481, 542, 777, 996, 1015, 1024], "volume11": 416, "volume2": 684, "volume7": [674, 675], "volunt": 394, "voluntari": 360, "von": [416, 460, 470, 699, 1019, 1048, 1049], "voronoi": [81, 101, 416], "voss": 1049, "vote": [2, 14, 138, 140, 145, 160, 161, 162, 189, 298, 353, 400, 401, 509, 563, 564, 565, 568, 572, 573, 577, 578, 665, 840, 854, 855, 860, 862, 1001, 1003, 1021, 1022, 1032, 1036, 1041, 1044, 1046, 1051], "votingclassifi": [2, 61, 63, 138, 189, 229, 365, 407, 423, 512, 572, 578, 639, 666, 850, 854, 917, 920, 989, 990, 1021, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1058, 1059], "votingregressor": [2, 163, 407, 423, 577, 990, 1050, 1051, 1052, 1055, 1058, 1059], "votingregressorifittedvotingregressor": 163, "voxel": [81, 101, 593], "vp": 1024, "vq": [83, 93], "vqean3": [1049, 1050], "vredevoogd": [1043, 1044], "vrigazov": 1056, "vrishank": [1048, 1049], "vs_buildtool": 384, "vstack": [51, 63, 92, 100, 179, 180, 202, 263, 267, 299, 312, 354, 639, 1001, 1049], "vstolbunov": 1046, "vt": 558, "vufg": 1049, "vukolov": [1049, 1050], "vulner": 410, "vuw": 538, "vvz2010": 992, "vx": 72, "vya": [1049, 1050, 1051], "vyom": [1056, 1057], "vz2010": 992, "v\u00e1zquez": 1044, "v\u0103n": 1056, "w": [2, 45, 51, 53, 66, 70, 75, 77, 80, 83, 93, 99, 131, 134, 174, 187, 219, 224, 237, 254, 255, 263, 264, 265, 268, 269, 289, 317, 331, 332, 353, 354, 356, 362, 369, 374, 381, 383, 392, 410, 416, 417, 421, 423, 424, 428, 433, 439, 445, 473, 477, 480, 482, 490, 491, 492, 531, 546, 548, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 575, 576, 577, 578, 596, 597, 599, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 701, 707, 733, 734, 764, 807, 808, 822, 830, 840, 841, 842, 843, 845, 846, 847, 848, 849, 850, 851, 854, 855, 858, 859, 862, 863, 869, 870, 905, 907, 908, 912, 913, 914, 915, 917, 918, 920, 921, 922, 923, 946, 951, 996, 1000, 1004, 1005, 1010, 1012, 1014, 1015, 1030, 1034, 1051, 1055, 1056, 1057, 1058], "w0": 123, "w1": [123, 423, 665], "w1992": 423, "w2": 423, "w3": 423, "w_": [421, 654, 655, 660, 661, 668, 669, 670, 671, 689, 692, 996, 1000, 1002, 1005], "w_0": 996, "w_1": [423, 996, 1004], "w_1x_1": 1004, "w_2": [423, 996, 1004], "w_2x_2": 1004, "w_3": 996, "w_4": 996, "w_5": 996, "w_i": [423, 991, 1000], "w_ij": 668, "w_init": [428, 541], "w_intercept": [912, 913], "w_j": [654, 660, 1000, 1014], "w_k": [416, 423, 996], "w_l": 996, "w_mx_m": 1004, "w_n": 423, "w_new": 421, "w_p": 996, "w_pad": [125, 148, 365], "w_x_1": [912, 913], "w_x_n": [912, 913], "wa": [0, 43, 47, 53, 64, 75, 104, 105, 113, 118, 123, 157, 160, 174, 185, 192, 197, 224, 244, 254, 257, 269, 271, 272, 274, 276, 278, 284, 285, 292, 296, 316, 324, 328, 329, 333, 340, 341, 360, 362, 368, 369, 373, 381, 383, 384, 386, 390, 391, 400, 404, 407, 410, 412, 413, 415, 416, 419, 420, 424, 428, 440, 448, 449, 450, 451, 453, 454, 455, 457, 458, 462, 465, 468, 472, 476, 477, 482, 490, 491, 492, 493, 523, 531, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 561, 562, 563, 564, 565, 566, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 666, 667, 672, 674, 680, 682, 684, 685, 687, 693, 694, 696, 697, 700, 721, 737, 738, 791, 792, 795, 805, 806, 808, 811, 812, 822, 835, 837, 849, 856, 859, 861, 864, 868, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 901, 904, 905, 909, 910, 943, 944, 967, 988, 989, 990, 999, 1000, 1003, 1006, 1010, 1013, 1016, 1019, 1025, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "wadawson": 1045, "wadsworth": [920, 921, 1016], "waelbenamara": 1052, "wagner": 1055, "wai": [0, 2, 37, 43, 55, 64, 85, 95, 105, 108, 144, 151, 156, 158, 174, 183, 192, 194, 195, 221, 224, 225, 235, 238, 249, 250, 253, 254, 257, 258, 273, 278, 285, 287, 319, 320, 331, 333, 334, 369, 373, 374, 375, 380, 382, 384, 385, 388, 389, 394, 395, 400, 401, 404, 407, 410, 413, 414, 415, 416, 417, 419, 420, 421, 423, 424, 425, 426, 427, 431, 451, 452, 459, 460, 461, 467, 468, 470, 471, 477, 504, 563, 564, 571, 580, 597, 607, 608, 619, 640, 674, 675, 684, 685, 686, 707, 712, 714, 725, 744, 745, 762, 763, 765, 771, 782, 786, 796, 803, 833, 841, 858, 879, 885, 890, 896, 922, 923, 971, 974, 989, 990, 994, 995, 996, 997, 998, 999, 1000, 1001, 1003, 1005, 1006, 1007, 1008, 1010, 1012, 1014, 1015, 1016, 1019, 1020, 1023, 1024, 1025, 1033, 1034, 1041, 1043, 1049, 1054, 1055, 1059], "waijean": 1054, "wainwright": [729, 731, 732], "waist": 383, "wait": [55, 384, 386, 390, 400, 674, 675, 676, 684, 686, 1053], "waithera": 1051, "wal": 51, "waldo": 333, "wale": 155, "walk": [416, 422, 1044], "walker": 1045, "wall": 416, "wallach": [1045, 1046], "walli": 1049, "wallygauz": 1049, "walsh": [266, 1053, 1055], "walt": [1044, 1045, 1049], "walter": 1047, "walton": 333, "wan": 1049, "wang": [421, 544, 687, 697, 701, 734, 764, 996, 997, 1000, 1044, 1046, 1047, 1048, 1049, 1053, 1056, 1057, 1059], "wangz10": 1046, "want": [0, 30, 43, 51, 58, 61, 62, 63, 90, 99, 105, 174, 188, 192, 220, 221, 222, 254, 257, 269, 272, 278, 293, 296, 302, 316, 343, 346, 360, 369, 373, 374, 375, 384, 385, 386, 387, 388, 390, 391, 392, 398, 399, 400, 401, 404, 407, 410, 414, 415, 416, 417, 418, 423, 424, 425, 508, 511, 512, 518, 543, 557, 662, 663, 664, 666, 667, 674, 676, 682, 683, 684, 772, 807, 830, 858, 861, 877, 884, 905, 912, 989, 996, 999, 1000, 1001, 1004, 1006, 1010, 1011, 1015, 1019, 1020, 1025, 1033, 1041, 1055, 1059], "ward": [0, 2, 53, 59, 71, 74, 75, 76, 79, 81, 87, 88, 89, 91, 97, 189, 195, 244, 406, 424, 449, 453, 471, 538, 865, 1021, 1041, 1044, 1046], "ward__n_clust": 89, "ward_tre": [2, 89, 449, 453, 1041, 1045], "wardagglom": 1046, "wardagglomer": 1044, "wardclust": 1044, "wareh": 742, "warm": [389, 400, 539, 545, 551, 553, 554, 618, 661, 667, 674, 675, 676, 684, 685, 686, 996, 1020, 1051, 1053, 1055], "warm_start": [143, 180, 213, 331, 388, 392, 400, 423, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 618, 654, 656, 657, 660, 666, 668, 670, 674, 675, 676, 677, 684, 685, 686, 688, 805, 806, 861, 869, 870, 1006, 1022, 1036, 1041, 1044, 1045, 1046, 1049, 1050, 1051, 1052, 1055, 1057], "warn": [2, 15, 79, 97, 106, 220, 235, 254, 281, 299, 315, 316, 323, 373, 374, 386, 389, 390, 391, 400, 410, 424, 504, 546, 548, 555, 558, 561, 562, 565, 566, 567, 568, 569, 570, 572, 573, 574, 579, 580, 581, 582, 583, 584, 586, 610, 644, 701, 720, 721, 737, 738, 746, 791, 792, 795, 862, 876, 877, 915, 916, 917, 918, 920, 921, 922, 923, 932, 933, 939, 949, 957, 970, 986, 987, 989, 1000, 1010, 1032, 1041, 1043, 1044, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "warn_for": 791, "warn_on_dtyp": 1050, "warn_when_not_sort": 867, "warner": [51, 1056, 1057], "warshal": [696, 997], "warshaw": 1047, "warut": [1048, 1049], "wase": [1058, 1059], "washington": [50, 183, 240, 266, 304, 312], "wasn": [104, 254, 1050], "waspa": 546, "wast": [145, 392, 420, 421, 989], "watanab": [1058, 1059], "watch": [52, 374], "watchtheblur": 1053, "water": 50, "waterburi": [1049, 1050], "waterland": 1044, "waterponei": [1047, 1048], "watson": [325, 417], "wattai": 1056, "wav": 380, "wave": [214, 386, 999], "waveform": 75, "wavelet": [53, 134, 421], "wavfil": 380, "waweru": 1058, "wa\u00ebl": 1059, "wb": [55, 410], "wchathura": 1056, "wclf": 351, "wconnel": 1052, "wdbc": [174, 383], "wderos": 1052, "wdevazelh": 1049, "wdisp": 351, "we": [0, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 58, 61, 62, 63, 64, 66, 68, 70, 72, 75, 76, 77, 79, 82, 84, 85, 88, 90, 91, 92, 93, 97, 99, 100, 101, 104, 105, 106, 107, 109, 111, 113, 114, 115, 118, 120, 121, 123, 125, 126, 127, 128, 130, 132, 133, 135, 139, 140, 142, 144, 145, 146, 147, 148, 149, 150, 152, 153, 155, 156, 157, 158, 160, 162, 163, 165, 169, 170, 171, 173, 174, 176, 178, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 203, 204, 206, 208, 209, 211, 213, 215, 217, 220, 221, 222, 223, 224, 226, 228, 229, 232, 233, 234, 235, 236, 238, 240, 241, 244, 245, 247, 248, 250, 251, 252, 254, 255, 257, 258, 260, 261, 263, 264, 265, 266, 268, 269, 272, 273, 274, 275, 276, 278, 279, 280, 281, 283, 284, 285, 287, 288, 289, 290, 292, 293, 296, 298, 299, 301, 302, 304, 307, 308, 309, 310, 312, 314, 315, 316, 317, 319, 320, 321, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 343, 345, 346, 347, 349, 350, 351, 352, 353, 354, 356, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 375, 380, 381, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 398, 399, 400, 401, 407, 410, 412, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 458, 477, 478, 479, 480, 481, 482, 483, 484, 509, 531, 539, 540, 542, 545, 553, 554, 557, 569, 570, 571, 577, 578, 590, 591, 597, 619, 625, 635, 640, 641, 646, 648, 659, 663, 666, 667, 674, 676, 681, 682, 683, 684, 685, 700, 726, 728, 734, 754, 764, 772, 789, 807, 814, 830, 831, 833, 854, 855, 856, 858, 860, 861, 862, 863, 864, 875, 884, 885, 886, 892, 897, 898, 900, 901, 902, 903, 905, 908, 912, 916, 964, 966, 989, 990, 992, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1024, 1025, 1029, 1030, 1031, 1032, 1033, 1034, 1038, 1045, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1057, 1059], "wea": 414, "weak": [117, 150, 153, 224, 238, 284, 420, 562, 567, 568, 638, 1003, 1024, 1057], "weak_learn": 139, "weak_learners_info": 139, "weak_learners_misclassification_error": 139, "weaker": [109, 569, 570], "weakest": [364, 1016], "weaklearn": 561, "weakli": 101, "weather": [43, 52, 181, 193, 415, 996, 1000], "web": [174, 380, 381, 383, 386, 389, 394, 410, 416, 424, 529, 905, 1000, 1010, 1037, 1041], "weber": 1048, "weblog": 416, "webpag": [55, 197, 386], "websit": [380, 381, 383, 386, 401, 404, 1004, 1014, 1023, 1024, 1034, 1042, 1043, 1044], "wed": [43, 155, 193], "weed": 612, "week": [43, 52, 155, 335, 385, 386, 401, 504, 1024, 1055], "weekdai": [43, 193], "weekday_co": 43, "weekday_sin": 43, "weekend": [43, 155], "weezel": [1056, 1057], "wegelin": 419, "wehenkel": [423, 565, 566, 573, 574, 922, 923], "wei": [0, 406, 1014, 1041, 1042, 1045, 1046, 1047, 1048, 1050, 1054, 1057], "weibul": 323, "weidemann": 1055, "weigh": [420, 1048], "weight": [2, 45, 50, 53, 54, 57, 61, 68, 89, 104, 135, 152, 161, 162, 167, 170, 171, 180, 181, 188, 189, 192, 198, 204, 209, 211, 220, 224, 225, 227, 230, 231, 232, 234, 235, 236, 238, 254, 259, 263, 267, 272, 276, 281, 285, 287, 302, 311, 313, 314, 315, 317, 324, 326, 328, 331, 335, 336, 338, 339, 344, 349, 351, 353, 354, 356, 357, 360, 361, 362, 368, 369, 382, 383, 395, 398, 400, 415, 416, 418, 419, 421, 422, 425, 427, 433, 439, 445, 448, 451, 452, 454, 455, 457, 461, 467, 468, 471, 472, 473, 475, 477, 482, 490, 491, 492, 504, 523, 532, 546, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 594, 597, 598, 599, 601, 605, 610, 611, 618, 619, 636, 640, 641, 642, 643, 645, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 697, 701, 705, 706, 708, 710, 711, 715, 716, 717, 720, 721, 724, 726, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 742, 743, 744, 746, 747, 748, 749, 751, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 764, 766, 767, 777, 790, 791, 792, 793, 795, 796, 797, 798, 799, 802, 803, 804, 805, 806, 807, 830, 838, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 865, 866, 868, 869, 870, 871, 874, 877, 891, 892, 893, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 924, 925, 926, 937, 938, 951, 975, 981, 990, 991, 996, 997, 999, 1000, 1002, 1003, 1004, 1005, 1007, 1010, 1013, 1014, 1015, 1016, 1020, 1021, 1025, 1032, 1034, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "weight_concentration_": 805, "weight_concentration_prior": [263, 269, 805, 999], "weight_concentration_prior_": 805, "weight_concentration_prior_typ": [263, 269, 805, 999, 1047], "weight_vector": [1041, 1051], "weighted_acc": 407, "weighted_mod": [2, 395], "weighted_n_node_sampl": 368, "weightedmetaregressor": 254, "weights_": [263, 805, 806, 1055], "weights_handl": 233, "weights_init": 806, "weijiadu": 1055, "weinberg": 424, "weinsberg": 1041, "weinstein": 1042, "weisberg": 996, "weiss": [0, 265, 406, 416, 699, 1041], "weitzenfeld": 1024, "weka": 849, "welch": 1047, "welcom": [385, 386, 394, 401, 1020], "welind": 1041, "well": [0, 8, 43, 48, 51, 58, 61, 62, 64, 70, 74, 83, 88, 92, 93, 97, 104, 111, 118, 139, 140, 142, 145, 150, 152, 158, 160, 174, 181, 183, 191, 192, 193, 194, 197, 204, 208, 218, 220, 221, 222, 224, 228, 240, 241, 242, 245, 247, 251, 254, 257, 265, 272, 278, 285, 287, 289, 294, 296, 299, 302, 304, 305, 306, 326, 329, 330, 331, 332, 333, 334, 335, 336, 353, 356, 360, 361, 362, 369, 381, 383, 385, 386, 390, 392, 394, 395, 398, 399, 400, 401, 410, 414, 416, 418, 420, 421, 423, 425, 427, 430, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 467, 468, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 708, 729, 730, 731, 732, 793, 796, 800, 803, 805, 806, 807, 808, 811, 812, 822, 830, 837, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 947, 948, 989, 990, 992, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1010, 1013, 1014, 1016, 1017, 1019, 1020, 1024, 1033, 1034, 1041, 1042, 1045, 1047, 1048, 1049, 1052, 1059], "wen": 1056, "wenbo": [1051, 1053], "wendi": 1051, "wendling": 1048, "weng": 1015, "wenhao": [277, 1049, 1050], "wenhaoz": 277, "wenhua": 1047, "wenjian": 1047, "wenliwyan": 1052, "went": [390, 1000], "were": [0, 43, 68, 104, 105, 108, 113, 114, 145, 149, 152, 155, 171, 174, 181, 188, 220, 221, 224, 248, 257, 287, 289, 316, 317, 324, 329, 330, 332, 333, 334, 335, 336, 341, 353, 360, 362, 368, 369, 380, 381, 383, 386, 387, 390, 398, 400, 407, 413, 417, 423, 424, 472, 475, 476, 504, 569, 570, 610, 811, 812, 827, 836, 859, 909, 910, 989, 992, 1000, 1001, 1016, 1033, 1034, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058, 1059], "weren": [360, 886, 1050], "werman": 1053, "werneck": 1049, "werner": [1048, 1053], "werror": 394, "wersd\u00f6rfer": 1043, "weslei": [598, 738], "westermann": [0, 376, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "western": 424, "weston": [44, 421, 543, 601, 602, 908], "westov": 1049, "wetter": 193, "weyb": 1059, "wfc": 51, "wget": 394, "wh": [421, 546, 548, 555], "wh_i": 421, "what": [0, 2, 43, 48, 51, 52, 75, 80, 87, 88, 118, 126, 130, 148, 191, 192, 209, 226, 228, 236, 249, 254, 261, 316, 360, 362, 364, 369, 374, 381, 384, 386, 387, 388, 390, 392, 394, 399, 400, 401, 403, 415, 416, 422, 423, 424, 511, 544, 596, 597, 599, 654, 660, 704, 897, 898, 900, 901, 902, 903, 920, 921, 922, 923, 999, 1000, 1001, 1003, 1016, 1020, 1025, 1041, 1048], "whatnot": 360, "whats_miss": 390, "whats_new": [390, 394], "wheel": [384, 386, 390, 404, 1027, 1051, 1053, 1055], "wheeler": [1052, 1053], "wheelhouse_upload": 390, "when": [0, 2, 43, 48, 49, 50, 52, 58, 61, 62, 63, 64, 70, 74, 75, 78, 91, 95, 102, 104, 105, 106, 111, 113, 114, 118, 125, 128, 129, 130, 132, 142, 145, 148, 149, 150, 152, 155, 156, 160, 161, 162, 171, 176, 187, 191, 192, 193, 194, 195, 199, 200, 204, 209, 211, 213, 217, 220, 222, 224, 225, 236, 247, 248, 249, 253, 254, 261, 264, 266, 274, 277, 278, 279, 280, 281, 285, 287, 288, 292, 296, 299, 301, 302, 305, 306, 307, 319, 321, 323, 324, 325, 326, 328, 329, 330, 331, 332, 335, 336, 340, 341, 343, 349, 352, 353, 356, 360, 361, 362, 364, 369, 373, 374, 375, 380, 381, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 404, 407, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 423, 424, 425, 426, 427, 428, 432, 439, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 467, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 490, 491, 492, 493, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 516, 517, 518, 520, 523, 532, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 581, 583, 584, 586, 589, 590, 591, 592, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 614, 617, 618, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 699, 700, 701, 702, 703, 706, 708, 709, 710, 712, 713, 715, 716, 720, 721, 724, 735, 736, 737, 738, 740, 742, 743, 746, 754, 756, 759, 762, 763, 765, 769, 771, 775, 776, 777, 779, 782, 786, 789, 790, 791, 792, 793, 795, 796, 797, 799, 800, 801, 803, 805, 806, 807, 808, 811, 812, 813, 814, 822, 826, 827, 830, 831, 833, 834, 835, 836, 837, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 875, 876, 877, 878, 879, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 898, 899, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 926, 928, 931, 932, 933, 939, 943, 947, 948, 949, 950, 952, 953, 958, 961, 969, 989, 990, 992, 994, 996, 997, 998, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1020, 1023, 1024, 1025, 1031, 1032, 1033, 1034, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "whenev": [183, 191, 272, 369, 380, 394, 400, 404, 414, 490, 491, 492, 504, 636, 638, 991, 999, 1020, 1051], "where": [47, 50, 51, 53, 55, 57, 58, 61, 62, 63, 68, 88, 90, 92, 113, 118, 123, 125, 128, 134, 135, 139, 141, 143, 145, 149, 150, 152, 155, 157, 171, 172, 174, 176, 182, 185, 188, 192, 199, 204, 212, 221, 224, 229, 230, 231, 233, 237, 238, 240, 242, 243, 247, 248, 251, 254, 255, 257, 259, 269, 272, 274, 275, 278, 280, 284, 285, 287, 289, 290, 292, 296, 298, 317, 319, 321, 322, 323, 324, 325, 326, 328, 330, 331, 336, 339, 340, 347, 353, 356, 357, 358, 360, 364, 365, 369, 373, 374, 375, 380, 382, 383, 385, 386, 388, 390, 392, 393, 394, 398, 399, 400, 401, 404, 407, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 439, 445, 452, 455, 456, 460, 469, 471, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 495, 504, 534, 539, 541, 542, 543, 545, 546, 547, 548, 549, 550, 551, 553, 554, 555, 557, 558, 559, 560, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 590, 591, 592, 596, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 614, 617, 618, 619, 621, 623, 627, 630, 631, 633, 635, 636, 637, 638, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 692, 696, 699, 700, 701, 704, 715, 719, 720, 724, 733, 737, 738, 739, 747, 749, 763, 771, 776, 777, 778, 781, 789, 790, 791, 792, 795, 796, 800, 802, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 835, 836, 837, 839, 840, 841, 844, 845, 846, 847, 848, 849, 850, 851, 855, 859, 860, 862, 863, 864, 865, 866, 867, 868, 869, 870, 872, 875, 882, 885, 887, 888, 891, 892, 898, 900, 906, 907, 908, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 940, 941, 942, 943, 949, 957, 960, 985, 989, 991, 992, 993, 994, 995, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1025, 1026, 1041, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "wherea": [52, 70, 83, 88, 102, 113, 156, 234, 257, 279, 280, 281, 287, 302, 324, 353, 356, 357, 375, 401, 420, 423, 452, 454, 573, 666, 667, 810, 826, 840, 992, 999, 1001, 1003, 1010, 1016, 1054, 1059], "wherein": 400, "whether": [2, 47, 49, 52, 105, 137, 156, 179, 182, 184, 192, 193, 220, 224, 238, 241, 248, 254, 272, 276, 319, 368, 369, 374, 381, 384, 385, 386, 388, 390, 391, 392, 400, 407, 415, 416, 417, 418, 420, 421, 423, 425, 428, 448, 450, 459, 461, 462, 467, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 486, 490, 491, 492, 493, 495, 496, 499, 500, 504, 505, 511, 516, 517, 522, 530, 535, 539, 540, 545, 546, 547, 548, 550, 553, 554, 556, 560, 563, 564, 565, 566, 569, 570, 571, 572, 573, 574, 589, 596, 597, 598, 599, 605, 610, 614, 615, 616, 617, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 637, 639, 640, 641, 643, 644, 645, 646, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 678, 680, 681, 682, 683, 684, 685, 686, 687, 689, 690, 691, 692, 693, 694, 698, 702, 703, 705, 706, 708, 710, 712, 719, 720, 750, 769, 775, 782, 786, 790, 797, 807, 808, 811, 812, 813, 814, 822, 826, 827, 830, 831, 832, 835, 836, 838, 841, 843, 846, 847, 848, 849, 851, 854, 855, 856, 858, 860, 862, 863, 864, 865, 866, 869, 870, 876, 893, 899, 912, 913, 914, 915, 916, 917, 918, 924, 926, 930, 932, 933, 934, 936, 948, 949, 956, 957, 973, 984, 988, 989, 990, 995, 996, 1000, 1005, 1006, 1012, 1014, 1015, 1024, 1048, 1049, 1050, 1058, 1060], "whi": [192, 194], "which": [0, 2, 43, 46, 49, 51, 52, 53, 54, 55, 57, 58, 59, 62, 63, 64, 70, 72, 74, 75, 78, 79, 81, 84, 88, 90, 91, 92, 93, 100, 102, 104, 105, 106, 109, 111, 113, 114, 118, 121, 123, 127, 129, 130, 135, 139, 142, 143, 144, 145, 149, 151, 152, 155, 156, 158, 159, 160, 161, 162, 163, 165, 169, 171, 173, 174, 176, 177, 181, 182, 183, 187, 188, 191, 192, 193, 195, 197, 199, 200, 204, 209, 213, 220, 221, 222, 224, 226, 228, 234, 236, 237, 238, 240, 241, 242, 244, 247, 248, 251, 252, 253, 254, 255, 257, 258, 263, 264, 268, 269, 271, 272, 276, 277, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 289, 292, 293, 294, 296, 298, 299, 304, 305, 306, 315, 319, 321, 322, 323, 324, 325, 326, 328, 330, 331, 332, 333, 334, 335, 336, 338, 340, 341, 342, 349, 353, 356, 358, 360, 361, 362, 364, 368, 369, 373, 374, 375, 378, 380, 381, 383, 384, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 403, 404, 407, 410, 412, 413, 414, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 433, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 463, 464, 465, 467, 468, 470, 471, 472, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 490, 491, 492, 495, 531, 539, 540, 541, 542, 545, 546, 548, 549, 550, 552, 553, 554, 555, 556, 557, 558, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 581, 582, 587, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 615, 616, 618, 619, 620, 621, 622, 623, 625, 627, 630, 635, 636, 637, 638, 640, 641, 642, 648, 650, 651, 652, 655, 656, 657, 659, 660, 661, 662, 663, 664, 666, 667, 669, 671, 673, 674, 675, 676, 677, 679, 680, 681, 682, 683, 684, 685, 686, 688, 698, 699, 700, 702, 703, 704, 705, 706, 707, 708, 709, 710, 715, 717, 724, 725, 727, 728, 731, 733, 734, 742, 743, 744, 745, 750, 751, 754, 764, 766, 786, 787, 788, 789, 790, 791, 797, 805, 806, 807, 808, 811, 812, 813, 814, 816, 818, 822, 826, 827, 828, 829, 830, 831, 832, 833, 834, 836, 837, 839, 840, 841, 842, 843, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 858, 859, 860, 862, 863, 864, 865, 866, 869, 872, 876, 879, 883, 885, 886, 887, 890, 891, 892, 893, 894, 896, 904, 905, 907, 908, 909, 912, 914, 917, 918, 920, 921, 922, 923, 924, 928, 941, 944, 948, 949, 951, 956, 957, 958, 960, 969, 972, 975, 981, 984, 989, 990, 991, 992, 993, 994, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1024, 1025, 1027, 1029, 1032, 1033, 1034, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "whichev": [416, 423, 454, 552, 569, 570, 641, 658, 662, 664, 672, 690, 691, 705], "whidou": 1054, "while": [0, 2, 25, 43, 46, 47, 49, 51, 55, 58, 61, 64, 70, 72, 74, 78, 79, 83, 90, 97, 101, 104, 107, 109, 123, 129, 130, 139, 142, 145, 146, 150, 155, 157, 160, 174, 177, 182, 184, 185, 187, 191, 192, 193, 194, 197, 199, 201, 204, 209, 214, 220, 222, 224, 236, 247, 250, 251, 254, 255, 264, 265, 269, 271, 272, 273, 277, 278, 279, 281, 285, 286, 287, 288, 289, 291, 301, 319, 320, 321, 324, 325, 326, 328, 331, 334, 335, 346, 349, 360, 362, 368, 369, 374, 378, 379, 380, 381, 382, 385, 386, 388, 390, 391, 392, 394, 395, 398, 400, 401, 410, 414, 415, 416, 419, 420, 421, 423, 424, 425, 426, 427, 428, 452, 472, 475, 476, 491, 493, 504, 529, 540, 560, 565, 566, 567, 568, 572, 573, 574, 575, 576, 577, 578, 583, 590, 596, 597, 598, 599, 602, 605, 610, 614, 642, 651, 654, 655, 657, 664, 665, 666, 667, 684, 685, 686, 687, 716, 738, 762, 782, 786, 796, 802, 805, 808, 809, 810, 813, 814, 815, 816, 817, 818, 822, 823, 824, 826, 831, 833, 834, 835, 836, 837, 839, 847, 858, 860, 862, 863, 864, 871, 872, 873, 874, 875, 888, 900, 905, 910, 912, 913, 920, 921, 922, 923, 928, 953, 989, 990, 992, 993, 994, 996, 997, 999, 1000, 1001, 1002, 1003, 1006, 1007, 1010, 1012, 1015, 1016, 1019, 1020, 1025, 1031, 1032, 1033, 1034, 1041, 1044, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "whilst": [143, 242], "whisker": 49, "white": [2, 93, 95, 125, 181, 192, 234, 240, 305, 317, 321, 343, 348, 421, 424, 633, 1016, 1041, 1044, 1047, 1051, 1055], "whitekernel": [2, 176, 181, 182, 426, 619, 620, 622, 1052], "whiten": [45, 125, 126, 127, 303, 421, 428, 541, 542, 549, 890, 892, 1010, 1030, 1045, 1047, 1055, 1056, 1059], "whiten_solv": [428, 541, 1056], "whitening_": 541, "whitespac": 424, "whl": 390, "who": [0, 104, 192, 374, 381, 386, 393, 401, 404, 854, 855, 856, 858, 860, 862, 863, 864, 1019, 1043, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "whole": [49, 85, 108, 155, 163, 188, 221, 257, 275, 282, 349, 353, 364, 373, 386, 398, 399, 417, 419, 423, 426, 457, 491, 546, 563, 564, 565, 566, 571, 572, 573, 574, 578, 693, 694, 808, 811, 812, 822, 836, 847, 848, 849, 850, 851, 989, 1000, 1010, 1034, 1049, 1051], "whose": [2, 90, 112, 113, 114, 174, 181, 220, 347, 381, 394, 395, 400, 414, 416, 418, 423, 425, 426, 429, 445, 446, 447, 456, 469, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 523, 542, 546, 548, 549, 552, 555, 557, 580, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 648, 679, 703, 726, 808, 815, 822, 837, 858, 877, 904, 905, 948, 979, 980, 994, 1001, 1005, 1006, 1007, 1015, 1044, 1049, 1050, 1052, 1055], "why": [64, 72, 87, 125, 139, 145, 155, 192, 194, 197, 209, 272, 275, 278, 296, 360, 361, 386, 394, 400, 416, 418, 421, 427, 452, 455, 459, 1000, 1002, 1015, 1029, 1032, 1044], "wick": 1053, "wide": [64, 95, 96, 121, 142, 251, 320, 398, 416, 421, 424, 989, 996, 1019, 1024, 1034, 1041, 1043, 1057], "widehat": 179, "wider": [52, 222, 424, 925, 996], "widetild": 1016, "width": [47, 49, 52, 80, 88, 113, 121, 127, 128, 133, 134, 135, 142, 148, 149, 152, 162, 170, 178, 184, 203, 261, 263, 277, 302, 319, 321, 322, 325, 330, 333, 346, 383, 417, 446, 447, 460, 472, 501, 502, 514, 529, 594, 877, 925, 1010, 1014, 1016, 1031, 1032, 1049], "wiesel": [418, 429, 483], "wignal": [1044, 1045, 1051, 1052], "wijewardena": [0, 1044, 1045, 1046], "wiki": [55, 61, 392, 394, 603, 644, 676, 679, 703, 713, 854, 855, 860, 861, 862, 863, 890, 906, 920, 921, 996, 1016], "wikic": 992, "wikipedia": [37, 42, 61, 189, 394, 416, 603, 615, 616, 644, 664, 676, 679, 690, 691, 703, 712, 713, 715, 717, 720, 724, 726, 734, 737, 738, 739, 742, 743, 746, 751, 764, 791, 793, 794, 796, 797, 800, 801, 854, 855, 860, 861, 862, 863, 890, 906, 920, 921, 992, 996, 1000, 1003, 1012, 1016, 1021, 1034, 1041, 1048], "wikipedia_principal_eigenvector": [55, 1021], "wikipediadet2017": 1000, "wil": 1053, "wild": [2, 45, 379, 501, 502, 516, 517, 1030, 1036, 1041], "wilderness_area": 257, "wildli": [304, 999], "wilei": [383, 990], "wilhelm": [237, 1045, 1047, 1051], "wilk": 414, "wilksch": 1056, "willamett": 325, "willard": 1053, "willdarnel": 1051, "willduan": 1048, "william": [174, 381, 383, 426, 618, 619, 622, 627, 630, 647, 992, 1000, 1004, 1048, 1049, 1050, 1051, 1056, 1057], "williamson": 1051, "willing": [191, 275, 415], "willocx": 1051, "willpeppo": 1053, "wilson": [113, 383, 1041, 1044], "wiman": 1041, "wimld": 1055, "win": 272, "winata": [1051, 1053], "wind": [193, 1001], "windber": 1052, "windiana42": 1057, "window": [57, 342, 381, 386, 388, 389, 424, 1019, 1041, 1044, 1048, 1052, 1054, 1055, 1059], "windowsapp": 404, "windowserror": 1057, "windspe": [43, 193], "wine": [2, 48, 260, 324, 325, 379, 518, 1036], "wine_review": 325, "wineri": 325, "winn": 1000, "winter": [43, 52], "winterman": 1042, "wip": [394, 404], "wipf": [653, 996], "wire": [392, 542, 549], "wiryadi": [1053, 1059], "wisc": [174, 383, 907], "wisconsin": [2, 174, 195, 379, 508, 1008, 1036, 1046], "wise": [2, 46, 63, 83, 184, 221, 247, 288, 319, 361, 373, 400, 414, 416, 420, 421, 425, 466, 539, 542, 545, 549, 553, 554, 557, 558, 561, 563, 564, 567, 568, 600, 603, 604, 606, 607, 608, 614, 648, 660, 708, 762, 840, 859, 889, 902, 903, 906, 973, 975, 976, 977, 978, 981, 992, 994, 996, 1000, 1001, 1014, 1020, 1041, 1046, 1049, 1050, 1051], "wish": [380, 386, 393, 395, 404, 416, 949, 1026, 1034, 1048], "wishart": 805, "wissen": 458, "with_cent": [890, 902], "with_error": 709, "with_mean": [391, 892, 903, 1010, 1049, 1054], "with_scal": [890, 902], "with_std": [892, 903, 1010, 1049], "withheld": 420, "within": [2, 41, 43, 58, 95, 144, 146, 147, 150, 155, 159, 171, 173, 174, 216, 221, 222, 232, 238, 254, 258, 276, 277, 281, 291, 319, 320, 330, 347, 350, 353, 356, 362, 369, 373, 381, 386, 390, 395, 398, 400, 401, 407, 413, 414, 416, 417, 420, 422, 423, 427, 452, 456, 469, 471, 472, 474, 477, 482, 523, 557, 575, 576, 577, 578, 601, 602, 640, 700, 704, 707, 718, 733, 789, 805, 806, 813, 814, 826, 827, 836, 837, 852, 853, 854, 855, 860, 862, 863, 864, 871, 872, 873, 885, 893, 897, 898, 900, 901, 902, 903, 914, 915, 916, 917, 918, 920, 921, 922, 923, 989, 994, 996, 997, 1003, 1006, 1010, 1013, 1015, 1016, 1020, 1024, 1025, 1029, 1032, 1034, 1043, 1044, 1048, 1049, 1054, 1055, 1057, 1058, 1059], "without": [2, 43, 44, 52, 53, 61, 71, 77, 79, 87, 90, 91, 97, 101, 102, 109, 130, 145, 150, 151, 154, 155, 157, 160, 166, 170, 174, 183, 189, 191, 192, 193, 204, 209, 228, 247, 251, 254, 255, 257, 258, 260, 271, 272, 279, 283, 285, 296, 300, 301, 302, 308, 309, 310, 311, 319, 320, 324, 326, 328, 353, 356, 361, 375, 381, 382, 384, 386, 387, 388, 390, 391, 392, 395, 398, 399, 400, 407, 410, 416, 417, 421, 423, 424, 425, 426, 441, 447, 449, 454, 466, 477, 482, 504, 512, 523, 540, 542, 563, 564, 571, 587, 588, 619, 635, 639, 642, 647, 667, 700, 708, 789, 811, 812, 813, 820, 822, 837, 838, 854, 861, 865, 871, 872, 875, 878, 881, 882, 884, 888, 889, 890, 892, 897, 912, 928, 969, 989, 990, 992, 994, 996, 997, 1000, 1003, 1006, 1010, 1014, 1015, 1016, 1019, 1020, 1021, 1025, 1026, 1034, 1038, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1055, 1056, 1057, 1058, 1059, 1060], "withstrok": 75, "witten": 420, "wittenau": 1046, "wk": 713, "wl": 384, "wminkowski": [1053, 1055], "wmt": 51, "wnl": 424, "wo": 424, "wojdyla": [1056, 1057], "wolberg": [174, 383], "wolf": [2, 49, 65, 70, 110, 111, 114, 115, 189, 308, 481, 483, 487, 488, 520, 557, 994, 1021, 1048], "wolframalpha": 1051, "wolodzko": 1054, "wolosonovich": 1049, "wolpert": [423, 575, 576], "wompner": 1049, "won": [160, 316, 361, 390, 416, 476, 504, 635, 636, 638, 695, 712, 725, 744, 745, 763, 765, 803, 999, 1010, 1046, 1047, 1052], "wonder": [360, 384], "wonpil": 996, "wood": 1050, "woolam": [338, 339, 340, 343, 1041], "word": [47, 54, 57, 104, 176, 251, 255, 349, 361, 362, 373, 381, 382, 386, 388, 391, 400, 413, 415, 416, 418, 419, 420, 421, 461, 519, 531, 542, 544, 549, 596, 597, 599, 704, 841, 851, 909, 994, 998, 1002, 1005, 1010, 1013, 1014, 1024, 1032, 1033, 1041, 1049], "word_col": 57, "word_scor": 57, "word_token": 424, "wordnetlemmat": 424, "work": [0, 3, 43, 48, 52, 55, 68, 79, 80, 83, 87, 102, 111, 142, 149, 163, 174, 182, 183, 191, 192, 193, 209, 224, 237, 254, 263, 265, 276, 296, 305, 306, 325, 329, 331, 332, 334, 351, 353, 361, 362, 369, 374, 375, 380, 381, 384, 386, 387, 388, 389, 390, 391, 392, 394, 399, 400, 401, 410, 412, 413, 414, 416, 417, 418, 421, 423, 424, 425, 428, 429, 430, 431, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 468, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 490, 491, 492, 493, 512, 516, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 696, 697, 698, 699, 700, 703, 716, 750, 782, 786, 787, 788, 789, 796, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 949, 953, 989, 990, 992, 994, 995, 996, 997, 999, 1000, 1002, 1003, 1006, 1007, 1010, 1013, 1014, 1019, 1020, 1024, 1025, 1026, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "work_directori": 1034, "workabl": 391, "workaround": [325, 386, 808, 822], "workclass": [335, 504], "worker": [374, 400, 424, 966, 967, 1056], "workflow": [386, 389, 390, 399, 420, 1023, 1036], "working_memori": [373, 374, 476, 789, 910, 1049], "workingdai": [43, 193], "workload": 1019, "workshop": [0, 416, 424, 847, 1002, 1018], "workspac": 1034, "workstat": 394, "world": [0, 90, 104, 108, 192, 224, 244, 257, 272, 360, 373, 379, 383, 416, 421, 424, 965, 990, 1000, 1002, 1018, 1020, 1024, 1028, 1036, 1041], "worldwid": 1024, "wornbb": 1052, "worri": [89, 997, 1026], "wors": [43, 118, 139, 177, 193, 226, 278, 286, 298, 324, 369, 414, 416, 426, 439, 473, 490, 491, 492, 560, 562, 564, 566, 568, 570, 573, 576, 578, 618, 619, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 677, 678, 680, 681, 686, 687, 688, 713, 729, 730, 731, 732, 736, 793, 845, 846, 855, 863, 870, 913, 915, 918, 921, 923, 1000, 1010, 1050], "worse_prob": 278, "worsen": 150, "worst": [174, 220, 325, 383, 416, 452, 455, 716, 737, 738, 791, 792, 795, 800, 801, 837, 1000, 1024, 1041, 1054], "worth": [90, 148, 193, 220, 386, 394, 1024], "worthwhil": [106, 400], "would": [0, 25, 43, 45, 48, 52, 63, 64, 68, 80, 88, 90, 93, 104, 111, 113, 114, 118, 123, 130, 139, 152, 174, 176, 181, 182, 192, 193, 194, 195, 197, 204, 210, 220, 221, 222, 235, 238, 247, 254, 257, 265, 272, 274, 278, 279, 284, 286, 288, 292, 296, 299, 305, 316, 319, 320, 324, 325, 331, 334, 341, 349, 353, 356, 357, 360, 362, 368, 369, 373, 381, 382, 386, 387, 388, 392, 394, 395, 398, 399, 400, 401, 407, 410, 413, 414, 416, 417, 418, 419, 420, 421, 423, 424, 425, 439, 454, 473, 476, 490, 491, 492, 497, 535, 540, 542, 544, 549, 552, 560, 562, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 576, 578, 591, 592, 595, 597, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 678, 680, 681, 682, 683, 684, 686, 687, 708, 710, 716, 720, 721, 728, 764, 786, 790, 793, 797, 808, 810, 822, 837, 845, 846, 855, 863, 870, 897, 898, 900, 901, 902, 903, 904, 905, 910, 912, 913, 915, 918, 920, 921, 922, 923, 957, 960, 989, 990, 993, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1008, 1010, 1015, 1019, 1020, 1024, 1025, 1030, 1032, 1034, 1038, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "wp": [424, 665, 679], "wpd": 360, "wprd": 424, "wrap": [125, 144, 152, 299, 336, 380, 388, 400, 410, 440, 516, 665, 684, 838, 896, 990, 1000, 1003, 1015, 1019, 1041, 1046, 1049, 1051, 1052, 1054, 1056], "wraparound": 387, "wrapper": [2, 64, 299, 392, 395, 420, 426, 552, 628, 676, 679, 750, 912, 996, 1016, 1019, 1045, 1053], "wrapt": [666, 667], "wrath": 417, "write": [47, 55, 188, 254, 360, 373, 374, 380, 384, 385, 386, 390, 391, 392, 394, 395, 398, 400, 410, 412, 417, 421, 424, 1011, 1020, 1034, 1042, 1054, 1058], "writer": 360, "written": [41, 44, 46, 65, 86, 88, 120, 128, 172, 189, 227, 271, 303, 331, 338, 339, 374, 383, 386, 387, 388, 392, 394, 398, 400, 417, 422, 495, 510, 516, 705, 721, 838, 917, 924, 994, 996, 1000, 1004, 1005, 1014, 1018, 1021, 1025, 1026, 1031, 1034, 1050], "wrong": [95, 220, 272, 305, 360, 369, 383, 386, 388, 424, 512, 734, 764, 801, 1000, 1006, 1015, 1044, 1046, 1048, 1049, 1050, 1051, 1054, 1058], "wrongli": [220, 349, 1059], "wrote": [160, 381], "ws2001": 992, "wspace": [53, 54, 74, 79, 80, 97, 113, 125, 141, 220, 238, 247, 263, 265, 266, 269, 304, 312, 339, 346], "wstate": 1054, "wtv": 392, "wtw": 392, "wu": [1015, 1045, 1053], "wurp": [1055, 1056], "wuthrich": [220, 238], "ww": 421, "www": [45, 105, 197, 220, 236, 238, 248, 292, 298, 316, 380, 381, 386, 394, 416, 420, 450, 457, 495, 516, 517, 539, 542, 545, 549, 652, 666, 672, 679, 693, 694, 861, 868, 920, 921, 996, 1013, 1030], "www4": [174, 383], "wyseguy7": 1047, "w\u00fcthrich": 414, "x": [2, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 61, 62, 63, 64, 66, 67, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 108, 109, 112, 113, 114, 115, 117, 118, 122, 123, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 171, 172, 173, 174, 177, 178, 179, 180, 181, 182, 183, 184, 185, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 238, 240, 241, 242, 245, 247, 248, 250, 251, 252, 253, 254, 255, 257, 258, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 293, 294, 296, 298, 299, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 379, 380, 381, 386, 387, 388, 390, 391, 392, 393, 394, 395, 398, 399, 400, 407, 410, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 501, 502, 503, 506, 508, 509, 510, 513, 514, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 593, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 714, 718, 719, 733, 740, 743, 750, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 796, 800, 801, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 875, 876, 877, 878, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 928, 929, 930, 931, 932, 933, 936, 946, 948, 949, 950, 951, 960, 961, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 989, 990, 991, 992, 994, 995, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1020, 1025, 1029, 1030, 1032, 1033, 1034, 1038, 1041, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1058, 1059], "x0": [51, 212, 229, 243, 319, 346, 400, 437, 472, 575, 576, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 875, 876, 877, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893], "x00": 424, "x006": 1042, "x00a": 424, "x00b": 424, "x00c": 424, "x00d": 424, "x00e": 424, "x00f": 424, "x00g": 424, "x00h": 424, "x00i": 424, "x00l": 424, "x00n": 424, "x00o": 424, "x00r": 424, "x00t": 424, "x00u": 424, "x00z": 424, "x0_cat": [332, 1010], "x0_infrequent_sklearn": [332, 1010], "x0_label": 319, "x0_rabbit": [332, 1010], "x0_str_femal": 885, "x0_str_male": 885, "x0l": 1045, "x1": [51, 117, 122, 141, 151, 179, 232, 243, 319, 346, 388, 400, 437, 472, 517, 575, 576, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 635, 636, 637, 638, 707, 875, 876, 877, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 1033], "x110": 1056, "x1_int_1": 885, "x1_int_2": 885, "x1_int_3": 885, "x1_label": 319, "x2": [117, 122, 141, 151, 179, 232, 388, 417, 596, 637, 707, 1033], "x27": [63, 105, 106, 144, 160, 163, 171, 192, 193, 194, 248, 249, 258, 259, 261, 268, 272, 276, 278, 279, 285, 290, 292, 317, 325, 329, 330, 332, 340], "x2_tr": 637, "x3": [151, 417, 1033], "x64": 384, "x8": 88, "x86": 384, "x86_64": [389, 404], "x9ft": 424, "x_": [169, 177, 269, 278, 328, 388, 416, 419, 421, 635, 643, 772, 867, 907, 908, 996, 1002, 1007, 1047], "x_0": [221, 665], "x_1": [125, 169, 179, 217, 221, 419, 421, 423, 426, 621, 633, 665, 885, 912, 913, 996, 1002, 1004, 1010, 1014], "x_1d": 332, "x_1x_2": 1010, "x_1x_2x_3": 1010, "x_1x_3": 1010, "x_2": [169, 179, 217, 421, 423, 424, 426, 621, 633, 996, 1004, 1010], "x_20": 342, "x_2d": 349, "x_2x_3": 1010, "x_3": [169, 1010], "x_6": 885, "x_7": 885, "x_a": 323, "x_adult": 335, "x_aniso": [79, 92, 97], "x_approx": 1033, "x_axi": [127, 228, 282], "x_b": 323, "x_bimod": 323, "x_bin": 320, "x_bound": [426, 625], "x_c": [490, 491, 493, 1007], "x_calib": 445, "x_california": 188, "x_cardiotocographi": 257, "x_center": 201, "x_check": 933, "x_chisq": 323, "x_cluster": 864, "x_convert": 932, "x_copi": 1052, "x_cu": 412, "x_d": [426, 622], "x_dens": [335, 552], "x_df": 157, "x_diabet": [188, 1029], "x_different_covari": 70, "x_digit": [107, 166, 315, 417, 1029, 1030, 1032], "x_dist_graph": 856, "x_embed": [308, 309, 700, 704, 861, 1003], "x_error": 226, "x_errors_larg": 226, "x_featur": [108, 648, 649, 650, 992], "x_filter": 92, "x_fit": 696, "x_fit_": [543, 651], "x_fold": 1029, "x_forestcov": 257, "x_full": [187, 188, 319], "x_full_train": 144, "x_gaussian": 323, "x_hashed_lsa": 361, "x_hat": [539, 545, 553, 554], "x_hetero": 132, "x_homo": 132, "x_i": [52, 113, 143, 169, 192, 221, 331, 356, 416, 421, 422, 423, 426, 622, 623, 627, 630, 631, 633, 847, 848, 851, 991, 992, 996, 1002, 1003, 1004, 1010, 1014, 1015, 1016], "x_idx_sort": 1053, "x_imput": 638, "x_indic": 170, "x_inform": 326, "x_inlier": 306, "x_inv": [596, 599], "x_ipca": 129, "x_iri": [283, 1033], "x_isotropic_covari": 70, "x_j": [416, 426, 622, 623, 627, 630, 631, 633, 991, 992, 996, 1003, 1015, 1016], "x_k": [419, 421, 994, 1003], "x_label": 188, "x_leav": [565, 566, 567, 568, 572, 573, 574, 920, 921, 922, 923], "x_left_lower_corn": [50, 312, 381, 506], "x_legend": 47, "x_list": 322, "x_loadings_": [490, 491, 492], "x_lognorm": [323, 1010], "x_lsa": 361, "x_m": 1004, "x_max": [67, 87, 93, 141, 148, 158, 167, 178, 252, 314, 321, 343, 353, 354], "x_max_": 643, "x_mean": 428, "x_mean_": 1053, "x_min": [67, 87, 93, 141, 148, 152, 158, 167, 178, 209, 252, 314, 321, 343, 353, 354], "x_min_": 643, "x_miss": [155, 187, 188], "x_miss_california": 188, "x_miss_diabet": 188, "x_n": [125, 421, 912, 913, 1002, 1004, 1014], "x_near_unique_categori": 326, "x_new": [91, 417, 421, 425, 440, 450, 451, 453, 455, 457, 539, 540, 541, 542, 543, 544, 545, 547, 549, 550, 551, 552, 557, 575, 577, 578, 590, 591, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 636, 638, 643, 646, 647, 648, 649, 650, 696, 697, 698, 699, 700, 861, 868, 875, 876, 877, 878, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 904, 905, 1012, 1025], "x_new_again": 1012, "x_new_count": 1034, "x_new_invers": 1012, "x_new_tfidf": 1034, "x_norm_squar": [771, 1046, 1058], "x_normal": 1010, "x_np": 412, "x_offset": 201, "x_offset_": [652, 653, 1053], "x_origin": [542, 547, 549, 551, 552, 638, 904, 905], "x_out": [333, 876, 885, 886], "x_outlier": [202, 234, 305, 306, 348], "x_p": [416, 996], "x_pca": 129, "x_plot": [199, 221, 226, 253, 281, 304, 324], "x_plot_ext": 221, "x_plot_scal": 324, "x_po": 298, "x_q": 416, "x_r": [133, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611], "x_r2": 133, "x_rand": 284, "x_random": 209, "x_reconstruct": [332, 490, 491, 492, 591], "x_reconstructed_kernel_pca": [44, 130], "x_reconstructed_pca": [44, 130], "x_red": 87, "x_reduc": [86, 121, 158, 453, 1033], "x_restor": 86, "x_right": 70, "x_rope": 278, "x_rotations_": [419, 490, 491, 492], "x_scale": [201, 882, 898, 1010], "x_scale_": [652, 653, 1053], "x_scaler": 49, "x_score": [306, 490, 491, 492, 493], "x_scores_": [492, 1053], "x_select": 369, "x_shared_covari": 70, "x_shuffl": 326, "x_size": 114, "x_sp": 206, "x_spars": [335, 542, 971, 974], "x_sparse_embed": 574, "x_squared_norm": [266, 468], "x_src": 304, "x_std": [882, 898, 1010], "x_std_": 1053, "x_t": [472, 635, 871], "x_test": [44, 45, 46, 47, 49, 52, 61, 62, 63, 64, 67, 68, 104, 105, 109, 111, 117, 118, 130, 139, 142, 144, 146, 151, 152, 153, 154, 155, 156, 159, 166, 167, 170, 171, 181, 184, 191, 192, 193, 194, 195, 197, 200, 204, 210, 215, 217, 218, 226, 227, 228, 234, 235, 236, 238, 248, 250, 256, 260, 261, 265, 271, 272, 275, 276, 281, 285, 287, 291, 293, 298, 302, 305, 307, 308, 314, 316, 317, 321, 323, 324, 326, 328, 329, 330, 335, 336, 341, 342, 348, 360, 364, 366, 367, 368, 369, 373, 380, 388, 391, 399, 410, 417, 420, 423, 446, 478, 479, 480, 481, 482, 483, 484, 517, 566, 567, 568, 575, 576, 705, 706, 708, 710, 807, 830, 838, 840, 843, 861, 869, 870, 872, 886, 922, 923, 990, 1000, 1002, 1003, 1004, 1006, 1010, 1014, 1015, 1016, 1029, 1030, 1032, 1038, 1041], "x_test_df": 261, "x_test_kernel_pca": 130, "x_test_maxab": 1010, "x_test_minmax": 1010, "x_test_miss": 155, "x_test_no_cf_encod": 326, "x_test_noisi": 44, "x_test_np": 261, "x_test_pca": [45, 130, 1030], "x_test_r": 117, "x_test_scal": 261, "x_test_sel": 195, "x_test_select": 369, "x_test_text": 47, "x_test_tran": 1010, "x_test_transform": [369, 420], "x_text": 47, "x_tfidf": 361, "x_thresholds_": [250, 643, 1053], "x_torch": 412, "x_tr": [875, 881, 884, 885, 886, 890, 892, 895, 897, 898, 902, 903], "x_train": [44, 45, 46, 47, 49, 52, 61, 62, 63, 64, 67, 68, 104, 105, 109, 111, 117, 118, 130, 139, 142, 146, 150, 151, 152, 153, 154, 155, 156, 159, 166, 167, 170, 171, 182, 183, 184, 185, 191, 192, 193, 194, 195, 197, 200, 204, 215, 217, 218, 221, 227, 228, 234, 235, 236, 238, 248, 256, 260, 261, 265, 267, 271, 272, 275, 276, 281, 285, 287, 291, 298, 302, 305, 307, 308, 314, 316, 317, 321, 323, 324, 326, 328, 329, 330, 335, 336, 341, 342, 348, 360, 364, 368, 369, 373, 380, 388, 391, 399, 417, 420, 423, 445, 446, 517, 566, 567, 568, 575, 576, 705, 706, 708, 710, 807, 830, 838, 840, 843, 861, 869, 870, 872, 886, 922, 923, 990, 1000, 1002, 1003, 1004, 1006, 1008, 1010, 1014, 1015, 1029, 1030, 1038], "x_train_": 619, "x_train_count": 1034, "x_train_ensembl": 144, "x_train_linear": 144, "x_train_maxab": 1010, "x_train_minmax": 1010, "x_train_miss": 155, "x_train_no_cf_encod": 326, "x_train_noisi": 44, "x_train_pca": [45, 1030], "x_train_preprocess": 192, "x_train_r": 117, "x_train_sel": 195, "x_train_select": 369, "x_train_std_transform": 324, "x_train_text": 47, "x_train_tf": 1034, "x_train_tfidf": 1034, "x_train_tran": 1010, "x_train_transform": [324, 369, 420], "x_train_valid": 63, "x_tran": [323, 334, 388, 412, 450, 472, 888, 893, 900, 1010], "x_trans_bc": 323, "x_trans_qt": 323, "x_trans_yj": 323, "x_transform": [129, 158, 254, 493, 539, 540, 541, 542, 543, 545, 547, 551, 574, 646, 647, 696, 697, 698, 699], "x_transformed_fit_": 543, "x_true": 243, "x_type": 388, "x_uniform": 323, "x_val": [150, 1008], "x_valid": 63, "x_valu": 341, "x_vari": 92, "x_weibul": 323, "x_weights_": [419, 490, 491, 492, 493], "x_wrong": 70, "xa": 589, "xanchor": 279, "xarg": 1041, "xarrai": 1019, "xavier": [869, 870, 1049, 1050, 1051, 1053, 1054, 1059], "xaxi": [80, 121, 131, 145, 217, 240, 242, 245, 299, 304, 360], "xaxis2": 145, "xb": [117, 891], "xbar_": 557, "xbc": 424, "xc3": 424, "xcjason": 1051, "xcode": 384, "xd": 534, "xdang": 687, "xerox": 51, "xerr": [187, 188, 361], "xethan": 1053, "xfail": [388, 394], "xfc": 424, "xfcche": 424, "xfea": 424, "xff": 424, "xgamma": 693, "xgboost": [155, 157, 423, 1019], "xgrid": [50, 312], "xhan": 1050, "xhy": 1048, "xi": [2, 79, 100, 383, 416, 419, 424, 458, 464, 517, 1014, 1052], "xi_i": 1014, "xi_k": 419, "xiang": 1059, "xiangyin": 1054, "xiao": [0, 397, 405, 1049, 1051, 1054, 1055, 1056, 1057, 1058, 1059], "xiaojin": 907, "xiaoyu": 1053, "xiaoyuchai": 1054, "xin": [687, 996, 1049], "xinfan": [1041, 1042, 1045], "xing": [1049, 1050], "xinv": 877, "xinyu": 416, "xinyuliu12": 1050, "xiong": [1049, 1050, 1055], "xj": 414, "xk": [100, 558], "xlabel": [43, 47, 48, 52, 61, 62, 63, 64, 69, 72, 76, 96, 111, 112, 114, 115, 117, 118, 121, 127, 132, 140, 141, 143, 149, 151, 152, 153, 154, 155, 159, 163, 165, 169, 170, 173, 176, 177, 178, 179, 181, 182, 183, 192, 199, 202, 203, 204, 205, 207, 208, 209, 210, 213, 214, 220, 222, 223, 225, 227, 229, 230, 234, 238, 251, 253, 255, 257, 273, 277, 278, 282, 283, 287, 288, 291, 293, 301, 302, 305, 306, 325, 326, 346, 348, 349, 352, 360, 365, 366, 367, 639, 1029, 1033], "xlim": [51, 63, 79, 93, 97, 107, 111, 112, 113, 127, 141, 142, 143, 159, 165, 177, 178, 192, 199, 210, 212, 219, 226, 229, 234, 247, 255, 264, 269, 273, 287, 293, 305, 306, 348, 353, 354, 357, 367], "xm": [51, 243], "xmax": [50, 111, 210, 212, 229, 230, 312], "xmin": [50, 111, 210, 212, 229, 230, 312], "xn": 517, "xom": 51, "xor": [175, 177, 178, 179, 181, 182, 183, 189, 230, 233, 267, 322, 354, 618, 622, 630, 996, 1016, 1021, 1048], "xp": [419, 887], "xpreprocessor": 384, "xrang": 1047, "xred": [453, 1057], "xrot": 53, "xrx": 51, "xs_sp": 206, "xsat": 1051, "xscale": [177, 182, 253], "xt": [163, 299, 400, 453, 546, 548, 635, 637, 808, 811, 812, 822, 856, 864, 872, 877, 882, 889, 901, 930, 1057, 1059], "xtick": [43, 45, 47, 50, 66, 70, 75, 79, 81, 85, 86, 87, 93, 94, 97, 115, 117, 128, 149, 151, 155, 178, 179, 180, 184, 203, 210, 216, 233, 247, 255, 264, 265, 266, 269, 277, 278, 293, 303, 312, 317, 325, 338, 349, 352, 354, 705, 1030], "xtick_period": 193, "xtick_start": 193, "xticklabel": [43, 49, 149, 155, 193, 325], "xticks_label": 151, "xticks_po": 151, "xticks_rot": [45, 705, 1030], "xtrain": 312, "xu": [416, 419, 427, 452, 1014, 1054, 1055, 1058, 1059], "xue": [0, 1045, 1046, 1047, 1049, 1050, 1053], "xuefeng": [1058, 1059], "xueqin": [687, 996], "xun": [1051, 1053], "xuniu": 1056, "xval": 188, "xw": [219, 331, 654, 655, 657, 660, 661, 662, 663, 664, 668, 669, 670, 671, 680, 689, 690, 691, 692, 996], "xx": [77, 93, 113, 148, 152, 158, 167, 178, 179, 180, 193, 207, 227, 230, 231, 232, 233, 234, 245, 247, 255, 267, 305, 314, 321, 322, 343, 348, 349, 353, 354, 357, 358, 390], "xx0": [141, 639], "xx1": [141, 639], "xx_coarser": 148, "xxx": 400, "xy": [48, 63, 84, 285, 312, 354, 404, 654, 655, 658, 659, 660, 661, 662, 663, 668, 669, 670, 671, 672, 689, 690, 691, 692, 694], "xycoord": [48, 63], "xyguo": [1047, 1049], "xytext": [48, 63, 197], "xyz": 385, "y": [2, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 61, 62, 63, 64, 66, 67, 69, 70, 74, 75, 77, 78, 79, 80, 87, 89, 91, 92, 95, 96, 97, 100, 101, 105, 106, 108, 109, 114, 117, 118, 122, 123, 127, 129, 130, 131, 133, 134, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 171, 172, 173, 174, 177, 178, 179, 180, 181, 182, 183, 184, 185, 191, 192, 193, 194, 195, 197, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 241, 242, 245, 248, 250, 251, 252, 253, 254, 255, 257, 258, 260, 261, 263, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 293, 294, 296, 298, 299, 301, 302, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 364, 365, 366, 367, 368, 369, 378, 379, 380, 381, 384, 386, 388, 391, 393, 395, 399, 400, 407, 410, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 493, 495, 506, 508, 510, 513, 516, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 591, 593, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 705, 706, 707, 708, 709, 710, 714, 719, 734, 740, 743, 749, 750, 764, 766, 767, 768, 769, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 793, 796, 797, 800, 801, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 868, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 904, 905, 907, 908, 909, 910, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 925, 932, 937, 938, 960, 962, 963, 964, 971, 974, 987, 989, 990, 991, 992, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1007, 1010, 1014, 1015, 1016, 1020, 1025, 1029, 1030, 1032, 1033, 1036, 1038, 1041, 1042, 1043, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "y0": [51, 243], "y1": [51, 122, 141, 243, 517, 724, 1001, 1002], "y1_label": 46, "y2": [122, 141, 724, 1001], "y2_label": 46, "y3": 1001, "y_": [250, 264, 268, 269, 311, 388, 419, 421, 645, 656, 677, 688, 737, 738, 746, 772, 791, 792, 795, 996, 1000, 1047], "y_1": [140, 366, 367, 419, 1000, 1004, 1014], "y_2": [140, 366, 367, 1004], "y_20": 342, "y_2d": 349, "y_3": 367, "y_30": 343, "y_50": 343, "y_adult": 335, "y_all": [674, 676, 684, 840, 841, 869], "y_ard": 199, "y_ard_std": 199, "y_axi": [127, 228], "y_bia": 142, "y_brr": 199, "y_brr_std": 199, "y_c": [490, 491, 493], "y_calib": 445, "y_california": 188, "y_coclust": 57, "y_convert": 932, "y_cov": 619, "y_cu": 412, "y_decis": [335, 843], "y_dens": 1001, "y_diabet": [188, 1029], "y_different_covari": 70, "y_digit": [107, 166, 315, 417, 1029, 1030, 1032], "y_error": [142, 226], "y_errors_larg": 226, "y_filter": 92, "y_fold": 1029, "y_full": [187, 188, 319], "y_full_train": 144, "y_grid_pr": 158, "y_hat": 473, "y_high": 152, "y_i": [143, 331, 356, 414, 423, 991, 992, 996, 1000, 1004, 1014, 1015, 1016], "y_indic": 883, "y_iri": [283, 1033], "y_isotropic_covari": 70, "y_j": [992, 1000, 1002, 1010, 1015], "y_k": [419, 1010], "y_kmean": 57, "y_kr": 253, "y_l": 1000, "y_label": 238, "y_left_lower_corn": [50, 312, 381, 506], "y_limit": 149, "y_loadings_": [490, 491, 492], "y_loc": 360, "y_log_prob": 843, "y_log_proba": 872, "y_low": 152, "y_lower": [95, 152], "y_mask": 342, "y_max": [67, 93, 141, 148, 158, 167, 178, 238, 252, 314, 321, 343, 353, 354, 643, 645], "y_mean": [181, 182, 185, 619, 652, 653], "y_mean_": 1053, "y_med": 152, "y_min": [67, 93, 141, 148, 158, 167, 178, 252, 314, 321, 343, 353, 354, 643, 645], "y_miss": [187, 188], "y_miss_california": 188, "y_miss_diabet": 188, "y_multirf": 159, "y_n": [1000, 1004, 1014], "y_new": 91, "y_nois": 142, "y_noisi": 219, "y_norm_squar": 771, "y_normal": 222, "y_np": 412, "y_numer": 932, "y_observ": 336, "y_onehot_test": 287, "y_org": 937, "y_outlier": 202, "y_pareto": 222, "y_plot": [199, 221, 226, 281], "y_plot_ext": 221, "y_po": 362, "y_pred": [43, 45, 46, 52, 62, 66, 68, 70, 79, 92, 97, 104, 109, 139, 152, 153, 155, 160, 171, 192, 220, 222, 227, 230, 235, 237, 238, 247, 248, 257, 272, 274, 276, 281, 306, 310, 317, 324, 336, 341, 342, 369, 386, 393, 400, 423, 439, 447, 473, 490, 491, 492, 557, 560, 562, 564, 565, 566, 568, 570, 572, 573, 575, 576, 578, 619, 639, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 686, 687, 688, 705, 706, 708, 709, 710, 711, 716, 720, 721, 726, 729, 730, 731, 732, 736, 737, 738, 742, 744, 746, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 791, 792, 793, 795, 796, 798, 799, 804, 808, 811, 812, 822, 833, 843, 845, 846, 855, 863, 870, 872, 912, 913, 914, 915, 916, 917, 918, 921, 923, 1000, 1002, 1030, 1047, 1048, 1050, 1052, 1056, 1057, 1058], "y_pred_ard": 204, "y_pred_bin": 220, "y_pred_chain": 298, "y_pred_empti": [737, 738], "y_pred_enet": 204, "y_pred_ensembl": 298, "y_pred_lasso": 204, "y_pred_lr": 222, "y_pred_nnl": 215, "y_pred_ol": 215, "y_pred_outli": [234, 305, 348], "y_pred_outliers_sgd": 234, "y_pred_ovr": 298, "y_pred_product": 238, "y_pred_qr": 222, "y_pred_ridg": 109, "y_pred_ridge_with_trans_target": 109, "y_pred_scal": 324, "y_pred_seg": 220, "y_pred_test": [234, 305, 348], "y_pred_test_sgd": 234, "y_pred_tot": 238, "y_pred_train": [234, 348], "y_pred_train_sgd": 234, "y_pred_with_": 191, "y_pred_without_": 191, "y_predict": [142, 388, 1041], "y_prob": [62, 64, 179, 446, 447, 717, 843, 869, 1000, 1055, 1059], "y_proba": [151, 154, 324, 400, 717, 872, 1059], "y_proba_sc": 324, "y_rand": 343, "y_reconstruct": [490, 491, 492], "y_rf": 159, "y_right": 70, "y_rotations_": [419, 490, 491, 492], "y_sampl": [185, 619], "y_scaler": 49, "y_score": [248, 285, 287, 400, 490, 491, 492, 715, 728, 734, 735, 747, 748, 764, 790, 796, 797, 802, 808, 811, 812, 822, 872, 1000, 1047, 1055, 1057, 1059], "y_scores_": [492, 1053], "y_shared_covari": 70, "y_spars": 1001, "y_std": [182, 185, 560, 619, 652, 653, 1054], "y_std_": 1053, "y_svr": 253, "y_test": [44, 45, 46, 47, 49, 52, 61, 62, 63, 64, 67, 68, 104, 105, 109, 117, 118, 130, 139, 142, 144, 146, 151, 152, 153, 154, 155, 156, 159, 166, 167, 170, 171, 184, 191, 192, 193, 194, 195, 197, 204, 215, 217, 220, 226, 227, 228, 235, 236, 238, 248, 256, 260, 261, 265, 271, 272, 275, 276, 281, 285, 287, 291, 298, 302, 307, 308, 314, 316, 317, 321, 324, 326, 328, 329, 330, 335, 336, 341, 342, 360, 364, 368, 369, 380, 391, 399, 417, 420, 423, 446, 517, 566, 567, 568, 575, 576, 705, 706, 708, 710, 807, 830, 838, 840, 843, 861, 869, 870, 872, 922, 923, 1000, 1002, 1003, 1010, 1015, 1029, 1030, 1038, 1041], "y_test_pr": 265, "y_test_predict": 256, "y_test_r": 117, "y_test_tru": 341, "y_thresholds_": [250, 643, 1053], "y_torch": 412, "y_train": [44, 45, 46, 47, 49, 52, 61, 62, 63, 64, 67, 68, 104, 105, 109, 117, 118, 130, 139, 142, 146, 150, 151, 152, 153, 154, 155, 156, 159, 166, 167, 170, 171, 182, 183, 184, 185, 191, 192, 193, 194, 195, 197, 200, 204, 215, 217, 218, 221, 227, 228, 235, 236, 248, 256, 260, 261, 265, 271, 272, 275, 276, 281, 285, 287, 291, 298, 302, 307, 308, 314, 316, 317, 321, 324, 326, 328, 329, 330, 335, 336, 338, 339, 341, 342, 343, 360, 364, 368, 369, 373, 380, 388, 391, 399, 417, 420, 423, 445, 446, 517, 566, 567, 568, 575, 576, 705, 706, 708, 710, 807, 830, 838, 840, 843, 861, 869, 870, 872, 922, 923, 990, 1000, 1002, 1003, 1008, 1010, 1015, 1029, 1030, 1038], "y_train_": 619, "y_train_ensembl": 144, "y_train_linear": 144, "y_train_noisi": 183, "y_train_pr": 265, "y_train_r": 117, "y_train_valid": 63, "y_tran": 109, "y_transform": 493, "y_true": [43, 52, 57, 68, 94, 109, 139, 160, 179, 220, 230, 238, 257, 266, 272, 341, 386, 439, 446, 447, 473, 490, 491, 492, 560, 562, 564, 565, 566, 568, 570, 572, 573, 576, 578, 619, 643, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 668, 669, 670, 671, 672, 673, 675, 678, 680, 681, 686, 687, 705, 706, 708, 709, 710, 711, 715, 716, 717, 720, 721, 726, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 742, 743, 744, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 764, 790, 791, 792, 793, 795, 796, 797, 798, 799, 802, 804, 807, 845, 846, 855, 863, 870, 913, 915, 918, 921, 923, 1000, 1042, 1047, 1048, 1049, 1050, 1052, 1053, 1055, 1056, 1058], "y_true_bin": 220, "y_true_categor": [717, 1000], "y_true_empti": 737, "y_true_mean": 222, "y_true_seg": 220, "y_type_": 879, "y_uniqu": 61, "y_upper": [95, 152], "y_val": [150, 1008], "y_valid": 63, "y_var": 142, "y_vari": 92, "y_weights_": [419, 490, 491, 492, 493], "y_wrong": 70, "yacin": 1049, "yadav": 1055, "yagi": 1053, "yahoo": 51, "yair": [416, 699], "yakov": 1053, "yalburgi": [1048, 1049], "yaman": 1056, "yamanishi": 381, "yamin": 1041, "yaml": 390, "yan": [1045, 1053], "yanchor": 279, "yang": [381, 416, 421, 542, 647, 1047, 1048, 1051, 1053, 1054, 1055, 1057, 1058], "yangarbit": 1048, "yanhong": 1056, "yanlend": 1047, "yann": [317, 1041, 1043], "yanni": 416, "yannick": [1041, 1043], "yao": [0, 383, 397, 405, 1047, 1048, 1049, 1050, 1057, 1058, 1059], "yap": 1048, "yar": 1055, "yaroslav": [0, 405, 1041, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1057, 1058], "yarowski": [330, 909, 1013], "yashika": 1053, "yasmeen": 1054, "yat2016": 416, "yate": [598, 738], "yates2011": 598, "yau": [54, 1044, 1045, 1046, 1047, 1048], "yaxi": [46, 49, 80, 95, 121, 131, 145, 217, 240, 242, 245, 263, 299, 304, 360], "ye": [360, 394, 400, 410, 666, 667, 879, 896, 996], "year": [0, 43, 163, 174, 181, 191, 192, 193, 220, 221, 238, 336, 383, 385, 390, 398, 420, 424, 810, 815, 817, 891, 996, 1000, 1020, 1024, 1032], "yearli": 43, "yearremodadd": 160, "yeast": [298, 843], "yee": [1048, 1049], "yegelwel": 1053, "yeh": 1054, "yelit": 1047, "yellow": [70, 123, 349, 1001], "yellowbrick": 1019, "yellowgreen": [221, 223, 230, 366], "yen": [1047, 1048], "yenchen": [0, 1047], "yenchenlin": 1047, "yenugula": 1059, "yeo": [319, 323, 888, 900, 1010, 1049, 1055, 1057], "yep": 389, "yerr": [107, 112, 114, 146, 149, 173, 301, 325, 341], "yesy": 1027, "yesyesclassificationclassificationnumb": 1027, "yesyesdo": 1027, "yesyesfew": 1027, "yesyesllel": 1027, "yesyespredict": 1027, "yesyessgdclassifiersgd": 1027, "yesyessgdregressorsgd": 1027, "yesyestextdatatext": 1027, "yet": [48, 92, 204, 238, 268, 279, 362, 375, 381, 385, 390, 398, 403, 404, 407, 420, 421, 423, 424, 426, 456, 460, 469, 470, 473, 561, 562, 585, 601, 602, 610, 786, 909, 984, 989, 996, 1000, 1006, 1014, 1020, 1050, 1058], "yeung": 1047, "ygrid": [50, 312], "yhoo": 51, "yi": [517, 1002, 1045, 1049, 1050, 1053], "yichuan": [1047, 1048], "yield": [47, 48, 62, 80, 90, 111, 112, 113, 114, 152, 204, 215, 220, 235, 238, 283, 298, 314, 319, 346, 351, 360, 361, 369, 373, 375, 380, 391, 400, 413, 416, 418, 420, 421, 423, 424, 425, 445, 457, 476, 480, 516, 517, 545, 546, 547, 549, 554, 561, 562, 567, 568, 569, 570, 575, 576, 602, 610, 655, 659, 660, 661, 663, 669, 671, 673, 681, 683, 694, 734, 789, 796, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 835, 836, 837, 839, 843, 846, 904, 905, 943, 950, 952, 953, 958, 992, 994, 996, 997, 1000, 1015, 1016, 1029, 1046, 1047, 1049, 1052, 1054], "yifan": 1004, "yime": 1049, "ying": [416, 460, 470, 1055], "yinglr": 1051, "yisheng": 1058, "yiyangq": 1055, "yj": [117, 323], "ylabel": [43, 47, 48, 52, 61, 62, 63, 64, 69, 72, 96, 111, 112, 114, 115, 117, 118, 121, 127, 132, 140, 141, 143, 151, 152, 153, 154, 155, 159, 163, 165, 169, 170, 173, 176, 177, 178, 179, 181, 182, 183, 192, 199, 202, 203, 204, 205, 207, 208, 209, 210, 213, 214, 220, 222, 223, 225, 227, 229, 230, 238, 251, 253, 255, 273, 277, 278, 281, 282, 283, 287, 288, 291, 293, 302, 326, 346, 349, 352, 360, 365, 366, 367, 639, 1029, 1033], "ylim": [51, 61, 63, 69, 72, 79, 93, 97, 111, 112, 113, 127, 141, 142, 149, 152, 159, 162, 177, 178, 192, 207, 209, 210, 212, 213, 214, 226, 229, 230, 234, 247, 255, 264, 269, 273, 277, 281, 287, 291, 293, 305, 306, 348, 353, 354, 357, 360, 367, 1029], "ylorbr_r": 113, "ym": [51, 243], "ymax": [47, 49, 50, 111, 207, 209, 212, 213, 221, 229, 278, 312], "ymazari": 1049, "ymean": 200, "ymin": [50, 111, 207, 209, 212, 213, 221, 229, 278, 312], "yn": [517, 1001, 1002], "yoav": 1047, "yoch": 1054, "yogendrasingh": 1056, "yojana": 1056, "yokasr": 1051, "yoni": 1044, "yoon": 1052, "yoram": [296, 743], "york": [277, 796, 805, 990, 1000, 1012], "yoshihiro": [200, 1051], "yoshiki": [1044, 1047], "yoshizawa": 1049, "yoshua": [869, 870, 1013], "yosshi999": 1055, "yosuk": [1053, 1054], "yotam": 1057, "you": [0, 30, 54, 58, 61, 105, 121, 147, 148, 151, 153, 171, 174, 188, 193, 208, 221, 222, 224, 249, 254, 261, 266, 273, 278, 279, 285, 294, 305, 328, 329, 332, 334, 335, 339, 342, 353, 360, 369, 373, 374, 375, 380, 381, 384, 385, 386, 387, 388, 390, 391, 392, 394, 395, 399, 400, 404, 407, 410, 412, 414, 415, 416, 417, 418, 420, 423, 424, 425, 427, 428, 433, 445, 451, 452, 454, 455, 457, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 490, 491, 492, 508, 511, 512, 517, 518, 540, 541, 542, 544, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 587, 588, 589, 590, 596, 597, 598, 599, 602, 615, 616, 618, 619, 635, 643, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 695, 698, 707, 708, 793, 806, 807, 809, 810, 811, 812, 813, 815, 817, 823, 824, 826, 827, 828, 830, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 862, 863, 869, 870, 871, 872, 875, 876, 877, 878, 879, 884, 885, 886, 891, 892, 897, 898, 900, 901, 902, 903, 905, 907, 908, 912, 913, 914, 915, 916, 917, 918, 920, 921, 922, 923, 949, 966, 989, 990, 995, 996, 1000, 1001, 1004, 1006, 1007, 1010, 1011, 1014, 1015, 1016, 1018, 1019, 1023, 1024, 1025, 1026, 1027, 1029, 1032, 1034, 1041, 1044, 1045, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "youden": 1000, "younger": 238, "your": [16, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 374, 375, 380, 384, 385, 386, 387, 389, 390, 392, 394, 395, 398, 399, 400, 404, 410, 412, 415, 416, 417, 418, 423, 424, 427, 428, 452, 454, 511, 541, 569, 570, 610, 642, 654, 695, 719, 808, 811, 812, 814, 822, 831, 835, 837, 943, 997, 1004, 1010, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1023, 1024, 1027, 1034, 1042, 1045, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "your_regex_goes_her": 386, "yourlogin": 386, "yourself": [105, 385, 386, 387, 391, 394, 1004], "ypred": 1048, "yrsold": 160, "yscale": [177, 182, 220, 253, 360], "ystd": 200, "yt": 883, "ython": 0, "ytick": [45, 50, 66, 70, 75, 79, 81, 85, 86, 87, 93, 94, 97, 115, 117, 128, 153, 170, 178, 179, 180, 184, 203, 210, 216, 233, 247, 255, 264, 265, 266, 269, 273, 293, 303, 312, 317, 338, 349, 354, 360, 1029, 1030], "yticklabel": [273, 360], "ytrain": 312, "ytrue": 1048, "yu": [204, 416, 460, 470, 666, 996, 1004, 1044, 1045, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055], "yuan": [1055, 1056, 1057, 1058, 1059], "yuchen": [1057, 1058], "yucheng": 1046, "yue": [1053, 1059], "yufeng": 1049, "yuichi": 1048, "yuki": 1055, "yule": [458, 465, 786, 787, 788], "yulia": 1051, "yum": 384, "yun": [1056, 1057], "yung": [1044, 1047], "yunqian": 996, "yurchak": [0, 405, 424, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055], "yuri": [1044, 1046], "yusuf": [1056, 1057], "yusuk": 1054, "yusukenagasaka": 1054, "yutaro": 1053, "yuusuk": 1058, "yuval": [413, 459], "yv": 419, "yve": 1054, "yy": [77, 93, 113, 148, 158, 167, 178, 180, 193, 227, 231, 232, 233, 234, 245, 247, 255, 305, 314, 321, 322, 343, 348, 349, 353, 354, 357, 358], "yy_": 227, "yy_coars": 148, "yy_down": 354, "yy_up": 354, "yzhenman": 1054, "z": [50, 93, 148, 167, 178, 180, 193, 230, 232, 233, 240, 242, 247, 252, 267, 305, 312, 314, 321, 324, 343, 349, 354, 358, 383, 413, 421, 423, 561, 562, 593, 647, 672, 679, 693, 694, 697, 701, 707, 732, 793, 892, 996, 997, 1004, 1005, 1033, 1056], "z_": 421, "z_1": 996, "z_2": 996, "z_3": 996, "z_4": 996, "z_5": 996, "z_i": [143, 1004], "z_l": 1004, "z_points_coars": 148, "zablit": 1056, "zac": 1046, "zacchari": 1053, "zach": [1049, 1050, 1055], "zachariah": 1049, "zadrozni": [64, 414, 445, 684], "zaffalon": 278, "zahlii": 1054, "zain": [0, 405, 1055, 1056, 1057, 1058], "zalkow": 1046, "zambelli": 1044, "zamrii": 1051, "zanouda": 1048, "zaxi": [80, 121, 131, 217, 240], "zayd": 1050, "zaytsev": 1044, "zdzieblo": 1058, "zebra": 720, "zedan": 1057, "zeel": 1055, "zeeshan": [1056, 1057], "zempleni": 1055, "zen": 937, "zenin": 1047, "zentrum": 1000, "zero": [2, 25, 49, 50, 53, 64, 70, 72, 75, 76, 87, 89, 112, 114, 115, 125, 128, 130, 141, 142, 151, 153, 154, 159, 171, 174, 188, 199, 204, 206, 211, 213, 214, 219, 220, 221, 224, 225, 226, 230, 235, 238, 251, 254, 255, 257, 263, 267, 269, 275, 278, 283, 287, 288, 304, 319, 329, 330, 353, 356, 361, 362, 364, 368, 373, 374, 381, 388, 392, 400, 414, 416, 418, 421, 423, 424, 425, 426, 429, 454, 460, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 495, 505, 516, 517, 531, 534, 535, 539, 540, 543, 545, 546, 547, 548, 550, 551, 555, 556, 560, 565, 566, 567, 568, 569, 570, 572, 573, 574, 589, 593, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 615, 616, 619, 644, 647, 651, 652, 653, 658, 666, 667, 672, 673, 674, 675, 676, 679, 684, 685, 686, 693, 694, 711, 717, 720, 721, 723, 724, 733, 737, 738, 742, 746, 748, 754, 791, 792, 793, 795, 804, 805, 823, 824, 827, 828, 841, 852, 853, 854, 855, 856, 858, 860, 861, 862, 863, 864, 865, 866, 867, 868, 875, 882, 884, 885, 887, 888, 889, 891, 892, 898, 899, 900, 901, 905, 912, 920, 921, 922, 923, 947, 975, 986, 990, 996, 998, 999, 1002, 1003, 1004, 1010, 1011, 1012, 1014, 1015, 1016, 1025, 1032, 1034, 1041, 1043, 1045, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "zero_bas": [495, 516, 517], "zero_class": 255, "zero_divis": [317, 721, 737, 738, 746, 791, 792, 795, 1000, 1051, 1053, 1057], "zero_impute_scor": 188, "zero_on": [386, 1042], "zero_one_loss": [2, 386, 412, 711, 742, 1000, 1042, 1043, 1044, 1058], "zero_one_scor": 1042, "zerodivisionerror": [1048, 1051, 1057], "zeros_lik": [84, 222, 287], "zeta": 1015, "zeta_i": 1015, "zev": [1047, 1048, 1049, 1050], "zeyusun": 1054, "zha": [697, 701, 997], "zhai_pro": 1046, "zhan": 1056, "zhang": [277, 416, 450, 672, 687, 693, 694, 697, 701, 766, 767, 996, 997, 998, 1002, 1014, 1045, 1046, 1048, 1049, 1050, 1051, 1053, 1057, 1058, 1059], "zhang02c": 684, "zhang96": [416, 450], "zhao": [1051, 1053, 1054, 1055, 1056], "zhaowei": 1053, "zhaoweiwang": 1054, "zhauniarovich": 1046, "zhdanovich": 1049, "zhechev": 1056, "zhehao": [1054, 1055, 1056, 1057, 1059], "zhenfish": 1055, "zheng": [1047, 1048, 1053], "zhenq": 1049, "zhi": [571, 1006], "zhiqe": 1049, "zhou": [571, 647, 908, 1006, 1049, 1057, 1058], "zht2007": 208, "zhu": [139, 423, 527, 561, 666, 907], "zhuyi": [1049, 1050], "zhuzhunashvili": [416, 470], "zibulevski": [672, 693, 694], "zichen": 1046, "zielinska": 1052, "zihna": 1054, "ziji": [1049, 1050], "zijlstra": 1044, "zike": 1047, "zimek": 454, "zimmer": [1045, 1055], "zinkov": [227, 1041, 1042, 1043, 1045, 1046], "zip": [43, 44, 47, 48, 51, 52, 61, 63, 67, 68, 70, 72, 73, 75, 77, 80, 84, 90, 98, 99, 109, 118, 123, 125, 126, 129, 133, 134, 135, 141, 143, 150, 160, 161, 182, 187, 189, 192, 193, 194, 205, 211, 212, 220, 228, 229, 240, 251, 257, 264, 268, 269, 272, 276, 280, 281, 282, 285, 287, 299, 302, 304, 307, 314, 315, 316, 321, 323, 324, 325, 342, 346, 356, 357, 365, 384, 423, 836, 1010, 1034, 1037], "zisserman": [646, 992, 1000], "zito": [1041, 1054], "ziv": 1047, "zivori": 1047, "zj": [1049, 1050], "zlabel": 1033, "zoj613": 1053, "zolisa": 1053, "zoom": [43, 144, 319, 1027], "zoom_in_percentile_rang": 319, "zorder": [51, 93, 127, 157, 167, 177, 185, 210, 218, 241, 243, 250, 253, 263, 329, 335, 354], "zou": [139, 208, 423, 527, 561, 664, 996, 1014], "zou_et_al_criterion_resc": 208, "zoubin": 907, "zoubir": 114, "zouhar": 1054, "zsh": 374, "zuckerberg": 0, "zwinck": 1043, "zxcvbniu": 1048, "zz": 113, "zzrh2009": 423, "z\u00e9": 1049, "\u00e4yr\u00e4m\u00f6": 996, "\u00f3scar": [1045, 1046, 1047, 1048], "\u00f6zer": 1054, "\u0142ukasz": 1056, "\u015fahin": 1055, "\u675c\u4e16\u6a4b": [0, 406], "\u8d75\u4e30": 1055}, "titles": ["About us", "Recently Deprecated", "API Reference", "sklearn", "sklearn.base", "sklearn.calibration", "sklearn.cluster", "sklearn.compose", "sklearn.covariance", "sklearn.cross_decomposition", "sklearn.datasets", "sklearn.decomposition", "sklearn.discriminant_analysis", "sklearn.dummy", "sklearn.ensemble", "sklearn.exceptions", "sklearn.experimental", "sklearn.feature_extraction", "sklearn.feature_selection", "sklearn.gaussian_process", "sklearn.impute", "sklearn.inspection", "sklearn.isotonic", "sklearn.kernel_approximation", "sklearn.kernel_ridge", "sklearn.linear_model", "sklearn.manifold", "sklearn.metrics", "sklearn.mixture", "sklearn.model_selection", "sklearn.multiclass", "sklearn.multioutput", "sklearn.naive_bayes", "sklearn.neighbors", "sklearn.neural_network", "sklearn.pipeline", "sklearn.preprocessing", "sklearn.random_projection", "sklearn.semi_supervised", "sklearn.svm", "sklearn.tree", "sklearn.utils", "Examples based on real world datasets", "Time-related feature engineering", "Image denoising using kernel PCA", "Faces recognition example using eigenfaces and SVMs", "Model Complexity Influence", "Out-of-core classification of text documents", "Outlier detection on a real data set", "Prediction Latency", "Species distribution modeling", "Visualizing the stock market structure", "Lagged features for time series forecasting", "Compressive sensing: tomography reconstruction with L1 prior (Lasso)", "Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation", "Wikipedia principal eigenvector", "Biclustering", "Biclustering documents with the Spectral Co-clustering algorithm", "A demo of the Spectral Biclustering algorithm", "A demo of the Spectral Co-Clustering algorithm", "Calibration", "Probability calibration of classifiers", "Probability Calibration curves", "Probability Calibration for 3-class classification", "Comparison of Calibration of Classifiers", "Classification", "Plot classification probability", "Classifier comparison", "Recognizing hand-written digits", "Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification", "Linear and Quadratic Discriminant Analysis with covariance ellipsoid", "Clustering", "Adjustment for chance in clustering performance evaluation", "Demo of affinity propagation clustering algorithm", "Agglomerative clustering with and without structure", "Agglomerative clustering with different metrics", "Plot Hierarchical Clustering Dendrogram", "Compare BIRCH and MiniBatchKMeans", "Bisecting K-Means and Regular K-Means Performance Comparison", "Comparing different clustering algorithms on toy datasets", "K-means Clustering", "Segmenting the picture of greek coins in regions", "A demo of structured Ward hierarchical clustering on an image of coins", "Color Quantization using K-Means", "Demo of DBSCAN clustering algorithm", "Online learning of a dictionary of parts of faces", "Feature agglomeration", "Various Agglomerative Clustering on a 2D embedding of digits", "Vector Quantization Example", "Feature agglomeration vs. univariate selection", "Demo of HDBSCAN clustering algorithm", "Inductive Clustering", "Demonstration of k-means assumptions", "A demo of K-Means clustering on the handwritten digits data", "An example of K-Means++ initialization", "Selecting the number of clusters with silhouette analysis on KMeans clustering", "Empirical evaluation of the impact of k-means initialization", "Comparing different hierarchical linkage methods on toy datasets", "A demo of the mean-shift clustering algorithm", "Comparison of the K-Means and MiniBatchKMeans clustering algorithms", "Demo of OPTICS clustering algorithm", "Spectral clustering for image segmentation", "Hierarchical clustering: structured vs unstructured ward", "Pipelines and composite estimators", "Column Transformer with Heterogeneous Data Sources", "Column Transformer with Mixed Types", "Selecting dimensionality reduction with Pipeline and GridSearchCV", "Pipelining: chaining a PCA and a logistic regression", "Concatenating multiple feature extraction methods", "Effect of transforming the targets in regression model", "Covariance estimation", "Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood", "Ledoit-Wolf vs OAS estimation", "Robust covariance estimation and Mahalanobis distances relevance", "Robust vs Empirical covariance estimate", "Sparse inverse covariance estimation", "Cross decomposition", "Compare cross decomposition methods", "Principal Component Regression vs Partial Least Squares Regression", "Dataset examples", "The Digit Dataset", "The Iris Dataset", "Plot randomly generated classification dataset", "Plot randomly generated multilabel dataset", "Decomposition", "Faces dataset decompositions", "Blind source separation using FastICA", "FastICA on 2D point clouds", "Image denoising using dictionary learning", "Incremental PCA", "Kernel PCA", "PCA example with Iris Data-set", "Model selection with Probabilistic PCA and Factor Analysis (FA)", "Comparison of LDA and PCA 2D projection of Iris dataset", "Sparse coding with a precomputed dictionary", "Factor Analysis (with rotation) to visualize patterns", "Developing Estimators", "<code class=\"docutils literal notranslate\"><span class=\"pre\">__sklearn_is_fitted__</span></code> as Developer API", "Ensemble methods", "Multi-class AdaBoosted Decision Trees", "Decision Tree Regression with AdaBoost", "Two-class AdaBoost", "Single estimator versus bagging: bias-variance decomposition", "OOB Errors for Random Forests", "Feature transformations with ensembles of trees", "Comparing Random Forests and Histogram Gradient Boosting models", "Feature importances with a forest of trees", "Pixel importances with a parallel forest of trees", "Plot the decision surfaces of ensembles of trees on the iris dataset", "Categorical Feature Support in Gradient Boosting", "Early stopping in Gradient Boosting", "Gradient Boosting Out-of-Bag estimates", "Prediction Intervals for Gradient Boosting Regression", "Gradient Boosting regression", "Gradient Boosting regularization", "Features in Histogram Gradient Boosting Trees", "IsolationForest example", "Monotonic Constraints", "Hashing feature transformation using Totally Random Trees", "Comparing random forests and the multi-output meta estimator", "Combine predictors using stacking", "Plot the decision boundaries of a VotingClassifier", "Plot class probabilities calculated by the VotingClassifier", "Plot individual and voting regression predictions", "Tutorial exercises", "Cross-validation on diabetes Dataset Exercise", "Digits Classification Exercise", "SVM Exercise", "Feature Selection", "Comparison of F-test and mutual information", "Univariate Feature Selection", "Pipeline ANOVA SVM", "Recursive feature elimination", "Recursive feature elimination with cross-validation", "Model-based and sequential feature selection", "Gaussian Process for Machine Learning", "Comparison of kernel ridge and Gaussian process regression", "Probabilistic predictions with Gaussian process classification (GPC)", "Gaussian process classification (GPC) on iris dataset", "Iso-probability lines for Gaussian Processes classification (GPC)", "Illustration of Gaussian process classification (GPC) on the XOR dataset", "Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)", "Ability of Gaussian process regression (GPR) to estimate data noise-level", "Gaussian Processes regression: basic introductory example", "Gaussian processes on discrete data structures", "Illustration of prior and posterior Gaussian process for different kernels", "Missing Value Imputation", "Imputing missing values with variants of IterativeImputer", "Imputing missing values before building an estimator", "Examples", "Inspection", "Failure of Machine Learning to infer causal effects", "Common pitfalls in the interpretation of coefficients of linear models", "Partial Dependence and Individual Conditional Expectation Plots", "Permutation Importance vs Random Forest Feature Importance (MDI)", "Permutation Importance with Multicollinear or Correlated Features", "Kernel Approximation", "Scalable learning with polynomial kernel approximation", "Generalized Linear Models", "Comparing Linear Bayesian Regressors", "Curve Fitting with Bayesian Ridge Regression", "Fitting an Elastic Net with a precomputed Gram Matrix and Weighted Samples", "HuberRegressor vs Ridge on dataset with strong outliers", "Logistic Regression 3-class Classifier", "L1-based models for Sparse Signals", "Lasso and Elastic Net", "Lasso on dense and sparse data", "Lasso path using LARS", "Lasso model selection via information criteria", "Lasso model selection: AIC-BIC / cross-validation", "Logistic function", "L1 Penalty and Sparsity in Logistic Regression", "Plot multinomial and One-vs-Rest Logistic Regression", "Regularization path of L1- Logistic Regression", "Joint feature selection with multi-task Lasso", "Non-negative least squares", "Linear Regression Example", "Sparsity Example: Fitting only features 1  and 2", "Ordinary Least Squares and Ridge Regression Variance", "Orthogonal Matching Pursuit", "Poisson regression and non-normal loss", "Polynomial and Spline interpolation", "Quantile regression", "Robust linear model estimation using RANSAC", "Ridge coefficients as a function of the L2 Regularization", "Plot Ridge coefficients as a function of the regularization", "Robust linear estimator fitting", "Comparing various online solvers", "Early stopping of Stochastic Gradient Descent", "Plot multi-class SGD on the iris dataset", "SGD: convex loss functions", "SGD: Penalties", "SGD: Maximum margin separating hyperplane", "SGD: Weighted samples", "One-Class SVM versus One-Class SVM using Stochastic Gradient Descent", "Multiclass sparse logistic regression on 20newgroups", "MNIST classification using multinomial logistic + L1", "Theil-Sen Regression", "Tweedie regression on insurance claims", "Manifold learning", "Comparison of Manifold Learning methods", "Manifold learning on handwritten digits: Locally Linear Embedding, Isomap\u2026", "Manifold Learning methods on a severed sphere", "Multi-dimensional scaling", "Swiss Roll And Swiss-Hole Reduction", "t-SNE: The effect of various perplexity values on the shape", "Miscellaneous", "Comparing anomaly detection algorithms for outlier detection on toy datasets", "Visualizations with Display Objects", "Displaying estimators and complex pipelines", "Isotonic Regression", "The Johnson-Lindenstrauss bound for embedding with random projections", "Explicit feature map approximation for RBF kernels", "Comparison of kernel ridge regression and SVR", "Metadata Routing", "Multilabel classification", "Face completion with a multi-output estimators", "Evaluation of outlier detection estimators", "Advanced Plotting With Partial Dependence", "Displaying Pipelines", "ROC Curve with Visualization API", "Introducing the <code class=\"docutils literal notranslate\"><span class=\"pre\">set_output</span></code> API", "Gaussian Mixture Models", "Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture", "Gaussian Mixture Model Ellipsoids", "GMM covariances", "GMM Initialization Methods", "Density Estimation for a Gaussian mixture", "Gaussian Mixture Model Selection", "Gaussian Mixture Model Sine Curve", "Model Selection", "Confusion matrix", "Post-tuning the decision threshold for cost-sensitive learning", "Visualizing cross-validation behavior in scikit-learn", "Plotting Cross-Validated Predictions", "Detection error tradeoff (DET) curve", "Custom refit strategy of a grid search with cross-validation", "Balance model complexity and cross-validated score", "Statistical comparison of models using grid search", "Sample pipeline for text feature extraction and evaluation", "Plotting Learning Curves and Checking Models\u2019 Scalability", "Class Likelihood Ratios to measure classification performance", "Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV", "Nested versus non-nested cross-validation", "Test with permutations the significance of a classification score", "Precision-Recall", "Comparing randomized search and grid search for hyperparameter estimation", "Multiclass Receiver Operating Characteristic (ROC)", "Receiver Operating Characteristic (ROC) with cross validation", "Comparison between grid search and successive halving", "Successive Halving Iterations", "Train error vs Test error", "Post-hoc tuning the cut-off point of decision function", "Underfitting vs. Overfitting", "Plotting Validation Curves", "Multiclass methods", "Overview of multiclass training meta-estimators", "Multioutput methods", "Multilabel classification using a classifier chain", "Approximate nearest neighbors in TSNE", "Nearest Neighbors", "Caching nearest neighbors", "Nearest Neighbors Classification", "Kernel Density Estimation", "Simple 1D Kernel Density Estimation", "Novelty detection with Local Outlier Factor (LOF)", "Outlier detection with Local Outlier Factor (LOF)", "Comparing Nearest Neighbors with and without Neighborhood Components Analysis", "Dimensionality Reduction with Neighborhood Components Analysis", "Neighborhood Components Analysis Illustration", "Nearest Centroid Classification", "Nearest Neighbors regression", "Kernel Density Estimate of Species Distributions", "Neural Networks", "Varying regularization in Multi-layer Perceptron", "Compare Stochastic learning strategies for MLPClassifier", "Visualization of MLP weights on MNIST", "Restricted Boltzmann Machine features for digit classification", "Preprocessing", "Compare the effect of different scalers on data with outliers", "Using KBinsDiscretizer to discretize continuous features", "Feature discretization", "Demonstrating the different strategies of KBinsDiscretizer", "Map data to a normal distribution", "Importance of Feature Scaling", "Comparing Target Encoder with Other Encoders", "Target Encoder\u2019s Internal Cross fitting", "Release Highlights", "Release Highlights for scikit-learn 0.22", "Release Highlights for scikit-learn 0.23", "Release Highlights for scikit-learn 0.24", "Release Highlights for scikit-learn 1.0", "Release Highlights for scikit-learn 1.1", "Release Highlights for scikit-learn 1.2", "Release Highlights for scikit-learn 1.3", "Release Highlights for scikit-learn 1.4", "Release Highlights for scikit-learn 1.5", "Semi Supervised Classification", "Label Propagation digits: Demonstrating performance", "Label Propagation digits active learning", "Label Propagation learning a complex structure", "Effect of varying threshold for self-training", "Semi-supervised Classification on a Text Dataset", "Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset", "Support Vector Machines", "SVM with custom kernel", "Plot different SVM classifiers in the iris dataset", "Plot the support vectors in LinearSVC", "One-class SVM with non-linear kernel (RBF)", "RBF SVM parameters", "SVM: Maximum margin separating hyperplane", "SVM: Separating hyperplane for unbalanced classes", "SVM-Anova: SVM with univariate feature selection", "Plot classification boundaries with different SVM Kernels", "SVM Margins Example", "Support Vector Regression (SVR) using linear and non-linear kernels", "Scaling the regularization parameter for SVCs", "SVM Tie Breaking Example", "SVM: Weighted samples", "Working with text documents", "Classification of text documents using sparse features", "Clustering text documents using k-means", "FeatureHasher and DictVectorizer Comparison", "Decision Trees", "Post pruning decision trees with cost complexity pruning", "Plot the decision surface of decision trees trained on the iris dataset", "Decision Tree Regression", "Multi-output Decision Tree Regression", "Understanding the decision tree structure", "<span class=\"section-number\">10. </span>Common pitfalls and recommended practices", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">8. </span>Computing with scikit-learn", "<span class=\"section-number\">8.2. </span>Computational Performance", "<span class=\"section-number\">8.3. </span>Parallelism, resource management, and configuration", "<span class=\"section-number\">8.1. </span>Strategies to scale computationally: bigger data", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">6. </span>Dataset transformations", "<span class=\"section-number\">7. </span>Dataset loading utilities", "<span class=\"section-number\">7.4. </span>Loading other datasets", "<span class=\"section-number\">7.2. </span>Real world datasets", "<span class=\"section-number\">7.3. </span>Generated datasets", "<span class=\"section-number\">7.1. </span>Toy datasets", "Installing the development version of scikit-learn", "Bug triaging and issue curation", "Contributing", "Cython Best Practices, Conventions and Knowledge", "Developing scikit-learn estimators", "Developer\u2019s Guide", "Maintainer/Core-Developer Information", "Crafting a minimal reproducer for scikit-learn", "How to optimize for speed", "Developing with the Plotting API", "Developers\u2019 Tips and Tricks", "Utilities for Developers", "<span class=\"section-number\">11. </span>Dispatching", "&lt;no title&gt;", "Frequently Asked Questions", "Getting Started", "Glossary of Common Terms and API Elements", "Scikit-learn governance and decision-making", "Index", "<span class=\"section-number\">4. </span>Inspection", "Installing scikit-learn", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">1. </span>Metadata Routing", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">9. </span>Model persistence", "<span class=\"section-number\">3. </span>Model selection and evaluation", "<span class=\"section-number\">11.1. </span>Array API support (experimental)", "<span class=\"section-number\">2.4. </span>Biclustering", "<span class=\"section-number\">1.16. </span>Probability calibration", "<span class=\"section-number\">3.3. </span>Tuning the decision threshold for class prediction", "<span class=\"section-number\">2.3. </span>Clustering", "<span class=\"section-number\">6.1. </span>Pipelines and composite estimators", "<span class=\"section-number\">2.6. </span>Covariance estimation", "<span class=\"section-number\">1.8. </span>Cross decomposition", "<span class=\"section-number\">3.1. </span>Cross-validation: evaluating estimator performance", "<span class=\"section-number\">2.5. </span>Decomposing signals in components (matrix factorization problems)", "<span class=\"section-number\">2.8. </span>Density Estimation", "<span class=\"section-number\">1.11. </span>Ensembles: Gradient boosting, random forests, bagging, voting, stacking", "<span class=\"section-number\">6.2. </span>Feature extraction", "<span class=\"section-number\">1.13. </span>Feature selection", "<span class=\"section-number\">1.7. </span>Gaussian Processes", "dbscan", "fastica", "oas", "BaseEstimator", "BiclusterMixin", "ClassNamePrefixFeaturesOutMixin", "ClassifierMixin", "ClusterMixin", "DensityMixin", "MetaEstimatorMixin", "OneToOneFeatureMixin", "OutlierMixin", "RegressorMixin", "TransformerMixin", "clone", "is_classifier", "is_clusterer", "is_regressor", "CalibratedClassifierCV", "CalibrationDisplay", "calibration_curve", "AffinityPropagation", "AgglomerativeClustering", "Birch", "BisectingKMeans", "DBSCAN", "FeatureAgglomeration", "HDBSCAN", "KMeans", "MeanShift", "MiniBatchKMeans", "OPTICS", "SpectralBiclustering", "SpectralClustering", "SpectralCoclustering", "affinity_propagation", "cluster_optics_dbscan", "cluster_optics_xi", "compute_optics_graph", "estimate_bandwidth", "k_means", "kmeans_plusplus", "mean_shift", "spectral_clustering", "ward_tree", "ColumnTransformer", "TransformedTargetRegressor", "make_column_selector", "make_column_transformer", "config_context", "EllipticEnvelope", "EmpiricalCovariance", "GraphicalLasso", "GraphicalLassoCV", "LedoitWolf", "MinCovDet", "OAS", "ShrunkCovariance", "empirical_covariance", "graphical_lasso", "ledoit_wolf", "ledoit_wolf_shrinkage", "shrunk_covariance", "CCA", "PLSCanonical", "PLSRegression", "PLSSVD", "clear_data_home", "dump_svmlight_file", "fetch_20newsgroups", "fetch_20newsgroups_vectorized", "fetch_california_housing", "fetch_covtype", "fetch_kddcup99", "fetch_lfw_pairs", "fetch_lfw_people", "fetch_olivetti_faces", "fetch_openml", "fetch_rcv1", "fetch_species_distributions", "get_data_home", "load_breast_cancer", "load_diabetes", "load_digits", "load_files", "load_iris", "load_linnerud", "load_sample_image", "load_sample_images", "load_svmlight_file", "load_svmlight_files", "load_wine", "make_biclusters", "make_blobs", "make_checkerboard", "make_circles", "make_classification", "make_friedman1", "make_friedman2", "make_friedman3", "make_gaussian_quantiles", "make_hastie_10_2", "make_low_rank_matrix", "make_moons", "make_multilabel_classification", "make_regression", "make_s_curve", "make_sparse_coded_signal", "make_sparse_spd_matrix", "make_sparse_uncorrelated", "make_spd_matrix", "make_swiss_roll", "DictionaryLearning", "FactorAnalysis", "FastICA", "IncrementalPCA", "KernelPCA", "LatentDirichletAllocation", "MiniBatchDictionaryLearning", "MiniBatchNMF", "MiniBatchSparsePCA", "NMF", "PCA", "SparseCoder", "SparsePCA", "TruncatedSVD", "dict_learning", "dict_learning_online", "non_negative_factorization", "sparse_encode", "LinearDiscriminantAnalysis", "QuadraticDiscriminantAnalysis", "DummyClassifier", "DummyRegressor", "AdaBoostClassifier", "AdaBoostRegressor", "BaggingClassifier", "BaggingRegressor", "ExtraTreesClassifier", "ExtraTreesRegressor", "GradientBoostingClassifier", "GradientBoostingRegressor", "HistGradientBoostingClassifier", "HistGradientBoostingRegressor", "IsolationForest", "RandomForestClassifier", "RandomForestRegressor", "RandomTreesEmbedding", "StackingClassifier", "StackingRegressor", "VotingClassifier", "VotingRegressor", "ConvergenceWarning", "DataConversionWarning", "DataDimensionalityWarning", "EfficiencyWarning", "FitFailedWarning", "InconsistentVersionWarning", "NotFittedError", "UndefinedMetricWarning", "enable_halving_search_cv", "enable_iterative_imputer", "DictVectorizer", "FeatureHasher", "PatchExtractor", "extract_patches_2d", "grid_to_graph", "img_to_graph", "reconstruct_from_patches_2d", "CountVectorizer", "HashingVectorizer", "TfidfTransformer", "TfidfVectorizer", "GenericUnivariateSelect", "RFE", "RFECV", "SelectFdr", "SelectFpr", "SelectFromModel", "SelectFwe", "SelectKBest", "SelectPercentile", "SelectorMixin", "SequentialFeatureSelector", "VarianceThreshold", "chi2", "f_classif", "f_regression", "mutual_info_classif", "mutual_info_regression", "r_regression", "GaussianProcessClassifier", "GaussianProcessRegressor", "CompoundKernel", "ConstantKernel", "DotProduct", "ExpSineSquared", "Exponentiation", "Hyperparameter", "Kernel", "Matern", "PairwiseKernel", "Product", "RBF", "RationalQuadratic", "Sum", "WhiteKernel", "get_config", "IterativeImputer", "KNNImputer", "MissingIndicator", "SimpleImputer", "DecisionBoundaryDisplay", "PartialDependenceDisplay", "partial_dependence", "permutation_importance", "IsotonicRegression", "check_increasing", "isotonic_regression", "AdditiveChi2Sampler", "Nystroem", "PolynomialCountSketch", "RBFSampler", "SkewedChi2Sampler", "KernelRidge", "ARDRegression", "BayesianRidge", "ElasticNet", "ElasticNetCV", "GammaRegressor", "HuberRegressor", "Lars", "LarsCV", "Lasso", "LassoCV", "LassoLars", "LassoLarsCV", "LassoLarsIC", "LinearRegression", "LogisticRegression", "LogisticRegressionCV", "MultiTaskElasticNet", "MultiTaskElasticNetCV", "MultiTaskLasso", "MultiTaskLassoCV", "OrthogonalMatchingPursuit", "OrthogonalMatchingPursuitCV", "PassiveAggressiveClassifier", "PassiveAggressiveRegressor", "Perceptron", "PoissonRegressor", "QuantileRegressor", "RANSACRegressor", "Ridge", "RidgeCV", "RidgeClassifier", "RidgeClassifierCV", "SGDClassifier", "SGDOneClassSVM", "SGDRegressor", "TheilSenRegressor", "TweedieRegressor", "enet_path", "lars_path", "lars_path_gram", "lasso_path", "orthogonal_mp", "orthogonal_mp_gram", "ridge_regression", "Isomap", "LocallyLinearEmbedding", "MDS", "SpectralEmbedding", "TSNE", "locally_linear_embedding", "smacof", "spectral_embedding", "trustworthiness", "ConfusionMatrixDisplay", "DetCurveDisplay", "DistanceMetric", "PrecisionRecallDisplay", "PredictionErrorDisplay", "RocCurveDisplay", "accuracy_score", "adjusted_mutual_info_score", "adjusted_rand_score", "auc", "average_precision_score", "balanced_accuracy_score", "brier_score_loss", "calinski_harabasz_score", "check_scoring", "class_likelihood_ratios", "classification_report", "contingency_matrix", "pair_confusion_matrix", "cohen_kappa_score", "completeness_score", "confusion_matrix", "consensus_score", "coverage_error", "d2_absolute_error_score", "d2_log_loss_score", "d2_pinball_score", "d2_tweedie_score", "davies_bouldin_score", "dcg_score", "det_curve", "explained_variance_score", "f1_score", "fbeta_score", "fowlkes_mallows_score", "get_scorer", "get_scorer_names", "hamming_loss", "hinge_loss", "homogeneity_completeness_v_measure", "homogeneity_score", "jaccard_score", "label_ranking_average_precision_score", "label_ranking_loss", "log_loss", "make_scorer", "matthews_corrcoef", "max_error", "mean_absolute_error", "mean_absolute_percentage_error", "mean_gamma_deviance", "mean_pinball_loss", "mean_poisson_deviance", "mean_squared_error", "mean_squared_log_error", "mean_tweedie_deviance", "median_absolute_error", "multilabel_confusion_matrix", "mutual_info_score", "ndcg_score", "normalized_mutual_info_score", "additive_chi2_kernel", "chi2_kernel", "cosine_distances", "cosine_similarity", "distance_metrics", "euclidean_distances", "haversine_distances", "kernel_metrics", "laplacian_kernel", "linear_kernel", "manhattan_distances", "nan_euclidean_distances", "paired_cosine_distances", "paired_distances", "paired_euclidean_distances", "paired_manhattan_distances", "pairwise_kernels", "polynomial_kernel", "rbf_kernel", "sigmoid_kernel", "pairwise_distances", "pairwise_distances_argmin", "pairwise_distances_argmin_min", "pairwise_distances_chunked", "precision_recall_curve", "precision_recall_fscore_support", "precision_score", "r2_score", "rand_score", "recall_score", "roc_auc_score", "roc_curve", "root_mean_squared_error", "root_mean_squared_log_error", "silhouette_samples", "silhouette_score", "top_k_accuracy_score", "v_measure_score", "zero_one_loss", "BayesianGaussianMixture", "GaussianMixture", "FixedThresholdClassifier", "GridSearchCV", "GroupKFold", "GroupShuffleSplit", "HalvingGridSearchCV", "HalvingRandomSearchCV", "KFold", "LearningCurveDisplay", "LeaveOneGroupOut", "LeaveOneOut", "LeavePGroupsOut", "LeavePOut", "ParameterGrid", "ParameterSampler", "PredefinedSplit", "RandomizedSearchCV", "RepeatedKFold", "RepeatedStratifiedKFold", "ShuffleSplit", "StratifiedGroupKFold", "StratifiedKFold", "StratifiedShuffleSplit", "TimeSeriesSplit", "TunedThresholdClassifierCV", "ValidationCurveDisplay", "check_cv", "cross_val_predict", "cross_val_score", "cross_validate", "learning_curve", "permutation_test_score", "train_test_split", "validation_curve", "OneVsOneClassifier", "OneVsRestClassifier", "OutputCodeClassifier", "ClassifierChain", "MultiOutputClassifier", "MultiOutputRegressor", "RegressorChain", "BernoulliNB", "CategoricalNB", "ComplementNB", "GaussianNB", "MultinomialNB", "BallTree", "KDTree", "KNeighborsClassifier", "KNeighborsRegressor", "KNeighborsTransformer", "KernelDensity", "LocalOutlierFactor", "NearestCentroid", "NearestNeighbors", "NeighborhoodComponentsAnalysis", "RadiusNeighborsClassifier", "RadiusNeighborsRegressor", "RadiusNeighborsTransformer", "kneighbors_graph", "radius_neighbors_graph", "sort_graph_by_row_values", "BernoulliRBM", "MLPClassifier", "MLPRegressor", "FeatureUnion", "Pipeline", "make_pipeline", "make_union", "Binarizer", "FunctionTransformer", "KBinsDiscretizer", "KernelCenterer", "LabelBinarizer", "LabelEncoder", "MaxAbsScaler", "MinMaxScaler", "MultiLabelBinarizer", "Normalizer", "OneHotEncoder", "OrdinalEncoder", "PolynomialFeatures", "PowerTransformer", "QuantileTransformer", "RobustScaler", "SplineTransformer", "StandardScaler", "TargetEncoder", "add_dummy_feature", "binarize", "label_binarize", "maxabs_scale", "minmax_scale", "normalize", "power_transform", "quantile_transform", "robust_scale", "scale", "GaussianRandomProjection", "SparseRandomProjection", "johnson_lindenstrauss_min_dim", "LabelPropagation", "LabelSpreading", "SelfTrainingClassifier", "set_config", "show_versions", "LinearSVC", "LinearSVR", "NuSVC", "NuSVR", "OneClassSVM", "SVC", "SVR", "l1_min_c", "DecisionTreeClassifier", "DecisionTreeRegressor", "ExtraTreeClassifier", "ExtraTreeRegressor", "export_graphviz", "export_text", "plot_tree", "Bunch", "_safe_indexing", "min_pos", "as_float_array", "assert_all_finite", "check_X_y", "check_array", "check_consistent_length", "check_random_state", "check_scalar", "compute_class_weight", "compute_sample_weight", "deprecated", "all_displays", "all_estimators", "all_functions", "check_estimator", "parametrize_with_checks", "estimator_html_repr", "density", "fast_logdet", "randomized_range_finder", "randomized_svd", "safe_sparse_dot", "weighted_mode", "gen_batches", "gen_even_slices", "single_source_shortest_path_length", "indexable", "MetadataRequest", "MetadataRouter", "MethodMapping", "get_routing_for_object", "process_routing", "available_if", "is_multilabel", "type_of_target", "unique_labels", "murmurhash3_32", "Parallel", "delayed", "parallel_backend", "sample_without_replacement", "register_parallel_backend", "resample", "safe_mask", "safe_sqr", "shuffle", "incr_mean_variance_axis", "inplace_column_scale", "inplace_csr_column_scale", "inplace_row_scale", "inplace_swap_column", "inplace_swap_row", "mean_variance_axis", "inplace_csr_row_normalize_l1", "inplace_csr_row_normalize_l2", "check_is_fitted", "check_memory", "check_symmetric", "column_or_1d", "has_fit_parameter", "<span class=\"section-number\">3.2. </span>Tuning the hyper-parameters of an estimator", "<span class=\"section-number\">6.4. </span>Imputation of missing values", "<span class=\"section-number\">1.15. </span>Isotonic regression", "<span class=\"section-number\">6.7. </span>Kernel Approximation", "<span class=\"section-number\">1.3. </span>Kernel ridge regression", "<span class=\"section-number\">1.2. </span>Linear and Quadratic Discriminant Analysis", "<span class=\"section-number\">3.5. </span>Validation curves: plotting scores to evaluate models", "<span class=\"section-number\">1.1. </span>Linear Models", "<span class=\"section-number\">2.2. </span>Manifold learning", "<span class=\"section-number\">6.8. </span>Pairwise metrics, Affinities and Kernels", "<span class=\"section-number\">2.1. </span>Gaussian mixture models", "<span class=\"section-number\">3.4. </span>Metrics and scoring: quantifying the quality of predictions", "<span class=\"section-number\">1.12. </span>Multiclass and multioutput algorithms", "<span class=\"section-number\">1.9. </span>Naive Bayes", "<span class=\"section-number\">1.6. </span>Nearest Neighbors", "<span class=\"section-number\">1.17. </span>Neural network models (supervised)", "<span class=\"section-number\">2.9. </span>Neural network models (unsupervised)", "<span class=\"section-number\">2.7. </span>Novelty and Outlier Detection", "<span class=\"section-number\">4.1. </span>Partial Dependence and Individual Conditional Expectation plots", "<span class=\"section-number\">4.2. </span>Permutation feature importance", "&lt;no title&gt;", "<span class=\"section-number\">6.3. </span>Preprocessing data", "<span class=\"section-number\">6.9. </span>Transforming the prediction target (<code class=\"docutils literal notranslate\"><span class=\"pre\">y</span></code>)", "<span class=\"section-number\">6.6. </span>Random Projection", "<span class=\"section-number\">1.14. </span>Semi-supervised learning", "<span class=\"section-number\">1.5. </span>Stochastic Gradient Descent", "<span class=\"section-number\">1.4. </span>Support Vector Machines", "<span class=\"section-number\">1.10. </span>Decision Trees", "<span class=\"section-number\">6.5. </span>Unsupervised dimensionality reduction", "External Resources, Videos and Talks", "Related Projects", "Roadmap", "Computation times", "<span class=\"section-number\">1. </span>Supervised learning", "Support", "Testimonials", "An introduction to machine learning with scikit-learn", "scikit-learn Tutorials", "Choosing the right estimator", "A tutorial on statistical-learning for scientific data processing", "Model selection: choosing estimators and their parameters", "Putting it all together", "Statistical learning: the setting and the estimator object in scikit-learn", "Supervised learning: predicting an output variable from high-dimensional observations", "Unsupervised learning: seeking representations of the data", "Working With Text Data", "<span class=\"section-number\">2. </span>Unsupervised learning", "User Guide", "Available documentation for scikit-learn", "<span class=\"section-number\">5. </span>Visualizations", "Release History", "&lt;no title&gt;", "Older Versions", "Version 0.13", "Version 0.14", "Version 0.15", "Version 0.16", "Version 0.17", "Version 0.18", "Version 0.19", "Version 0.20", "Version 0.21", "Version 0.22", "Version 0.23", "Version 0.24", "Version 1.0", "Version 1.1", "Version 1.2", "Version 1.3", "Version 1.4", "Version 1.5", "Version 1.6"], "titleterms": {"": [194, 324, 326, 389, 398, 423, 1000], "0": [188, 328, 329, 330, 331, 1016, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "1": [193, 217, 331, 332, 333, 334, 335, 336, 398, 1034, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "10": [102, 1041], "11": 1041, "12": 1041, "13": 1042, "14": 1043, "15": 1044, "16": 1045, "17": 1046, "18": 1047, "19": 1048, "1d": 304, "2": [217, 333, 1034, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058], "20": [104, 360, 381, 1034, 1049], "2018": 1020, "20newgroup": 235, "21": 1050, "22": [328, 1051], "23": [329, 1052], "24": [330, 1053], "2d": [51, 87, 127, 133, 193], "3": [63, 203, 334, 1034, 1049, 1050, 1055, 1057], "3d": 193, "4": [335, 1041, 1049, 1058], "5": [336, 1016, 1041, 1059], "6": [1041, 1060], "7": 1041, "8": 1041, "9": 1041, "99": 381, "A": [52, 58, 59, 82, 93, 98, 220, 331, 385, 392, 420, 1028, 1031], "And": [244, 401], "In": 285, "NOT": 391, "One": [212, 234, 287, 331, 348, 420, 1006, 1014], "The": [0, 118, 120, 121, 191, 192, 220, 245, 251, 272, 276, 285, 292, 296, 381, 390, 394, 420, 424, 999, 1000, 1012, 1032, 1033], "Will": 398, "With": [258, 1034], "__sklearn_is_fitted__": 137, "_safe_index": 928, "abil": 182, "ablat": 257, "about": [0, 192, 398], "absolut": 1000, "access": 417, "accuraci": [194, 252, 360, 364, 1000], "accuracy_scor": 711, "across": 369, "action": 386, "activ": 339, "ad": 416, "adaboost": [139, 140, 141, 423], "adaboostclassifi": [139, 561], "adaboostregressor": 562, "add": [335, 398], "add_dummy_featur": 894, "addit": [423, 992], "additive_chi2_kernel": 766, "additivechi2sampl": 646, "address": 272, "adjac": 55, "adjust": 72, "adjusted_mutual_info_scor": 712, "adjusted_rand_scor": 713, "advanc": 258, "advantag": 416, "affin": [51, 73, 416, 998], "affinity_propag": 462, "affinitypropag": 448, "agglom": [74, 75, 87, 1033], "agglomer": [86, 89, 1017, 1033], "agglomerativeclust": 449, "aggress": [989, 996], "aic": [209, 996], "algebra": [373, 395], "algorithm": [57, 58, 59, 73, 79, 84, 90, 98, 99, 100, 240, 247, 392, 398, 994, 996, 1001, 1003, 1004, 1008, 1016, 1032], "alias": 394, "align": 997, "all": [278, 287, 332, 404, 1030, 1056, 1057, 1058], "all_displai": 940, "all_estim": 941, "all_funct": 942, "alloc": [54, 421], "alpha": [165, 364], "alpin": 404, "alreadi": 55, "also": 390, "altern": [384, 989], "am": [149, 257], "amount": [290, 989], "an": [82, 94, 137, 188, 201, 209, 309, 328, 332, 398, 424, 989, 1006, 1025, 1031, 1032], "anaconda": 404, "analysi": [43, 64, 69, 70, 95, 125, 132, 135, 139, 152, 193, 204, 263, 280, 281, 288, 307, 308, 309, 360, 419, 421, 994, 1003, 1017, 1033, 1034], "analyz": [52, 989], "angl": [209, 996], "ani": 398, "anomali": 247, "anova": [171, 352], "api": [2, 41, 137, 260, 261, 328, 331, 333, 374, 388, 393, 400, 407, 412, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1051, 1058, 1059, 1060], "appli": 165, "applic": [424, 1033], "approach": [111, 209, 278], "approxim": [189, 196, 197, 252, 299, 330, 418, 992], "ar": [102, 272, 331, 398], "arch": 404, "architectur": 1020, "ard": [204, 996], "ardregress": 652, "arff": 380, "argument": [331, 388, 1052, 1054], "arm64": 394, "arrai": [41, 333, 336, 368, 395, 412, 1025, 1058, 1059, 1060], "artifact": 410, "artwork": 0, "as_float_arrai": 930, "ask": 398, "assert": 388, "assert_all_finit": 931, "assign": 416, "assumpt": 92, "atom": [49, 373], "attent": 398, "attribut": [388, 400, 412, 989], "auc": [328, 714], "author": 1041, "automat": [204, 399, 996], "auxiliari": 41, "avail": [332, 989, 1037, 1038], "available_if": 961, "averag": [285, 287, 416, 423, 1000], "average_precision_scor": 715, "avoid": [369, 417], "aweb": 1024, "ax": 393, "b": 117, "backend": 394, "backward": 386, "bag": [142, 151, 360, 423, 424, 989, 1034], "baggingclassifi": 563, "baggingregressor": 564, "balanc": [277, 1000], "balanced_accuracy_scor": 716, "ball": 1003, "balltre": [852, 1003], "base": [4, 41, 42, 43, 117, 146, 147, 174, 189, 204, 253, 328, 329, 331, 333, 334, 335, 386, 416, 420, 423, 425, 996, 1008, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1060], "baseestim": [388, 430], "baselin": [197, 220], "basi": [44, 185, 426, 992, 996, 1032], "basic": [183, 238, 399, 418, 426], "batch": [416, 421], "bay": [61, 62, 1002], "bayesian": [25, 199, 200, 263, 278, 996, 999], "bayesiangaussianmixtur": 805, "bayesianridg": 653, "befor": [188, 390], "behavior": 273, "behind": 0, "being": 192, "benchmark": [46, 49, 93, 360], "bernoulli": [1002, 1005], "bernoullinb": 847, "bernoullirbm": 868, "best": [268, 387, 398], "bestofmedia": 1024, "beta": 421, "betawork": 1024, "between": [99, 289, 996], "bia": 142, "bic": [209, 268, 996], "biclust": [27, 56, 57, 58, 189, 382, 413], "biclustermixin": 431, "bigger": 375, "bike": [43, 52, 193], "bin": 1010, "binar": [875, 895, 1010, 1011], "binari": [285, 298, 336, 996, 1000], "birch": [77, 416, 450], "birchbox": 1024, "bisect": [78, 416], "bisectingkmean": [332, 451], "blind": 126, "bnp": 1024, "boil": 391, "boltzmann": [317, 1005], "bonu": 165, "book": 1024, "boost": [43, 145, 149, 150, 151, 152, 153, 154, 155, 193, 220, 328, 329, 331, 333, 334, 423], "bouldin": 416, "bound": 251, "boundari": [156, 161, 302, 343, 353], "branch": 394, "break": 357, "breast": [195, 383], "brier": 1000, "brier_score_loss": 717, "brute": [989, 1003], "bug": [385, 386, 390, 1023, 1044, 1045, 1046, 1047, 1048, 1049, 1050], "build": [181, 188, 384, 386, 394, 417, 1034, 1059], "bulk": [49, 373], "bunch": [398, 927], "busi": 272, "c": 392, "c4": 1016, "c5": 1016, "cach": [106, 301, 417], "calcul": [150, 162], "calibr": [5, 60, 61, 62, 63, 64, 152, 189, 220, 414, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "calibratedclassifiercv": 445, "calibration_curv": 447, "calibrationdisplai": 446, "california": 381, "calinski": 416, "calinski_harabasz_scor": 718, "call": [369, 385], "callgrind": 392, "can": [165, 398], "cancer": [195, 383], "candid": [290, 989], "canon": [117, 419], "card": 272, "cardif": 1024, "cardiotocographi": 257, "cart": 1016, "case": [356, 996, 1000], "cast": 1025, "categor": [149, 325, 330, 335, 398, 423, 1002, 1010], "categori": [43, 332, 334, 1010], "categoricalnb": 848, "caus": 404, "causal": [191, 192], "cautiou": 192, "cca": [117, 490], "center": [125, 1010], "central": 55, "centroid": [310, 1003], "chain": [107, 259, 298, 399, 417], "chanc": 72, "chang": [254, 386, 401, 1024, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "changelog": [1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "characterist": [287, 288, 1000], "check": [192, 280, 328, 394, 412, 1049, 1050, 1051], "check_arrai": 933, "check_consistent_length": 934, "check_cv": 832, "check_estim": 943, "check_increas": 644, "check_is_fit": [388, 984], "check_memori": 985, "check_random_st": 935, "check_scalar": 936, "check_scor": 719, "check_symmetr": 986, "check_x_i": 932, "checker": 41, "checklist": [386, 390], "chi": [992, 998], "chi2": 612, "chi2_kernel": 767, "choic": 421, "choos": [46, 989, 1025, 1027, 1029], "ci": 386, "circl": 101, "cite": 0, "claim": [220, 238], "class": [41, 63, 72, 139, 141, 162, 203, 229, 234, 281, 285, 287, 331, 348, 351, 400, 415, 420, 423, 424, 1000, 1003, 1006, 1014, 1015, 1041, 1042], "class_likelihood_ratio": 720, "classic": 25, "classif": [27, 47, 63, 65, 66, 68, 69, 104, 122, 166, 177, 178, 179, 180, 184, 189, 236, 255, 281, 284, 285, 288, 298, 302, 310, 317, 328, 337, 342, 353, 360, 382, 426, 996, 1000, 1001, 1003, 1004, 1014, 1015, 1016, 1032, 1034], "classifi": [25, 41, 61, 62, 64, 67, 137, 163, 203, 259, 275, 292, 298, 302, 328, 336, 343, 346, 349, 360, 368, 414, 423, 994, 1003, 1032, 1034], "classification_report": 721, "classifierchain": [843, 1001], "classifiermixin": 433, "classnameprefixfeaturesoutmixin": 432, "clear": 1051, "clear_data_hom": 494, "cli": 1034, "clone": [388, 441], "close": 385, "cloud": 127, "cloudpickl": 410, "cluster": [6, 27, 51, 57, 59, 71, 72, 73, 74, 75, 76, 79, 80, 82, 84, 87, 90, 91, 93, 95, 98, 99, 100, 101, 102, 125, 189, 332, 334, 361, 382, 413, 416, 421, 1000, 1033, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "cluster_optics_dbscan": 463, "cluster_optics_xi": 464, "clustermixin": 434, "co": [57, 59, 413], "co2": 181, "code": [46, 125, 134, 386, 388, 391, 392, 394, 421, 1045, 1046, 1047, 1048, 1049], "coeffici": [174, 192, 199, 224, 225, 416, 1000], "cohen": 1000, "cohen_kappa_scor": 724, "coin": [81, 82], "color": 83, "column": [104, 105, 259], "column_or_1d": 987, "columntransform": [336, 417, 472], "com": 1024, "combin": [160, 248], "comment": 391, "committe": 401, "common": [192, 369, 400, 412, 424, 1000], "commun": [0, 386], "compact": 249, "compar": [63, 77, 79, 97, 111, 117, 145, 159, 170, 197, 199, 206, 222, 227, 247, 253, 278, 286, 307, 315, 319, 325, 398], "comparison": [64, 67, 70, 78, 99, 113, 133, 149, 150, 169, 176, 240, 241, 253, 278, 289, 296, 362, 996], "compat": [41, 328, 386, 388, 412], "compil": [384, 392], "complement": 1002, "complementnb": 849, "complet": [256, 416], "completeness_scor": 725, "complex": [46, 249, 259, 277, 280, 340, 364, 373, 996, 1003, 1004, 1014, 1015, 1016], "compon": [118, 125, 307, 308, 309, 421, 1003, 1017, 1033], "compos": [7, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "composit": [103, 189, 417, 989], "compoundkernel": 620, "compress": [53, 88, 373], "comput": [41, 55, 73, 82, 84, 98, 99, 102, 111, 145, 213, 225, 291, 372, 373, 417, 420, 1007, 1021], "computation": 375, "compute_class_weight": 937, "compute_optics_graph": 465, "compute_sample_weight": 938, "concaten": 108, "concentr": 263, "concept": [400, 996], "conclud": [43, 244], "conclus": [46, 52, 176, 204, 209, 296, 302, 326, 353], "conda": 384, "condit": [193, 330, 1007], "confid": 152, "config_context": 476, "configur": [373, 374], "confus": [271, 416, 1000], "confusion_matrix": 726, "confusionmatrixdisplai": [248, 705], "connect": [416, 424, 1033], "consensu": 996, "consensus_scor": 727, "consider": [272, 381], "constant": [220, 272, 990], "constantkernel": 621, "constrain": 1033, "constraint": [155, 157, 333, 335, 416, 423], "construct": 253, "consum": 254, "content": [398, 1025], "conting": 416, "contingency_matrix": 722, "continu": [320, 386], "contribut": [386, 398], "contributor": [0, 385, 386, 401, 1045, 1046, 1047, 1048, 1049], "control": [369, 423, 1004], "convent": [387, 1025], "converg": 139, "convergencewarn": 579, "convex": 230, "cookbook": 185, "coordin": 209, "core": [0, 47, 375, 385, 390, 392, 398, 401, 1002], "corpu": 424, "correl": [192, 195, 419, 1000, 1008], "cosin": 998, "cosine_dist": 768, "cosine_similar": 769, "cost": [272, 364, 1016], "countvector": 596, "covari": [8, 70, 110, 111, 113, 114, 115, 189, 265, 418, 994, 1049, 1053, 1054, 1055, 1057, 1058], "coverag": [386, 394, 1000], "coverage_error": 728, "covertyp": [257, 381], "craft": 391, "crash": 398, "creat": [104, 132, 139, 224, 248, 285, 326, 352, 353, 398], "credit": 272, "criteria": [208, 398, 996, 1016], "criterion": [209, 330, 989, 1014], "cross": [43, 116, 117, 165, 173, 189, 209, 272, 273, 274, 276, 277, 281, 283, 288, 326, 352, 369, 415, 419, 420, 989, 996, 1029], "cross_decomposit": [9, 1051, 1053, 1055, 1057, 1059], "cross_val_predict": 833, "cross_val_scor": [282, 834], "cross_valid": [420, 835], "cubic": 200, "cumul": 1000, "curat": 385, "curs": 1032, "curv": [62, 64, 200, 253, 260, 269, 275, 280, 285, 287, 294, 414, 995], "custom": [137, 276, 336, 345, 424, 1010, 1015], "cut": [272, 292], "cv": [273, 369], "cv_results_": 989, "cython": [387, 392, 394], "d": [420, 1003], "d2_absolute_error_scor": 729, "d2_log_loss_scor": 730, "d2_pinball_scor": 731, "d2_tweedie_scor": 732, "data": [43, 46, 48, 51, 55, 58, 61, 63, 70, 73, 82, 84, 85, 90, 92, 93, 98, 99, 101, 102, 104, 109, 111, 113, 115, 117, 118, 126, 127, 130, 131, 132, 140, 146, 147, 150, 153, 155, 156, 160, 170, 173, 174, 182, 184, 188, 191, 194, 195, 197, 200, 206, 213, 214, 224, 248, 253, 260, 268, 273, 275, 279, 284, 285, 287, 288, 291, 302, 306, 311, 317, 319, 323, 324, 325, 335, 338, 349, 352, 355, 356, 361, 362, 369, 373, 375, 381, 391, 398, 400, 416, 417, 420, 425, 1010, 1014, 1024, 1025, 1028, 1031, 1033, 1034], "dataconversionwarn": 580, "datadimensionalitywarn": 581, "datafram": [328, 335, 398, 1058], "dataiku": 1024, "datarobot": 1024, "dataset": [10, 42, 43, 44, 47, 52, 61, 62, 64, 68, 79, 93, 97, 104, 117, 119, 120, 121, 122, 123, 125, 133, 139, 145, 148, 149, 160, 165, 176, 178, 180, 181, 183, 185, 189, 191, 192, 193, 199, 202, 204, 209, 220, 222, 229, 238, 240, 241, 247, 252, 257, 258, 272, 276, 284, 285, 292, 296, 298, 326, 342, 343, 346, 353, 360, 365, 378, 379, 380, 381, 382, 383, 391, 398, 426, 1025, 1031, 1032, 1034, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "davi": 416, "davies_bouldin_scor": 733, "dbscan": [84, 416, 427, 452], "dbscan_clust": 90, "dcg_score": 734, "deal": [41, 398], "debian": 404, "debug": 394, "debugg": 392, "decis": [139, 140, 148, 156, 161, 189, 252, 272, 292, 302, 334, 336, 343, 353, 363, 364, 365, 366, 367, 368, 398, 401, 415, 1016], "decisionboundarydisplai": 639, "decisiontre": 140, "decisiontreeclassifi": 920, "decisiontreeregressor": [330, 921], "decod": 424, "decompos": 421, "decomposit": [11, 116, 117, 124, 125, 142, 189, 382, 419, 421, 1033, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "decreas": [146, 147, 194], "deep": 398, "default": [254, 306, 386], "defin": [72, 82, 93, 102, 240, 273, 275, 276, 362, 1000], "definit": [238, 317, 1007, 1051], "deflat": 117, "delai": 967, "demand": [43, 52], "demo": [58, 59, 73, 82, 84, 90, 93, 98, 100], "demonstr": [92, 282, 322, 338], "dendrogram": 76, "denois": [44, 128], "dens": 206, "densiti": [267, 303, 304, 312, 334, 422, 946, 1015], "densitymixin": 435, "depend": [193, 254, 258, 384, 1007, 1041, 1054, 1055], "deploi": 398, "deploy": 404, "deprec": [1, 254, 386, 939, 1051], "descent": [209, 228, 234, 996, 1014], "descript": 191, "design": 181, "det": [275, 1000], "det_curv": 735, "detail": [992, 1014, 1015], "detcurvedisplai": 706, "detect": [48, 247, 257, 275, 305, 306, 1000, 1006, 1015], "determin": [114, 204, 418, 996, 1000], "develop": [0, 136, 137, 189, 254, 384, 387, 388, 389, 390, 393, 394, 395, 989, 1036, 1057], "devianc": [153, 1000], "devic": 412, "diabet": [165, 258, 292, 383, 1032], "diagnost": 383, "dict": 424, "dict_learn": 553, "dict_learning_onlin": 554, "dictionari": [85, 125, 128, 134, 421], "dictionarylearn": 539, "dictvector": [362, 589], "did": 398, "diff": 394, "differ": [75, 79, 97, 111, 185, 193, 319, 322, 325, 346, 353, 388, 398, 407, 416, 996, 1032], "digit": [68, 87, 93, 120, 166, 241, 317, 338, 339, 383, 1031], "dimension": [106, 240, 243, 259, 308, 324, 361, 994, 997, 1003, 1017, 1032], "direct": 237, "directli": 398, "dirichlet": [54, 421, 999], "discount": 1000, "discov": 41, "discret": [156, 184, 320, 321, 1010], "discrimin": [69, 70, 994], "discriminant_analysi": [12, 1049, 1050, 1053, 1055, 1056, 1057], "discuss": 385, "disk": 55, "dispatch": 396, "displai": [128, 225, 248, 249, 259, 333, 334, 335, 394, 1038, 1057], "distanc": [27, 113, 336], "distance_metr": 770, "distancemetr": 707, "distort": 128, "distribut": [50, 238, 240, 312, 323, 381, 404, 997, 1010], "diverg": 421, "divid": 332, "do": [391, 398], "document": [0, 47, 57, 189, 330, 331, 359, 360, 361, 386, 1019, 1020, 1023, 1037, 1041, 1044, 1045, 1048, 1049], "doe": 398, "domain": 1019, "donat": 0, "dot": [185, 426], "dotproduct": 622, "down": 391, "download": [55, 160, 188, 380], "drawback": 416, "drop": [149, 1060], "dtype": 335, "dummi": [13, 1000, 1049, 1050, 1051, 1054, 1055, 1059], "dummyclassifi": 559, "dummyregressor": 560, "dump_svmlight_fil": 495, "dure": 369, "d\u00b2": 1000, "each": [285, 290, 360, 989], "earli": [150, 155, 228], "earlier": 1041, "eas": 387, "effect": [109, 155, 191, 245, 319, 324, 341, 364], "effici": [333, 335, 395], "efficiencywarn": 582, "eigenfac": [45, 125, 1030], "eigenmap": 997, "eigenvector": 55, "elast": [201, 205, 996], "elasticnet": [204, 329, 654], "elasticnetcv": 655, "element": 400, "elimin": [172, 173, 425, 989], "ellipsoid": [70, 264], "ellipt": 1006, "ellipticenvelop": 477, "embed": [51, 87, 240, 241, 251, 309, 423, 997], "emeritu": 0, "empir": [96, 114, 251, 418], "empirical_covari": 485, "empiricalcovari": 478, "enable_halving_search_cv": 587, "enable_iterative_imput": 588, "encod": [88, 149, 325, 326, 334, 1010, 1011], "enet_path": 689, "enforc": [1052, 1054], "engin": [43, 52, 194, 1019, 1024], "enhanc": [333, 401, 1019, 1044, 1045, 1046, 1047, 1048], "enrich": 335, "ensembl": [14, 138, 144, 148, 189, 423, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "enthought": 404, "entir": 398, "entri": 1013, "envelop": 1006, "environ": [374, 410], "equival": 278, "error": [139, 143, 150, 152, 165, 199, 224, 275, 291, 394, 404, 996, 1000], "establish": [99, 197], "estim": [41, 103, 110, 111, 112, 113, 114, 115, 136, 137, 142, 149, 151, 159, 182, 188, 189, 199, 223, 226, 249, 254, 256, 257, 267, 286, 296, 303, 304, 312, 328, 329, 330, 333, 335, 369, 388, 398, 399, 400, 412, 417, 418, 420, 422, 423, 989, 990, 994, 996, 1000, 1015, 1019, 1027, 1029, 1031, 1042, 1049, 1050, 1051], "estimate_bandwidth": 466, "estimator_html_repr": 945, "euclidean_dist": 771, "evalu": [52, 72, 93, 96, 114, 220, 257, 272, 279, 282, 317, 325, 361, 399, 411, 413, 416, 420, 423, 989, 995, 1000, 1034], "evernot": 1024, "exact": 421, "exampl": [42, 45, 48, 88, 94, 109, 119, 131, 137, 156, 183, 189, 216, 217, 224, 354, 357, 375, 391, 398, 407, 412, 415, 424, 426, 430, 433, 436, 439, 440, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 466, 468, 470, 472, 473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 484, 485, 487, 490, 491, 492, 496, 497, 498, 499, 500, 502, 503, 504, 506, 507, 508, 509, 510, 512, 514, 518, 519, 520, 521, 522, 523, 527, 528, 529, 530, 531, 532, 533, 534, 535, 538, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 592, 595, 596, 597, 598, 599, 601, 602, 605, 607, 608, 610, 612, 613, 614, 615, 616, 618, 619, 621, 622, 623, 625, 626, 627, 630, 631, 633, 635, 636, 638, 639, 640, 641, 642, 643, 647, 648, 649, 651, 652, 653, 654, 655, 656, 657, 660, 661, 663, 664, 665, 666, 667, 670, 672, 673, 674, 676, 677, 678, 679, 680, 681, 682, 684, 685, 686, 687, 688, 689, 690, 692, 696, 697, 698, 699, 700, 701, 705, 706, 708, 709, 710, 711, 712, 713, 714, 715, 717, 720, 721, 725, 726, 727, 735, 737, 740, 742, 743, 745, 746, 749, 750, 753, 754, 756, 757, 758, 760, 761, 763, 765, 769, 786, 787, 790, 792, 793, 794, 795, 796, 797, 798, 800, 801, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 845, 847, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 865, 868, 869, 870, 871, 872, 873, 876, 877, 879, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 898, 901, 905, 906, 908, 909, 910, 912, 915, 916, 917, 918, 919, 920, 921, 926, 927, 935, 944, 946, 953, 957, 958, 959, 960, 961, 974, 984, 1025, 1031, 1033, 1041], "except": [15, 395, 1053, 1057], "execut": [369, 398], "exercis": [164, 165, 166, 167, 189, 1029, 1032, 1034], "exhaust": 989, "exist": 386, "exp": [185, 426], "expans": 199, "expect": [193, 330, 1007], "experi": [0, 72, 385], "experiment": [16, 333, 390, 412, 1057], "explain": 1000, "explained_variance_scor": 736, "explicit": 252, "explor": 43, "exponenti": 624, "export": [40, 398], "export_graphviz": 924, "export_text": 925, "expsinesquar": 623, "extend": 996, "extens": [392, 404], "extern": [380, 1018, 1025, 1041, 1050], "extract": [54, 108, 128, 238, 279, 361, 373, 375, 424, 1034], "extract_patches_2d": 592, "extrapol": 181, "extratreeclassifi": 922, "extratreeregressor": 923, "extratreesclassifi": 565, "extratreesregressor": 566, "extrem": [391, 423], "f": [169, 1000], "f1": 285, "f1_score": 737, "f_classif": 613, "f_regress": 614, "fa": [125, 132], "face": [45, 85, 125, 256, 381, 1024, 1030], "factor": [54, 125, 132, 135, 305, 306, 421, 1006], "factoranalysi": 540, "fail": 391, "failur": [191, 989], "fast_logdet": 947, "faster": [333, 423], "fastica": [125, 126, 127, 428, 541], "fbeta_scor": 738, "featur": [43, 52, 86, 89, 108, 130, 144, 146, 147, 149, 153, 155, 157, 158, 168, 170, 172, 173, 174, 189, 194, 195, 197, 199, 214, 217, 238, 252, 258, 279, 317, 320, 321, 324, 325, 328, 330, 331, 352, 360, 361, 373, 375, 386, 390, 407, 417, 423, 424, 425, 990, 1008, 1010, 1017, 1033, 1034, 1044, 1045, 1046, 1047, 1048], "feature_extract": [17, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "feature_select": [18, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "featureagglomer": [416, 453], "featurehash": [362, 590], "featureunion": [417, 871], "fedora": 404, "fetch_20newsgroup": 496, "fetch_20newsgroups_vector": 497, "fetch_california_h": 498, "fetch_covtyp": 499, "fetch_kddcup99": 500, "fetch_lfw_pair": 501, "fetch_lfw_peopl": 502, "fetch_olivetti_fac": 503, "fetch_openml": [333, 504], "fetch_rcv1": 505, "fetch_species_distribut": 506, "file": [55, 404, 424, 1034], "final": [92, 176], "find": 1003, "first": [48, 72], "fit": [29, 58, 63, 92, 126, 132, 146, 147, 152, 153, 181, 199, 200, 201, 214, 217, 222, 226, 285, 298, 306, 311, 326, 355, 369, 388, 399, 407, 412, 423, 1002, 1006, 1025], "fitfailedwarn": 583, "fix": [72, 390, 1041, 1044, 1045, 1046, 1047, 1048, 1054], "fixedthresholdclassifi": [336, 807], "flag": 394, "flexibl": [331, 990], "fold": [394, 420], "footprint": 88, "forc": [989, 1003], "forecast": [52, 181], "forest": [143, 145, 146, 147, 159, 194, 195, 257, 260, 335, 381, 423, 1006], "forg": 384, "format": [380, 391, 398, 1001], "formul": [413, 423, 994, 1003, 1014, 1015, 1016], "four": 101, "fowlk": 416, "fowlkes_mallows_scor": 739, "framework": 1019, "free": 183, "freebsd": 384, "freez": 398, "french": 220, "frequenc": [238, 1034], "frequent": 398, "frequentist": 278, "frobeniu": 421, "from": [17, 51, 128, 174, 194, 325, 328, 374, 380, 384, 398, 424, 1000, 1025, 1032, 1033, 1034, 1051], "fruit": 385, "fulli": 191, "function": [41, 49, 70, 185, 210, 224, 225, 230, 241, 273, 291, 292, 330, 352, 362, 395, 420, 423, 426, 992, 996, 1000, 1015, 1032, 1058], "functiontransform": 876, "fund": 0, "futur": 398, "futurewarn": 1051, "gain": [272, 1000], "galleri": [430, 433, 436, 439, 440, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 466, 468, 470, 472, 473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 484, 485, 487, 490, 491, 492, 496, 497, 498, 499, 500, 502, 503, 504, 506, 507, 508, 509, 510, 512, 514, 518, 519, 520, 521, 522, 523, 527, 528, 529, 530, 531, 532, 533, 534, 535, 538, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 557, 558, 559, 560, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 589, 590, 592, 595, 596, 597, 598, 599, 601, 602, 605, 607, 608, 610, 612, 613, 614, 615, 616, 618, 619, 621, 622, 623, 625, 626, 627, 630, 631, 633, 635, 636, 638, 639, 640, 641, 642, 643, 647, 648, 649, 651, 652, 653, 654, 655, 656, 657, 660, 661, 663, 664, 665, 666, 667, 670, 672, 673, 674, 676, 677, 678, 679, 680, 681, 682, 684, 685, 686, 687, 688, 689, 690, 692, 696, 697, 698, 699, 700, 701, 705, 706, 708, 709, 710, 711, 712, 713, 714, 715, 717, 720, 721, 725, 726, 727, 735, 737, 740, 742, 743, 745, 746, 749, 750, 753, 754, 756, 757, 758, 760, 761, 763, 765, 769, 786, 787, 790, 792, 793, 794, 795, 796, 797, 798, 800, 801, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 845, 847, 849, 850, 851, 854, 855, 856, 857, 858, 859, 860, 861, 865, 868, 869, 870, 871, 872, 873, 876, 877, 879, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 896, 898, 901, 905, 906, 908, 909, 910, 912, 915, 916, 917, 918, 919, 920, 921, 926, 927, 935, 944, 946, 953, 957, 958, 959, 960, 961, 974, 984], "gamma": [238, 334, 1000], "gammaregressor": 656, "gaussian": [61, 62, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 189, 262, 263, 264, 267, 268, 269, 319, 426, 999, 1002, 1010, 1012], "gaussian_process": [19, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "gaussianmixtur": 806, "gaussiannb": 850, "gaussianprocessclassifi": 618, "gaussianprocessregressor": 619, "gaussianrandomproject": 904, "gdb": 392, "gen_batch": 952, "gen_even_slic": 953, "gener": [10, 25, 52, 58, 61, 70, 73, 82, 84, 90, 92, 98, 99, 101, 102, 111, 113, 115, 122, 123, 126, 127, 128, 146, 156, 170, 173, 176, 182, 183, 185, 189, 198, 199, 200, 204, 214, 220, 222, 253, 268, 275, 291, 306, 311, 317, 329, 338, 355, 356, 369, 382, 386, 400, 421, 423, 996, 1010, 1020, 1029], "genericunivariateselect": 600, "german": 272, "get": [369, 398, 399], "get_config": 634, "get_data_hom": 507, "get_feature_names_out": 332, "get_param": 388, "get_routing_for_object": 959, "get_scor": 740, "get_scorer_nam": 741, "git": 386, "github": 386, "gitter": 1023, "glm": 25, "glossari": 400, "gmm": [265, 266], "goal": 1020, "good": [386, 391], "govern": [0, 401], "gpc": [177, 178, 179, 180, 426], "gperftool": 392, "gpr": [181, 182, 426], "gprof": 392, "gpu": 398, "gradient": [43, 145, 149, 150, 151, 152, 153, 154, 155, 193, 220, 228, 234, 328, 329, 331, 333, 334, 423, 996, 1014], "gradientboostingclassifi": [423, 567], "gradientboostingregressor": [423, 568], "gram": 201, "graph": [41, 51, 328, 395, 398, 416, 424], "graphic": [398, 1005], "graphical_lasso": 486, "graphicallasso": 479, "graphicallassocv": 480, "greek": 81, "grid": [259, 276, 278, 286, 289, 989, 1029, 1034], "grid_to_graph": 593, "gridsearchcv": [106, 165, 282, 808], "ground": [72, 199], "group": [332, 334, 420, 1024, 1033], "groupkfold": 809, "groupshufflesplit": 810, "grow": 72, "guid": [389, 1036], "guidelin": [386, 388], "halv": [289, 290, 330, 989], "halvinggridsearchcv": 811, "halvingrandomsearchcv": 812, "ham": 1000, "hamming_loss": 742, "hand": 68, "handl": [41, 195, 990], "handwritten": [93, 241, 383], "harabasz": 416, "hard": 423, "has_fit_paramet": 988, "hash": [158, 395, 424], "hashingvector": [361, 597], "haversine_dist": 772, "hdbscan": [90, 334, 416, 454], "help": [385, 398], "helper": [49, 185, 241, 395], "here": [368, 1034], "hessian": 997, "heterogen": [104, 417], "hierarch": [76, 82, 97, 102, 334, 416, 1033], "hierarchi": 416, "high": 1032, "higher": 374, "highlight": [189, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 1041, 1044, 1045, 1048, 1049], "hing": 1000, "hinge_loss": 743, "histgradientboost": [330, 335], "histgradientboostingclassifi": [423, 569], "histgradientboostingregressor": [332, 570], "histogram": [145, 155, 329, 331, 333, 422, 423], "histori": [0, 1039], "hmm": 398, "hoc": 292, "hole": 244, "home": 278, "homebrew": 384, "homogen": 416, "homogeneity_completeness_v_measur": 744, "homogeneity_scor": 745, "hot": 149, "hour": 52, "hourli": 191, "hous": [149, 257, 381], "how": [165, 369, 386, 392, 398], "howaboutw": 1024, "html": [249, 388], "huber": 996, "huberregressor": [202, 657], "hug": 1024, "hyper": [29, 152, 276, 330, 989], "hyperparamet": [90, 181, 182, 279, 286, 296, 625], "hyperplan": [232, 350, 351], "i": [336, 368, 391, 398, 420, 1024], "ic": [193, 1007], "ica": [126, 421, 1033], "id3": 1016, "identif": 1034, "idf": 424, "illustr": [106, 180, 185, 309, 426], "imag": [17, 44, 82, 85, 88, 101, 128, 380, 398, 424], "img_to_graph": 594, "impact": [43, 96, 1056, 1057, 1058, 1059], "implement": [137, 206, 398, 1000, 1003, 1014, 1015], "import": [146, 147, 153, 174, 194, 195, 252, 296, 324, 328, 415, 423, 1008], "improv": [329, 330, 331, 332, 333, 335, 336, 385, 386, 1044, 1045], "impur": [146, 147, 194, 364, 1008], "imput": [20, 186, 187, 188, 189, 328, 336, 990, 1010, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "includ": 398, "inclus": 398, "incom": 191, "inconsist": 369, "inconsistentversionwarn": 584, "incr_mean_variance_axi": 975, "increment": [129, 375, 421], "incrementalpca": 542, "independ": [125, 421, 1033], "index": [416, 955], "indic": 273, "individu": [163, 193, 330, 1007], "induct": 91, "infer": 191, "influenc": [46, 49, 373], "infonea": 1024, "inform": [169, 188, 208, 209, 390, 416, 989, 996], "infrastructur": 0, "infrequ": [332, 334, 1010], "init": 388, "initi": [94, 96, 266], "inplace_column_scal": 976, "inplace_csr_column_scal": 977, "inplace_csr_row_normalize_l1": 982, "inplace_csr_row_normalize_l2": 983, "inplace_row_scal": 978, "inplace_swap_column": 979, "inplace_swap_row": 980, "input": [41, 373, 388, 412, 416, 1010], "inria": 1024, "inspect": [21, 189, 190, 403, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "instal": [384, 404], "instanc": [369, 375], "instanti": 388, "instead": 272, "instruct": 384, "insur": 238, "integr": 386, "intel": 404, "interact": [43, 193, 333, 423], "interfac": [27, 407], "intern": [326, 415], "internet": 51, "interoper": 1019, "interpol": 221, "interpret": [181, 192, 224, 257, 298, 421, 423], "interv": 152, "introduc": 261, "introduct": [997, 1025], "introductori": 183, "invari": [90, 281], "invers": [115, 418, 1012], "inverse_transform": 1033, "io": 410, "iri": [121, 131, 133, 148, 178, 229, 343, 346, 365, 383, 426, 1031], "iris": 1032, "is_classifi": 442, "is_cluster": 443, "is_multilabel": 962, "is_regressor": 444, "iso": [179, 285], "isol": 1006, "isolationforest": [156, 571], "isomap": [240, 241, 696, 997], "isoton": [22, 250, 414, 991, 1049, 1050, 1051, 1053, 1055, 1056], "isotonic_regress": 645, "isotonicregress": 643, "issu": [385, 386], "iter": [188, 290, 420, 989], "iterativeimput": [187, 635, 990], "j": 1024, "jaccard": 1000, "jaccard_scor": 746, "job": 398, "joblib": [374, 392, 410], "johnson": [251, 1012], "johnson_lindenstrauss_min_dim": 906, "joint": 214, "k": [78, 80, 83, 92, 93, 94, 96, 99, 102, 117, 302, 324, 361, 416, 420, 1000, 1003, 1010, 1032, 1033], "k_mean": 467, "kappa": 1000, "kbinsdiscret": [320, 322, 877], "kcachegrind": 392, "kddcup": 381, "kddcup99": 257, "kdtree": [853, 1003], "keep": 990, "kei": 410, "kernel": [19, 43, 44, 130, 176, 181, 182, 184, 185, 189, 196, 197, 252, 253, 303, 304, 312, 330, 345, 348, 353, 355, 421, 422, 426, 626, 992, 993, 998, 1010, 1015, 1032], "kernel_approxim": [23, 1051, 1053, 1054, 1055, 1056, 1057], "kernel_metr": 773, "kernel_ridg": [24, 1058], "kernelcenter": 878, "kerneldens": 857, "kernelpca": [130, 543], "kernelridg": 651, "keyword": [331, 1052, 1054], "kfold": 813, "kmean": [95, 99, 329, 455], "kmeans_plusplu": 468, "kneighbors_graph": 865, "kneighborsclassifi": 854, "kneighborsregressor": 855, "kneighborstransform": 856, "knn": [188, 328], "knnimput": 636, "knowledg": 387, "known": [390, 1049, 1050], "kpca": 421, "l": 200, "l1": [53, 204, 211, 213, 236, 356, 425], "l1_min_c": 919, "l2": [224, 356], "label": [41, 72, 285, 338, 339, 340, 381, 382, 416, 420, 423, 1000, 1011, 1013], "label_binar": 896, "label_ranking_average_precision_scor": 747, "label_ranking_loss": 748, "labelbinar": [879, 1011], "labelencod": 880, "labelpropag": 907, "labelspread": 908, "lag": 52, "languag": 1034, "laplacian": 998, "laplacian_kernel": 774, "lar": [207, 658, 996], "larg": 424, "lars_path": 690, "lars_path_gram": 691, "larscv": 659, "lasso": [53, 204, 205, 206, 207, 208, 209, 214, 329, 660, 996], "lasso_path": 692, "lassocv": 661, "lassolar": 662, "lassolars": 664, "lassolarscv": 663, "latenc": [49, 373], "latent": [54, 117, 421], "latentdirichletalloc": 544, "latest": 404, "layer": [193, 314, 1004], "lda": [70, 133, 421, 994], "leakag": 369, "learn": [0, 41, 44, 51, 85, 125, 128, 175, 189, 191, 192, 193, 197, 239, 240, 241, 242, 253, 254, 272, 273, 280, 309, 315, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 372, 373, 375, 382, 384, 386, 387, 388, 390, 391, 398, 401, 404, 421, 423, 995, 997, 1005, 1013, 1019, 1020, 1022, 1024, 1025, 1026, 1028, 1031, 1032, 1033, 1034, 1035, 1037], "learner": [139, 423], "learning_curv": 836, "learningcurvedisplai": 814, "least": [118, 152, 209, 215, 218, 996], "leav": [364, 420, 996], "leaveonegroupout": 815, "leaveoneout": 816, "leavepgroupsout": 817, "leavepout": 818, "ledoit": [69, 112, 418], "ledoit_wolf": 487, "ledoit_wolf_shrinkag": 488, "ledoitwolf": [111, 481], "lemma": 1012, "length": [156, 404], "lesson": [191, 192], "level": [181, 182, 374, 416, 423], "liabil": 220, "librari": [373, 374], "libsvm": 380, "likelihood": [111, 199, 200, 281, 1000, 1005], "limit": [149, 176, 373, 404, 410, 424], "lindenstrauss": [251, 1012], "line": [165, 179], "linear": [25, 43, 62, 69, 70, 152, 176, 189, 192, 198, 199, 216, 220, 223, 226, 240, 241, 252, 329, 348, 353, 355, 373, 395, 398, 994, 996, 997, 998, 1010, 1032], "linear_kernel": 775, "linear_model": [25, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "lineardiscriminantanalysi": [333, 557], "linearregress": [222, 665], "linearsvc": [347, 912], "linearsvr": 913, "link": [373, 1000], "linkag": [97, 416], "linnerrud": 383, "linux": [384, 398, 404], "list": [72, 1023], "loa": 181, "load": [44, 46, 55, 85, 93, 121, 145, 147, 149, 153, 165, 174, 194, 213, 238, 241, 248, 252, 260, 279, 287, 288, 298, 302, 324, 325, 349, 352, 360, 361, 362, 379, 380, 391, 398, 424, 1025, 1033, 1034], "load_breast_canc": 508, "load_diabet": 509, "load_digit": 510, "load_fil": 511, "load_iri": 512, "load_linnerud": 513, "load_sample_imag": [514, 515], "load_svmlight_fil": [516, 517], "load_win": 518, "loader": 10, "local": [240, 241, 305, 306, 997, 1006], "locally_linear_embed": 701, "locallylinearembed": 697, "localoutlierfactor": 858, "lof": [305, 306], "log": [199, 200, 1000], "log_loss": 749, "logarithm": 1000, "logist": [107, 203, 210, 211, 212, 213, 235, 236, 996, 1032], "logisticregress": [298, 666], "logisticregressioncv": 667, "loo": 420, "look": [52, 253, 355], "loss": [155, 220, 230, 329, 332, 334, 423, 1000, 1058], "lot": 398, "love": 1024, "low": [416, 423, 425], "lower": 374, "lpo": 420, "lsa": 361, "mac": 404, "machin": [175, 189, 191, 192, 193, 317, 344, 394, 1005, 1015, 1025, 1032], "machinali": 1024, "maco": 384, "macport": 404, "macro": 287, "mahalanobi": 113, "mail": 1023, "main": [47, 220], "maintain": [0, 386, 390, 410], "major": [390, 423, 1049, 1050], "make": [160, 163, 188, 386, 390, 401], "make_biclust": 519, "make_blob": [391, 520], "make_checkerboard": 521, "make_circl": 522, "make_classif": [391, 523], "make_column_selector": 474, "make_column_transform": 475, "make_friedman1": 524, "make_friedman2": 525, "make_friedman3": 526, "make_gaussian_quantil": 527, "make_hastie_10_2": 528, "make_low_rank_matrix": 529, "make_moon": 530, "make_multilabel_classif": 531, "make_pipelin": 873, "make_regress": [391, 532], "make_s_curv": 533, "make_scor": 750, "make_sparse_coded_sign": 534, "make_sparse_spd_matrix": 535, "make_sparse_uncorrel": 536, "make_spd_matrix": 537, "make_swiss_rol": 538, "make_union": 874, "mallow": 416, "manag": [374, 404], "manhattan_dist": 776, "mani": [273, 333, 374, 398, 1058, 1059], "manifold": [26, 189, 239, 240, 241, 242, 382, 997, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "manual": [272, 415], "map": [252, 323, 1010], "mar": 1024, "margin": [199, 200, 232, 350, 354], "mark": 990, "markdown": 391, "market": [51, 1030], "match": [219, 996], "matern": 627, "mathemat": [41, 413, 423, 992, 994, 1003, 1007, 1014, 1015, 1016], "matric": [41, 395, 1010], "matrix": [54, 55, 184, 201, 271, 416, 421, 1000], "matter": 192, "matthew": 1000, "matthews_corrcoef": 751, "mat\u00e9rn": [185, 426], "max": [111, 1000], "max_error": 752, "maxabs_scal": 897, "maxabsscal": [319, 881], "maximum": [232, 350, 1005], "md": [698, 997], "mdi": [147, 194], "mean": [78, 80, 83, 92, 93, 94, 96, 98, 99, 146, 147, 188, 194, 224, 361, 416, 1000, 1010, 1033], "mean_absolute_error": 753, "mean_absolute_percentage_error": 754, "mean_gamma_devi": 755, "mean_pinball_loss": 756, "mean_poisson_devi": 757, "mean_shift": 469, "mean_squared_error": 758, "mean_squared_log_error": 759, "mean_tweedie_devi": 760, "mean_variance_axi": 981, "meanshift": [98, 456], "measur": [160, 281, 416, 1000], "media": 1023, "median": [996, 1000], "median_absolute_error": 761, "member": 385, "memori": [88, 335, 373, 392, 394], "merg": 390, "meson": [394, 1059], "messag": 278, "meta": [41, 159, 254, 296, 330, 423], "metadata": [41, 254, 334, 335, 360, 400, 407, 1058, 1059, 1060], "metadatarequest": 956, "metadatarout": 957, "metaestimatormixin": 436, "method": [97, 108, 117, 138, 176, 189, 240, 242, 266, 295, 297, 400, 416, 992, 1006, 1007, 1033], "methodmap": 958, "metric": [27, 72, 75, 152, 272, 282, 412, 416, 420, 989, 998, 1000, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "micro": [285, 287], "min_cluster_s": 90, "min_po": 929, "min_resourc": 989, "min_sampl": 90, "mincovdet": 482, "mini": [416, 421], "minibatchdictionarylearn": 545, "minibatchkmean": [77, 99, 125, 457], "minibatchnmf": [332, 546], "minibatchsparsepca": [125, 421, 547], "minim": [391, 1016, 1054, 1055], "minimum": [114, 418], "minmax_scal": 898, "minmaxscal": [319, 882], "minor": 390, "misc": 1041, "miscellan": [25, 189, 246, 1049, 1050, 1051, 1052, 1053, 1054, 1057], "mislead": 1008, "miss": [155, 186, 187, 188, 189, 328, 334, 335, 423, 990, 1010, 1016], "missingind": 637, "mix": 105, "mixin": 388, "mixtur": [28, 189, 262, 263, 264, 267, 268, 269, 999, 1049, 1050, 1054, 1055, 1057, 1059], "mlp": 316, "mlpclassifi": [315, 869], "mlpregressor": 870, "mnist": [236, 316], "mode": [117, 373], "model": [25, 27, 29, 43, 46, 50, 52, 92, 109, 117, 126, 132, 145, 146, 147, 149, 150, 153, 156, 173, 174, 176, 181, 189, 192, 193, 194, 197, 198, 199, 204, 208, 209, 214, 220, 223, 238, 248, 253, 257, 258, 262, 264, 268, 269, 270, 272, 277, 278, 280, 285, 298, 306, 311, 317, 324, 329, 331, 335, 353, 355, 360, 373, 388, 398, 399, 401, 410, 411, 420, 989, 995, 996, 999, 1000, 1002, 1004, 1005, 1025, 1029, 1032, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "model_select": [29, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "modifi": 997, "modul": [1041, 1049, 1050, 1056, 1057, 1058, 1059], "mona": 181, "monitor": 386, "monoton": [155, 157, 335, 423], "more": [331, 398, 1004], "morgan": 1024, "most": 338, "motor": 220, "movi": 1034, "mp": 412, "much": 165, "multi": [25, 90, 139, 159, 193, 214, 229, 243, 256, 282, 285, 314, 367, 392, 996, 997, 1000, 1004, 1015, 1016], "multiclass": [30, 41, 189, 235, 287, 295, 296, 328, 395, 414, 1000, 1001, 1025, 1032, 1050, 1053, 1054, 1055], "multicollinear": 195, "multidimension": 240, "multilabel": [27, 123, 255, 298, 382, 395, 1000, 1001, 1025], "multilabel_confusion_matrix": 762, "multilabelbinar": [883, 1011], "multinomi": [212, 236, 996, 1002], "multinomialnb": 851, "multioutput": [31, 189, 297, 1001, 1049, 1050, 1051, 1052, 1053, 1056, 1057, 1058, 1059], "multioutputclassifi": [844, 1001], "multioutputregressor": [845, 1001], "multipl": [108, 259, 282, 369, 393, 420, 989, 990, 1000, 1049, 1050], "multitaskelasticnet": 668, "multitaskelasticnetcv": 669, "multitasklasso": 670, "multitasklassocv": 671, "multivari": [117, 990], "murmurhash3_32": 965, "mutual": [169, 416], "mutual_info_classif": 615, "mutual_info_regress": 616, "mutual_info_scor": 763, "my": 398, "n_featur": 49, "n_job": 398, "naiv": [43, 52, 61, 62, 1002], "naive_bay": [32, 1049, 1051, 1052, 1053, 1054, 1056, 1057], "name": [157, 331, 398, 417], "nan": 990, "nan_euclidean_dist": 777, "nativ": [149, 325, 328, 330, 335], "ndcg_score": 764, "nearest": [102, 189, 299, 300, 301, 302, 307, 310, 311, 328, 990, 1003, 1032], "nearestcentroid": 859, "nearestneighbor": 860, "necessari": 391, "need": 398, "neg": [54, 125, 174, 215, 421, 996], "neighbor": [33, 102, 189, 240, 299, 300, 301, 302, 307, 311, 324, 328, 990, 997, 1003, 1032, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "neighborhood": [307, 308, 309, 1003], "neighborhoodcomponentsanalysi": 861, "nest": [283, 417, 1029], "net": [201, 205, 996], "netbsd": 404, "network": [189, 193, 313, 1004, 1005], "neural": [189, 193, 313, 1004, 1005], "neural_network": [34, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "new": [328, 330, 331, 333, 334, 386, 398, 1018, 1041, 1042, 1044, 1045, 1046, 1047, 1048], "newsgroup": [104, 360, 381, 1034], "next": [52, 399], "nightli": 384, "nmf": [125, 332, 421, 548], "nnmf": 421, "nois": [182, 183, 200], "noisi": [128, 183, 224], "non": [43, 54, 125, 152, 215, 220, 224, 240, 283, 336, 348, 355, 421, 996, 1010], "non_negative_factor": 555, "none": 369, "norm": 421, "normal": [69, 197, 220, 319, 323, 884, 899, 1000, 1010], "normalized_mutual_info_scor": 765, "note": [375, 412, 415, 420], "notfittederror": 585, "novelti": [305, 1006, 1015], "now": [328, 331, 1051], "number": [72, 95, 149, 155, 173, 290, 373, 388, 989, 990], "numer": [192, 336, 374, 388], "numpi": [374, 391], "nusvc": 914, "nusvr": 915, "nystroem": [647, 992], "oa": [69, 111, 112, 429, 483], "object": [41, 248, 273, 388, 398, 989, 1000, 1031, 1038], "observ": [191, 1032, 1033], "obtain": [398, 420], "occurr": 1034, "off": [272, 292, 996], "offici": 1060, "okcupid": 1024, "older": 1041, "olivetti": 381, "omp": 996, "one": [118, 149, 258, 996, 1000], "oneclasssvm": 916, "onehotencod": [332, 885], "onetoonefeaturemixin": 437, "onevsoneclassifi": [840, 1001], "onevsrestclassifi": [298, 841, 1001], "onli": [217, 237, 1052, 1054], "onlin": [85, 227, 331, 332, 1014], "onnx": 410, "oob": 143, "open": 1030, "openml": [44, 325, 328, 380], "openmp": [374, 387], "oper": [41, 287, 288, 385, 395, 426, 1000], "optic": [100, 383, 416, 458], "optim": [29, 41, 392, 989], "optimis": 182, "option": [388, 415], "oracl": 418, "ordin": 149, "ordinalencod": [334, 886], "ordinari": [218, 996], "org": [380, 390, 1024], "origin": [88, 130, 284, 309, 319], "orthogon": [219, 996], "orthogonal_mp": 693, "orthogonal_mp_gram": 694, "orthogonalmatchingpursuit": 672, "orthogonalmatchingpursuitcv": 673, "osx": [398, 404], "other": [325, 380, 398, 423, 1019, 1041], "otto": 1024, "our": [93, 273, 276, 292, 386], "out": [47, 151, 375, 394, 420, 989, 996, 1002], "outdat": 394, "outlier": [25, 48, 202, 237, 247, 257, 305, 306, 319, 996, 1006, 1010], "outliermixin": 438, "outlin": 1008, "output": [159, 256, 319, 333, 335, 367, 1016, 1032], "outputcodeclassifi": [842, 1001], "over": 259, "overfit": 293, "overhead": 373, "oversubscript": 374, "overview": [296, 393, 410, 416, 1006], "ovo": 287, "ovr": 287, "own": [388, 398, 1000], "p": [420, 1024], "packag": [252, 1019, 1053], "pair": 416, "pair_confusion_matrix": 723, "paired_cosine_dist": 778, "paired_dist": 779, "paired_euclidean_dist": 780, "paired_manhattan_dist": 781, "pairwis": [27, 43, 278, 336, 998], "pairwise_dist": 786, "pairwise_distances_argmin": 787, "pairwise_distances_argmin_min": 788, "pairwise_distances_chunk": 789, "pairwise_kernel": 782, "pairwisekernel": 628, "panda": [333, 391, 398], "parallel": [41, 147, 374, 392, 416, 423, 966, 989], "parallel_backend": 968, "paramet": [29, 41, 46, 111, 152, 276, 330, 349, 356, 386, 388, 399, 400, 417, 423, 989, 996, 1000, 1015, 1025, 1029, 1034], "parametergrid": 819, "parametersampl": 820, "parametr": 1005, "parametrize_with_check": 944, "pariba": 1024, "paristech": 1024, "pariti": 99, "parser": [333, 380], "part": [85, 425], "parti": [220, 254, 404], "partial": [118, 191, 193, 258, 1007], "partial_depend": 641, "partialdependencedisplai": 640, "partit": 197, "passiv": 996, "passiveaggressiveclassifi": 674, "passiveaggressiveregressor": 675, "past": 0, "patch": [128, 424], "patchextractor": 591, "path": [156, 207, 213, 225, 368, 404], "pattern": 135, "pca": [44, 93, 107, 121, 125, 126, 129, 130, 131, 132, 133, 324, 335, 336, 421, 549, 1017, 1033], "pdp": 193, "peerindex": 1024, "penalti": [211, 231, 356], "peopl": [0, 398, 1041, 1042, 1043, 1044], "per": 361, "percentag": 1000, "percentil": 352, "perceptron": [193, 314, 676, 996, 1004], "perform": [72, 78, 281, 324, 330, 332, 336, 338, 361, 373, 386, 387, 416, 420, 1034], "period": [43, 221], "permiss": 398, "permut": [146, 194, 195, 284, 328, 420, 1008], "permutation_import": 642, "permutation_test_scor": 837, "perplex": 245, "persist": 410, "phimeca": 1024, "pickl": 410, "pictur": 81, "pinbal": 1000, "pipelin": [35, 103, 104, 106, 107, 160, 171, 189, 192, 249, 254, 259, 279, 325, 352, 388, 398, 399, 417, 425, 872, 1017, 1030, 1034, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059], "pitfal": [192, 369], "pixel": 147, "pl": 117, "plai": 352, "plan": 398, "plant": 383, "platform": [384, 394, 404], "plot": [21, 27, 40, 46, 47, 49, 58, 61, 66, 70, 73, 76, 82, 84, 85, 92, 98, 99, 101, 102, 111, 115, 117, 121, 122, 123, 126, 127, 140, 145, 148, 153, 156, 160, 161, 162, 163, 165, 173, 188, 193, 199, 200, 204, 212, 213, 214, 224, 225, 229, 241, 248, 252, 257, 258, 260, 268, 274, 275, 280, 282, 285, 287, 291, 294, 298, 306, 317, 325, 328, 330, 331, 338, 346, 347, 352, 353, 360, 365, 393, 995, 1007, 1038], "plot_tre": 926, "pls1": 117, "pls2": 117, "plscanon": [419, 491], "plsregress": [419, 492], "plssvd": [419, 493], "point": [127, 272, 292, 309, 410], "poisson": [220, 238, 329, 330, 1000], "poissonregressor": 677, "polar": [52, 335], "polynomi": [43, 197, 199, 200, 221, 353, 992, 996, 998, 1010, 1032], "polynomial_kernel": 783, "polynomialcountsketch": [330, 648], "polynomialfeatur": 887, "posit": [125, 331], "possibl": [92, 391], "post": [29, 272, 281, 292, 364, 415], "post1": 1051, "posterior": 185, "power": [118, 220], "power_transform": 900, "powertransform": [319, 888], "pr": [385, 390], "practic": [278, 369, 387, 391, 997, 1004, 1014, 1015, 1016], "pre": [281, 369, 399], "precis": [285, 1000], "precision_recall_curv": 790, "precision_recall_fscore_support": 791, "precision_scor": 792, "precisionrecalldisplai": [248, 708], "precomput": [134, 201, 328, 421], "predefin": [420, 1000], "predefinedsplit": 821, "predict": [43, 49, 52, 61, 118, 140, 152, 163, 177, 191, 200, 220, 253, 272, 274, 285, 338, 373, 398, 399, 415, 420, 426, 1000, 1011, 1025, 1032], "predictionerrordisplai": 709, "predictor": 160, "premium": 238, "prepar": [125, 140, 150, 155, 197, 240, 287, 288, 324, 349, 390], "preprocess": [36, 153, 160, 189, 192, 193, 257, 259, 318, 362, 369, 398, 1010, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "preprocessor": 193, "preserv": 394, "preval": 281, "princip": [55, 118, 421, 1017, 1033], "prior": [53, 185, 263], "privat": 1058, "probabilist": [132, 177, 421, 426], "probabl": [61, 62, 63, 66, 162, 179, 414, 423, 1015], "problem": [192, 272, 421, 1015, 1016, 1025, 1030, 1032, 1033], "process": [175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 189, 192, 369, 401, 426, 999, 1028], "process_rout": 960, "processor": 399, "product": [185, 238, 394, 398, 410, 426, 629], "profil": 392, "project": [0, 118, 130, 133, 251, 388, 398, 1012, 1017, 1019], "pronounc": 398, "propag": [51, 73, 338, 339, 340, 416, 1013], "proper": [52, 181], "properti": 400, "propos": 401, "provid": 391, "prune": [328, 364, 1016], "public": 1051, "publica": 1024, "pull": [386, 390, 394, 398], "pure": 238, "purpos": [224, 362, 1020], "pursuit": [219, 996], "put": 1030, "pypi": [398, 1060], "pytest": 394, "python": [252, 374, 392, 1018, 1019], "pytorch": 412, "qda": [70, 994], "quadradt": 185, "quadrat": [70, 426, 994], "quadraticdiscriminantanalysi": 558, "qualit": [43, 52], "qualiti": [361, 1000], "quantifi": [361, 1000], "quantil": [52, 152, 155, 222, 331, 332, 996], "quantile_transform": 901, "quantileregressor": [222, 678], "quantiletransform": [319, 889], "quantiz": [83, 88, 1033], "question": [398, 1023], "r2_score": 793, "r_regress": 617, "radial": [185, 426, 992, 1032], "radius_neighbors_graph": 866, "radiusneighborsclassifi": 862, "radiusneighborsregressor": 863, "radiusneighborstransform": 864, "rand": 416, "rand_scor": 794, "random": [41, 55, 125, 143, 145, 158, 159, 194, 195, 251, 260, 284, 286, 335, 369, 388, 395, 420, 421, 423, 989, 996, 1012, 1017], "random_project": [37, 1055], "random_st": 398, "randomforestclassifi": 572, "randomforestregressor": 573, "randomized_range_find": 948, "randomized_svd": 949, "randomizedsearchcv": 822, "randomli": [122, 123], "randomst": 369, "randomtreesembed": 574, "rang": 1010, "rangespan": 1024, "rank": [27, 220, 1000], "ransac": [223, 996], "ransacregressor": 679, "rate": 423, "ratio": [281, 1000], "ration": [185, 426], "rationalquadrat": 631, "rbf": [252, 348, 349, 353, 426, 630, 998, 1015, 1032], "rbf_kernel": 784, "rbfsampler": 649, "rcv1": 381, "reachabl": 416, "read": 386, "real": [42, 48, 109, 189, 381], "recal": [285, 1000], "recall_scor": 795, "receiv": [287, 288, 1000], "recent": 1, "recogn": 68, "recognit": [45, 381, 383, 1030], "recommend": [369, 381, 1019], "reconstruct": [44, 53, 128], "reconstruct_from_patches_2d": 595, "recov": 199, "recurs": [172, 173, 425], "redirect": 55, "reduc": [93, 373], "reduct": [106, 240, 244, 259, 308, 324, 361, 994, 1003, 1017], "refer": [2, 50, 62, 64, 114, 128, 142, 197, 204, 296, 312, 426, 990], "refit": [272, 276, 1025], "regard": [272, 415], "region": [81, 278], "register_parallel_backend": 970, "regress": [25, 27, 43, 52, 107, 109, 117, 118, 140, 152, 153, 163, 176, 181, 182, 183, 184, 199, 200, 203, 209, 211, 212, 213, 216, 218, 220, 222, 235, 237, 238, 250, 253, 311, 355, 366, 367, 382, 417, 426, 991, 993, 996, 1000, 1001, 1003, 1004, 1014, 1015, 1016, 1032], "regressor": [25, 49, 140, 152, 199, 224, 326, 328, 331, 423], "regressorchain": [846, 1001], "regressormixin": 439, "regular": [78, 111, 154, 192, 213, 224, 225, 314, 356, 996, 1004], "reinforc": 398, "relat": [43, 47, 1008, 1019, 1048], "releas": [189, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 390, 404, 1039], "relev": [113, 204, 996], "remark": [43, 92, 244, 251], "remot": 394, "remov": [398, 425, 1010, 1041], "repeat": [369, 417, 420], "repeatedkfold": 823, "repeatedstratifiedkfold": 824, "replac": 188, "repli": 394, "replic": 410, "report": [386, 391, 1000], "repositori": 380, "represent": [121, 193, 249, 329, 373, 388, 424, 1033], "reproduc": [369, 391], "request": [386, 390, 394, 398], "resampl": 971, "rescal": 324, "reshap": [373, 1031], "resourc": [290, 374, 386, 989, 1018, 1023], "respect": 281, "respons": [117, 401], "rest": [212, 287], "restart": 392, "restrict": [317, 1005], "result": [46, 47, 58, 64, 73, 82, 84, 85, 92, 93, 98, 99, 102, 111, 113, 115, 126, 127, 140, 145, 160, 163, 188, 197, 204, 225, 253, 257, 282, 291, 298, 306, 325, 355, 361, 369, 989], "retriev": [51, 328], "return": 412, "reuter": 47, "review": [385, 386, 394, 1034], "rfe": 601, "rfecv": 602, "rich": [249, 329], "ridg": [176, 200, 202, 218, 224, 225, 253, 326, 680, 993, 996], "ridge_regress": 695, "ridgeclassifi": 682, "ridgeclassifiercv": 683, "ridgecv": 681, "right": 1027, "roadmap": 1020, "robust": [25, 90, 113, 114, 199, 223, 226, 369, 418, 989, 996], "robust_scal": 902, "robustscal": [319, 890], "roc": [260, 275, 287, 288, 328, 1000], "roc_auc_scor": 796, "roc_curv": 797, "roccurvedisplai": [248, 710], "role": 401, "roll": [244, 388], "root_mean_squared_error": 798, "root_mean_squared_log_error": 799, "rotat": 135, "rout": [41, 254, 334, 335, 400, 407, 1058, 1059, 1060], "routin": [47, 374, 395], "rule": 1000, "run": [46, 93, 282], "runtim": [335, 384], "r\u00b2": 1000, "sa": 257, "safe_mask": 972, "safe_sparse_dot": 950, "safe_sqr": 973, "same": 1032, "sampl": [10, 41, 58, 73, 90, 98, 111, 126, 127, 170, 201, 233, 253, 279, 291, 311, 329, 355, 358, 380, 395, 400, 423, 996], "sample_without_replac": 969, "saniti": 394, "save": 398, "scalabl": [197, 280, 329], "scale": [90, 192, 240, 243, 324, 356, 375, 903, 997, 1006, 1010, 1017], "scaler": 319, "scatter": [117, 121], "scenario": 996, "scientif": [1018, 1028], "scikit": [0, 41, 254, 273, 328, 329, 330, 331, 332, 333, 334, 335, 336, 372, 373, 384, 387, 388, 390, 391, 398, 401, 404, 1019, 1020, 1024, 1025, 1026, 1031, 1034, 1037], "scipi": [374, 1058], "score": [55, 117, 145, 165, 173, 188, 199, 268, 277, 284, 285, 352, 407, 416, 420, 995, 1000, 1015, 1029], "script": 391, "search": [259, 276, 278, 286, 289, 296, 399, 989, 1029, 1034], "second": [48, 72], "section": 1025, "secur": [410, 1059], "seek": 1033, "segment": [81, 101], "select": [25, 27, 89, 95, 106, 132, 165, 168, 170, 173, 174, 189, 208, 209, 214, 268, 270, 352, 398, 407, 411, 420, 425, 989, 996, 1029, 1047], "selectfdr": 603, "selectfpr": 604, "selectfrommodel": [425, 605], "selectfw": 606, "selectkbest": 607, "selectormixin": 609, "selectpercentil": 608, "self": [330, 341, 1013], "selftrainingclassifi": 909, "semant": 421, "semi": [189, 337, 338, 342, 343, 1013], "semi_supervis": [38, 1051, 1052, 1053, 1057], "sen": [237, 996], "sens": 53, "sensit": 272, "sentiment": 1034, "separ": [126, 232, 350, 351], "sequenc": [184, 398], "sequenti": [174, 425], "sequentialfeatureselector": [330, 610], "seri": [52, 214, 420], "serv": 410, "set": [48, 109, 111, 131, 160, 188, 224, 272, 285, 336, 349, 364, 398, 415, 420, 996, 1025, 1031, 1032, 1034], "set_config": 910, "set_output": [261, 333, 335, 388], "set_param": 388, "setup": 1034, "sever": [238, 242], "sgd": [229, 230, 231, 232, 233, 996, 1014], "sgdclassifi": 684, "sgdoneclasssvm": 685, "sgdregressor": 686, "shape": [245, 1025], "share": [43, 52, 193], "shift": [98, 416], "ship": 1031, "should": 398, "show": [165, 287], "show_vers": 911, "shrinkag": [111, 418, 423, 994, 1032], "shrunk": 418, "shrunk_covari": 489, "shrunkcovari": 484, "shrunken": 1003, "shuffl": [420, 974], "shufflesplit": 825, "sigmoid": [353, 414, 998, 1032], "sigmoid_kernel": 785, "signal": [204, 421, 1033], "signific": 284, "silhouett": [95, 416], "silhouette_sampl": 800, "silhouette_scor": 801, "similar": [184, 998, 1000], "simpl": [137, 176, 254, 304, 392, 1031], "simpleimput": [336, 638], "simul": 191, "sine": [185, 269, 426], "singl": [142, 160, 238, 248, 382, 416, 990], "single_source_shortest_path_length": 954, "singular": [55, 421], "sinusoid": 200, "site": 390, "size": 423, "sketch": 992, "skew": 992, "skewedchi2sampl": 650, "sklearn": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "sklearn_assume_finit": 374, "sklearn_build_enable_debug_symbol": 374, "sklearn_enable_debug_cython_direct": 374, "sklearn_pairwise_dist_chunk_s": 374, "sklearn_run_float32_test": 374, "sklearn_se": 374, "sklearn_skip_network_test": 374, "sklearn_tests_global_random_se": 374, "sklearn_warnings_as_error": 374, "sklearn_working_memori": 374, "skop": 410, "slep": 401, "smacof": 702, "small": 391, "sne": [245, 997], "so": 398, "social": 1023, "soft": 423, "solido": 1024, "solut": 92, "solv": [1032, 1033], "solver": [227, 421, 996], "some": 352, "someth": 391, "sometim": 398, "sort_graph_by_row_valu": 867, "sourc": [104, 126, 384], "space": [51, 130, 417, 989, 997], "spars": [41, 115, 125, 134, 192, 204, 206, 235, 328, 335, 360, 361, 395, 418, 421, 425, 1010, 1012, 1014, 1058], "sparse_encod": 556, "sparsecod": 550, "sparsefunc": 1050, "sparsepca": [421, 551], "sparserandomproject": 905, "sparsiti": [211, 217, 424, 1032], "spawn": 374, "speci": [50, 312, 381], "special": 362, "specif": [287, 384, 388, 989, 1019, 1020], "specifi": [157, 398, 989], "spectral": [57, 58, 59, 101, 240, 413, 416, 997], "spectral_clust": 470, "spectral_embed": 703, "spectralbiclust": [58, 459], "spectralclust": 460, "spectralcoclust": 461, "spectralembed": 699, "speed": [49, 392], "sphere": 242, "sphinx": 386, "spline": [43, 221, 331, 1010], "splinetransform": 891, "split": [149, 330, 369, 420], "splitter": [29, 369], "sponsor": 0, "spotifi": 1024, "sprint": 0, "squar": [118, 152, 185, 215, 218, 224, 426, 992, 996, 998, 1000], "stabil": 329, "stabl": 331, "stack": [160, 328, 423], "stackingclassifi": 575, "stackingregressor": 576, "stall": 386, "standard": [394, 1010], "standardscal": [319, 892], "start": 399, "statement": 1020, "statist": [278, 1019, 1028, 1031], "statlog": 272, "statu": 407, "std": [165, 199], "step": [43, 259, 399, 417], "stochast": [228, 234, 240, 315, 996, 997, 1005, 1014], "stock": [51, 1030], "stop": [150, 155, 228, 424, 1014], "strategi": [88, 276, 296, 315, 322, 334, 336, 375, 416, 1000], "stratif": 420, "stratifi": 420, "stratifiedgroupkfold": [420, 826], "stratifiedkfold": 827, "stratifiedshufflesplit": 828, "stream": 375, "string": 398, "strip": 360, "strong": 202, "strongli": 1008, "structur": [51, 74, 82, 102, 184, 340, 368, 1030], "studi": 257, "submit": 386, "subpackag": 1020, "subsampl": 423, "subscript": 336, "subtleti": 369, "success": [289, 290, 330, 989], "sum": 632, "summar": 410, "summari": [62, 150, 209, 361, 362, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048], "supervis": [189, 337, 338, 342, 343, 1004, 1013, 1022, 1032], "support": [0, 62, 149, 155, 189, 214, 325, 328, 329, 330, 331, 333, 334, 335, 344, 347, 355, 398, 404, 407, 412, 414, 423, 1015, 1016, 1023, 1032, 1058, 1059, 1060], "surfac": [148, 252, 365], "svc": [260, 353, 356, 917, 1015], "svd": [55, 125, 421], "svm": [39, 45, 167, 170, 171, 197, 234, 252, 331, 343, 345, 346, 348, 349, 350, 351, 352, 353, 354, 357, 358, 996, 1006, 1014, 1032, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057], "svmlight": 380, "svr": [253, 355, 918, 1015], "swiss": 244, "switch": 374, "symmetr": 117, "synthet": [61, 109, 199, 204, 275, 326, 391], "system": 384, "t": [240, 245, 997], "tabl": 398, "tag": [384, 386, 388], "take": 278, "takeawai": 220, "talk": 1018, "tangent": 997, "target": [41, 109, 183, 238, 325, 326, 398, 400, 417, 1001, 1010, 1011], "targetencod": [334, 893], "task": [25, 214, 996, 1019], "team": [0, 385], "technic": 401, "techniqu": 241, "templat": 388, "tensor": 992, "term": [361, 400, 424], "test": [44, 111, 169, 281, 284, 291, 360, 364, 384, 386, 388, 394, 395, 420, 1025, 1032, 1034], "text": [17, 47, 189, 249, 279, 342, 359, 360, 361, 362, 381, 424, 1034], "tf": 424, "tfidftransform": 598, "tfidfvector": [361, 362, 599], "than": 398, "theil": [237, 996], "theilsenregressor": 687, "them": [128, 385], "theoret": 251, "thi": [224, 1020], "third": [220, 254, 404], "thread": 374, "threshold": [272, 292, 336, 341, 415], "throughput": [49, 373], "tie": 357, "time": [43, 52, 145, 214, 252, 253, 360, 420, 1021], "timeseriessplit": 829, "tip": [373, 387, 394, 989, 997, 1004, 1014, 1015, 1016], "togeth": [258, 287, 1030, 1033], "toi": [79, 97, 247, 383], "token": 1034, "toler": 174, "tomographi": 53, "too": 374, "tool": [395, 398, 412], "top": [361, 1000], "top_k_accuracy_scor": 802, "topic": 54, "total": [158, 364, 423], "tough": 385, "track": [394, 417], "tracker": [386, 1023], "trade": 996, "tradeoff": [275, 1000], "train": [139, 140, 150, 153, 156, 163, 173, 224, 248, 253, 257, 258, 260, 268, 291, 296, 317, 325, 326, 330, 341, 349, 353, 360, 364, 365, 368, 410, 420, 1003, 1013, 1025, 1032, 1034], "train_test_split": 838, "transform": [104, 105, 106, 109, 117, 144, 158, 259, 330, 331, 332, 378, 398, 399, 417, 1003, 1010, 1011, 1012, 1033], "transformedtargetregressor": 473, "transformermixin": 440, "translat": 1019, "tree": [40, 139, 140, 144, 146, 147, 148, 155, 158, 189, 194, 220, 328, 333, 334, 335, 363, 364, 365, 366, 367, 368, 398, 423, 425, 1003, 1008, 1016, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "triag": 385, "trick": [373, 392, 394, 424], "trigonometr": 43, "troubleshoot": 404, "true": [199, 200], "truncat": 421, "truncatedsvd": 552, "trust": 165, "trustworthi": 704, "truth": [72, 199], "tsne": [299, 700], "tune": [29, 152, 272, 276, 279, 292, 330, 336, 415, 989, 1034], "tunedthresholdclassifiercv": [336, 830], "tutori": [164, 189, 1018, 1026, 1028, 1034], "tweedi": [238, 1000], "tweedieregressor": [238, 688], "two": [101, 141, 206, 258, 278], "type": [105, 263, 387, 388, 400, 412, 416, 1025], "type_of_target": 963, "typic": 385, "t\u00e9l\u00e9com": 1024, "u": 0, "ubuntu": 404, "uci": 296, "unbalanc": [351, 1015], "uncertain": 338, "uncertainti": 52, "unclaim": 386, "undefinedmetricwarn": 586, "under": [184, 398, 1036, 1057], "underfit": 293, "understand": 368, "unfold": 394, "uniform": [319, 1010], "unique_label": 964, "univari": [89, 117, 170, 352, 425, 990], "univers": 388, "unlabel": 1013, "unless": 391, "unstructur": 102, "unsupervis": [1003, 1005, 1017, 1033, 1035], "unweight": 407, "up": 1006, "updat": [1025, 1051], "us": [44, 45, 51, 55, 83, 125, 126, 128, 157, 158, 160, 174, 181, 207, 223, 234, 236, 278, 282, 287, 298, 320, 355, 360, 361, 368, 369, 375, 387, 391, 392, 394, 398, 420, 421, 424, 425, 994, 996, 997, 1000, 1004, 1014, 1015, 1016, 1024, 1032, 1034, 1051], "usabl": 398, "usag": [392, 398, 407, 412, 414, 417, 423, 424, 996], "user": [1023, 1036], "util": [41, 379, 391, 395, 1034, 1038, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059], "v": [89, 102, 111, 112, 114, 118, 130, 173, 193, 194, 202, 212, 238, 281, 287, 291, 293, 364, 416, 423, 990, 1025], "v_measure_scor": 803, "valgrind": [392, 394], "valid": [29, 41, 43, 165, 173, 209, 251, 272, 273, 274, 276, 277, 281, 283, 288, 294, 352, 369, 373, 388, 395, 415, 420, 989, 995, 996, 1029], "validation_curv": 839, "validationcurvedisplai": [334, 831], "valu": [155, 174, 186, 187, 188, 189, 245, 254, 328, 334, 335, 368, 386, 412, 421, 423, 990, 1000, 1008, 1010, 1016], "vanilla": [272, 292], "vari": [72, 314, 341, 416], "variabl": [25, 117, 191, 192, 374, 398, 1032], "varianc": [142, 218, 425, 1000, 1010], "variancethreshold": 611, "variant": 187, "variat": [263, 999], "variou": [49, 87, 227, 245], "vector": [55, 62, 88, 189, 344, 347, 355, 360, 362, 424, 1015, 1032, 1033], "version": [332, 380, 384, 386, 390, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060], "versu": [142, 234, 283, 343, 373], "via": [44, 52, 88, 208, 209, 238, 423, 992], "video": [386, 1018], "visual": [5, 29, 51, 93, 135, 150, 248, 253, 260, 273, 316, 329, 349, 416, 417, 1000, 1038], "vocabulari": 1032, "vote": [163, 423], "votingclassifi": [161, 162, 577], "votingregressor": 578, "wage": [191, 192], "wai": [193, 386, 398], "ward": [82, 102, 416, 1033], "ward_tre": 471, "warm": 392, "warm_start": 1004, "warn": 395, "we": 102, "weak": [139, 423], "web": 390, "websit": 1051, "weight": [41, 139, 199, 201, 233, 316, 329, 358, 407, 423, 424], "weighted_mod": 951, "what": [368, 398], "when": 272, "where": 1034, "which": 996, "whitekernel": 633, "who": 1024, "why": [398, 423], "wikipedia": 55, "wild": 381, "window": [384, 404], "wine": 383, "winpython": 404, "wisconsin": 383, "within": 106, "without": [74, 307, 360], "wolf": [69, 112, 418], "word": [360, 424, 1034], "work": [41, 189, 359, 373, 385, 398, 1034], "workflow": [385, 410], "world": [42, 109, 189, 381], "would": 1031, "wrap": 298, "written": 68, "wrong": [192, 398], "x": 237, "x86_64": 394, "xor": [180, 353, 426], "y": [237, 398, 1011, 1013], "yeast": 296, "yep": 392, "yhat": 1024, "you": [165, 398], "your": [388, 391, 1000], "zero": 1000, "zero_one_loss": 804, "zopa": 1024}})