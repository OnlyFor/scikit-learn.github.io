

<!DOCTYPE html>
<!-- data-theme below is forced to be "light" but should be changed if we use pydata-theme-sphinx in the future -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" data-content_root="../../" data-theme="light"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" data-content_root="../../" data-theme="light"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Lagged features for time series forecasting" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/auto_examples/applications/plot_time_series_lagged_features.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="This example demonstrates how Polars-engineered lagged features can be used for time series forecasting with HistGradientBoostingRegressor on the Bike Sharing Demand dataset. See the example on Tim..." />
<meta property="og:image" content="https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="This example demonstrates how Polars-engineered lagged features can be used for time series forecasting with HistGradientBoostingRegressor on the Bike Sharing Demand dataset. See the example on Tim..." />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>Lagged features for time series forecasting &mdash; scikit-learn 1.5.dev0 documentation</title>
  
  <link rel="canonical" href="https://scikit-learn.org/stable/auto_examples/applications/plot_time_series_lagged_features.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../https://fonts.googleapis.com/css?family=Vibur" type="text/css" />
  <link rel="stylesheet" href="../../_static/jupyterlite_sphinx.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/js/vendor/jquery-3.6.3.slim.min.js"></script>
<script src="../../_static/js/details-permalink.js"></script> 
</head>
<body>




<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://blog.scikit-learn.org/">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html" >Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html" >Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v1.5.html" >What's new</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html" >Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../developers/index.html" >Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html" >FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html" >Support</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html" >Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html" >Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../governance.html" >Governance</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html" >About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html" >Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html" >Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v1.5.html" >What's new</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html" >Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../developers/index.html" >Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html" >FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html" >Support</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html" >Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html" >Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../governance.html" >Governance</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html" >About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="plot_digits_denoising.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Image denoising using kernel PCA">Prev</a><a href="index.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Examples based on real world datasets">Up</a>
            <a href="plot_model_complexity_influence.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Model Complexity Influence">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 1.5.dev0</strong><br/>
          <a href="https://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#">Lagged features for time series forecasting</a><ul>
<li><a class="reference internal" href="#analyzing-the-bike-sharing-demand-dataset">Analyzing the Bike Sharing Demand dataset</a></li>
<li><a class="reference internal" href="#generating-polars-engineered-lagged-features">Generating Polars-engineered lagged features</a></li>
<li><a class="reference internal" href="#naive-evaluation-of-the-next-hour-bike-demand-regression">Naive evaluation of the next hour bike demand regression</a></li>
<li><a class="reference internal" href="#proper-next-hour-forecasting-evaluation">Proper next hour forecasting evaluation</a></li>
<li><a class="reference internal" href="#modeling-predictive-uncertainty-via-quantile-regression">Modeling predictive uncertainty via quantile regression</a></li>
<li><a class="reference internal" href="#a-qualitative-look-at-the-predictions">A qualitative look at the predictions</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-applications-plot-time-series-lagged-features-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code or to run this example in your browser via JupyterLite or Binder</p>
</div>
<section class="sphx-glr-example-title" id="lagged-features-for-time-series-forecasting">
<span id="sphx-glr-auto-examples-applications-plot-time-series-lagged-features-py"></span><h1>Lagged features for time series forecasting<a class="headerlink" href="#lagged-features-for-time-series-forecasting" title="Link to this heading">¶</a></h1>
<p>This example demonstrates how Polars-engineered lagged features can be used
for time series forecasting with
<a class="reference internal" href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code></a> on the Bike Sharing
Demand dataset.</p>
<p>See the example on
<a class="reference internal" href="plot_cyclical_feature_engineering.html#sphx-glr-auto-examples-applications-plot-cyclical-feature-engineering-py"><span class="std std-ref">Time-related feature engineering</span></a>
for some data exploration on this dataset and a demo on periodic feature
engineering.</p>
<section id="analyzing-the-bike-sharing-demand-dataset">
<h2>Analyzing the Bike Sharing Demand dataset<a class="headerlink" href="#analyzing-the-bike-sharing-demand-dataset" title="Link to this heading">¶</a></h2>
<p>We start by loading the data from the OpenML repository
as a pandas dataframe. This will be replaced with Polars
once <code class="docutils literal notranslate"><span class="pre">fetch_openml</span></code> adds a native support for it.
We convert to Polars for feature engineering, as it automatically caches
common subexpressions which are reused in multiple expressions
(like <code class="docutils literal notranslate"><span class="pre">pl.col(&quot;count&quot;).shift(1)</span></code> below). See
<a class="reference external" href="https://docs.pola.rs/user-guide/lazy/optimizations/">https://docs.pola.rs/user-guide/lazy/optimizations/</a> for more information.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">polars</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.datasets.fetch_openml.html#sklearn.datasets.fetch_openml" title="sklearn.datasets.fetch_openml" class="sphx-glr-backref-module-sklearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_openml</span></a>

<span class="n">pl</span><span class="o">.</span><span class="n">Config</span><span class="o">.</span><span class="n">set_fmt_str_lengths</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>

<span class="n">bike_sharing</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.datasets.fetch_openml.html#sklearn.datasets.fetch_openml" title="sklearn.datasets.fetch_openml" class="sphx-glr-backref-module-sklearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_openml</span></a><span class="p">(</span>
    <span class="s2">&quot;Bike_Sharing_Demand&quot;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parser</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span>
<span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bike_sharing</span><span class="o">.</span><span class="n">frame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">col</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">})</span>
</pre></div>
</div>
<p>Next, we take a look at the statistical summary of the dataset
so that we can better understand the data that we are working with.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">polars.selectors</span> <span class="k">as</span> <span class="nn">cs</span>

<span class="n">summary</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">cs</span><span class="o">.</span><span class="n">numeric</span><span class="p">())</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
<span class="n">summary</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (9, 10)</small><table border="1" class="dataframe"><thead><tr><th>statistic</th><th>year</th><th>month</th><th>hour</th><th>weekday</th><th>temp</th><th>feel_temp</th><th>humidity</th><th>windspeed</th><th>count</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>17379.0</td><td>17379.0</td><td>17379.0</td><td>17379.0</td><td>17379.0</td><td>17379.0</td><td>17379.0</td><td>17379.0</td><td>17379.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>0.502561</td><td>6.537775</td><td>11.546752</td><td>3.003683</td><td>20.376474</td><td>23.788755</td><td>0.627229</td><td>12.73654</td><td>189.463088</td></tr><tr><td>&quot;std&quot;</td><td>0.500008</td><td>3.438776</td><td>6.914405</td><td>2.005771</td><td>7.894801</td><td>8.592511</td><td>0.19293</td><td>8.196795</td><td>181.387599</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.82</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>0.0</td><td>4.0</td><td>6.0</td><td>1.0</td><td>13.94</td><td>16.665</td><td>0.48</td><td>7.0015</td><td>40.0</td></tr><tr><td>&quot;50%&quot;</td><td>1.0</td><td>7.0</td><td>12.0</td><td>3.0</td><td>20.5</td><td>24.24</td><td>0.63</td><td>12.998</td><td>142.0</td></tr><tr><td>&quot;75%&quot;</td><td>1.0</td><td>10.0</td><td>18.0</td><td>5.0</td><td>27.06</td><td>31.06</td><td>0.78</td><td>16.9979</td><td>281.0</td></tr><tr><td>&quot;max&quot;</td><td>1.0</td><td>12.0</td><td>23.0</td><td>6.0</td><td>41.0</td><td>50.0</td><td>1.0</td><td>56.9969</td><td>977.0</td></tr></tbody></table></div>
</div>
<br />
<br /><p>Let us look at the count of the seasons <code class="docutils literal notranslate"><span class="pre">&quot;fall&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;spring&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;summer&quot;</span></code>
and <code class="docutils literal notranslate"><span class="pre">&quot;winter&quot;</span></code> present in the dataset to confirm they are balanced.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">df</span><span class="p">[</span><span class="s2">&quot;season&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (4, 2)</small><table border="1" class="dataframe"><thead><tr><th>season</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;summer&quot;</td><td>4409</td></tr><tr><td>&quot;spring&quot;</td><td>4242</td></tr><tr><td>&quot;fall&quot;</td><td>4496</td></tr><tr><td>&quot;winter&quot;</td><td>4232</td></tr></tbody></table></div>
</div>
<br />
<br /></section>
<section id="generating-polars-engineered-lagged-features">
<h2>Generating Polars-engineered lagged features<a class="headerlink" href="#generating-polars-engineered-lagged-features" title="Link to this heading">¶</a></h2>
<p>Let’s consider the problem of predicting the demand at the
next hour given past demands. Since the demand is a continuous
variable, one could intuitively use any regression model. However, we do
not have the usual <code class="docutils literal notranslate"><span class="pre">(X_train,</span> <span class="pre">y_train)</span></code> dataset. Instead, we just have
the <code class="docutils literal notranslate"><span class="pre">y_train</span></code> demand data sequentially organized by time.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">lagged_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="s2">&quot;count&quot;</span><span class="p">,</span>
    <span class="o">*</span><span class="p">[</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;lagged_count_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">h&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>
    <span class="n">lagged_count_1d</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">24</span><span class="p">),</span>
    <span class="n">lagged_count_1d_1h</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">24</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">lagged_count_7d</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">24</span><span class="p">),</span>
    <span class="n">lagged_count_7d_1h</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">24</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">lagged_mean_24h</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">rolling_mean</span><span class="p">(</span><span class="mi">24</span><span class="p">),</span>
    <span class="n">lagged_max_24h</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">rolling_max</span><span class="p">(</span><span class="mi">24</span><span class="p">),</span>
    <span class="n">lagged_min_24h</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">rolling_min</span><span class="p">(</span><span class="mi">24</span><span class="p">),</span>
    <span class="n">lagged_mean_7d</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">rolling_mean</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">24</span><span class="p">),</span>
    <span class="n">lagged_max_7d</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">rolling_max</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">24</span><span class="p">),</span>
    <span class="n">lagged_min_7d</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">rolling_min</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">24</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">lagged_df</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (10, 14)</small><table border="1" class="dataframe"><thead><tr><th>count</th><th>lagged_count_1h</th><th>lagged_count_2h</th><th>lagged_count_3h</th><th>lagged_count_1d</th><th>lagged_count_1d_1h</th><th>lagged_count_7d</th><th>lagged_count_7d_1h</th><th>lagged_mean_24h</th><th>lagged_max_24h</th><th>lagged_min_24h</th><th>lagged_mean_7d</th><th>lagged_max_7d</th><th>lagged_min_7d</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>247</td><td>203</td><td>224</td><td>157</td><td>160</td><td>169</td><td>70</td><td>135</td><td>93.5</td><td>224</td><td>1</td><td>67.732143</td><td>271</td><td>1</td></tr><tr><td>315</td><td>247</td><td>203</td><td>224</td><td>138</td><td>160</td><td>46</td><td>70</td><td>97.125</td><td>247</td><td>1</td><td>68.785714</td><td>271</td><td>1</td></tr><tr><td>214</td><td>315</td><td>247</td><td>203</td><td>133</td><td>138</td><td>33</td><td>46</td><td>104.5</td><td>315</td><td>1</td><td>70.386905</td><td>315</td><td>1</td></tr><tr><td>164</td><td>214</td><td>315</td><td>247</td><td>123</td><td>133</td><td>33</td><td>33</td><td>107.875</td><td>315</td><td>1</td><td>71.464286</td><td>315</td><td>1</td></tr><tr><td>122</td><td>164</td><td>214</td><td>315</td><td>125</td><td>123</td><td>26</td><td>33</td><td>109.583333</td><td>315</td><td>1</td><td>72.244048</td><td>315</td><td>1</td></tr><tr><td>119</td><td>122</td><td>164</td><td>214</td><td>102</td><td>125</td><td>26</td><td>26</td><td>109.458333</td><td>315</td><td>1</td><td>72.815476</td><td>315</td><td>1</td></tr><tr><td>89</td><td>119</td><td>122</td><td>164</td><td>72</td><td>102</td><td>18</td><td>26</td><td>110.166667</td><td>315</td><td>1</td><td>73.369048</td><td>315</td><td>1</td></tr><tr><td>90</td><td>89</td><td>119</td><td>122</td><td>47</td><td>72</td><td>23</td><td>18</td><td>110.875</td><td>315</td><td>1</td><td>73.791667</td><td>315</td><td>1</td></tr><tr><td>61</td><td>90</td><td>89</td><td>119</td><td>36</td><td>47</td><td>22</td><td>23</td><td>112.666667</td><td>315</td><td>1</td><td>74.190476</td><td>315</td><td>1</td></tr><tr><td>49</td><td>61</td><td>90</td><td>89</td><td>49</td><td>36</td><td>12</td><td>22</td><td>113.708333</td><td>315</td><td>1</td><td>74.422619</td><td>315</td><td>1</td></tr></tbody></table></div>
</div>
<br />
<br /><p>Watch out however, the first lines have undefined values because their own
past is unknown. This depends on how much lag we used:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">lagged_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (10, 14)</small><table border="1" class="dataframe"><thead><tr><th>count</th><th>lagged_count_1h</th><th>lagged_count_2h</th><th>lagged_count_3h</th><th>lagged_count_1d</th><th>lagged_count_1d_1h</th><th>lagged_count_7d</th><th>lagged_count_7d_1h</th><th>lagged_mean_24h</th><th>lagged_max_24h</th><th>lagged_min_24h</th><th>lagged_mean_7d</th><th>lagged_max_7d</th><th>lagged_min_7d</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>16</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>40</td><td>16</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>32</td><td>40</td><td>16</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>13</td><td>32</td><td>40</td><td>16</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1</td><td>13</td><td>32</td><td>40</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1</td><td>1</td><td>13</td><td>32</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2</td><td>1</td><td>1</td><td>13</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>3</td><td>2</td><td>1</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>8</td><td>3</td><td>2</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>14</td><td>8</td><td>3</td><td>2</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>
</div>
<br />
<br /><p>We can now separate the lagged features in a matrix <code class="docutils literal notranslate"><span class="pre">X</span></code> and the target variable
(the counts to predict) in an array of the same first dimension <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">lagged_df</span> <span class="o">=</span> <span class="n">lagged_df</span><span class="o">.</span><span class="n">drop_nulls</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">lagged_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">lagged_df</span><span class="p">[</span><span class="s2">&quot;count&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X shape: </span><span class="si">{}</span><span class="se">\n</span><span class="s2">y shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>X shape: (17210, 13)
y shape: (17210,)
</pre></div>
</div>
</section>
<section id="naive-evaluation-of-the-next-hour-bike-demand-regression">
<h2>Naive evaluation of the next hour bike demand regression<a class="headerlink" href="#naive-evaluation-of-the-next-hour-bike-demand-regression" title="Link to this heading">¶</a></h2>
<p>Let’s randomly split our tabularized dataset to train a gradient
boosting regression tree (GBRT) model and evaluate it using Mean
Absolute Percentage Error (MAPE). If our model is aimed at forecasting
(i.e., predicting future data from past data), we should not use training
data that are ulterior to the testing data. In time series machine learning
the “i.i.d” (independent and identically distributed) assumption does not
hold true as the data points are not independent and have a temporal
relationship.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">HistGradientBoostingRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function"><span class="n">train_test_split</span></a>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function"><span class="n">train_test_split</span></a><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">HistGradientBoostingRegressor</span></a><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Taking a look at the performance of the model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error" title="sklearn.metrics.mean_absolute_percentage_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_absolute_percentage_error</span></a>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<a href="../../modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error" title="sklearn.metrics.mean_absolute_percentage_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_absolute_percentage_error</span></a><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>0.3889873516666431
</pre></div>
</div>
</section>
<section id="proper-next-hour-forecasting-evaluation">
<h2>Proper next hour forecasting evaluation<a class="headerlink" href="#proper-next-hour-forecasting-evaluation" title="Link to this heading">¶</a></h2>
<p>Let’s use a proper evaluation splitting strategies that takes into account
the temporal structure of the dataset to evaluate our model’s ability to
predict data points in the future (to avoid cheating by reading values from
the lagged features in the training set).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TimeSeriesSplit</span></a>

<span class="n">ts_cv</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TimeSeriesSplit</span></a><span class="p">(</span>
    <span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>  <span class="c1"># to keep the notebook fast enough on common laptops</span>
    <span class="n">gap</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span>  <span class="c1"># 2 days data gap between train and test</span>
    <span class="n">max_train_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>  <span class="c1"># keep train sets of comparable sizes</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span>  <span class="c1"># for 2 or 3 digits of precision in scores</span>
<span class="p">)</span>
<span class="n">all_splits</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ts_cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
<p>Training the model and evaluating its performance based on MAPE.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="n">all_splits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">HistGradientBoostingRegressor</span></a><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<a href="../../modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error" title="sklearn.metrics.mean_absolute_percentage_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_absolute_percentage_error</span></a><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>0.44300751539296973
</pre></div>
</div>
<p>The generalization error measured via a shuffled trained test split
is too optimistic. The generalization via a time-based split is likely to
be more representative of the true performance of the regression model.
Let’s assess this variability of our error evaluation with proper
cross-validation:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function"><span class="n">cross_val_score</span></a>

<span class="n">cv_mape_scores</span> <span class="o">=</span> <span class="o">-</span><a href="../../modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function"><span class="n">cross_val_score</span></a><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_absolute_percentage_error&quot;</span>
<span class="p">)</span>
<span class="n">cv_mape_scores</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>array([0.44300752, 0.27772182, 0.3697178 ])
</pre></div>
</div>
<p>The variability across splits is quite large! In a real life setting
it would be advised to use more splits to better assess the variability.
Let’s report the mean CV scores and their standard deviation from now on.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CV MAPE: </span><span class="si">{</span><span class="n">cv_mape_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">cv_mape_scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>CV MAPE: 0.363 ± 0.068
</pre></div>
</div>
<p>We can compute several combinations of evaluation metrics and loss functions,
which are reported a bit below.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/collections.html#collections.defaultdict" title="collections.defaultdict" class="sphx-glr-backref-module-collections sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">defaultdict</span></a>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span>
    <a href="../../modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">make_scorer</span></a><span class="p">,</span>
    <a href="../../modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_absolute_error</span></a><span class="p">,</span>
    <a href="../../modules/generated/sklearn.metrics.mean_pinball_loss.html#sklearn.metrics.mean_pinball_loss" title="sklearn.metrics.mean_pinball_loss" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_pinball_loss</span></a><span class="p">,</span>
    <a href="../../modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error" title="sklearn.metrics.root_mean_squared_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">root_mean_squared_error</span></a><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function"><span class="n">cross_validate</span></a>


<span class="k">def</span> <span class="nf">consolidate_scores</span><span class="p">(</span><span class="n">cv_results</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s2">&quot;MAPE&quot;</span><span class="p">:</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">scores</span>


<span class="n">scoring</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;MAPE&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">make_scorer</span></a><span class="p">(</span><a href="../../modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error" title="sklearn.metrics.mean_absolute_percentage_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_absolute_percentage_error</span></a><span class="p">),</span>
    <span class="s2">&quot;RMSE&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">make_scorer</span></a><span class="p">(</span><a href="../../modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error" title="sklearn.metrics.root_mean_squared_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">root_mean_squared_error</span></a><span class="p">),</span>
    <span class="s2">&quot;MAE&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">make_scorer</span></a><span class="p">(</span><a href="../../modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_absolute_error</span></a><span class="p">),</span>
    <span class="s2">&quot;pinball_loss_05&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">make_scorer</span></a><span class="p">(</span><a href="../../modules/generated/sklearn.metrics.mean_pinball_loss.html#sklearn.metrics.mean_pinball_loss" title="sklearn.metrics.mean_pinball_loss" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_pinball_loss</span></a><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">),</span>
    <span class="s2">&quot;pinball_loss_50&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">make_scorer</span></a><span class="p">(</span><a href="../../modules/generated/sklearn.metrics.mean_pinball_loss.html#sklearn.metrics.mean_pinball_loss" title="sklearn.metrics.mean_pinball_loss" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_pinball_loss</span></a><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.50</span><span class="p">),</span>
    <span class="s2">&quot;pinball_loss_95&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">make_scorer</span></a><span class="p">(</span><a href="../../modules/generated/sklearn.metrics.mean_pinball_loss.html#sklearn.metrics.mean_pinball_loss" title="sklearn.metrics.mean_pinball_loss" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_pinball_loss</span></a><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">),</span>
<span class="p">}</span>
<span class="n">loss_functions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;squared_error&quot;</span><span class="p">,</span> <span class="s2">&quot;poisson&quot;</span><span class="p">,</span> <span class="s2">&quot;absolute_error&quot;</span><span class="p">]</span>
<span class="n">scores</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/collections.html#collections.defaultdict" title="collections.defaultdict" class="sphx-glr-backref-module-collections sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">defaultdict</span></a><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">loss_func</span> <span class="ow">in</span> <span class="n">loss_functions</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">HistGradientBoostingRegressor</span></a><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss_func</span><span class="p">)</span>
    <span class="n">cv_results</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function"><span class="n">cross_validate</span></a><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">time</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;fit_time&quot;</span><span class="p">]</span>
    <span class="n">scores</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_func</span><span class="p">)</span>
    <span class="n">scores</span><span class="p">[</span><span class="s2">&quot;fit_time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;test_&quot;</span><span class="p">):</span>
            <span class="n">metric</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;test_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">consolidate_scores</span><span class="p">(</span><span class="n">cv_results</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">metric</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="modeling-predictive-uncertainty-via-quantile-regression">
<h2>Modeling predictive uncertainty via quantile regression<a class="headerlink" href="#modeling-predictive-uncertainty-via-quantile-regression" title="Link to this heading">¶</a></h2>
<p>Instead of modeling the expected value of the distribution of
<span class="math notranslate nohighlight">\(Y|X\)</span> like the least squares and Poisson losses do, one could try to
estimate quantiles of the conditional distribution.</p>
<p><span class="math notranslate nohighlight">\(Y|X=x_i\)</span> is expected to be a random variable for a given data point
<span class="math notranslate nohighlight">\(x_i\)</span> because we expect that the number of rentals cannot be 100%
accurately predicted from the features. It can be influenced by other
variables not properly captured by the existing lagged features. For
instance whether or not it will rain in the next hour cannot be fully
anticipated from the past hours bike rental data. This is what we
call aleatoric uncertainty.</p>
<p>Quantile regression makes it possible to give a finer description of that
distribution without making strong assumptions on its shape.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">quantile_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">]</span>

<span class="k">for</span> <span class="n">quantile</span> <span class="ow">in</span> <span class="n">quantile_list</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">HistGradientBoostingRegressor</span></a><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;quantile&quot;</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="n">quantile</span><span class="p">)</span>
    <span class="n">cv_results</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function"><span class="n">cross_validate</span></a><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">time</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;fit_time&quot;</span><span class="p">]</span>
    <span class="n">scores</span><span class="p">[</span><span class="s2">&quot;fit_time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>

    <span class="n">scores</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;quantile </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">quantile</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;test_&quot;</span><span class="p">):</span>
            <span class="n">metric</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;test_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">consolidate_scores</span><span class="p">(</span><span class="n">cv_results</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">metric</span><span class="p">)</span>

<span class="n">scores_df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="n">scores_df</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (6, 8)</small><table border="1" class="dataframe"><thead><tr><th>loss</th><th>fit_time</th><th>MAPE</th><th>RMSE</th><th>MAE</th><th>pinball_loss_05</th><th>pinball_loss_50</th><th>pinball_loss_95</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;squared_error&quot;</td><td>&quot;0.31 ± 0.00 s&quot;</td><td>&quot;0.36 ± 0.07&quot;</td><td>&quot;62.3 ± 3.5&quot;</td><td>&quot;39.1 ± 2.3&quot;</td><td>&quot;17.7 ± 1.3&quot;</td><td>&quot;19.5 ± 1.1&quot;</td><td>&quot;21.4 ± 2.4&quot;</td></tr><tr><td>&quot;poisson&quot;</td><td>&quot;0.33 ± 0.02 s&quot;</td><td>&quot;0.32 ± 0.07&quot;</td><td>&quot;64.2 ± 4.0&quot;</td><td>&quot;39.3 ± 2.8&quot;</td><td>&quot;16.7 ± 1.5&quot;</td><td>&quot;19.7 ± 1.4&quot;</td><td>&quot;22.6 ± 3.0&quot;</td></tr><tr><td>&quot;absolute_error&quot;</td><td>&quot;0.42 ± 0.01 s&quot;</td><td>&quot;0.32 ± 0.06&quot;</td><td>&quot;64.6 ± 3.8&quot;</td><td>&quot;39.9 ± 3.2&quot;</td><td>&quot;17.1 ± 1.1&quot;</td><td>&quot;19.9 ± 1.6&quot;</td><td>&quot;22.7 ± 3.1&quot;</td></tr><tr><td>&quot;quantile 5&quot;</td><td>&quot;0.57 ± 0.01 s&quot;</td><td>&quot;0.41 ± 0.01&quot;</td><td>&quot;145.6 ± 20.9&quot;</td><td>&quot;92.5 ± 16.2&quot;</td><td>&quot;5.9 ± 0.9&quot;</td><td>&quot;46.2 ± 8.1&quot;</td><td>&quot;86.6 ± 15.3&quot;</td></tr><tr><td>&quot;quantile 50&quot;</td><td>&quot;0.60 ± 0.01 s&quot;</td><td>&quot;0.32 ± 0.06&quot;</td><td>&quot;64.6 ± 3.8&quot;</td><td>&quot;39.9 ± 3.2&quot;</td><td>&quot;17.1 ± 1.1&quot;</td><td>&quot;19.9 ± 1.6&quot;</td><td>&quot;22.7 ± 3.1&quot;</td></tr><tr><td>&quot;quantile 95&quot;</td><td>&quot;0.61 ± 0.05 s&quot;</td><td>&quot;1.07 ± 0.27&quot;</td><td>&quot;99.6 ± 8.7&quot;</td><td>&quot;72.0 ± 6.1&quot;</td><td>&quot;62.9 ± 7.4&quot;</td><td>&quot;36.0 ± 3.1&quot;</td><td>&quot;9.1 ± 1.3&quot;</td></tr></tbody></table></div>
</div>
<br />
<br /><p>Let us take a look at the losses that minimise each metric.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">min_arg</span><span class="p">(</span><span class="n">col</span><span class="p">):</span>
    <span class="n">col_split</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pl</span><span class="o">.</span><span class="n">arg_sort_by</span><span class="p">(</span>
        <span class="n">col_split</span><span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">Float64</span><span class="p">),</span>
        <span class="n">col_split</span><span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">Float64</span><span class="p">),</span>
    <span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>


<span class="n">scores_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">min_arg</span><span class="p">(</span><span class="n">col_name</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">col_name</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="n">scores_df</span><span class="o">.</span><span class="n">columns</span>
    <span class="k">if</span> <span class="n">col_name</span> <span class="o">!=</span> <span class="s2">&quot;loss&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (1, 7)</small><table border="1" class="dataframe"><thead><tr><th>fit_time</th><th>MAPE</th><th>RMSE</th><th>MAE</th><th>pinball_loss_05</th><th>pinball_loss_50</th><th>pinball_loss_95</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;squared_error&quot;</td><td>&quot;absolute_error&quot;</td><td>&quot;squared_error&quot;</td><td>&quot;squared_error&quot;</td><td>&quot;quantile 5&quot;</td><td>&quot;squared_error&quot;</td><td>&quot;quantile 95&quot;</td></tr></tbody></table></div>
</div>
<br />
<br /><p>Even if the score distributions overlap due to the variance in the dataset,
it is true that the average RMSE is lower when <code class="docutils literal notranslate"><span class="pre">loss=&quot;squared_error&quot;</span></code>, whereas
the average MAPE is lower when <code class="docutils literal notranslate"><span class="pre">loss=&quot;absolute_error&quot;</span></code> as expected. That is
also the case for the Mean Pinball Loss with the quantiles 5 and 95. The score
corresponding to the 50 quantile loss is overlapping with the score obtained
by minimizing other loss functions, which is also the case for the MAE.</p>
</section>
<section id="a-qualitative-look-at-the-predictions">
<h2>A qualitative look at the predictions<a class="headerlink" href="#a-qualitative-look-at-the-predictions" title="Link to this heading">¶</a></h2>
<p>We can now visualize the performance of the model with regards
to the 5th percentile, median and the 95th percentile:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">all_splits</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ts_cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="n">all_splits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>

<span class="n">max_iter</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">gbrt_mean_poisson</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">HistGradientBoostingRegressor</span></a><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;poisson&quot;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">)</span>
<span class="n">gbrt_mean_poisson</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">mean_predictions</span> <span class="o">=</span> <span class="n">gbrt_mean_poisson</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">gbrt_median</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">HistGradientBoostingRegressor</span></a><span class="p">(</span>
    <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;quantile&quot;</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span>
<span class="p">)</span>
<span class="n">gbrt_median</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">median_predictions</span> <span class="o">=</span> <span class="n">gbrt_median</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">gbrt_percentile_5</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">HistGradientBoostingRegressor</span></a><span class="p">(</span>
    <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;quantile&quot;</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span>
<span class="p">)</span>
<span class="n">gbrt_percentile_5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">percentile_5_predictions</span> <span class="o">=</span> <span class="n">gbrt_percentile_5</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">gbrt_percentile_95</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">HistGradientBoostingRegressor</span></a><span class="p">(</span>
    <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;quantile&quot;</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span>
<span class="p">)</span>
<span class="n">gbrt_percentile_95</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">percentile_95_predictions</span> <span class="o">=</span> <span class="n">gbrt_percentile_95</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p>We can now take a look at the predictions made by the regression models:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">last_hours</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="mi">96</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title" title="matplotlib.pyplot.title" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">title</span></a><span class="p">(</span><span class="s2">&quot;Predictions by regression models&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">&quot;x-&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Actual demand&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">median_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">&quot;^-&quot;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;GBRT median&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">mean_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">&quot;x-&quot;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;GBRT mean (Poisson)&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mi">96</span><span class="p">),</span>
    <span class="n">percentile_5_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="n">percentile_95_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;GBRT 90</span><span class="si">% i</span><span class="s2">nterval&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_time_series_lagged_features_001.png" srcset="../../_images/sphx_glr_plot_time_series_lagged_features_001.png" alt="Predictions by regression models" class = "sphx-glr-single-img"/><p>Here it’s interesting to notice that the blue area between the 5% and 95%
percentile estimators has a width that varies with the time of the day:</p>
<ul class="simple">
<li><p>At night, the blue band is much narrower: the pair of models is quite
certain that there will be a small number of bike rentals. And furthermore
these seem correct in the sense that the actual demand stays in that blue
band.</p></li>
<li><p>During the day, the blue band is much wider: the uncertainty grows, probably
because of the variability of the weather that can have a very large impact,
especially on week-ends.</p></li>
<li><p>We can also see that during week-days, the commute pattern is still visible in
the 5% and 95% estimations.</p></li>
<li><p>Finally, it is expected that 10% of the time, the actual demand does not lie
between the 5% and 95% percentile estimates. On this test span, the actual
demand seems to be higher, especially during the rush hours. It might reveal that
our 95% percentile estimator underestimates the demand peaks. This could be be
quantitatively confirmed by computing empirical coverage numbers as done in
the <a class="reference internal" href="../ensemble/plot_gradient_boosting_quantile.html#calibration-section"><span class="std std-ref">calibration of confidence intervals</span></a>.</p></li>
</ul>
<p>Looking at the performance of non-linear regression models vs
the best models:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">PredictionErrorDisplay</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Non-linear regression models&quot;</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">median_predictions</span><span class="p">,</span>
    <span class="n">percentile_5_predictions</span><span class="p">,</span>
    <span class="n">percentile_95_predictions</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Median&quot;</span><span class="p">,</span>
    <span class="s2">&quot;5th percentile&quot;</span><span class="p">,</span>
    <span class="s2">&quot;95th percentile&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <a href="../../modules/generated/sklearn.metrics.PredictionErrorDisplay.html#sklearn.metrics.PredictionErrorDisplay.from_predictions" title="sklearn.metrics.PredictionErrorDisplay.from_predictions" class="sphx-glr-backref-module-sklearn-metrics-PredictionErrorDisplay sphx-glr-backref-type-py-method"><span class="n">PredictionErrorDisplay</span><span class="o">.</span><span class="n">from_predictions</span></a><span class="p">(</span>
        <span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span>
        <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;residual_vs_predicted&quot;</span><span class="p">,</span>
        <span class="n">scatter_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">},</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Predicted demand&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;True demand&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Best model&quot;</span><span class="p">,</span> <span class="n">label</span><span class="p">])</span>

<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="matplotlib.pyplot.show" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_time_series_lagged_features_002.png" srcset="../../_images/sphx_glr_plot_time_series_lagged_features_002.png" alt="Non-linear regression models" class = "sphx-glr-single-img"/></section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">¶</a></h2>
<p>Through this example we explored time series forecasting using lagged
features. We compared a naive regression (using the standardized
<a class="reference internal" href="../../modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code class="xref py py-class docutils literal notranslate"><span class="pre">train_test_split</span></code></a>) with a proper time
series evaluation strategy using
<a class="reference internal" href="../../modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeriesSplit</span></code></a>. We observed that the
model trained using <a class="reference internal" href="../../modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code class="xref py py-class docutils literal notranslate"><span class="pre">train_test_split</span></code></a>,
having a default value of <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> set to <code class="docutils literal notranslate"><span class="pre">True</span></code> produced an overly
optimistic Mean Average Percentage Error (MAPE). The results
produced from the time-based split better represent the performance
of our time-series regression model. We also analyzed the predictive uncertainty
of our model via Quantile Regression. Predictions based on the 5th and
95th percentile using <code class="docutils literal notranslate"><span class="pre">loss=&quot;quantile&quot;</span></code> provide us with a quantitative estimate
of the uncertainty of the forecasts made by our time series regression model.
Uncertainty estimation can also be performed
using <a class="reference external" href="https://mapie.readthedocs.io/en/latest/index.html">MAPIE</a>,
that provides an implementation based on recent work on conformal prediction
methods and estimates both aleatoric and epistemic uncertainty at the same time.
Furthermore, functionalities provided
by <a class="reference external" href="https://www.sktime.net/en/latest/users.html">sktime</a>
can be used to extend scikit-learn estimators by making use of recursive time
series forecasting, that enables dynamic predictions of future values.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 9.182 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-applications-plot-time-series-lagged-features-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/scikit-learn/scikit-learn/main?urlpath=lab/tree/notebooks/auto_examples/applications/plot_time_series_lagged_features.ipynb"><img alt="Launch binder" src="../../_images/binder_badge_logo.svg" width="150px" /></a>
</div>
<div class="lite-badge docutils container">
<a class="reference external image-reference" href="../../lite/lab/?path=auto_examples/applications/plot_time_series_lagged_features.ipynb"><img alt="Launch JupyterLite" src="../../_images/jupyterlite_badge_logo.svg" width="150px" /></a>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/6953689dfdc5dd401dda89604bbdaefb/plot_time_series_lagged_features.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_time_series_lagged_features.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/983937feb1a5f82dab78ed11a2af1217/plot_time_series_lagged_features.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_time_series_lagged_features.py</span></code></a></p>
</div>
</div>
<p class="rubric">Related examples</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This notebook introduces different strategies to leverage time-related features for a bike shar..."><img alt="" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_thumb.png" />
<p><a class="reference internal" href="plot_cyclical_feature_engineering.html#sphx-glr-auto-examples-applications-plot-cyclical-feature-engineering-py"><span class="std std-ref">Time-related feature engineering</span></a></p>
  <div class="sphx-glr-thumbnail-title">Time-related feature engineering</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="histogram_based_gradient_boosting (HGBT) models may be one of the most useful supervised learni..."><img alt="" src="../../_images/sphx_glr_plot_hgbt_regression_thumb.png" />
<p><a class="reference internal" href="../ensemble/plot_hgbt_regression.html#sphx-glr-auto-examples-ensemble-plot-hgbt-regression-py"><span class="std std-ref">Features in Histogram Gradient Boosting Trees</span></a></p>
  <div class="sphx-glr-thumbnail-title">Features in Histogram Gradient Boosting Trees</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how quantile regression can be used to create prediction intervals. See sphx..."><img alt="" src="../../_images/sphx_glr_plot_gradient_boosting_quantile_thumb.png" />
<p><a class="reference internal" href="../ensemble/plot_gradient_boosting_quantile.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py"><span class="std std-ref">Prediction Intervals for Gradient Boosting Regression</span></a></p>
  <div class="sphx-glr-thumbnail-title">Prediction Intervals for Gradient Boosting Regression</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how quantile regression can predict non-trivial conditional quantiles."><img alt="" src="../../_images/sphx_glr_plot_quantile_regression_thumb.png" />
<p><a class="reference internal" href="../linear_model/plot_quantile_regression.html#sphx-glr-auto-examples-linear-model-plot-quantile-regression-py"><span class="std std-ref">Quantile regression</span></a></p>
  <div class="sphx-glr-thumbnail-title">Quantile regression</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.1! Many bug fixes and improvements wer..."><img alt="" src="../../_images/sphx_glr_plot_release_highlights_1_1_0_thumb.png" />
<p><a class="reference internal" href="../release_highlights/plot_release_highlights_1_1_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-1-1-0-py"><span class="std std-ref">Release Highlights for scikit-learn 1.1</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.1</div>
</div></div><p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2024, scikit-learn developers (BSD License).
          <a href="../../_sources/auto_examples/applications/plot_time_series_lagged_features.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script defer data-domain="scikit-learn.org" src="https://views.scientific-python.org/js/script.js">
</script>


<script src="../../_static/clipboard.min.js"></script>
<script src="../../_static/copybutton.js"></script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
    <script src="https://scikit-learn.org/versionwarning.js"></script>
</body>
</html>